{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 -- Import Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dustin/anaconda3/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/dustin/anaconda3/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D,MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pickle_path = 'Pickled/Small_Train/'\n",
    "\n",
    "pickle_path = 'Pickled/Train_Data/'\n",
    "\n",
    "#pickle_path = 'Pickled/Test_Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 -- Define Data Generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The amplitude of each training example varies over many orders of magnitude. Due to this, the function that will perform the act of getting 'chunks' from storage into memory (Data_Gen) will also perform for the log-normalization of the data. The bit of code immediately below this text is responsible for obtaining the log-mean of ALL the chunks of training data. This value will then be fed into Data_Gen for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% Complete\r"
     ]
    }
   ],
   "source": [
    "X_files = sorted(os.listdir(pickle_path + \"Spectra\"))\n",
    "num_files = len(X_files)\n",
    "count=0\n",
    "\n",
    "mean_list=[]\n",
    "\n",
    "for X_file in X_files:\n",
    "    \n",
    "    file = open(pickle_path + \"Spectra/\" + X_file, \"rb\")\n",
    "    X=pickle.load(file)\n",
    "    file.close()\n",
    "    \n",
    "    mean_list.append(np.mean(np.log(X)))\n",
    "    \n",
    "    count+=1\n",
    "    percent_complete = round(count/num_files*100,1)\n",
    "    print(str(percent_complete) + '% Complete', end='\\r', flush=True)\n",
    "    \n",
    "mean_log_amplitude = np.mean(mean_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the output..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -10.189\n",
      "2 Sigma: 0.062\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean: \" + str(round(mean_log_amplitude,3)))\n",
    "print(\"2 Sigma: \" + str(round(2*np.std(mean_list),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Its nice to see that about 95% of the training data log-means fall within a 0.6% deviation of the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is the function that generates the training data from storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns i-th chunk of X,y data at path.\n",
    "def Data_Gen(X_path, y_path, mean_log_amplitude):\n",
    "        \n",
    "    # X data\n",
    "    file = open(pickle_path + \"Spectra/\" + X_path, \"rb\")\n",
    "    X=pickle.load(file)\n",
    "    file.close()\n",
    "    \n",
    "    X = np.stack((X,), -1)    \n",
    "    X = np.log(X) - mean_log_amplitude # log + normalization\n",
    "    \n",
    "    # y data\n",
    "    file = open(pickle_path + \"Targets/\" + y_path, \"rb\")\n",
    "    y=pickle.load(file)\n",
    "    file.close()\n",
    "    \n",
    "    y = keras.utils.np_utils.to_categorical(y)        \n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 -- Define CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model architechture below was defined mostly through a trial and error approach. Some research was conducted in determining a simple general CNN architecture. It was found that the below model works well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(4, 4), strides=(1, 1), activation='relu', input_shape=(129,129,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (4, 4), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (4, 4), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 126, 126, 16)      272       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 63, 63, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 60, 60, 32)        8224      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 27, 27, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 10816)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              11076608  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 11,124,086\n",
      "Trainable params: 11,124,086\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CNN. For now use a validation split of 12.5% to track model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 1 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.5310 - acc: 0.1808 - val_loss: 1.7636 - val_acc: 0.2578\n",
      "chunk number: 2 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.7583 - acc: 0.2254 - val_loss: 1.6909 - val_acc: 0.2578\n",
      "chunk number: 3 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.5665 - acc: 0.3739 - val_loss: 1.4153 - val_acc: 0.4375\n",
      "chunk number: 4 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.2766 - acc: 0.5045 - val_loss: 1.1031 - val_acc: 0.5625\n",
      "chunk number: 5 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.2507 - acc: 0.5167 - val_loss: 1.2319 - val_acc: 0.5547\n",
      "chunk number: 6 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1029 - acc: 0.5703 - val_loss: 1.0192 - val_acc: 0.6016\n",
      "chunk number: 7 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1246 - acc: 0.5346 - val_loss: 1.1760 - val_acc: 0.5156\n",
      "chunk number: 8 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0791 - acc: 0.6049 - val_loss: 1.1927 - val_acc: 0.5234\n",
      "chunk number: 9 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0527 - acc: 0.6004 - val_loss: 0.9877 - val_acc: 0.6094\n",
      "chunk number: 10 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0337 - acc: 0.6004 - val_loss: 0.9018 - val_acc: 0.6484\n",
      "chunk number: 11 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0230 - acc: 0.5837 - val_loss: 0.9281 - val_acc: 0.6719\n",
      "chunk number: 12 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9822 - acc: 0.6217 - val_loss: 0.8739 - val_acc: 0.6016\n",
      "chunk number: 13 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9544 - acc: 0.6183 - val_loss: 0.8789 - val_acc: 0.6406\n",
      "chunk number: 14 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0094 - acc: 0.6016 - val_loss: 0.9316 - val_acc: 0.6719\n",
      "chunk number: 15 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9382 - acc: 0.6350 - val_loss: 0.8291 - val_acc: 0.7109\n",
      "chunk number: 16 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9205 - acc: 0.6362 - val_loss: 1.0803 - val_acc: 0.5859\n",
      "chunk number: 17 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9508 - acc: 0.6317 - val_loss: 0.9010 - val_acc: 0.6484\n",
      "chunk number: 18 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9495 - acc: 0.6272 - val_loss: 0.8692 - val_acc: 0.7031\n",
      "chunk number: 19 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9480 - acc: 0.6328 - val_loss: 1.0027 - val_acc: 0.6094\n",
      "chunk number: 20 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9410 - acc: 0.6551 - val_loss: 0.9165 - val_acc: 0.6562\n",
      "chunk number: 21 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8755 - acc: 0.6440 - val_loss: 0.8304 - val_acc: 0.7109\n",
      "chunk number: 22 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9115 - acc: 0.6362 - val_loss: 0.9101 - val_acc: 0.6172\n",
      "chunk number: 23 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9083 - acc: 0.6618 - val_loss: 0.8322 - val_acc: 0.6562\n",
      "chunk number: 24 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9365 - acc: 0.6217 - val_loss: 0.8463 - val_acc: 0.6875\n",
      "chunk number: 25 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8617 - acc: 0.6786 - val_loss: 0.9710 - val_acc: 0.6562\n",
      "chunk number: 26 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8796 - acc: 0.6663 - val_loss: 0.9272 - val_acc: 0.6719\n",
      "chunk number: 27 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8665 - acc: 0.6641 - val_loss: 0.7208 - val_acc: 0.7344\n",
      "chunk number: 28 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9190 - acc: 0.6484 - val_loss: 0.8917 - val_acc: 0.6172\n",
      "chunk number: 29 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8771 - acc: 0.6574 - val_loss: 0.8004 - val_acc: 0.7031\n",
      "chunk number: 30 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8724 - acc: 0.6641 - val_loss: 0.9506 - val_acc: 0.6172\n",
      "chunk number: 31 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8672 - acc: 0.6529 - val_loss: 0.8193 - val_acc: 0.7109\n",
      "chunk number: 32 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8565 - acc: 0.6607 - val_loss: 0.9591 - val_acc: 0.6016\n",
      "chunk number: 33 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9111 - acc: 0.6451 - val_loss: 0.7994 - val_acc: 0.6484\n",
      "chunk number: 34 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8903 - acc: 0.6417 - val_loss: 0.8506 - val_acc: 0.7344\n",
      "chunk number: 35 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8433 - acc: 0.6775 - val_loss: 0.9077 - val_acc: 0.6484\n",
      "chunk number: 36 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8558 - acc: 0.6652 - val_loss: 0.7583 - val_acc: 0.7031\n",
      "chunk number: 37 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8294 - acc: 0.6842 - val_loss: 0.6967 - val_acc: 0.7422\n",
      "chunk number: 38 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8668 - acc: 0.6618 - val_loss: 0.7668 - val_acc: 0.7500\n",
      "chunk number: 39 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8060 - acc: 0.6842 - val_loss: 0.7386 - val_acc: 0.7188\n",
      "chunk number: 40 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8940 - acc: 0.6551 - val_loss: 0.8510 - val_acc: 0.7109\n",
      "chunk number: 41 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7885 - acc: 0.6987 - val_loss: 0.8592 - val_acc: 0.6641\n",
      "chunk number: 42 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8306 - acc: 0.7009 - val_loss: 0.8021 - val_acc: 0.6719\n",
      "chunk number: 43 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8087 - acc: 0.6931 - val_loss: 0.7865 - val_acc: 0.6875\n",
      "chunk number: 44 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8040 - acc: 0.7076 - val_loss: 0.7673 - val_acc: 0.7188\n",
      "chunk number: 45 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8768 - acc: 0.6685 - val_loss: 0.6662 - val_acc: 0.6953\n",
      "chunk number: 46 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7986 - acc: 0.6998 - val_loss: 0.9127 - val_acc: 0.6562\n",
      "chunk number: 47 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8226 - acc: 0.6931 - val_loss: 0.8439 - val_acc: 0.6562\n",
      "chunk number: 48 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8543 - acc: 0.6808 - val_loss: 0.8173 - val_acc: 0.6875\n",
      "chunk number: 49 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7186 - acc: 0.7132 - val_loss: 0.8236 - val_acc: 0.6797\n",
      "chunk number: 50 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8535 - acc: 0.6763 - val_loss: 0.9105 - val_acc: 0.6641\n",
      "chunk number: 51 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8161 - acc: 0.6897 - val_loss: 0.8531 - val_acc: 0.6797\n",
      "chunk number: 52 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7971 - acc: 0.7020 - val_loss: 0.7554 - val_acc: 0.7188\n",
      "chunk number: 53 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8273 - acc: 0.6685 - val_loss: 0.7649 - val_acc: 0.7188\n",
      "chunk number: 54 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8257 - acc: 0.6730 - val_loss: 0.6903 - val_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 55 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8097 - acc: 0.6886 - val_loss: 0.7432 - val_acc: 0.7188\n",
      "chunk number: 56 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8284 - acc: 0.6741 - val_loss: 0.7375 - val_acc: 0.7031\n",
      "chunk number: 57 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7949 - acc: 0.7009 - val_loss: 0.7241 - val_acc: 0.7109\n",
      "chunk number: 58 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8123 - acc: 0.6920 - val_loss: 0.7573 - val_acc: 0.7500\n",
      "chunk number: 59 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7770 - acc: 0.7098 - val_loss: 0.7324 - val_acc: 0.7266\n",
      "chunk number: 60 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8909 - acc: 0.6797 - val_loss: 0.7880 - val_acc: 0.6797\n",
      "chunk number: 61 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8123 - acc: 0.6998 - val_loss: 0.7243 - val_acc: 0.7500\n",
      "chunk number: 62 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7929 - acc: 0.7109 - val_loss: 0.6524 - val_acc: 0.7656\n",
      "chunk number: 63 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8132 - acc: 0.6964 - val_loss: 0.8461 - val_acc: 0.6797\n",
      "chunk number: 64 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7206 - acc: 0.7400 - val_loss: 0.8482 - val_acc: 0.6328\n",
      "chunk number: 65 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8311 - acc: 0.6830 - val_loss: 0.6854 - val_acc: 0.7031\n",
      "chunk number: 66 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7952 - acc: 0.6752 - val_loss: 0.8408 - val_acc: 0.6562\n",
      "chunk number: 67 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7644 - acc: 0.7176 - val_loss: 0.7690 - val_acc: 0.6641\n",
      "chunk number: 68 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8153 - acc: 0.6808 - val_loss: 0.9006 - val_acc: 0.6719\n",
      "chunk number: 69 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8288 - acc: 0.6830 - val_loss: 0.7559 - val_acc: 0.6562\n",
      "chunk number: 70 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8182 - acc: 0.7020 - val_loss: 0.8643 - val_acc: 0.7031\n",
      "chunk number: 71 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7820 - acc: 0.6964 - val_loss: 0.8968 - val_acc: 0.6484\n",
      "chunk number: 72 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7966 - acc: 0.6819 - val_loss: 0.7664 - val_acc: 0.7109\n",
      "chunk number: 73 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7082 - acc: 0.7266 - val_loss: 0.8158 - val_acc: 0.6875\n",
      "chunk number: 74 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7305 - acc: 0.7087 - val_loss: 0.9097 - val_acc: 0.6484\n",
      "chunk number: 75 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7287 - acc: 0.7277 - val_loss: 0.6825 - val_acc: 0.7500\n",
      "chunk number: 76 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7116 - acc: 0.7288 - val_loss: 0.7079 - val_acc: 0.7188\n",
      "chunk number: 77 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7797 - acc: 0.7065 - val_loss: 0.6233 - val_acc: 0.7656\n",
      "chunk number: 78 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7364 - acc: 0.7132 - val_loss: 1.0502 - val_acc: 0.6016\n",
      "chunk number: 79 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7375 - acc: 0.7243 - val_loss: 0.6446 - val_acc: 0.7578\n",
      "chunk number: 80 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7351 - acc: 0.7299 - val_loss: 0.8018 - val_acc: 0.7109\n",
      "chunk number: 81 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7180 - acc: 0.7243 - val_loss: 0.6348 - val_acc: 0.7188\n",
      "chunk number: 82 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7341 - acc: 0.7221 - val_loss: 0.6622 - val_acc: 0.7422\n",
      "chunk number: 83 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8068 - acc: 0.6987 - val_loss: 0.7998 - val_acc: 0.6719\n",
      "chunk number: 84 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7105 - acc: 0.7266 - val_loss: 0.7121 - val_acc: 0.7266\n",
      "chunk number: 85 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7492 - acc: 0.7455 - val_loss: 0.6471 - val_acc: 0.7266\n",
      "chunk number: 86 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7762 - acc: 0.7054 - val_loss: 0.6493 - val_acc: 0.7656\n",
      "chunk number: 87 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7721 - acc: 0.7143 - val_loss: 0.7982 - val_acc: 0.7344\n",
      "chunk number: 88 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7986 - acc: 0.7031 - val_loss: 0.6129 - val_acc: 0.7656\n",
      "chunk number: 89 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7355 - acc: 0.7143 - val_loss: 0.6988 - val_acc: 0.7656\n",
      "chunk number: 90 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7612 - acc: 0.7288 - val_loss: 0.6518 - val_acc: 0.7656\n",
      "chunk number: 91 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7337 - acc: 0.7254 - val_loss: 0.7939 - val_acc: 0.6875\n",
      "chunk number: 92 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7148 - acc: 0.7199 - val_loss: 0.6668 - val_acc: 0.7188\n",
      "chunk number: 93 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7063 - acc: 0.7299 - val_loss: 0.7618 - val_acc: 0.7031\n",
      "chunk number: 94 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7176 - acc: 0.7199 - val_loss: 0.7138 - val_acc: 0.7188\n",
      "chunk number: 95 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6902 - acc: 0.7344 - val_loss: 0.6565 - val_acc: 0.7500\n",
      "chunk number: 96 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6954 - acc: 0.7310 - val_loss: 0.6473 - val_acc: 0.7734\n",
      "chunk number: 97 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7193 - acc: 0.7109 - val_loss: 0.6898 - val_acc: 0.7422\n",
      "chunk number: 98 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7309 - acc: 0.7176 - val_loss: 0.8062 - val_acc: 0.7344\n",
      "chunk number: 99 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6873 - acc: 0.7411 - val_loss: 0.6378 - val_acc: 0.7578\n",
      "chunk number: 100 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7789 - acc: 0.6763 - val_loss: 0.7320 - val_acc: 0.6797\n",
      "chunk number: 101 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6981 - acc: 0.7366 - val_loss: 0.6859 - val_acc: 0.7266\n",
      "chunk number: 102 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7943 - acc: 0.7020 - val_loss: 0.7540 - val_acc: 0.6875\n",
      "chunk number: 103 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7160 - acc: 0.7154 - val_loss: 0.6601 - val_acc: 0.7578\n",
      "chunk number: 104 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6965 - acc: 0.7344 - val_loss: 0.6905 - val_acc: 0.7266\n",
      "chunk number: 105 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7367 - acc: 0.7121 - val_loss: 0.7508 - val_acc: 0.7344\n",
      "chunk number: 106 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6878 - acc: 0.7344 - val_loss: 0.7257 - val_acc: 0.7266\n",
      "chunk number: 107 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6912 - acc: 0.7444 - val_loss: 0.7242 - val_acc: 0.7500\n",
      "chunk number: 108 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7152 - acc: 0.7232 - val_loss: 0.7149 - val_acc: 0.7031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 109 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6883 - acc: 0.7489 - val_loss: 0.6427 - val_acc: 0.7656\n",
      "chunk number: 110 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6930 - acc: 0.7500 - val_loss: 0.6757 - val_acc: 0.7422\n",
      "chunk number: 111 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7049 - acc: 0.7132 - val_loss: 0.7039 - val_acc: 0.7422\n",
      "chunk number: 112 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7280 - acc: 0.7232 - val_loss: 0.6051 - val_acc: 0.7812\n",
      "chunk number: 113 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7116 - acc: 0.7254 - val_loss: 0.6547 - val_acc: 0.7578\n",
      "chunk number: 114 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7934 - acc: 0.7009 - val_loss: 0.7300 - val_acc: 0.7188\n",
      "chunk number: 115 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7208 - acc: 0.7254 - val_loss: 0.7075 - val_acc: 0.7578\n",
      "chunk number: 116 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6826 - acc: 0.7277 - val_loss: 0.9076 - val_acc: 0.6641\n",
      "chunk number: 117 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7274 - acc: 0.7266 - val_loss: 0.6539 - val_acc: 0.7500\n",
      "chunk number: 118 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6905 - acc: 0.7310 - val_loss: 0.6718 - val_acc: 0.7500\n",
      "chunk number: 119 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7008 - acc: 0.7333 - val_loss: 0.7995 - val_acc: 0.6875\n",
      "chunk number: 120 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7450 - acc: 0.7176 - val_loss: 0.7096 - val_acc: 0.6953\n",
      "chunk number: 121 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6524 - acc: 0.7500 - val_loss: 0.6033 - val_acc: 0.7578\n",
      "chunk number: 122 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7180 - acc: 0.7054 - val_loss: 0.6763 - val_acc: 0.7266\n",
      "chunk number: 123 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6786 - acc: 0.7444 - val_loss: 0.5935 - val_acc: 0.7734\n",
      "chunk number: 124 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7009 - acc: 0.7098 - val_loss: 0.6547 - val_acc: 0.7500\n",
      "chunk number: 125 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6558 - acc: 0.7400 - val_loss: 0.7071 - val_acc: 0.7656\n",
      "chunk number: 126 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7047 - acc: 0.7310 - val_loss: 0.7410 - val_acc: 0.7344\n",
      "chunk number: 127 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6961 - acc: 0.7165 - val_loss: 0.5569 - val_acc: 0.8125\n",
      "chunk number: 128 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6974 - acc: 0.7478 - val_loss: 0.7527 - val_acc: 0.7109\n",
      "chunk number: 129 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7239 - acc: 0.7199 - val_loss: 0.6964 - val_acc: 0.7578\n",
      "chunk number: 130 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7162 - acc: 0.7310 - val_loss: 0.8280 - val_acc: 0.6797\n",
      "chunk number: 131 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7073 - acc: 0.7355 - val_loss: 0.6651 - val_acc: 0.7812\n",
      "chunk number: 132 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6789 - acc: 0.7388 - val_loss: 0.8358 - val_acc: 0.6641\n",
      "chunk number: 133 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7537 - acc: 0.7098 - val_loss: 0.6743 - val_acc: 0.7500\n",
      "chunk number: 134 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7166 - acc: 0.7143 - val_loss: 0.7625 - val_acc: 0.7578\n",
      "chunk number: 135 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7046 - acc: 0.7400 - val_loss: 0.7986 - val_acc: 0.7109\n",
      "chunk number: 136 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7163 - acc: 0.7355 - val_loss: 0.6215 - val_acc: 0.7344\n",
      "chunk number: 137 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6911 - acc: 0.7243 - val_loss: 0.5021 - val_acc: 0.8047\n",
      "chunk number: 138 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7011 - acc: 0.7500 - val_loss: 0.6571 - val_acc: 0.7734\n",
      "chunk number: 139 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6776 - acc: 0.7400 - val_loss: 0.7197 - val_acc: 0.7109\n",
      "chunk number: 140 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7267 - acc: 0.7199 - val_loss: 0.5917 - val_acc: 0.8047\n",
      "chunk number: 141 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6435 - acc: 0.7623 - val_loss: 0.6216 - val_acc: 0.7500\n",
      "chunk number: 142 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7015 - acc: 0.7489 - val_loss: 0.7165 - val_acc: 0.6875\n",
      "chunk number: 143 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6743 - acc: 0.7522 - val_loss: 0.7371 - val_acc: 0.7031\n",
      "chunk number: 144 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6941 - acc: 0.7489 - val_loss: 0.6398 - val_acc: 0.7578\n",
      "chunk number: 145 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7420 - acc: 0.7098 - val_loss: 0.5675 - val_acc: 0.7734\n",
      "chunk number: 146 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6831 - acc: 0.7489 - val_loss: 0.6919 - val_acc: 0.7266\n",
      "chunk number: 147 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6528 - acc: 0.7634 - val_loss: 0.7799 - val_acc: 0.7422\n",
      "chunk number: 148 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7555 - acc: 0.7165 - val_loss: 0.8239 - val_acc: 0.6719\n",
      "chunk number: 149 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6161 - acc: 0.7645 - val_loss: 0.7554 - val_acc: 0.7344\n",
      "chunk number: 150 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7173 - acc: 0.7154 - val_loss: 0.7475 - val_acc: 0.7344\n",
      "chunk number: 151 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6637 - acc: 0.7444 - val_loss: 0.7639 - val_acc: 0.7422\n",
      "chunk number: 152 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6777 - acc: 0.7467 - val_loss: 0.5846 - val_acc: 0.7969\n",
      "chunk number: 153 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7029 - acc: 0.7199 - val_loss: 0.7177 - val_acc: 0.7578\n",
      "chunk number: 154 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7129 - acc: 0.7310 - val_loss: 0.5665 - val_acc: 0.8047\n",
      "chunk number: 155 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6789 - acc: 0.7388 - val_loss: 0.6564 - val_acc: 0.7422\n",
      "chunk number: 156 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7186 - acc: 0.7310 - val_loss: 0.6440 - val_acc: 0.7422\n",
      "chunk number: 157 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7017 - acc: 0.7455 - val_loss: 0.6088 - val_acc: 0.7422\n",
      "chunk number: 158 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6639 - acc: 0.7467 - val_loss: 0.6675 - val_acc: 0.7500\n",
      "chunk number: 159 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6662 - acc: 0.7489 - val_loss: 0.7059 - val_acc: 0.7734\n",
      "chunk number: 160 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7625 - acc: 0.7098 - val_loss: 0.6217 - val_acc: 0.7500\n",
      "chunk number: 161 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7257 - acc: 0.7310 - val_loss: 0.6277 - val_acc: 0.7578\n",
      "chunk number: 162 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6846 - acc: 0.7489 - val_loss: 0.5576 - val_acc: 0.7891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 163 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6978 - acc: 0.7333 - val_loss: 0.8793 - val_acc: 0.6484\n",
      "chunk number: 164 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6205 - acc: 0.7667 - val_loss: 0.7339 - val_acc: 0.7344\n",
      "chunk number: 165 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7281 - acc: 0.7210 - val_loss: 0.6267 - val_acc: 0.7500\n",
      "chunk number: 166 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6949 - acc: 0.7411 - val_loss: 0.7350 - val_acc: 0.7188\n",
      "chunk number: 167 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6626 - acc: 0.7478 - val_loss: 0.6144 - val_acc: 0.7188\n",
      "chunk number: 168 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7060 - acc: 0.7165 - val_loss: 0.8382 - val_acc: 0.7188\n",
      "chunk number: 169 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7101 - acc: 0.7199 - val_loss: 0.6702 - val_acc: 0.7578\n",
      "chunk number: 170 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7052 - acc: 0.7355 - val_loss: 0.8201 - val_acc: 0.6953\n",
      "chunk number: 171 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6349 - acc: 0.7444 - val_loss: 0.6706 - val_acc: 0.7109\n",
      "chunk number: 172 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6851 - acc: 0.7455 - val_loss: 0.6611 - val_acc: 0.7812\n",
      "chunk number: 173 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6172 - acc: 0.7578 - val_loss: 0.6800 - val_acc: 0.7578\n",
      "chunk number: 174 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6141 - acc: 0.7667 - val_loss: 0.7864 - val_acc: 0.6719\n",
      "chunk number: 175 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6665 - acc: 0.7478 - val_loss: 0.5831 - val_acc: 0.7500\n",
      "chunk number: 176 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6292 - acc: 0.7545 - val_loss: 0.6295 - val_acc: 0.7422\n",
      "chunk number: 177 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6662 - acc: 0.7489 - val_loss: 0.5445 - val_acc: 0.8125\n",
      "chunk number: 178 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6387 - acc: 0.7500 - val_loss: 0.9199 - val_acc: 0.6172\n",
      "chunk number: 179 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6502 - acc: 0.7522 - val_loss: 0.5980 - val_acc: 0.7578\n",
      "chunk number: 180 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6536 - acc: 0.7623 - val_loss: 0.6692 - val_acc: 0.7969\n",
      "chunk number: 181 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6409 - acc: 0.7634 - val_loss: 0.5970 - val_acc: 0.7500\n",
      "chunk number: 182 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6433 - acc: 0.7634 - val_loss: 0.6092 - val_acc: 0.7500\n",
      "chunk number: 183 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6862 - acc: 0.7411 - val_loss: 0.7213 - val_acc: 0.6875\n",
      "chunk number: 184 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6085 - acc: 0.7589 - val_loss: 0.6099 - val_acc: 0.7656\n",
      "chunk number: 185 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6217 - acc: 0.7734 - val_loss: 0.5569 - val_acc: 0.7812\n",
      "chunk number: 186 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6300 - acc: 0.7690 - val_loss: 0.5894 - val_acc: 0.7734\n",
      "chunk number: 187 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6718 - acc: 0.7433 - val_loss: 0.6738 - val_acc: 0.7500\n",
      "chunk number: 188 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6946 - acc: 0.7500 - val_loss: 0.5213 - val_acc: 0.8516\n",
      "chunk number: 189 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6356 - acc: 0.7511 - val_loss: 0.6034 - val_acc: 0.7891\n",
      "chunk number: 190 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6565 - acc: 0.7634 - val_loss: 0.5872 - val_acc: 0.7812\n",
      "chunk number: 191 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6202 - acc: 0.7489 - val_loss: 0.6675 - val_acc: 0.7422\n",
      "chunk number: 192 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6260 - acc: 0.7533 - val_loss: 0.6534 - val_acc: 0.7500\n",
      "chunk number: 193 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6323 - acc: 0.7545 - val_loss: 0.6742 - val_acc: 0.7031\n",
      "chunk number: 194 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6597 - acc: 0.7567 - val_loss: 0.6439 - val_acc: 0.7344\n",
      "chunk number: 195 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5794 - acc: 0.7824 - val_loss: 0.5710 - val_acc: 0.7812\n",
      "chunk number: 196 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6637 - acc: 0.7489 - val_loss: 0.6101 - val_acc: 0.7656\n",
      "chunk number: 197 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6555 - acc: 0.7589 - val_loss: 0.6164 - val_acc: 0.8125\n",
      "chunk number: 198 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6485 - acc: 0.7455 - val_loss: 0.6475 - val_acc: 0.7500\n",
      "chunk number: 199 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6198 - acc: 0.7723 - val_loss: 0.6018 - val_acc: 0.7812\n",
      "chunk number: 200 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6653 - acc: 0.7433 - val_loss: 0.5802 - val_acc: 0.7656\n",
      "chunk number: 201 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6281 - acc: 0.7712 - val_loss: 0.5948 - val_acc: 0.7500\n",
      "chunk number: 202 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6684 - acc: 0.7612 - val_loss: 0.6408 - val_acc: 0.7812\n",
      "chunk number: 203 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6304 - acc: 0.7679 - val_loss: 0.5710 - val_acc: 0.7891\n",
      "chunk number: 204 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6194 - acc: 0.7712 - val_loss: 0.6166 - val_acc: 0.7500\n",
      "chunk number: 205 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6666 - acc: 0.7533 - val_loss: 0.7059 - val_acc: 0.7422\n",
      "chunk number: 206 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6303 - acc: 0.7690 - val_loss: 0.6543 - val_acc: 0.7422\n",
      "chunk number: 207 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6725 - acc: 0.7388 - val_loss: 0.6553 - val_acc: 0.7656\n",
      "chunk number: 208 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6462 - acc: 0.7478 - val_loss: 0.6085 - val_acc: 0.7812\n",
      "chunk number: 209 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6353 - acc: 0.7545 - val_loss: 0.6300 - val_acc: 0.7500\n",
      "chunk number: 210 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6466 - acc: 0.7478 - val_loss: 0.6649 - val_acc: 0.7578\n",
      "chunk number: 211 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6672 - acc: 0.7422 - val_loss: 0.6096 - val_acc: 0.7812\n",
      "chunk number: 212 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6898 - acc: 0.7589 - val_loss: 0.5807 - val_acc: 0.7578\n",
      "chunk number: 213 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6240 - acc: 0.7734 - val_loss: 0.6247 - val_acc: 0.7500\n",
      "chunk number: 214 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7405 - acc: 0.7121 - val_loss: 0.6419 - val_acc: 0.7891\n",
      "chunk number: 215 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6367 - acc: 0.7690 - val_loss: 0.5704 - val_acc: 0.7812\n",
      "chunk number: 216 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5842 - acc: 0.7768 - val_loss: 0.7986 - val_acc: 0.6797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 217 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6582 - acc: 0.7556 - val_loss: 0.6205 - val_acc: 0.7656\n",
      "chunk number: 218 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5847 - acc: 0.7757 - val_loss: 0.6049 - val_acc: 0.7734\n",
      "chunk number: 219 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6338 - acc: 0.7522 - val_loss: 0.7142 - val_acc: 0.7188\n",
      "chunk number: 220 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6636 - acc: 0.7467 - val_loss: 0.5974 - val_acc: 0.7734\n",
      "chunk number: 221 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5745 - acc: 0.7634 - val_loss: 0.5199 - val_acc: 0.8125\n",
      "chunk number: 222 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6225 - acc: 0.7455 - val_loss: 0.6400 - val_acc: 0.7656\n",
      "chunk number: 223 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6085 - acc: 0.7835 - val_loss: 0.5694 - val_acc: 0.8047\n",
      "chunk number: 224 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6318 - acc: 0.7567 - val_loss: 0.6195 - val_acc: 0.7734\n",
      "chunk number: 225 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5896 - acc: 0.7567 - val_loss: 0.6146 - val_acc: 0.8047\n",
      "chunk number: 226 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6232 - acc: 0.7444 - val_loss: 0.7755 - val_acc: 0.6953\n",
      "chunk number: 227 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6337 - acc: 0.7556 - val_loss: 0.5215 - val_acc: 0.8047\n",
      "chunk number: 228 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6396 - acc: 0.7478 - val_loss: 0.6995 - val_acc: 0.7266\n",
      "chunk number: 229 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6657 - acc: 0.7723 - val_loss: 0.6452 - val_acc: 0.7891\n",
      "chunk number: 230 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6427 - acc: 0.7522 - val_loss: 0.7138 - val_acc: 0.7266\n",
      "chunk number: 231 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6421 - acc: 0.7511 - val_loss: 0.6526 - val_acc: 0.7344\n",
      "chunk number: 232 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5991 - acc: 0.7757 - val_loss: 0.7687 - val_acc: 0.7422\n",
      "chunk number: 233 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6540 - acc: 0.7545 - val_loss: 0.6151 - val_acc: 0.7656\n",
      "chunk number: 234 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6446 - acc: 0.7388 - val_loss: 0.6572 - val_acc: 0.7656\n",
      "chunk number: 235 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6327 - acc: 0.7757 - val_loss: 0.8458 - val_acc: 0.7031\n",
      "chunk number: 236 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6578 - acc: 0.7533 - val_loss: 0.5817 - val_acc: 0.7891\n",
      "chunk number: 237 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6238 - acc: 0.7589 - val_loss: 0.4871 - val_acc: 0.8125\n",
      "chunk number: 238 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6162 - acc: 0.7679 - val_loss: 0.6232 - val_acc: 0.7812\n",
      "chunk number: 239 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6216 - acc: 0.7712 - val_loss: 0.5672 - val_acc: 0.7812\n",
      "chunk number: 240 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6797 - acc: 0.7533 - val_loss: 0.5535 - val_acc: 0.7891\n",
      "chunk number: 241 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5867 - acc: 0.7734 - val_loss: 0.5850 - val_acc: 0.7500\n",
      "chunk number: 242 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5838 - acc: 0.7924 - val_loss: 0.6227 - val_acc: 0.7578\n",
      "chunk number: 243 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5643 - acc: 0.7824 - val_loss: 0.6735 - val_acc: 0.7344\n",
      "chunk number: 244 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6032 - acc: 0.7746 - val_loss: 0.5847 - val_acc: 0.7500\n",
      "chunk number: 245 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5963 - acc: 0.7567 - val_loss: 0.5223 - val_acc: 0.7656\n",
      "chunk number: 246 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6102 - acc: 0.7645 - val_loss: 0.6481 - val_acc: 0.7266\n",
      "chunk number: 247 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5917 - acc: 0.7701 - val_loss: 0.6633 - val_acc: 0.7500\n",
      "chunk number: 248 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6429 - acc: 0.7656 - val_loss: 0.6567 - val_acc: 0.7500\n",
      "chunk number: 249 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5396 - acc: 0.7868 - val_loss: 0.6582 - val_acc: 0.7734\n",
      "chunk number: 250 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6458 - acc: 0.7388 - val_loss: 0.6631 - val_acc: 0.7500\n",
      "chunk number: 251 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6089 - acc: 0.7723 - val_loss: 0.6735 - val_acc: 0.7344\n",
      "chunk number: 252 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6149 - acc: 0.7656 - val_loss: 0.5160 - val_acc: 0.7969\n",
      "chunk number: 253 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6539 - acc: 0.7589 - val_loss: 0.6686 - val_acc: 0.7500\n",
      "chunk number: 254 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6172 - acc: 0.7634 - val_loss: 0.5145 - val_acc: 0.8281\n",
      "chunk number: 255 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6069 - acc: 0.7734 - val_loss: 0.6164 - val_acc: 0.7812\n",
      "chunk number: 256 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6645 - acc: 0.7411 - val_loss: 0.6383 - val_acc: 0.7188\n",
      "chunk number: 257 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6465 - acc: 0.7567 - val_loss: 0.5498 - val_acc: 0.8125\n",
      "chunk number: 258 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5780 - acc: 0.7790 - val_loss: 0.5485 - val_acc: 0.8047\n",
      "chunk number: 259 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5669 - acc: 0.7902 - val_loss: 0.5881 - val_acc: 0.8047\n",
      "chunk number: 260 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6896 - acc: 0.7366 - val_loss: 0.5477 - val_acc: 0.7891\n",
      "chunk number: 261 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6185 - acc: 0.7667 - val_loss: 0.5931 - val_acc: 0.7812\n",
      "chunk number: 262 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5975 - acc: 0.7757 - val_loss: 0.4815 - val_acc: 0.8203\n",
      "chunk number: 263 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6084 - acc: 0.7679 - val_loss: 0.7400 - val_acc: 0.7031\n",
      "chunk number: 264 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5463 - acc: 0.7980 - val_loss: 0.5878 - val_acc: 0.7812\n",
      "chunk number: 265 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6360 - acc: 0.7679 - val_loss: 0.5859 - val_acc: 0.7422\n",
      "chunk number: 266 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6164 - acc: 0.7533 - val_loss: 0.7050 - val_acc: 0.6953\n",
      "chunk number: 267 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5965 - acc: 0.7734 - val_loss: 0.5427 - val_acc: 0.7656\n",
      "chunk number: 268 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6091 - acc: 0.7578 - val_loss: 0.7262 - val_acc: 0.7500\n",
      "chunk number: 269 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6106 - acc: 0.7667 - val_loss: 0.5360 - val_acc: 0.7891\n",
      "chunk number: 270 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5883 - acc: 0.7690 - val_loss: 0.6923 - val_acc: 0.7266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 271 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5620 - acc: 0.7734 - val_loss: 0.6273 - val_acc: 0.7500\n",
      "chunk number: 272 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5967 - acc: 0.7779 - val_loss: 0.5837 - val_acc: 0.8047\n",
      "chunk number: 273 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5318 - acc: 0.8036 - val_loss: 0.5935 - val_acc: 0.7656\n",
      "chunk number: 274 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5547 - acc: 0.7935 - val_loss: 0.7029 - val_acc: 0.7422\n",
      "chunk number: 275 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5788 - acc: 0.7935 - val_loss: 0.5334 - val_acc: 0.7734\n",
      "chunk number: 276 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5499 - acc: 0.7991 - val_loss: 0.5683 - val_acc: 0.7891\n",
      "chunk number: 277 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5679 - acc: 0.7891 - val_loss: 0.4938 - val_acc: 0.8281\n",
      "chunk number: 278 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5337 - acc: 0.7980 - val_loss: 0.8129 - val_acc: 0.6641\n",
      "chunk number: 279 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5521 - acc: 0.7757 - val_loss: 0.5098 - val_acc: 0.7734\n",
      "chunk number: 280 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5656 - acc: 0.7812 - val_loss: 0.5722 - val_acc: 0.8047\n",
      "chunk number: 281 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5418 - acc: 0.8013 - val_loss: 0.5096 - val_acc: 0.8125\n",
      "chunk number: 282 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5943 - acc: 0.7746 - val_loss: 0.5495 - val_acc: 0.7734\n",
      "chunk number: 283 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6386 - acc: 0.7467 - val_loss: 0.6093 - val_acc: 0.7422\n",
      "chunk number: 284 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6094 - acc: 0.7623 - val_loss: 0.5644 - val_acc: 0.7734\n",
      "chunk number: 285 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5854 - acc: 0.7835 - val_loss: 0.5377 - val_acc: 0.8047\n",
      "chunk number: 286 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5887 - acc: 0.7712 - val_loss: 0.5401 - val_acc: 0.7969\n",
      "chunk number: 287 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6062 - acc: 0.7701 - val_loss: 0.6307 - val_acc: 0.7578\n",
      "chunk number: 288 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6221 - acc: 0.7712 - val_loss: 0.4822 - val_acc: 0.8438\n",
      "chunk number: 289 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5937 - acc: 0.7656 - val_loss: 0.5692 - val_acc: 0.8047\n",
      "chunk number: 290 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5739 - acc: 0.7790 - val_loss: 0.5753 - val_acc: 0.7812\n",
      "chunk number: 291 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5650 - acc: 0.7991 - val_loss: 0.6119 - val_acc: 0.7812\n",
      "chunk number: 292 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5602 - acc: 0.7913 - val_loss: 0.6170 - val_acc: 0.7500\n",
      "chunk number: 293 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5584 - acc: 0.7779 - val_loss: 0.6252 - val_acc: 0.7422\n",
      "chunk number: 294 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5543 - acc: 0.7879 - val_loss: 0.5921 - val_acc: 0.8047\n",
      "chunk number: 295 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5485 - acc: 0.7913 - val_loss: 0.5723 - val_acc: 0.7500\n",
      "chunk number: 296 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5812 - acc: 0.7734 - val_loss: 0.5271 - val_acc: 0.8125\n",
      "chunk number: 297 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5680 - acc: 0.7712 - val_loss: 0.5215 - val_acc: 0.8281\n",
      "chunk number: 298 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5805 - acc: 0.7712 - val_loss: 0.5331 - val_acc: 0.8281\n",
      "chunk number: 299 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5436 - acc: 0.7868 - val_loss: 0.5160 - val_acc: 0.7891\n",
      "chunk number: 300 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6058 - acc: 0.7679 - val_loss: 0.5314 - val_acc: 0.7656\n",
      "chunk number: 301 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5580 - acc: 0.7969 - val_loss: 0.4948 - val_acc: 0.8125\n",
      "chunk number: 302 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5951 - acc: 0.7879 - val_loss: 0.6285 - val_acc: 0.7734\n",
      "chunk number: 303 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5864 - acc: 0.7712 - val_loss: 0.5609 - val_acc: 0.7812\n",
      "chunk number: 304 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5630 - acc: 0.7667 - val_loss: 0.5366 - val_acc: 0.7812\n",
      "chunk number: 305 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5732 - acc: 0.7779 - val_loss: 0.6544 - val_acc: 0.7422\n",
      "chunk number: 306 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5239 - acc: 0.8069 - val_loss: 0.5671 - val_acc: 0.7969\n",
      "chunk number: 307 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5785 - acc: 0.7846 - val_loss: 0.5410 - val_acc: 0.7578\n",
      "chunk number: 308 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5360 - acc: 0.8036 - val_loss: 0.4409 - val_acc: 0.8203\n",
      "chunk number: 309 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5535 - acc: 0.7935 - val_loss: 0.5811 - val_acc: 0.7969\n",
      "chunk number: 310 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5877 - acc: 0.7712 - val_loss: 0.6450 - val_acc: 0.7656\n",
      "chunk number: 311 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5831 - acc: 0.7779 - val_loss: 0.5799 - val_acc: 0.7812\n",
      "chunk number: 312 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6219 - acc: 0.7567 - val_loss: 0.5170 - val_acc: 0.8047\n",
      "chunk number: 313 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5542 - acc: 0.8025 - val_loss: 0.6595 - val_acc: 0.7578\n",
      "chunk number: 314 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6384 - acc: 0.7589 - val_loss: 0.5744 - val_acc: 0.8203\n",
      "chunk number: 315 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5510 - acc: 0.7958 - val_loss: 0.5139 - val_acc: 0.8203\n",
      "chunk number: 316 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5273 - acc: 0.7980 - val_loss: 0.7874 - val_acc: 0.7266\n",
      "chunk number: 317 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5892 - acc: 0.7634 - val_loss: 0.5986 - val_acc: 0.7734\n",
      "chunk number: 318 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5518 - acc: 0.7991 - val_loss: 0.5221 - val_acc: 0.8047\n",
      "chunk number: 319 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5750 - acc: 0.7846 - val_loss: 0.7570 - val_acc: 0.6953\n",
      "chunk number: 320 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6223 - acc: 0.7545 - val_loss: 0.5661 - val_acc: 0.7812\n",
      "chunk number: 321 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5088 - acc: 0.8092 - val_loss: 0.4968 - val_acc: 0.8203\n",
      "chunk number: 322 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5713 - acc: 0.7790 - val_loss: 0.5919 - val_acc: 0.7891\n",
      "chunk number: 323 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5443 - acc: 0.8080 - val_loss: 0.4930 - val_acc: 0.7891\n",
      "chunk number: 324 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5386 - acc: 0.7924 - val_loss: 0.6003 - val_acc: 0.7891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 325 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5117 - acc: 0.8147 - val_loss: 0.5729 - val_acc: 0.8125\n",
      "chunk number: 326 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5375 - acc: 0.7902 - val_loss: 0.6709 - val_acc: 0.7422\n",
      "chunk number: 327 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5504 - acc: 0.7891 - val_loss: 0.5029 - val_acc: 0.7969\n",
      "chunk number: 328 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5805 - acc: 0.7790 - val_loss: 0.6285 - val_acc: 0.7656\n",
      "chunk number: 329 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5949 - acc: 0.7879 - val_loss: 0.6236 - val_acc: 0.8125\n",
      "chunk number: 330 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5464 - acc: 0.8002 - val_loss: 0.6696 - val_acc: 0.7422\n",
      "chunk number: 331 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5469 - acc: 0.7879 - val_loss: 0.5731 - val_acc: 0.7969\n",
      "chunk number: 332 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5466 - acc: 0.8036 - val_loss: 0.6611 - val_acc: 0.7500\n",
      "chunk number: 333 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5588 - acc: 0.7790 - val_loss: 0.5367 - val_acc: 0.7969\n",
      "chunk number: 334 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5730 - acc: 0.7746 - val_loss: 0.5673 - val_acc: 0.7344\n",
      "chunk number: 335 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5475 - acc: 0.7980 - val_loss: 0.7626 - val_acc: 0.7188\n",
      "chunk number: 336 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5633 - acc: 0.7935 - val_loss: 0.6005 - val_acc: 0.7422\n",
      "chunk number: 337 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5595 - acc: 0.7879 - val_loss: 0.4716 - val_acc: 0.8047\n",
      "chunk number: 338 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5536 - acc: 0.7935 - val_loss: 0.5547 - val_acc: 0.8203\n",
      "chunk number: 339 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5344 - acc: 0.7857 - val_loss: 0.5425 - val_acc: 0.7734\n",
      "chunk number: 340 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5856 - acc: 0.7812 - val_loss: 0.5239 - val_acc: 0.8047\n",
      "chunk number: 341 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5086 - acc: 0.8080 - val_loss: 0.4673 - val_acc: 0.8438\n",
      "chunk number: 342 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5334 - acc: 0.8092 - val_loss: 0.5860 - val_acc: 0.7578\n",
      "chunk number: 343 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5176 - acc: 0.7980 - val_loss: 0.6644 - val_acc: 0.7422\n",
      "chunk number: 344 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5697 - acc: 0.7924 - val_loss: 0.5722 - val_acc: 0.7578\n",
      "chunk number: 345 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5725 - acc: 0.7768 - val_loss: 0.5130 - val_acc: 0.7734\n",
      "chunk number: 346 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5619 - acc: 0.8013 - val_loss: 0.6536 - val_acc: 0.7422\n",
      "chunk number: 347 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5345 - acc: 0.7902 - val_loss: 0.6102 - val_acc: 0.7578\n",
      "chunk number: 348 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5929 - acc: 0.7801 - val_loss: 0.6873 - val_acc: 0.7266\n",
      "chunk number: 349 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5038 - acc: 0.8047 - val_loss: 0.6902 - val_acc: 0.7578\n",
      "chunk number: 350 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5680 - acc: 0.7746 - val_loss: 0.6394 - val_acc: 0.7578\n",
      "chunk number: 351 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5554 - acc: 0.7824 - val_loss: 0.6890 - val_acc: 0.7422\n",
      "chunk number: 352 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5542 - acc: 0.7980 - val_loss: 0.5278 - val_acc: 0.7812\n",
      "chunk number: 353 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5772 - acc: 0.7812 - val_loss: 0.6134 - val_acc: 0.7812\n",
      "chunk number: 354 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5519 - acc: 0.7779 - val_loss: 0.4175 - val_acc: 0.8438\n",
      "chunk number: 355 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5212 - acc: 0.7991 - val_loss: 0.5264 - val_acc: 0.8125\n",
      "chunk number: 356 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6009 - acc: 0.7667 - val_loss: 0.6402 - val_acc: 0.7344\n",
      "chunk number: 357 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5737 - acc: 0.7701 - val_loss: 0.5374 - val_acc: 0.8125\n",
      "chunk number: 358 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5276 - acc: 0.8036 - val_loss: 0.5607 - val_acc: 0.7812\n",
      "chunk number: 359 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5271 - acc: 0.7969 - val_loss: 0.6022 - val_acc: 0.7812\n",
      "chunk number: 360 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6344 - acc: 0.7667 - val_loss: 0.4688 - val_acc: 0.8203\n",
      "chunk number: 361 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5666 - acc: 0.7891 - val_loss: 0.5431 - val_acc: 0.8047\n",
      "chunk number: 362 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5480 - acc: 0.8147 - val_loss: 0.4465 - val_acc: 0.7969\n",
      "chunk number: 363 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5557 - acc: 0.7846 - val_loss: 0.6786 - val_acc: 0.7031\n",
      "chunk number: 364 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4957 - acc: 0.8147 - val_loss: 0.5442 - val_acc: 0.7969\n",
      "chunk number: 365 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5734 - acc: 0.7868 - val_loss: 0.5740 - val_acc: 0.7422\n",
      "chunk number: 366 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5480 - acc: 0.7946 - val_loss: 0.6789 - val_acc: 0.7109\n",
      "chunk number: 367 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5492 - acc: 0.7969 - val_loss: 0.5088 - val_acc: 0.7969\n",
      "chunk number: 368 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5538 - acc: 0.7746 - val_loss: 0.6584 - val_acc: 0.7422\n",
      "chunk number: 369 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5830 - acc: 0.7902 - val_loss: 0.5060 - val_acc: 0.7969\n",
      "chunk number: 370 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5211 - acc: 0.8147 - val_loss: 0.6853 - val_acc: 0.7578\n",
      "chunk number: 371 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5112 - acc: 0.7969 - val_loss: 0.5294 - val_acc: 0.7500\n",
      "chunk number: 372 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5535 - acc: 0.7790 - val_loss: 0.6316 - val_acc: 0.7812\n",
      "chunk number: 373 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4905 - acc: 0.8181 - val_loss: 0.5677 - val_acc: 0.7812\n",
      "chunk number: 374 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5346 - acc: 0.8103 - val_loss: 0.6536 - val_acc: 0.7266\n",
      "chunk number: 375 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5384 - acc: 0.8025 - val_loss: 0.4875 - val_acc: 0.8438\n",
      "chunk number: 376 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5378 - acc: 0.7958 - val_loss: 0.6151 - val_acc: 0.7891\n",
      "chunk number: 377 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5347 - acc: 0.7969 - val_loss: 0.4347 - val_acc: 0.8203\n",
      "chunk number: 378 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5161 - acc: 0.7946 - val_loss: 0.7309 - val_acc: 0.7109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 379 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5102 - acc: 0.8092 - val_loss: 0.5347 - val_acc: 0.7734\n",
      "chunk number: 380 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4984 - acc: 0.8114 - val_loss: 0.6165 - val_acc: 0.7891\n",
      "chunk number: 381 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5083 - acc: 0.8025 - val_loss: 0.5041 - val_acc: 0.7891\n",
      "chunk number: 382 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5507 - acc: 0.7902 - val_loss: 0.4502 - val_acc: 0.8281\n",
      "chunk number: 383 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5609 - acc: 0.7913 - val_loss: 0.5512 - val_acc: 0.7812\n",
      "chunk number: 384 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5393 - acc: 0.7946 - val_loss: 0.4982 - val_acc: 0.7734\n",
      "chunk number: 385 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5158 - acc: 0.8002 - val_loss: 0.4962 - val_acc: 0.8281\n",
      "chunk number: 386 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5016 - acc: 0.8058 - val_loss: 0.5308 - val_acc: 0.7969\n",
      "chunk number: 387 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5475 - acc: 0.8025 - val_loss: 0.5411 - val_acc: 0.8047\n",
      "chunk number: 388 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5457 - acc: 0.7913 - val_loss: 0.5107 - val_acc: 0.7891\n",
      "chunk number: 389 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5154 - acc: 0.8181 - val_loss: 0.5149 - val_acc: 0.8359\n",
      "chunk number: 390 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5300 - acc: 0.7991 - val_loss: 0.5572 - val_acc: 0.8047\n",
      "chunk number: 391 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5301 - acc: 0.8136 - val_loss: 0.5456 - val_acc: 0.7969\n",
      "chunk number: 392 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5075 - acc: 0.8103 - val_loss: 0.5558 - val_acc: 0.7656\n",
      "chunk number: 393 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4910 - acc: 0.7991 - val_loss: 0.6470 - val_acc: 0.7344\n",
      "chunk number: 394 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5392 - acc: 0.8013 - val_loss: 0.5688 - val_acc: 0.7734\n",
      "chunk number: 395 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4765 - acc: 0.8103 - val_loss: 0.5380 - val_acc: 0.7969\n",
      "chunk number: 396 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5477 - acc: 0.7946 - val_loss: 0.5025 - val_acc: 0.7891\n",
      "chunk number: 397 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5118 - acc: 0.8036 - val_loss: 0.4773 - val_acc: 0.8594\n",
      "chunk number: 398 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5443 - acc: 0.8036 - val_loss: 0.5438 - val_acc: 0.7969\n",
      "chunk number: 399 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5055 - acc: 0.8114 - val_loss: 0.4973 - val_acc: 0.8125\n",
      "chunk number: 400 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5168 - acc: 0.7958 - val_loss: 0.5184 - val_acc: 0.7500\n",
      "chunk number: 401 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4853 - acc: 0.8013 - val_loss: 0.4161 - val_acc: 0.8750\n",
      "chunk number: 402 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5412 - acc: 0.7958 - val_loss: 0.5405 - val_acc: 0.8125\n",
      "chunk number: 403 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4986 - acc: 0.8047 - val_loss: 0.4714 - val_acc: 0.7891\n",
      "chunk number: 404 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5067 - acc: 0.8013 - val_loss: 0.4772 - val_acc: 0.8203\n",
      "chunk number: 405 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5231 - acc: 0.8080 - val_loss: 0.6495 - val_acc: 0.7656\n",
      "chunk number: 406 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4839 - acc: 0.8069 - val_loss: 0.5776 - val_acc: 0.8125\n",
      "chunk number: 407 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5473 - acc: 0.8058 - val_loss: 0.5188 - val_acc: 0.7891\n",
      "chunk number: 408 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4942 - acc: 0.8136 - val_loss: 0.4662 - val_acc: 0.8125\n",
      "chunk number: 409 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5051 - acc: 0.8237 - val_loss: 0.5493 - val_acc: 0.7969\n",
      "chunk number: 410 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4788 - acc: 0.8259 - val_loss: 0.5843 - val_acc: 0.8047\n",
      "chunk number: 411 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5350 - acc: 0.7812 - val_loss: 0.5092 - val_acc: 0.7969\n",
      "chunk number: 412 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5433 - acc: 0.7846 - val_loss: 0.5359 - val_acc: 0.7734\n",
      "chunk number: 413 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4829 - acc: 0.8147 - val_loss: 0.5784 - val_acc: 0.7734\n",
      "chunk number: 414 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5600 - acc: 0.7779 - val_loss: 0.5370 - val_acc: 0.7891\n",
      "chunk number: 415 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5233 - acc: 0.7913 - val_loss: 0.5258 - val_acc: 0.8125\n",
      "chunk number: 416 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4839 - acc: 0.8103 - val_loss: 0.7751 - val_acc: 0.7266\n",
      "chunk number: 417 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5516 - acc: 0.7746 - val_loss: 0.5601 - val_acc: 0.7812\n",
      "chunk number: 418 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5239 - acc: 0.8047 - val_loss: 0.5337 - val_acc: 0.7734\n",
      "chunk number: 419 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5318 - acc: 0.8002 - val_loss: 0.6708 - val_acc: 0.7188\n",
      "chunk number: 420 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5779 - acc: 0.7857 - val_loss: 0.5012 - val_acc: 0.8203\n",
      "chunk number: 421 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4655 - acc: 0.8315 - val_loss: 0.4719 - val_acc: 0.8359\n",
      "chunk number: 422 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5130 - acc: 0.8069 - val_loss: 0.6356 - val_acc: 0.7656\n",
      "chunk number: 423 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4974 - acc: 0.8225 - val_loss: 0.5422 - val_acc: 0.7969\n",
      "chunk number: 424 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5156 - acc: 0.7958 - val_loss: 0.6717 - val_acc: 0.7656\n",
      "chunk number: 425 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5088 - acc: 0.8248 - val_loss: 0.5883 - val_acc: 0.7812\n",
      "chunk number: 426 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4814 - acc: 0.7969 - val_loss: 0.6101 - val_acc: 0.7500\n",
      "chunk number: 427 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4780 - acc: 0.8147 - val_loss: 0.4540 - val_acc: 0.8281\n",
      "chunk number: 428 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5059 - acc: 0.8136 - val_loss: 0.5882 - val_acc: 0.7578\n",
      "chunk number: 429 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5311 - acc: 0.8181 - val_loss: 0.5419 - val_acc: 0.7969\n",
      "chunk number: 430 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4988 - acc: 0.8147 - val_loss: 0.6822 - val_acc: 0.7734\n",
      "chunk number: 431 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5030 - acc: 0.8002 - val_loss: 0.4801 - val_acc: 0.8125\n",
      "chunk number: 432 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4634 - acc: 0.8225 - val_loss: 0.5996 - val_acc: 0.7578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 433 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5010 - acc: 0.8036 - val_loss: 0.5198 - val_acc: 0.7812\n",
      "chunk number: 434 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5152 - acc: 0.7879 - val_loss: 0.6295 - val_acc: 0.7500\n",
      "chunk number: 435 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4817 - acc: 0.8125 - val_loss: 0.7236 - val_acc: 0.7266\n",
      "chunk number: 436 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5000 - acc: 0.8114 - val_loss: 0.5166 - val_acc: 0.7812\n",
      "chunk number: 437 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4843 - acc: 0.8203 - val_loss: 0.4486 - val_acc: 0.7891\n",
      "chunk number: 438 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4998 - acc: 0.8192 - val_loss: 0.5646 - val_acc: 0.8125\n",
      "chunk number: 439 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5059 - acc: 0.8047 - val_loss: 0.5263 - val_acc: 0.7734\n",
      "chunk number: 440 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5346 - acc: 0.8103 - val_loss: 0.5839 - val_acc: 0.7734\n",
      "chunk number: 441 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4539 - acc: 0.8259 - val_loss: 0.4584 - val_acc: 0.8438\n",
      "chunk number: 442 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5073 - acc: 0.8114 - val_loss: 0.6069 - val_acc: 0.7656\n",
      "chunk number: 443 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4866 - acc: 0.8092 - val_loss: 0.5870 - val_acc: 0.7734\n",
      "chunk number: 444 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4989 - acc: 0.8136 - val_loss: 0.6254 - val_acc: 0.7812\n",
      "chunk number: 445 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5414 - acc: 0.8147 - val_loss: 0.5192 - val_acc: 0.7969\n",
      "chunk number: 446 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5178 - acc: 0.8058 - val_loss: 0.6696 - val_acc: 0.7656\n",
      "chunk number: 447 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4654 - acc: 0.8136 - val_loss: 0.5950 - val_acc: 0.7422\n",
      "chunk number: 448 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5069 - acc: 0.7969 - val_loss: 0.6475 - val_acc: 0.7656\n",
      "chunk number: 449 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4629 - acc: 0.8036 - val_loss: 0.6918 - val_acc: 0.7812\n",
      "chunk number: 450 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4803 - acc: 0.8103 - val_loss: 0.5696 - val_acc: 0.8047\n",
      "chunk number: 451 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5130 - acc: 0.8114 - val_loss: 0.7037 - val_acc: 0.7422\n",
      "chunk number: 452 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5006 - acc: 0.8158 - val_loss: 0.4907 - val_acc: 0.8203\n",
      "chunk number: 453 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5261 - acc: 0.7946 - val_loss: 0.6261 - val_acc: 0.7656\n",
      "chunk number: 454 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5125 - acc: 0.8136 - val_loss: 0.4139 - val_acc: 0.8594\n",
      "chunk number: 455 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4890 - acc: 0.7946 - val_loss: 0.4924 - val_acc: 0.8125\n",
      "chunk number: 456 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5131 - acc: 0.8125 - val_loss: 0.5973 - val_acc: 0.7422\n",
      "chunk number: 457 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5321 - acc: 0.8047 - val_loss: 0.4834 - val_acc: 0.8125\n",
      "chunk number: 458 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4837 - acc: 0.8292 - val_loss: 0.4920 - val_acc: 0.8281\n",
      "chunk number: 459 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5100 - acc: 0.8069 - val_loss: 0.5586 - val_acc: 0.7969\n",
      "chunk number: 460 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6210 - acc: 0.7567 - val_loss: 0.5099 - val_acc: 0.8281\n",
      "chunk number: 461 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5634 - acc: 0.7980 - val_loss: 0.5698 - val_acc: 0.7969\n",
      "chunk number: 462 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4997 - acc: 0.8237 - val_loss: 0.4829 - val_acc: 0.8047\n",
      "chunk number: 463 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5330 - acc: 0.7991 - val_loss: 0.6423 - val_acc: 0.7422\n",
      "chunk number: 464 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4414 - acc: 0.8337 - val_loss: 0.5389 - val_acc: 0.7891\n",
      "chunk number: 465 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4931 - acc: 0.8036 - val_loss: 0.4376 - val_acc: 0.8203\n",
      "chunk number: 466 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4804 - acc: 0.8248 - val_loss: 0.6018 - val_acc: 0.7500\n",
      "chunk number: 467 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4704 - acc: 0.8281 - val_loss: 0.5046 - val_acc: 0.7812\n",
      "chunk number: 468 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4917 - acc: 0.8047 - val_loss: 0.6462 - val_acc: 0.7734\n",
      "chunk number: 469 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5072 - acc: 0.8013 - val_loss: 0.4625 - val_acc: 0.8047\n",
      "chunk number: 470 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4777 - acc: 0.8292 - val_loss: 0.7054 - val_acc: 0.7266\n",
      "chunk number: 471 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4549 - acc: 0.8304 - val_loss: 0.4894 - val_acc: 0.8047\n",
      "chunk number: 472 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4933 - acc: 0.8025 - val_loss: 0.6312 - val_acc: 0.7734\n",
      "chunk number: 473 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4620 - acc: 0.8270 - val_loss: 0.5800 - val_acc: 0.7734\n",
      "chunk number: 474 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4914 - acc: 0.8192 - val_loss: 0.6437 - val_acc: 0.7656\n",
      "chunk number: 475 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4481 - acc: 0.8415 - val_loss: 0.4803 - val_acc: 0.8203\n",
      "chunk number: 476 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4719 - acc: 0.8147 - val_loss: 0.5063 - val_acc: 0.8125\n",
      "chunk number: 477 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4675 - acc: 0.8192 - val_loss: 0.4528 - val_acc: 0.8125\n",
      "chunk number: 478 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4643 - acc: 0.8203 - val_loss: 0.7822 - val_acc: 0.7031\n",
      "chunk number: 479 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4376 - acc: 0.8393 - val_loss: 0.5647 - val_acc: 0.7734\n",
      "chunk number: 480 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4618 - acc: 0.8281 - val_loss: 0.5519 - val_acc: 0.7969\n",
      "chunk number: 481 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4502 - acc: 0.8371 - val_loss: 0.5703 - val_acc: 0.7500\n",
      "chunk number: 482 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4773 - acc: 0.8192 - val_loss: 0.4210 - val_acc: 0.8359\n",
      "chunk number: 483 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4994 - acc: 0.8013 - val_loss: 0.5447 - val_acc: 0.7578\n",
      "chunk number: 484 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4916 - acc: 0.8103 - val_loss: 0.4717 - val_acc: 0.7969\n",
      "chunk number: 485 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4531 - acc: 0.8259 - val_loss: 0.4418 - val_acc: 0.8359\n",
      "chunk number: 486 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4608 - acc: 0.8348 - val_loss: 0.5284 - val_acc: 0.8047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 487 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4872 - acc: 0.8158 - val_loss: 0.5739 - val_acc: 0.7891\n",
      "chunk number: 488 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4988 - acc: 0.8025 - val_loss: 0.4467 - val_acc: 0.8203\n",
      "chunk number: 489 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4405 - acc: 0.8449 - val_loss: 0.4337 - val_acc: 0.8750\n",
      "chunk number: 490 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4467 - acc: 0.8259 - val_loss: 0.5488 - val_acc: 0.8281\n",
      "chunk number: 491 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4642 - acc: 0.8304 - val_loss: 0.4991 - val_acc: 0.7969\n",
      "chunk number: 492 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4445 - acc: 0.8259 - val_loss: 0.5333 - val_acc: 0.7656\n",
      "chunk number: 493 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4402 - acc: 0.8359 - val_loss: 0.5974 - val_acc: 0.7656\n",
      "chunk number: 494 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4552 - acc: 0.8359 - val_loss: 0.5364 - val_acc: 0.8125\n",
      "chunk number: 495 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4454 - acc: 0.8326 - val_loss: 0.5140 - val_acc: 0.7812\n",
      "chunk number: 496 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4701 - acc: 0.8136 - val_loss: 0.4643 - val_acc: 0.7969\n",
      "chunk number: 497 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4441 - acc: 0.8203 - val_loss: 0.4694 - val_acc: 0.8516\n",
      "chunk number: 498 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4703 - acc: 0.8259 - val_loss: 0.5718 - val_acc: 0.8203\n",
      "chunk number: 499 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4794 - acc: 0.8170 - val_loss: 0.4471 - val_acc: 0.8438\n",
      "chunk number: 500 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5049 - acc: 0.8036 - val_loss: 0.6002 - val_acc: 0.7812\n",
      "chunk number: 501 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5047 - acc: 0.8092 - val_loss: 0.4502 - val_acc: 0.8281\n",
      "chunk number: 502 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4802 - acc: 0.8170 - val_loss: 0.5807 - val_acc: 0.7969\n",
      "chunk number: 503 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4764 - acc: 0.8069 - val_loss: 0.5048 - val_acc: 0.8047\n",
      "chunk number: 504 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4630 - acc: 0.8192 - val_loss: 0.4667 - val_acc: 0.8125\n",
      "chunk number: 505 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4547 - acc: 0.8315 - val_loss: 0.6193 - val_acc: 0.7812\n",
      "chunk number: 506 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4246 - acc: 0.8315 - val_loss: 0.5653 - val_acc: 0.8047\n",
      "chunk number: 507 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4776 - acc: 0.8203 - val_loss: 0.4730 - val_acc: 0.7969\n",
      "chunk number: 508 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4376 - acc: 0.8337 - val_loss: 0.4003 - val_acc: 0.8672\n",
      "chunk number: 509 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4413 - acc: 0.8304 - val_loss: 0.5635 - val_acc: 0.7891\n",
      "chunk number: 510 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4413 - acc: 0.8382 - val_loss: 0.6006 - val_acc: 0.7969\n",
      "chunk number: 511 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4628 - acc: 0.8292 - val_loss: 0.5457 - val_acc: 0.8125\n",
      "chunk number: 512 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4949 - acc: 0.7991 - val_loss: 0.5050 - val_acc: 0.7969\n",
      "chunk number: 513 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4492 - acc: 0.8337 - val_loss: 0.5795 - val_acc: 0.7891\n",
      "chunk number: 514 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4942 - acc: 0.8092 - val_loss: 0.4999 - val_acc: 0.8516\n",
      "chunk number: 515 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4738 - acc: 0.8136 - val_loss: 0.5026 - val_acc: 0.7969\n",
      "chunk number: 516 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4207 - acc: 0.8304 - val_loss: 0.7943 - val_acc: 0.7266\n",
      "chunk number: 517 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4883 - acc: 0.8170 - val_loss: 0.5370 - val_acc: 0.7891\n",
      "chunk number: 518 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4423 - acc: 0.8315 - val_loss: 0.5151 - val_acc: 0.8203\n",
      "chunk number: 519 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4965 - acc: 0.8158 - val_loss: 0.6568 - val_acc: 0.7422\n",
      "chunk number: 520 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4837 - acc: 0.8092 - val_loss: 0.4894 - val_acc: 0.8438\n",
      "chunk number: 521 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4339 - acc: 0.8371 - val_loss: 0.4957 - val_acc: 0.7969\n",
      "chunk number: 522 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4532 - acc: 0.8337 - val_loss: 0.5424 - val_acc: 0.7656\n",
      "chunk number: 523 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4421 - acc: 0.8393 - val_loss: 0.4893 - val_acc: 0.8281\n",
      "chunk number: 524 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4371 - acc: 0.8281 - val_loss: 0.6519 - val_acc: 0.7422\n",
      "chunk number: 525 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3961 - acc: 0.8560 - val_loss: 0.5767 - val_acc: 0.8203\n",
      "chunk number: 526 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4157 - acc: 0.8203 - val_loss: 0.7049 - val_acc: 0.7422\n",
      "chunk number: 527 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4272 - acc: 0.8214 - val_loss: 0.4802 - val_acc: 0.8125\n",
      "chunk number: 528 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4602 - acc: 0.8270 - val_loss: 0.5619 - val_acc: 0.7891\n",
      "chunk number: 529 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4513 - acc: 0.8292 - val_loss: 0.4850 - val_acc: 0.8125\n",
      "chunk number: 530 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3954 - acc: 0.8471 - val_loss: 0.7530 - val_acc: 0.7188\n",
      "chunk number: 531 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4676 - acc: 0.8136 - val_loss: 0.4591 - val_acc: 0.8359\n",
      "chunk number: 532 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4109 - acc: 0.8527 - val_loss: 0.5861 - val_acc: 0.7969\n",
      "chunk number: 533 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4263 - acc: 0.8348 - val_loss: 0.4953 - val_acc: 0.8359\n",
      "chunk number: 534 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4450 - acc: 0.8259 - val_loss: 0.6074 - val_acc: 0.7734\n",
      "chunk number: 535 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4536 - acc: 0.8181 - val_loss: 0.7521 - val_acc: 0.7578\n",
      "chunk number: 536 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4366 - acc: 0.8315 - val_loss: 0.4973 - val_acc: 0.8125\n",
      "chunk number: 537 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4219 - acc: 0.8426 - val_loss: 0.4246 - val_acc: 0.7969\n",
      "chunk number: 538 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4587 - acc: 0.8304 - val_loss: 0.5551 - val_acc: 0.8359\n",
      "chunk number: 539 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4419 - acc: 0.8337 - val_loss: 0.5010 - val_acc: 0.7812\n",
      "chunk number: 540 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4759 - acc: 0.8259 - val_loss: 0.5763 - val_acc: 0.7734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 541 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3903 - acc: 0.8571 - val_loss: 0.4327 - val_acc: 0.8594\n",
      "chunk number: 542 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4505 - acc: 0.8371 - val_loss: 0.5873 - val_acc: 0.7734\n",
      "chunk number: 543 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4562 - acc: 0.8225 - val_loss: 0.5453 - val_acc: 0.7656\n",
      "chunk number: 544 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4499 - acc: 0.8404 - val_loss: 0.5388 - val_acc: 0.8125\n",
      "chunk number: 545 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4633 - acc: 0.8304 - val_loss: 0.4663 - val_acc: 0.8203\n",
      "chunk number: 546 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4466 - acc: 0.8426 - val_loss: 0.6119 - val_acc: 0.7891\n",
      "chunk number: 547 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4210 - acc: 0.8449 - val_loss: 0.5467 - val_acc: 0.7734\n",
      "chunk number: 548 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4316 - acc: 0.8281 - val_loss: 0.6373 - val_acc: 0.7734\n",
      "chunk number: 549 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4022 - acc: 0.8482 - val_loss: 0.6915 - val_acc: 0.7734\n",
      "chunk number: 550 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4111 - acc: 0.8415 - val_loss: 0.5728 - val_acc: 0.7734\n",
      "chunk number: 551 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4395 - acc: 0.8471 - val_loss: 0.6568 - val_acc: 0.7578\n",
      "chunk number: 552 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4484 - acc: 0.8326 - val_loss: 0.4650 - val_acc: 0.7969\n",
      "chunk number: 553 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4489 - acc: 0.8281 - val_loss: 0.6498 - val_acc: 0.7422\n",
      "chunk number: 554 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4304 - acc: 0.8371 - val_loss: 0.4270 - val_acc: 0.8516\n",
      "chunk number: 555 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4522 - acc: 0.8281 - val_loss: 0.5554 - val_acc: 0.8047\n",
      "chunk number: 556 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4808 - acc: 0.8103 - val_loss: 0.5739 - val_acc: 0.7656\n",
      "chunk number: 557 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4720 - acc: 0.8237 - val_loss: 0.4672 - val_acc: 0.8125\n",
      "chunk number: 558 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4199 - acc: 0.8326 - val_loss: 0.4530 - val_acc: 0.8516\n",
      "chunk number: 559 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4390 - acc: 0.8393 - val_loss: 0.4779 - val_acc: 0.8125\n",
      "chunk number: 560 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5179 - acc: 0.8158 - val_loss: 0.4958 - val_acc: 0.8125\n",
      "chunk number: 561 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4630 - acc: 0.8315 - val_loss: 0.6113 - val_acc: 0.8047\n",
      "chunk number: 562 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4557 - acc: 0.8348 - val_loss: 0.4831 - val_acc: 0.8203\n",
      "chunk number: 563 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4505 - acc: 0.8192 - val_loss: 0.5983 - val_acc: 0.7734\n",
      "chunk number: 564 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3920 - acc: 0.8672 - val_loss: 0.5267 - val_acc: 0.8203\n",
      "chunk number: 565 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4472 - acc: 0.8292 - val_loss: 0.5202 - val_acc: 0.7734\n",
      "chunk number: 566 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4025 - acc: 0.8359 - val_loss: 0.6029 - val_acc: 0.7578\n",
      "chunk number: 567 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4371 - acc: 0.8326 - val_loss: 0.4740 - val_acc: 0.8047\n",
      "chunk number: 568 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4371 - acc: 0.8337 - val_loss: 0.6752 - val_acc: 0.7891\n",
      "chunk number: 569 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4478 - acc: 0.8214 - val_loss: 0.4934 - val_acc: 0.7656\n",
      "chunk number: 570 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4148 - acc: 0.8471 - val_loss: 0.5442 - val_acc: 0.7812\n",
      "chunk number: 571 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3905 - acc: 0.8493 - val_loss: 0.5324 - val_acc: 0.8125\n",
      "chunk number: 572 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4255 - acc: 0.8315 - val_loss: 0.5441 - val_acc: 0.8047\n",
      "chunk number: 573 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4041 - acc: 0.8493 - val_loss: 0.5688 - val_acc: 0.8281\n",
      "chunk number: 574 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4018 - acc: 0.8504 - val_loss: 0.5833 - val_acc: 0.7734\n",
      "chunk number: 575 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3796 - acc: 0.8538 - val_loss: 0.4922 - val_acc: 0.8438\n",
      "chunk number: 576 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3966 - acc: 0.8348 - val_loss: 0.5386 - val_acc: 0.8125\n",
      "chunk number: 577 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4093 - acc: 0.8404 - val_loss: 0.4393 - val_acc: 0.8594\n",
      "chunk number: 578 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3681 - acc: 0.8627 - val_loss: 0.7975 - val_acc: 0.7578\n",
      "chunk number: 579 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3820 - acc: 0.8438 - val_loss: 0.5894 - val_acc: 0.7734\n",
      "chunk number: 580 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4233 - acc: 0.8359 - val_loss: 0.5664 - val_acc: 0.7891\n",
      "chunk number: 581 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4082 - acc: 0.8281 - val_loss: 0.5189 - val_acc: 0.7812\n",
      "chunk number: 582 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4263 - acc: 0.8471 - val_loss: 0.4416 - val_acc: 0.7969\n",
      "chunk number: 583 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4640 - acc: 0.8292 - val_loss: 0.5580 - val_acc: 0.7500\n",
      "chunk number: 584 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4584 - acc: 0.8292 - val_loss: 0.5332 - val_acc: 0.7812\n",
      "chunk number: 585 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4359 - acc: 0.8237 - val_loss: 0.4487 - val_acc: 0.8281\n",
      "chunk number: 586 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3954 - acc: 0.8504 - val_loss: 0.4555 - val_acc: 0.8125\n",
      "chunk number: 587 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4471 - acc: 0.8259 - val_loss: 0.5083 - val_acc: 0.7734\n",
      "chunk number: 588 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4326 - acc: 0.8248 - val_loss: 0.4999 - val_acc: 0.8047\n",
      "chunk number: 589 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4046 - acc: 0.8438 - val_loss: 0.4978 - val_acc: 0.7969\n",
      "chunk number: 590 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3837 - acc: 0.8627 - val_loss: 0.4996 - val_acc: 0.8125\n",
      "chunk number: 591 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3990 - acc: 0.8438 - val_loss: 0.5171 - val_acc: 0.7969\n",
      "chunk number: 592 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3502 - acc: 0.8661 - val_loss: 0.5483 - val_acc: 0.8125\n",
      "chunk number: 593 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3891 - acc: 0.8393 - val_loss: 0.6136 - val_acc: 0.7891\n",
      "chunk number: 594 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4278 - acc: 0.8382 - val_loss: 0.6004 - val_acc: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 595 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3957 - acc: 0.8605 - val_loss: 0.5127 - val_acc: 0.7969\n",
      "chunk number: 596 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4707 - acc: 0.8348 - val_loss: 0.4615 - val_acc: 0.8203\n",
      "chunk number: 597 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4215 - acc: 0.8393 - val_loss: 0.4800 - val_acc: 0.8438\n",
      "chunk number: 598 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4166 - acc: 0.8203 - val_loss: 0.5794 - val_acc: 0.8281\n",
      "chunk number: 599 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4186 - acc: 0.8337 - val_loss: 0.4316 - val_acc: 0.8359\n",
      "chunk number: 600 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4391 - acc: 0.8147 - val_loss: 0.5298 - val_acc: 0.7969\n",
      "chunk number: 601 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3741 - acc: 0.8594 - val_loss: 0.3510 - val_acc: 0.8828\n",
      "chunk number: 602 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4025 - acc: 0.8471 - val_loss: 0.5718 - val_acc: 0.7734\n",
      "chunk number: 603 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3980 - acc: 0.8359 - val_loss: 0.4779 - val_acc: 0.8125\n",
      "chunk number: 604 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4158 - acc: 0.8326 - val_loss: 0.4367 - val_acc: 0.8281\n",
      "chunk number: 605 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4078 - acc: 0.8415 - val_loss: 0.6984 - val_acc: 0.7969\n",
      "chunk number: 606 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3732 - acc: 0.8471 - val_loss: 0.5912 - val_acc: 0.8359\n",
      "chunk number: 607 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4190 - acc: 0.8605 - val_loss: 0.4700 - val_acc: 0.8203\n",
      "chunk number: 608 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4094 - acc: 0.8449 - val_loss: 0.4944 - val_acc: 0.8125\n",
      "chunk number: 609 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3754 - acc: 0.8549 - val_loss: 0.5584 - val_acc: 0.8047\n",
      "chunk number: 610 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4276 - acc: 0.8326 - val_loss: 0.6985 - val_acc: 0.7812\n",
      "chunk number: 611 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4435 - acc: 0.8281 - val_loss: 0.5077 - val_acc: 0.8125\n",
      "chunk number: 612 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4419 - acc: 0.8214 - val_loss: 0.5534 - val_acc: 0.7812\n",
      "chunk number: 613 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4155 - acc: 0.8471 - val_loss: 0.6427 - val_acc: 0.8281\n",
      "chunk number: 614 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4793 - acc: 0.8125 - val_loss: 0.5305 - val_acc: 0.8281\n",
      "chunk number: 615 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4243 - acc: 0.8449 - val_loss: 0.5599 - val_acc: 0.8281\n",
      "chunk number: 616 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3820 - acc: 0.8415 - val_loss: 0.8173 - val_acc: 0.7344\n",
      "chunk number: 617 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4090 - acc: 0.8326 - val_loss: 0.6034 - val_acc: 0.8047\n",
      "chunk number: 618 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4011 - acc: 0.8359 - val_loss: 0.5465 - val_acc: 0.8125\n",
      "chunk number: 619 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4318 - acc: 0.8504 - val_loss: 0.6081 - val_acc: 0.7422\n",
      "chunk number: 620 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4292 - acc: 0.8315 - val_loss: 0.5345 - val_acc: 0.8359\n",
      "chunk number: 621 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3687 - acc: 0.8471 - val_loss: 0.5154 - val_acc: 0.7734\n",
      "chunk number: 622 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4138 - acc: 0.8415 - val_loss: 0.5782 - val_acc: 0.7578\n",
      "chunk number: 623 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3915 - acc: 0.8627 - val_loss: 0.5126 - val_acc: 0.8047\n",
      "chunk number: 624 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4013 - acc: 0.8471 - val_loss: 0.6037 - val_acc: 0.7500\n",
      "chunk number: 625 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3540 - acc: 0.8739 - val_loss: 0.5412 - val_acc: 0.8125\n",
      "chunk number: 626 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3817 - acc: 0.8438 - val_loss: 0.6371 - val_acc: 0.7734\n",
      "chunk number: 627 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3484 - acc: 0.8549 - val_loss: 0.4919 - val_acc: 0.8125\n",
      "chunk number: 628 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3745 - acc: 0.8527 - val_loss: 0.5960 - val_acc: 0.8125\n",
      "chunk number: 629 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3932 - acc: 0.8594 - val_loss: 0.5707 - val_acc: 0.8125\n",
      "chunk number: 630 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3918 - acc: 0.8449 - val_loss: 0.7707 - val_acc: 0.7266\n",
      "chunk number: 631 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4035 - acc: 0.8527 - val_loss: 0.5701 - val_acc: 0.7891\n",
      "chunk number: 632 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3596 - acc: 0.8672 - val_loss: 0.5161 - val_acc: 0.8203\n",
      "chunk number: 633 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3589 - acc: 0.8694 - val_loss: 0.4760 - val_acc: 0.7969\n",
      "chunk number: 634 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3837 - acc: 0.8471 - val_loss: 0.6908 - val_acc: 0.7578\n",
      "chunk number: 635 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3615 - acc: 0.8694 - val_loss: 0.9164 - val_acc: 0.7344\n",
      "chunk number: 636 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4063 - acc: 0.8516 - val_loss: 0.6246 - val_acc: 0.7578\n",
      "chunk number: 637 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4268 - acc: 0.8315 - val_loss: 0.4816 - val_acc: 0.8125\n",
      "chunk number: 638 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4198 - acc: 0.8348 - val_loss: 0.5669 - val_acc: 0.8203\n",
      "chunk number: 639 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3676 - acc: 0.8527 - val_loss: 0.5422 - val_acc: 0.8047\n",
      "chunk number: 640 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4302 - acc: 0.8404 - val_loss: 0.5265 - val_acc: 0.8281\n",
      "chunk number: 641 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3438 - acc: 0.8795 - val_loss: 0.4459 - val_acc: 0.8281\n",
      "chunk number: 642 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3683 - acc: 0.8583 - val_loss: 0.6328 - val_acc: 0.7891\n",
      "chunk number: 643 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4099 - acc: 0.8549 - val_loss: 0.6105 - val_acc: 0.7969\n",
      "chunk number: 644 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3928 - acc: 0.8605 - val_loss: 0.6287 - val_acc: 0.7812\n",
      "chunk number: 645 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3800 - acc: 0.8583 - val_loss: 0.5551 - val_acc: 0.7812\n",
      "chunk number: 646 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3751 - acc: 0.8672 - val_loss: 0.6382 - val_acc: 0.7812\n",
      "chunk number: 647 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3688 - acc: 0.8560 - val_loss: 0.6133 - val_acc: 0.8203\n",
      "chunk number: 648 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3929 - acc: 0.8493 - val_loss: 0.6603 - val_acc: 0.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 649 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3628 - acc: 0.8393 - val_loss: 0.7918 - val_acc: 0.7812\n",
      "chunk number: 650 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3872 - acc: 0.8438 - val_loss: 0.5980 - val_acc: 0.7969\n",
      "chunk number: 651 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4275 - acc: 0.8281 - val_loss: 0.7228 - val_acc: 0.7344\n",
      "chunk number: 652 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4256 - acc: 0.8337 - val_loss: 0.5100 - val_acc: 0.7734\n",
      "chunk number: 653 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4348 - acc: 0.8348 - val_loss: 0.6238 - val_acc: 0.7578\n",
      "chunk number: 654 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4308 - acc: 0.8326 - val_loss: 0.3922 - val_acc: 0.8203\n",
      "chunk number: 655 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4025 - acc: 0.8371 - val_loss: 0.5760 - val_acc: 0.8125\n",
      "chunk number: 656 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4166 - acc: 0.8482 - val_loss: 0.6075 - val_acc: 0.7500\n",
      "chunk number: 657 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4332 - acc: 0.8270 - val_loss: 0.5078 - val_acc: 0.8125\n",
      "chunk number: 658 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3793 - acc: 0.8650 - val_loss: 0.4544 - val_acc: 0.8281\n",
      "chunk number: 659 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3702 - acc: 0.8627 - val_loss: 0.5195 - val_acc: 0.8125\n",
      "chunk number: 660 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4464 - acc: 0.8304 - val_loss: 0.4992 - val_acc: 0.7969\n",
      "chunk number: 661 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3969 - acc: 0.8493 - val_loss: 0.6263 - val_acc: 0.8125\n",
      "chunk number: 662 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3790 - acc: 0.8661 - val_loss: 0.4755 - val_acc: 0.8438\n",
      "chunk number: 663 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3874 - acc: 0.8415 - val_loss: 0.6269 - val_acc: 0.7734\n",
      "chunk number: 664 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3537 - acc: 0.8650 - val_loss: 0.5894 - val_acc: 0.8281\n",
      "chunk number: 665 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3799 - acc: 0.8527 - val_loss: 0.4979 - val_acc: 0.7656\n",
      "chunk number: 666 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3355 - acc: 0.8683 - val_loss: 0.6079 - val_acc: 0.7578\n",
      "chunk number: 667 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3640 - acc: 0.8638 - val_loss: 0.5039 - val_acc: 0.7812\n",
      "chunk number: 668 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4012 - acc: 0.8493 - val_loss: 0.6766 - val_acc: 0.7734\n",
      "chunk number: 669 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3885 - acc: 0.8538 - val_loss: 0.5525 - val_acc: 0.7734\n",
      "chunk number: 670 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3276 - acc: 0.8817 - val_loss: 0.5461 - val_acc: 0.7656\n",
      "chunk number: 671 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3229 - acc: 0.8772 - val_loss: 0.5181 - val_acc: 0.8203\n",
      "chunk number: 672 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3429 - acc: 0.8683 - val_loss: 0.6412 - val_acc: 0.7500\n",
      "chunk number: 673 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3181 - acc: 0.8739 - val_loss: 0.7193 - val_acc: 0.7656\n",
      "chunk number: 674 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3894 - acc: 0.8694 - val_loss: 0.6601 - val_acc: 0.7422\n",
      "chunk number: 675 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3740 - acc: 0.8538 - val_loss: 0.4962 - val_acc: 0.8125\n",
      "chunk number: 676 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3448 - acc: 0.8705 - val_loss: 0.5004 - val_acc: 0.7891\n",
      "chunk number: 677 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3307 - acc: 0.8605 - val_loss: 0.3798 - val_acc: 0.8594\n",
      "chunk number: 678 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3165 - acc: 0.8828 - val_loss: 0.8700 - val_acc: 0.7656\n",
      "chunk number: 679 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2985 - acc: 0.8917 - val_loss: 0.5861 - val_acc: 0.7812\n",
      "chunk number: 680 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3297 - acc: 0.8817 - val_loss: 0.5502 - val_acc: 0.8047\n",
      "chunk number: 681 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3532 - acc: 0.8560 - val_loss: 0.5170 - val_acc: 0.7656\n",
      "chunk number: 682 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3336 - acc: 0.8728 - val_loss: 0.4196 - val_acc: 0.8203\n",
      "chunk number: 683 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4308 - acc: 0.8371 - val_loss: 0.5030 - val_acc: 0.7500\n",
      "chunk number: 684 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3783 - acc: 0.8549 - val_loss: 0.5369 - val_acc: 0.7578\n",
      "chunk number: 685 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3737 - acc: 0.8661 - val_loss: 0.4478 - val_acc: 0.8438\n",
      "chunk number: 686 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3694 - acc: 0.8571 - val_loss: 0.5024 - val_acc: 0.8516\n",
      "chunk number: 687 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4218 - acc: 0.8371 - val_loss: 0.4982 - val_acc: 0.7891\n",
      "chunk number: 688 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3925 - acc: 0.8482 - val_loss: 0.4868 - val_acc: 0.8125\n",
      "chunk number: 689 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3689 - acc: 0.8650 - val_loss: 0.4920 - val_acc: 0.8281\n",
      "chunk number: 690 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3287 - acc: 0.8705 - val_loss: 0.6100 - val_acc: 0.8125\n",
      "chunk number: 691 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2994 - acc: 0.8862 - val_loss: 0.5967 - val_acc: 0.7500\n",
      "chunk number: 692 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2779 - acc: 0.8795 - val_loss: 0.7484 - val_acc: 0.7891\n",
      "chunk number: 693 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3348 - acc: 0.8549 - val_loss: 0.6375 - val_acc: 0.8047\n",
      "chunk number: 694 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3941 - acc: 0.8795 - val_loss: 0.6409 - val_acc: 0.7891\n",
      "chunk number: 695 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3699 - acc: 0.8750 - val_loss: 0.5412 - val_acc: 0.8281\n",
      "chunk number: 696 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3922 - acc: 0.8415 - val_loss: 0.4990 - val_acc: 0.8047\n",
      "chunk number: 697 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3566 - acc: 0.8683 - val_loss: 0.5787 - val_acc: 0.8125\n",
      "chunk number: 698 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3679 - acc: 0.8583 - val_loss: 0.5625 - val_acc: 0.8281\n",
      "chunk number: 699 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3666 - acc: 0.8594 - val_loss: 0.4238 - val_acc: 0.8125\n",
      "chunk number: 700 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3733 - acc: 0.8516 - val_loss: 0.6262 - val_acc: 0.7656\n",
      "chunk number: 701 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3344 - acc: 0.8806 - val_loss: 0.3534 - val_acc: 0.8672\n",
      "chunk number: 702 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3172 - acc: 0.8795 - val_loss: 0.6044 - val_acc: 0.7734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 703 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3418 - acc: 0.8605 - val_loss: 0.4677 - val_acc: 0.8203\n",
      "chunk number: 704 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3358 - acc: 0.8717 - val_loss: 0.5015 - val_acc: 0.8125\n",
      "chunk number: 705 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3315 - acc: 0.8750 - val_loss: 0.7204 - val_acc: 0.8125\n",
      "chunk number: 706 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3111 - acc: 0.8862 - val_loss: 0.5503 - val_acc: 0.8359\n",
      "chunk number: 707 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3461 - acc: 0.8783 - val_loss: 0.4847 - val_acc: 0.8281\n",
      "chunk number: 708 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3565 - acc: 0.8661 - val_loss: 0.5190 - val_acc: 0.8203\n",
      "chunk number: 709 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3679 - acc: 0.8583 - val_loss: 0.5961 - val_acc: 0.7969\n",
      "chunk number: 710 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3535 - acc: 0.8650 - val_loss: 0.7384 - val_acc: 0.7891\n",
      "chunk number: 711 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3954 - acc: 0.8449 - val_loss: 0.5731 - val_acc: 0.7578\n",
      "chunk number: 712 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4336 - acc: 0.8382 - val_loss: 0.5039 - val_acc: 0.8203\n",
      "chunk number: 713 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3710 - acc: 0.8627 - val_loss: 0.6653 - val_acc: 0.7812\n",
      "chunk number: 714 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4287 - acc: 0.8438 - val_loss: 0.4746 - val_acc: 0.8594\n",
      "chunk number: 715 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3801 - acc: 0.8527 - val_loss: 0.6431 - val_acc: 0.7734\n",
      "chunk number: 716 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3303 - acc: 0.8772 - val_loss: 0.8642 - val_acc: 0.7656\n",
      "chunk number: 717 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4034 - acc: 0.8426 - val_loss: 0.5406 - val_acc: 0.7969\n",
      "chunk number: 718 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3494 - acc: 0.8571 - val_loss: 0.5459 - val_acc: 0.8047\n",
      "chunk number: 719 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3333 - acc: 0.8638 - val_loss: 0.7608 - val_acc: 0.7031\n",
      "chunk number: 720 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3839 - acc: 0.8438 - val_loss: 0.5381 - val_acc: 0.8438\n",
      "chunk number: 721 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3232 - acc: 0.8705 - val_loss: 0.4934 - val_acc: 0.8203\n",
      "chunk number: 722 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3543 - acc: 0.8605 - val_loss: 0.5416 - val_acc: 0.7891\n",
      "chunk number: 723 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3492 - acc: 0.8772 - val_loss: 0.4916 - val_acc: 0.8281\n",
      "chunk number: 724 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3560 - acc: 0.8549 - val_loss: 0.6583 - val_acc: 0.7656\n",
      "chunk number: 725 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3093 - acc: 0.8850 - val_loss: 0.6109 - val_acc: 0.8125\n",
      "chunk number: 726 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3242 - acc: 0.8638 - val_loss: 0.6573 - val_acc: 0.7891\n",
      "chunk number: 727 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3305 - acc: 0.8795 - val_loss: 0.5642 - val_acc: 0.7969\n",
      "chunk number: 728 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3963 - acc: 0.8438 - val_loss: 0.6010 - val_acc: 0.7578\n",
      "chunk number: 729 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3502 - acc: 0.8705 - val_loss: 0.5406 - val_acc: 0.7891\n",
      "chunk number: 730 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3566 - acc: 0.8694 - val_loss: 0.8031 - val_acc: 0.7578\n",
      "chunk number: 731 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3664 - acc: 0.8482 - val_loss: 0.4871 - val_acc: 0.8516\n",
      "chunk number: 732 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3326 - acc: 0.8739 - val_loss: 0.7183 - val_acc: 0.8125\n",
      "chunk number: 733 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3466 - acc: 0.8761 - val_loss: 0.5163 - val_acc: 0.7969\n",
      "chunk number: 734 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3602 - acc: 0.8583 - val_loss: 0.7928 - val_acc: 0.7500\n",
      "chunk number: 735 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3061 - acc: 0.8717 - val_loss: 1.0169 - val_acc: 0.7266\n",
      "chunk number: 736 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3069 - acc: 0.8761 - val_loss: 0.6874 - val_acc: 0.7578\n",
      "chunk number: 737 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3292 - acc: 0.8862 - val_loss: 0.6356 - val_acc: 0.7812\n",
      "chunk number: 738 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3387 - acc: 0.8694 - val_loss: 0.6013 - val_acc: 0.8203\n",
      "chunk number: 739 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3191 - acc: 0.8795 - val_loss: 0.5262 - val_acc: 0.8281\n",
      "chunk number: 740 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3730 - acc: 0.8583 - val_loss: 0.5937 - val_acc: 0.8281\n",
      "chunk number: 741 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3301 - acc: 0.8661 - val_loss: 0.4742 - val_acc: 0.8281\n",
      "chunk number: 742 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3681 - acc: 0.8560 - val_loss: 0.8247 - val_acc: 0.7578\n",
      "chunk number: 743 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3470 - acc: 0.8783 - val_loss: 0.6453 - val_acc: 0.7812\n",
      "chunk number: 744 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3649 - acc: 0.8717 - val_loss: 0.6865 - val_acc: 0.7734\n",
      "chunk number: 745 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3678 - acc: 0.8516 - val_loss: 0.6016 - val_acc: 0.7734\n",
      "chunk number: 746 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3390 - acc: 0.8772 - val_loss: 0.5679 - val_acc: 0.7734\n",
      "chunk number: 747 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3083 - acc: 0.8761 - val_loss: 0.7433 - val_acc: 0.7578\n",
      "chunk number: 748 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3517 - acc: 0.8795 - val_loss: 0.6511 - val_acc: 0.7969\n",
      "chunk number: 749 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3202 - acc: 0.8661 - val_loss: 0.7861 - val_acc: 0.7812\n",
      "chunk number: 750 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3399 - acc: 0.8594 - val_loss: 0.6033 - val_acc: 0.8516\n",
      "chunk number: 751 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3569 - acc: 0.8616 - val_loss: 0.6623 - val_acc: 0.7656\n",
      "chunk number: 752 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3559 - acc: 0.8638 - val_loss: 0.5126 - val_acc: 0.8594\n",
      "chunk number: 753 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3979 - acc: 0.8482 - val_loss: 0.6961 - val_acc: 0.7031\n",
      "chunk number: 754 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3732 - acc: 0.8549 - val_loss: 0.3915 - val_acc: 0.8672\n",
      "chunk number: 755 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3701 - acc: 0.8504 - val_loss: 0.6104 - val_acc: 0.7812\n",
      "chunk number: 756 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3964 - acc: 0.8482 - val_loss: 0.5537 - val_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 757 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3649 - acc: 0.8571 - val_loss: 0.6573 - val_acc: 0.7578\n",
      "chunk number: 758 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3238 - acc: 0.8817 - val_loss: 0.4799 - val_acc: 0.8281\n",
      "chunk number: 759 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3501 - acc: 0.8750 - val_loss: 0.5166 - val_acc: 0.8359\n",
      "chunk number: 760 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3982 - acc: 0.8549 - val_loss: 0.5686 - val_acc: 0.7812\n",
      "chunk number: 761 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3676 - acc: 0.8683 - val_loss: 0.6285 - val_acc: 0.8359\n",
      "chunk number: 762 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3621 - acc: 0.8795 - val_loss: 0.4760 - val_acc: 0.8359\n",
      "chunk number: 763 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3130 - acc: 0.8884 - val_loss: 0.5891 - val_acc: 0.8359\n",
      "chunk number: 764 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2901 - acc: 0.8873 - val_loss: 0.7308 - val_acc: 0.7891\n",
      "chunk number: 765 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3450 - acc: 0.8594 - val_loss: 0.4780 - val_acc: 0.7812\n",
      "chunk number: 766 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2831 - acc: 0.8906 - val_loss: 0.6325 - val_acc: 0.7500\n",
      "chunk number: 767 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3285 - acc: 0.8828 - val_loss: 0.5718 - val_acc: 0.7891\n",
      "chunk number: 768 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3119 - acc: 0.8795 - val_loss: 0.8811 - val_acc: 0.7734\n",
      "chunk number: 769 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3244 - acc: 0.8772 - val_loss: 0.5918 - val_acc: 0.7969\n",
      "chunk number: 770 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2785 - acc: 0.8929 - val_loss: 0.5881 - val_acc: 0.7969\n",
      "chunk number: 771 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2746 - acc: 0.8940 - val_loss: 0.4686 - val_acc: 0.7969\n",
      "chunk number: 772 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2950 - acc: 0.8917 - val_loss: 0.8048 - val_acc: 0.7656\n",
      "chunk number: 773 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2709 - acc: 0.8962 - val_loss: 0.7120 - val_acc: 0.7969\n",
      "chunk number: 774 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2819 - acc: 0.8940 - val_loss: 0.6624 - val_acc: 0.7422\n",
      "chunk number: 775 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2836 - acc: 0.8850 - val_loss: 0.5889 - val_acc: 0.8203\n",
      "chunk number: 776 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3078 - acc: 0.8772 - val_loss: 0.4914 - val_acc: 0.7969\n",
      "chunk number: 777 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3020 - acc: 0.8817 - val_loss: 0.4618 - val_acc: 0.8438\n",
      "chunk number: 778 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2716 - acc: 0.9018 - val_loss: 1.0014 - val_acc: 0.7891\n",
      "chunk number: 779 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2370 - acc: 0.9007 - val_loss: 0.7699 - val_acc: 0.7891\n",
      "chunk number: 780 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2591 - acc: 0.8951 - val_loss: 0.6045 - val_acc: 0.8125\n",
      "chunk number: 781 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2806 - acc: 0.8984 - val_loss: 0.5913 - val_acc: 0.7969\n",
      "chunk number: 782 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3035 - acc: 0.8862 - val_loss: 0.3822 - val_acc: 0.8047\n",
      "chunk number: 783 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3520 - acc: 0.8594 - val_loss: 0.5890 - val_acc: 0.7266\n",
      "chunk number: 784 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3622 - acc: 0.8672 - val_loss: 0.5928 - val_acc: 0.7500\n",
      "chunk number: 785 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3186 - acc: 0.8817 - val_loss: 0.4525 - val_acc: 0.8281\n",
      "chunk number: 786 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3136 - acc: 0.8795 - val_loss: 0.5651 - val_acc: 0.8281\n",
      "chunk number: 787 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3512 - acc: 0.8728 - val_loss: 0.6253 - val_acc: 0.7891\n",
      "chunk number: 788 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3478 - acc: 0.8650 - val_loss: 0.4599 - val_acc: 0.8203\n",
      "chunk number: 789 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3253 - acc: 0.8739 - val_loss: 0.5225 - val_acc: 0.8125\n",
      "chunk number: 790 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3043 - acc: 0.8850 - val_loss: 0.6162 - val_acc: 0.7891\n",
      "chunk number: 791 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2732 - acc: 0.9062 - val_loss: 0.6535 - val_acc: 0.7812\n",
      "chunk number: 792 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2765 - acc: 0.8906 - val_loss: 0.5530 - val_acc: 0.8203\n",
      "chunk number: 793 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2535 - acc: 0.8929 - val_loss: 0.8952 - val_acc: 0.7734\n",
      "chunk number: 794 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3737 - acc: 0.8705 - val_loss: 0.7150 - val_acc: 0.7812\n",
      "chunk number: 795 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3641 - acc: 0.8650 - val_loss: 0.7079 - val_acc: 0.7891\n",
      "chunk number: 796 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3615 - acc: 0.8594 - val_loss: 0.5545 - val_acc: 0.8125\n",
      "chunk number: 797 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3568 - acc: 0.8672 - val_loss: 0.5488 - val_acc: 0.8203\n",
      "chunk number: 798 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3598 - acc: 0.8560 - val_loss: 0.5711 - val_acc: 0.8047\n",
      "chunk number: 799 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3512 - acc: 0.8717 - val_loss: 0.4456 - val_acc: 0.8359\n",
      "chunk number: 800 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3483 - acc: 0.8583 - val_loss: 0.7292 - val_acc: 0.7578\n",
      "chunk number: 801 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3093 - acc: 0.8873 - val_loss: 0.3790 - val_acc: 0.8672\n",
      "chunk number: 802 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2866 - acc: 0.8839 - val_loss: 0.7618 - val_acc: 0.7578\n",
      "chunk number: 803 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2807 - acc: 0.8850 - val_loss: 0.5545 - val_acc: 0.7969\n",
      "chunk number: 804 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2972 - acc: 0.8772 - val_loss: 0.4903 - val_acc: 0.7812\n",
      "chunk number: 805 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2790 - acc: 0.8984 - val_loss: 0.6657 - val_acc: 0.8203\n",
      "chunk number: 806 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2994 - acc: 0.8850 - val_loss: 0.7028 - val_acc: 0.8125\n",
      "chunk number: 807 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3247 - acc: 0.8839 - val_loss: 0.4700 - val_acc: 0.8125\n",
      "chunk number: 808 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2990 - acc: 0.8873 - val_loss: 0.5322 - val_acc: 0.7812\n",
      "chunk number: 809 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2706 - acc: 0.9029 - val_loss: 0.6681 - val_acc: 0.7656\n",
      "chunk number: 810 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2958 - acc: 0.8895 - val_loss: 0.8147 - val_acc: 0.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 811 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3261 - acc: 0.8772 - val_loss: 0.5366 - val_acc: 0.7812\n",
      "chunk number: 812 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4033 - acc: 0.8571 - val_loss: 0.5551 - val_acc: 0.7812\n",
      "chunk number: 813 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3215 - acc: 0.8638 - val_loss: 0.7157 - val_acc: 0.7812\n",
      "chunk number: 814 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3697 - acc: 0.8438 - val_loss: 0.4477 - val_acc: 0.8594\n",
      "chunk number: 815 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3210 - acc: 0.8828 - val_loss: 0.7426 - val_acc: 0.7500\n",
      "chunk number: 816 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2720 - acc: 0.8984 - val_loss: 0.9664 - val_acc: 0.7734\n",
      "chunk number: 817 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3169 - acc: 0.8772 - val_loss: 0.7011 - val_acc: 0.7422\n",
      "chunk number: 818 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3352 - acc: 0.8672 - val_loss: 0.5508 - val_acc: 0.7969\n",
      "chunk number: 819 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3017 - acc: 0.8828 - val_loss: 0.6548 - val_acc: 0.7656\n",
      "chunk number: 820 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3380 - acc: 0.8705 - val_loss: 0.5268 - val_acc: 0.8281\n",
      "chunk number: 821 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2683 - acc: 0.8984 - val_loss: 0.5118 - val_acc: 0.7891\n",
      "chunk number: 822 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2761 - acc: 0.8895 - val_loss: 0.6027 - val_acc: 0.7969\n",
      "chunk number: 823 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2678 - acc: 0.8951 - val_loss: 0.6773 - val_acc: 0.8047\n",
      "chunk number: 824 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2833 - acc: 0.8873 - val_loss: 0.7347 - val_acc: 0.7578\n",
      "chunk number: 825 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2232 - acc: 0.9208 - val_loss: 0.5638 - val_acc: 0.8047\n",
      "chunk number: 826 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2627 - acc: 0.9018 - val_loss: 0.8059 - val_acc: 0.7422\n",
      "chunk number: 827 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2519 - acc: 0.8951 - val_loss: 0.6665 - val_acc: 0.8125\n",
      "chunk number: 828 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2542 - acc: 0.8962 - val_loss: 0.6062 - val_acc: 0.8203\n",
      "chunk number: 829 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2593 - acc: 0.9051 - val_loss: 0.5753 - val_acc: 0.8438\n",
      "chunk number: 830 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2695 - acc: 0.8996 - val_loss: 0.9364 - val_acc: 0.7109\n",
      "chunk number: 831 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2931 - acc: 0.8906 - val_loss: 0.5955 - val_acc: 0.8047\n",
      "chunk number: 832 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3049 - acc: 0.8917 - val_loss: 0.5737 - val_acc: 0.8281\n",
      "chunk number: 833 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2790 - acc: 0.8984 - val_loss: 0.5691 - val_acc: 0.7969\n",
      "chunk number: 834 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3510 - acc: 0.8605 - val_loss: 0.8308 - val_acc: 0.7500\n",
      "chunk number: 835 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3037 - acc: 0.8862 - val_loss: 1.1065 - val_acc: 0.7422\n",
      "chunk number: 836 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2613 - acc: 0.9007 - val_loss: 0.5347 - val_acc: 0.7891\n",
      "chunk number: 837 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2697 - acc: 0.8973 - val_loss: 0.5481 - val_acc: 0.8203\n",
      "chunk number: 838 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2696 - acc: 0.8996 - val_loss: 0.7366 - val_acc: 0.7969\n",
      "chunk number: 839 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2472 - acc: 0.9040 - val_loss: 0.6968 - val_acc: 0.7969\n",
      "chunk number: 840 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2985 - acc: 0.8862 - val_loss: 0.7208 - val_acc: 0.7969\n",
      "chunk number: 841 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2839 - acc: 0.8940 - val_loss: 0.5573 - val_acc: 0.8359\n",
      "chunk number: 842 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3153 - acc: 0.8739 - val_loss: 0.7850 - val_acc: 0.7500\n",
      "chunk number: 843 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2943 - acc: 0.8929 - val_loss: 0.5857 - val_acc: 0.7734\n",
      "chunk number: 844 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3240 - acc: 0.8761 - val_loss: 0.7150 - val_acc: 0.8125\n",
      "chunk number: 845 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2980 - acc: 0.8750 - val_loss: 0.6000 - val_acc: 0.7891\n",
      "chunk number: 846 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3153 - acc: 0.8739 - val_loss: 0.5868 - val_acc: 0.7891\n",
      "chunk number: 847 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3122 - acc: 0.8728 - val_loss: 0.6912 - val_acc: 0.7969\n",
      "chunk number: 848 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3046 - acc: 0.8806 - val_loss: 0.8214 - val_acc: 0.7656\n",
      "chunk number: 849 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2696 - acc: 0.8828 - val_loss: 0.8494 - val_acc: 0.7891\n",
      "chunk number: 850 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2962 - acc: 0.8850 - val_loss: 0.7076 - val_acc: 0.7891\n",
      "chunk number: 851 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3262 - acc: 0.8728 - val_loss: 0.7880 - val_acc: 0.7422\n",
      "chunk number: 852 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2906 - acc: 0.8862 - val_loss: 0.6750 - val_acc: 0.7969\n",
      "chunk number: 853 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3438 - acc: 0.8772 - val_loss: 0.6596 - val_acc: 0.7812\n",
      "chunk number: 854 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3327 - acc: 0.8750 - val_loss: 0.5644 - val_acc: 0.8125\n",
      "chunk number: 855 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3451 - acc: 0.8549 - val_loss: 0.6096 - val_acc: 0.8203\n",
      "chunk number: 856 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3508 - acc: 0.8616 - val_loss: 0.6424 - val_acc: 0.7812\n",
      "chunk number: 857 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3228 - acc: 0.8728 - val_loss: 0.6328 - val_acc: 0.7969\n",
      "chunk number: 858 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2929 - acc: 0.8873 - val_loss: 0.4375 - val_acc: 0.8359\n",
      "chunk number: 859 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2720 - acc: 0.9074 - val_loss: 0.5722 - val_acc: 0.8359\n",
      "chunk number: 860 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3618 - acc: 0.8605 - val_loss: 0.6021 - val_acc: 0.7969\n",
      "chunk number: 861 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3208 - acc: 0.8806 - val_loss: 0.7299 - val_acc: 0.8438\n",
      "chunk number: 862 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3161 - acc: 0.8929 - val_loss: 0.5573 - val_acc: 0.7891\n",
      "chunk number: 863 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3133 - acc: 0.8828 - val_loss: 0.6582 - val_acc: 0.7891\n",
      "chunk number: 864 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2328 - acc: 0.9196 - val_loss: 0.8380 - val_acc: 0.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 865 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2980 - acc: 0.8906 - val_loss: 0.5241 - val_acc: 0.8047\n",
      "chunk number: 866 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2718 - acc: 0.8951 - val_loss: 0.7365 - val_acc: 0.7266\n",
      "chunk number: 867 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2455 - acc: 0.9074 - val_loss: 0.5061 - val_acc: 0.8203\n",
      "chunk number: 868 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2819 - acc: 0.8817 - val_loss: 0.9616 - val_acc: 0.7422\n",
      "chunk number: 869 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2813 - acc: 0.9085 - val_loss: 0.6632 - val_acc: 0.8125\n",
      "chunk number: 870 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2198 - acc: 0.9096 - val_loss: 0.7688 - val_acc: 0.7500\n",
      "chunk number: 871 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2337 - acc: 0.8984 - val_loss: 0.6282 - val_acc: 0.7812\n",
      "chunk number: 872 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2426 - acc: 0.9107 - val_loss: 0.8240 - val_acc: 0.8047\n",
      "chunk number: 873 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2053 - acc: 0.9230 - val_loss: 0.9966 - val_acc: 0.7891\n",
      "chunk number: 874 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2411 - acc: 0.9107 - val_loss: 0.8805 - val_acc: 0.6953\n",
      "chunk number: 875 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2593 - acc: 0.8984 - val_loss: 0.5625 - val_acc: 0.7969\n",
      "chunk number: 876 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2365 - acc: 0.9096 - val_loss: 0.5725 - val_acc: 0.7969\n",
      "chunk number: 877 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2295 - acc: 0.9129 - val_loss: 0.4801 - val_acc: 0.8359\n",
      "chunk number: 878 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2324 - acc: 0.9174 - val_loss: 0.9922 - val_acc: 0.7578\n",
      "chunk number: 879 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2436 - acc: 0.9141 - val_loss: 0.8146 - val_acc: 0.7656\n",
      "chunk number: 880 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2178 - acc: 0.9118 - val_loss: 0.6951 - val_acc: 0.8281\n",
      "chunk number: 881 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2805 - acc: 0.9018 - val_loss: 0.7334 - val_acc: 0.7891\n",
      "chunk number: 882 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2922 - acc: 0.8906 - val_loss: 0.4331 - val_acc: 0.8047\n",
      "chunk number: 883 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3285 - acc: 0.8772 - val_loss: 0.6194 - val_acc: 0.7266\n",
      "chunk number: 884 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3095 - acc: 0.8906 - val_loss: 0.6483 - val_acc: 0.7500\n",
      "chunk number: 885 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2714 - acc: 0.9018 - val_loss: 0.5045 - val_acc: 0.8359\n",
      "chunk number: 886 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2501 - acc: 0.9118 - val_loss: 0.5243 - val_acc: 0.8359\n",
      "chunk number: 887 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2576 - acc: 0.9074 - val_loss: 0.6765 - val_acc: 0.7734\n",
      "chunk number: 888 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2888 - acc: 0.8828 - val_loss: 0.4919 - val_acc: 0.8359\n",
      "chunk number: 889 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2714 - acc: 0.8895 - val_loss: 0.5369 - val_acc: 0.8281\n",
      "chunk number: 890 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2470 - acc: 0.9040 - val_loss: 0.8324 - val_acc: 0.7891\n",
      "chunk number: 891 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2566 - acc: 0.9074 - val_loss: 1.0284 - val_acc: 0.7266\n",
      "chunk number: 892 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2280 - acc: 0.9141 - val_loss: 0.6218 - val_acc: 0.7891\n",
      "chunk number: 893 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.1967 - acc: 0.9085 - val_loss: 0.8930 - val_acc: 0.7969\n",
      "chunk number: 894 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2664 - acc: 0.8962 - val_loss: 0.8052 - val_acc: 0.7031\n",
      "chunk number: 895 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3008 - acc: 0.8817 - val_loss: 0.6461 - val_acc: 0.7734\n",
      "chunk number: 896 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2888 - acc: 0.8806 - val_loss: 0.6999 - val_acc: 0.7891\n",
      "chunk number: 897 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2813 - acc: 0.8940 - val_loss: 0.6300 - val_acc: 0.7891\n",
      "chunk number: 898 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3147 - acc: 0.8728 - val_loss: 0.6980 - val_acc: 0.8281\n",
      "chunk number: 899 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2926 - acc: 0.8873 - val_loss: 0.4317 - val_acc: 0.8281\n",
      "chunk number: 900 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2944 - acc: 0.8839 - val_loss: 0.7463 - val_acc: 0.7578\n",
      "chunk number: 901 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2538 - acc: 0.9007 - val_loss: 0.3890 - val_acc: 0.8359\n",
      "chunk number: 902 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2839 - acc: 0.8973 - val_loss: 0.6750 - val_acc: 0.7422\n",
      "chunk number: 903 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2426 - acc: 0.9051 - val_loss: 0.6723 - val_acc: 0.8047\n",
      "chunk number: 904 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3118 - acc: 0.8862 - val_loss: 0.5491 - val_acc: 0.8047\n",
      "chunk number: 905 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2964 - acc: 0.8940 - val_loss: 0.7501 - val_acc: 0.7969\n",
      "chunk number: 906 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2598 - acc: 0.9051 - val_loss: 0.7319 - val_acc: 0.8203\n",
      "chunk number: 907 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2810 - acc: 0.8873 - val_loss: 0.5029 - val_acc: 0.8125\n",
      "chunk number: 908 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2385 - acc: 0.9163 - val_loss: 0.5889 - val_acc: 0.8203\n",
      "chunk number: 909 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2423 - acc: 0.9129 - val_loss: 0.8135 - val_acc: 0.7812\n",
      "chunk number: 910 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2465 - acc: 0.9118 - val_loss: 0.8075 - val_acc: 0.7969\n",
      "chunk number: 911 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2841 - acc: 0.8873 - val_loss: 0.5952 - val_acc: 0.7734\n",
      "chunk number: 912 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2717 - acc: 0.8906 - val_loss: 0.6539 - val_acc: 0.7891\n",
      "chunk number: 913 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2581 - acc: 0.8962 - val_loss: 0.7316 - val_acc: 0.7969\n",
      "chunk number: 914 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2939 - acc: 0.8828 - val_loss: 0.6116 - val_acc: 0.8281\n",
      "chunk number: 915 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2583 - acc: 0.8984 - val_loss: 0.8187 - val_acc: 0.7812\n",
      "chunk number: 916 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2426 - acc: 0.9051 - val_loss: 0.9673 - val_acc: 0.7656\n",
      "chunk number: 917 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2712 - acc: 0.8873 - val_loss: 0.7666 - val_acc: 0.8047\n",
      "chunk number: 918 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2472 - acc: 0.8951 - val_loss: 0.6852 - val_acc: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 919 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2526 - acc: 0.9074 - val_loss: 0.7551 - val_acc: 0.7812\n",
      "chunk number: 920 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2510 - acc: 0.9062 - val_loss: 0.6097 - val_acc: 0.8125\n",
      "chunk number: 921 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2424 - acc: 0.9174 - val_loss: 0.6293 - val_acc: 0.7969\n",
      "chunk number: 922 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2745 - acc: 0.9051 - val_loss: 0.6874 - val_acc: 0.7734\n",
      "chunk number: 923 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2471 - acc: 0.9074 - val_loss: 0.6448 - val_acc: 0.8281\n",
      "chunk number: 924 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2634 - acc: 0.8817 - val_loss: 0.8262 - val_acc: 0.7500\n",
      "chunk number: 925 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2384 - acc: 0.9118 - val_loss: 0.6384 - val_acc: 0.8125\n",
      "chunk number: 926 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2336 - acc: 0.8996 - val_loss: 0.7712 - val_acc: 0.7969\n",
      "chunk number: 927 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.1887 - acc: 0.9208 - val_loss: 0.6736 - val_acc: 0.8125\n",
      "chunk number: 928 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2358 - acc: 0.9040 - val_loss: 0.7559 - val_acc: 0.7812\n",
      "chunk number: 929 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2475 - acc: 0.9118 - val_loss: 0.6051 - val_acc: 0.8125\n",
      "chunk number: 930 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2316 - acc: 0.9085 - val_loss: 1.0000 - val_acc: 0.7422\n",
      "chunk number: 931 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2665 - acc: 0.9018 - val_loss: 0.7395 - val_acc: 0.7734\n",
      "chunk number: 932 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2217 - acc: 0.9174 - val_loss: 0.6090 - val_acc: 0.7891\n",
      "chunk number: 933 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2441 - acc: 0.9085 - val_loss: 0.7282 - val_acc: 0.7656\n",
      "chunk number: 934 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2777 - acc: 0.8951 - val_loss: 0.9980 - val_acc: 0.7578\n",
      "chunk number: 935 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2215 - acc: 0.9074 - val_loss: 1.1194 - val_acc: 0.7422\n",
      "chunk number: 936 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2459 - acc: 0.9118 - val_loss: 0.7673 - val_acc: 0.7656\n",
      "chunk number: 937 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2345 - acc: 0.9107 - val_loss: 0.5600 - val_acc: 0.7891\n",
      "chunk number: 938 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2239 - acc: 0.9096 - val_loss: 0.8518 - val_acc: 0.8203\n",
      "chunk number: 939 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2495 - acc: 0.8984 - val_loss: 0.7071 - val_acc: 0.7969\n",
      "chunk number: 940 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2464 - acc: 0.9062 - val_loss: 0.6796 - val_acc: 0.8438\n",
      "chunk number: 941 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2069 - acc: 0.9163 - val_loss: 0.6194 - val_acc: 0.8125\n",
      "chunk number: 942 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2725 - acc: 0.9007 - val_loss: 0.7882 - val_acc: 0.7656\n",
      "chunk number: 943 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2989 - acc: 0.8973 - val_loss: 0.7470 - val_acc: 0.7344\n",
      "chunk number: 944 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2628 - acc: 0.8940 - val_loss: 0.9293 - val_acc: 0.7812\n",
      "chunk number: 945 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2616 - acc: 0.8951 - val_loss: 0.6760 - val_acc: 0.7734\n",
      "chunk number: 946 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2645 - acc: 0.8929 - val_loss: 0.6485 - val_acc: 0.7656\n",
      "chunk number: 947 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2236 - acc: 0.9085 - val_loss: 0.8632 - val_acc: 0.8047\n",
      "chunk number: 948 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2613 - acc: 0.9018 - val_loss: 0.6702 - val_acc: 0.8047\n",
      "chunk number: 949 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2331 - acc: 0.9085 - val_loss: 0.9214 - val_acc: 0.7734\n",
      "chunk number: 950 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2823 - acc: 0.8917 - val_loss: 0.6060 - val_acc: 0.8281\n",
      "chunk number: 951 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2589 - acc: 0.8951 - val_loss: 0.6793 - val_acc: 0.7812\n",
      "chunk number: 952 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2468 - acc: 0.9051 - val_loss: 0.7365 - val_acc: 0.8047\n",
      "chunk number: 953 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2624 - acc: 0.8984 - val_loss: 0.7833 - val_acc: 0.7656\n",
      "chunk number: 954 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2745 - acc: 0.8817 - val_loss: 0.5228 - val_acc: 0.8203\n",
      "chunk number: 955 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2928 - acc: 0.8828 - val_loss: 0.6312 - val_acc: 0.7812\n",
      "chunk number: 956 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2664 - acc: 0.9007 - val_loss: 0.7300 - val_acc: 0.7734\n",
      "chunk number: 957 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2573 - acc: 0.9007 - val_loss: 0.7732 - val_acc: 0.7891\n",
      "chunk number: 958 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2367 - acc: 0.9085 - val_loss: 0.4370 - val_acc: 0.8672\n",
      "chunk number: 959 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2352 - acc: 0.9163 - val_loss: 0.7247 - val_acc: 0.8203\n",
      "chunk number: 960 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3375 - acc: 0.8739 - val_loss: 0.5902 - val_acc: 0.8203\n",
      "chunk number: 961 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3059 - acc: 0.8917 - val_loss: 0.8463 - val_acc: 0.8047\n",
      "chunk number: 962 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2787 - acc: 0.9007 - val_loss: 0.6024 - val_acc: 0.8203\n",
      "chunk number: 963 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2361 - acc: 0.9096 - val_loss: 0.7222 - val_acc: 0.7812\n",
      "chunk number: 964 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2064 - acc: 0.9208 - val_loss: 1.0616 - val_acc: 0.7500\n",
      "chunk number: 965 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2243 - acc: 0.9208 - val_loss: 0.5538 - val_acc: 0.7734\n",
      "chunk number: 966 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2326 - acc: 0.9208 - val_loss: 0.7922 - val_acc: 0.7188\n",
      "chunk number: 967 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2120 - acc: 0.9129 - val_loss: 0.5504 - val_acc: 0.7969\n",
      "chunk number: 968 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2033 - acc: 0.9196 - val_loss: 0.8921 - val_acc: 0.7656\n",
      "chunk number: 969 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2507 - acc: 0.8951 - val_loss: 0.7375 - val_acc: 0.7812\n",
      "chunk number: 970 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2270 - acc: 0.9185 - val_loss: 0.7071 - val_acc: 0.7969\n",
      "chunk number: 971 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2128 - acc: 0.9107 - val_loss: 0.6134 - val_acc: 0.8047\n",
      "chunk number: 972 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2010 - acc: 0.9152 - val_loss: 0.7516 - val_acc: 0.8203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 973 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.1840 - acc: 0.9196 - val_loss: 1.2360 - val_acc: 0.7812\n",
      "chunk number: 974 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.1788 - acc: 0.9342 - val_loss: 0.9288 - val_acc: 0.7578\n",
      "chunk number: 975 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2066 - acc: 0.9275 - val_loss: 0.6803 - val_acc: 0.8125\n",
      "chunk number: 976 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.1761 - acc: 0.9375 - val_loss: 0.8512 - val_acc: 0.7812\n",
      "chunk number: 977 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2723 - acc: 0.8940 - val_loss: 0.6590 - val_acc: 0.7656\n",
      "chunk number: 978 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2280 - acc: 0.9174 - val_loss: 1.1053 - val_acc: 0.7500\n",
      "chunk number: 979 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.1992 - acc: 0.9230 - val_loss: 0.9030 - val_acc: 0.7891\n",
      "chunk number: 980 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2018 - acc: 0.9185 - val_loss: 0.7557 - val_acc: 0.8125\n",
      "chunk number: 981 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2241 - acc: 0.9152 - val_loss: 0.9296 - val_acc: 0.7422\n",
      "chunk number: 982 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2265 - acc: 0.9185 - val_loss: 0.4985 - val_acc: 0.7891\n",
      "chunk number: 983 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2889 - acc: 0.8873 - val_loss: 0.6389 - val_acc: 0.7578\n",
      "chunk number: 984 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2430 - acc: 0.9062 - val_loss: 0.5604 - val_acc: 0.7969\n",
      "chunk number: 985 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2429 - acc: 0.9085 - val_loss: 0.6046 - val_acc: 0.7891\n",
      "chunk number: 986 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.1998 - acc: 0.9263 - val_loss: 0.5391 - val_acc: 0.8281\n",
      "chunk number: 987 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2150 - acc: 0.9252 - val_loss: 0.6759 - val_acc: 0.7656\n",
      "chunk number: 988 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2420 - acc: 0.9040 - val_loss: 0.5510 - val_acc: 0.8125\n",
      "chunk number: 989 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2104 - acc: 0.9163 - val_loss: 0.6053 - val_acc: 0.8281\n",
      "chunk number: 990 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2294 - acc: 0.9185 - val_loss: 0.7631 - val_acc: 0.7891\n",
      "chunk number: 991 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2328 - acc: 0.9141 - val_loss: 0.8963 - val_acc: 0.7109\n",
      "chunk number: 992 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.1853 - acc: 0.9252 - val_loss: 0.6368 - val_acc: 0.8125\n",
      "chunk number: 993 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2002 - acc: 0.9219 - val_loss: 0.9905 - val_acc: 0.7344\n",
      "chunk number: 994 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2144 - acc: 0.9152 - val_loss: 0.8670 - val_acc: 0.7656\n",
      "chunk number: 995 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2699 - acc: 0.9007 - val_loss: 0.6822 - val_acc: 0.8438\n",
      "chunk number: 996 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2924 - acc: 0.8917 - val_loss: 0.5753 - val_acc: 0.7812\n",
      "chunk number: 997 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2364 - acc: 0.9040 - val_loss: 0.8672 - val_acc: 0.7578\n",
      "chunk number: 998 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2547 - acc: 0.8917 - val_loss: 0.6702 - val_acc: 0.8203\n",
      "chunk number: 999 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2448 - acc: 0.9029 - val_loss: 0.4675 - val_acc: 0.8281\n",
      "chunk number: 1000 of 1000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2562 - acc: 0.9085 - val_loss: 0.8234 - val_acc: 0.7656\n"
     ]
    }
   ],
   "source": [
    "X_files = sorted(os.listdir(pickle_path + \"Spectra\"))\n",
    "y_files = sorted(os.listdir(pickle_path + \"Targets\"))\n",
    "\n",
    "num_chunks = len(y_files)\n",
    "iteration = 0\n",
    "\n",
    "acc=[]\n",
    "loss=[]\n",
    "\n",
    "val_loss=[]\n",
    "val_acc=[]\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for _ in range(num_epochs):\n",
    "    \n",
    "    for X_file, y_file in zip(X_files,y_files):\n",
    "\n",
    "        iteration +=1\n",
    "        print('chunk number: ' + str(iteration) + \" of \" + str(num_chunks*num_epochs))\n",
    "\n",
    "        X,y = Data_Gen(X_file, y_file, mean_log_amplitude)\n",
    "\n",
    "        history=model.fit(X, y, batch_size=128, epochs=1, validation_split=1/8, verbose = 2)\n",
    "\n",
    "        val_acc.append(history.history['val_acc'])\n",
    "        acc.append(history.history['acc'])\n",
    "        \n",
    "        loss.append(history.history['loss'])\n",
    "        val_loss.append(history.history['val_loss'])\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc02d812668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.plot(acc)\n",
    "plt.plot(val_acc, alpha=0.5)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss, alpha=0.5)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.subplots_adjust(right=1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few different model architectures have been tested but all yield the same results.  Clearly a generalization gap is occuring; more data is needed..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 -- DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since this is audio data one does not want to perform transformations that would significantly change the frequency domain; the frequency portion of the data is most important in classification. However tranformations in the temporal domain should lead to greater generalization; i.e. whether a sound clip starts a fraction of a second later or earlier shouldn't change its category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Data_Augment(data, threshold, h_shift_range):\n",
    "\n",
    "    for i in range(len(data[0])):\n",
    "        # Only apply         \n",
    "        if np.random.random() < threshold:\n",
    "            \n",
    "            # Randomize horizontal shift within the specified range\n",
    "            h_shift = np.random.randint(h_shift_range[0], h_shift_range[1]+1)\n",
    "            \n",
    "            # Apply horizontal shift to data\n",
    "            data[i,:,:]=np.roll(np.squeeze(data[i,:,:]), h_shift, axis=1)\n",
    "                                 \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The above function takes in a chunk of data and randomly applies a left or right horizontal shift to the data. The transformation is only applied when a randomly generated number between 0 and 1 is less than a given threshold. In this way the user can control how often to apply the transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns i-th chunk of X,y data at path.\n",
    "def Data_Gen(X_path, y_path, mean_log_amplitude, threshold, h_shift_range):\n",
    "\n",
    "    # X data\n",
    "    file = open(pickle_path + \"Spectra/\" + X_path, \"rb\")\n",
    "    X=pickle.load(file)\n",
    "    file.close()            \n",
    "       \n",
    "    X = np.log(X) - mean_log_amplitude    \n",
    "    X = Data_Augment(X, threshold, h_shift_range)\n",
    "    X = np.stack((X,), -1) \n",
    "    \n",
    "    \n",
    "    # y data\n",
    "    file = open(pickle_path + \"Targets/\" + y_path, \"rb\")\n",
    "    y=pickle.load(file)\n",
    "    file.close()\n",
    "    \n",
    "    y = keras.utils.np_utils.to_categorical(y)        \n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reinitialize model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(4, 4), strides=(1, 1), activation='relu', input_shape=(129,129,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (4, 4), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (4, 4), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going to try threshold = 0.5, i.e., 50% of the time a horizontal shift will be applied. The shift range will be +/-30 'pixels' to the left or right, or about +/- 23% of the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 1 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 4.3405 - acc: 0.1975 - val_loss: 1.7320 - val_acc: 0.3906\n",
      "chunk number: 2 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.6632 - acc: 0.3906 - val_loss: 1.4107 - val_acc: 0.4766\n",
      "chunk number: 3 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.3685 - acc: 0.4676 - val_loss: 1.3254 - val_acc: 0.4922\n",
      "chunk number: 4 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.2127 - acc: 0.5033 - val_loss: 1.1030 - val_acc: 0.5703\n",
      "chunk number: 5 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.2353 - acc: 0.4922 - val_loss: 1.2175 - val_acc: 0.5391\n",
      "chunk number: 6 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0746 - acc: 0.5792 - val_loss: 1.0764 - val_acc: 0.5234\n",
      "chunk number: 7 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1138 - acc: 0.5435 - val_loss: 1.1774 - val_acc: 0.5781\n",
      "chunk number: 8 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0930 - acc: 0.5792 - val_loss: 1.1228 - val_acc: 0.5234\n",
      "chunk number: 9 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0171 - acc: 0.6105 - val_loss: 0.9668 - val_acc: 0.6328\n",
      "chunk number: 10 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0455 - acc: 0.5926 - val_loss: 0.9168 - val_acc: 0.6406\n",
      "chunk number: 11 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0336 - acc: 0.5882 - val_loss: 0.9845 - val_acc: 0.6172\n",
      "chunk number: 12 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0044 - acc: 0.6038 - val_loss: 0.9065 - val_acc: 0.6719\n",
      "chunk number: 13 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9464 - acc: 0.6261 - val_loss: 0.9134 - val_acc: 0.6641\n",
      "chunk number: 14 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0836 - acc: 0.5737 - val_loss: 1.0268 - val_acc: 0.6016\n",
      "chunk number: 15 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9991 - acc: 0.6083 - val_loss: 0.8662 - val_acc: 0.6875\n",
      "chunk number: 16 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9201 - acc: 0.6451 - val_loss: 1.0354 - val_acc: 0.6016\n",
      "chunk number: 17 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9473 - acc: 0.6116 - val_loss: 0.8561 - val_acc: 0.6953\n",
      "chunk number: 18 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9499 - acc: 0.6172 - val_loss: 0.8841 - val_acc: 0.6953\n",
      "chunk number: 19 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9654 - acc: 0.6250 - val_loss: 0.9891 - val_acc: 0.5938\n",
      "chunk number: 20 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9574 - acc: 0.6239 - val_loss: 0.9338 - val_acc: 0.6328\n",
      "chunk number: 21 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8881 - acc: 0.6551 - val_loss: 0.9261 - val_acc: 0.6406\n",
      "chunk number: 22 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9208 - acc: 0.6217 - val_loss: 0.9735 - val_acc: 0.5859\n",
      "chunk number: 23 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8598 - acc: 0.6763 - val_loss: 0.8102 - val_acc: 0.7188\n",
      "chunk number: 24 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9147 - acc: 0.6239 - val_loss: 0.8621 - val_acc: 0.6406\n",
      "chunk number: 25 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8652 - acc: 0.6574 - val_loss: 0.9724 - val_acc: 0.6719\n",
      "chunk number: 26 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9193 - acc: 0.6105 - val_loss: 0.9762 - val_acc: 0.5859\n",
      "chunk number: 27 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8362 - acc: 0.6708 - val_loss: 0.7565 - val_acc: 0.6875\n",
      "chunk number: 28 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8955 - acc: 0.6462 - val_loss: 0.9192 - val_acc: 0.6484\n",
      "chunk number: 29 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9174 - acc: 0.6328 - val_loss: 0.8190 - val_acc: 0.7344\n",
      "chunk number: 30 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9119 - acc: 0.6440 - val_loss: 1.0449 - val_acc: 0.5781\n",
      "chunk number: 31 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8952 - acc: 0.6417 - val_loss: 0.8685 - val_acc: 0.6328\n",
      "chunk number: 32 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8814 - acc: 0.6417 - val_loss: 0.9104 - val_acc: 0.6484\n",
      "chunk number: 33 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8690 - acc: 0.6618 - val_loss: 0.7519 - val_acc: 0.6719\n",
      "chunk number: 34 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8635 - acc: 0.6496 - val_loss: 0.9131 - val_acc: 0.6562\n",
      "chunk number: 35 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8613 - acc: 0.6674 - val_loss: 0.8999 - val_acc: 0.6328\n",
      "chunk number: 36 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8823 - acc: 0.6496 - val_loss: 0.7844 - val_acc: 0.7031\n",
      "chunk number: 37 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8530 - acc: 0.6797 - val_loss: 0.8152 - val_acc: 0.6797\n",
      "chunk number: 38 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8718 - acc: 0.6484 - val_loss: 0.8209 - val_acc: 0.7109\n",
      "chunk number: 39 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8342 - acc: 0.6864 - val_loss: 0.7578 - val_acc: 0.7031\n",
      "chunk number: 40 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8650 - acc: 0.6696 - val_loss: 0.8026 - val_acc: 0.7266\n",
      "chunk number: 41 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8119 - acc: 0.6775 - val_loss: 0.8298 - val_acc: 0.6562\n",
      "chunk number: 42 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8401 - acc: 0.6931 - val_loss: 0.8204 - val_acc: 0.6641\n",
      "chunk number: 43 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8455 - acc: 0.6696 - val_loss: 0.7334 - val_acc: 0.7422\n",
      "chunk number: 44 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7716 - acc: 0.7042 - val_loss: 0.7655 - val_acc: 0.6953\n",
      "chunk number: 45 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8576 - acc: 0.6574 - val_loss: 0.7639 - val_acc: 0.7031\n",
      "chunk number: 46 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8223 - acc: 0.6875 - val_loss: 0.8208 - val_acc: 0.7031\n",
      "chunk number: 47 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7875 - acc: 0.7020 - val_loss: 0.8389 - val_acc: 0.6797\n",
      "chunk number: 48 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8810 - acc: 0.6518 - val_loss: 0.8860 - val_acc: 0.6719\n",
      "chunk number: 49 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7957 - acc: 0.6797 - val_loss: 0.8788 - val_acc: 0.6953\n",
      "chunk number: 50 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8714 - acc: 0.6641 - val_loss: 0.9289 - val_acc: 0.6875\n",
      "chunk number: 51 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8021 - acc: 0.6975 - val_loss: 0.8703 - val_acc: 0.6797\n",
      "chunk number: 52 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7819 - acc: 0.6975 - val_loss: 0.7803 - val_acc: 0.6875\n",
      "chunk number: 53 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8137 - acc: 0.6797 - val_loss: 0.8183 - val_acc: 0.6641\n",
      "chunk number: 54 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8247 - acc: 0.6953 - val_loss: 0.7520 - val_acc: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 55 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8125 - acc: 0.6942 - val_loss: 0.7760 - val_acc: 0.6953\n",
      "chunk number: 56 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8583 - acc: 0.6797 - val_loss: 0.7509 - val_acc: 0.7578\n",
      "chunk number: 57 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8538 - acc: 0.6551 - val_loss: 0.7783 - val_acc: 0.7031\n",
      "chunk number: 58 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7880 - acc: 0.7076 - val_loss: 0.6747 - val_acc: 0.7188\n",
      "chunk number: 59 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7659 - acc: 0.7031 - val_loss: 0.7691 - val_acc: 0.7422\n",
      "chunk number: 60 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8802 - acc: 0.6473 - val_loss: 0.8576 - val_acc: 0.6797\n",
      "chunk number: 61 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8257 - acc: 0.6830 - val_loss: 0.6949 - val_acc: 0.7578\n",
      "chunk number: 62 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7598 - acc: 0.7087 - val_loss: 0.6789 - val_acc: 0.7422\n",
      "chunk number: 63 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8463 - acc: 0.6629 - val_loss: 0.8800 - val_acc: 0.6016\n",
      "chunk number: 64 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7609 - acc: 0.7165 - val_loss: 0.8442 - val_acc: 0.6875\n",
      "chunk number: 65 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7884 - acc: 0.6998 - val_loss: 0.7498 - val_acc: 0.6953\n",
      "chunk number: 66 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8238 - acc: 0.6629 - val_loss: 0.7926 - val_acc: 0.6953\n",
      "chunk number: 67 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8063 - acc: 0.6819 - val_loss: 0.7876 - val_acc: 0.6641\n",
      "chunk number: 68 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8441 - acc: 0.6797 - val_loss: 0.9045 - val_acc: 0.6016\n",
      "chunk number: 69 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8170 - acc: 0.6730 - val_loss: 0.7628 - val_acc: 0.6875\n",
      "chunk number: 70 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8209 - acc: 0.6752 - val_loss: 1.0509 - val_acc: 0.6172\n",
      "chunk number: 71 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8081 - acc: 0.6741 - val_loss: 0.7828 - val_acc: 0.7422\n",
      "chunk number: 72 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7708 - acc: 0.7009 - val_loss: 0.8414 - val_acc: 0.6875\n",
      "chunk number: 73 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7705 - acc: 0.6942 - val_loss: 0.7849 - val_acc: 0.7188\n",
      "chunk number: 74 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7814 - acc: 0.6964 - val_loss: 0.9361 - val_acc: 0.6406\n",
      "chunk number: 75 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7893 - acc: 0.6864 - val_loss: 0.6784 - val_acc: 0.7344\n",
      "chunk number: 76 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7420 - acc: 0.7154 - val_loss: 0.7341 - val_acc: 0.7578\n",
      "chunk number: 77 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7330 - acc: 0.7277 - val_loss: 0.6709 - val_acc: 0.7812\n",
      "chunk number: 78 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7211 - acc: 0.7254 - val_loss: 0.9459 - val_acc: 0.6875\n",
      "chunk number: 79 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7621 - acc: 0.7109 - val_loss: 0.6909 - val_acc: 0.7188\n",
      "chunk number: 80 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7838 - acc: 0.7221 - val_loss: 0.7587 - val_acc: 0.7578\n",
      "chunk number: 81 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7631 - acc: 0.7009 - val_loss: 0.6255 - val_acc: 0.7656\n",
      "chunk number: 82 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7693 - acc: 0.7087 - val_loss: 0.8053 - val_acc: 0.6562\n",
      "chunk number: 83 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8243 - acc: 0.6786 - val_loss: 0.7669 - val_acc: 0.6641\n",
      "chunk number: 84 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7483 - acc: 0.7243 - val_loss: 0.6815 - val_acc: 0.7266\n",
      "chunk number: 85 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7563 - acc: 0.7188 - val_loss: 0.7562 - val_acc: 0.7109\n",
      "chunk number: 86 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7782 - acc: 0.6920 - val_loss: 0.7415 - val_acc: 0.7266\n",
      "chunk number: 87 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7879 - acc: 0.6975 - val_loss: 0.7966 - val_acc: 0.7188\n",
      "chunk number: 88 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8054 - acc: 0.6908 - val_loss: 0.6499 - val_acc: 0.7422\n",
      "chunk number: 89 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7541 - acc: 0.7098 - val_loss: 0.7825 - val_acc: 0.6875\n",
      "chunk number: 90 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8012 - acc: 0.6775 - val_loss: 0.6348 - val_acc: 0.7812\n",
      "chunk number: 91 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7704 - acc: 0.6875 - val_loss: 0.8097 - val_acc: 0.7188\n",
      "chunk number: 92 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7370 - acc: 0.6987 - val_loss: 0.6792 - val_acc: 0.7188\n",
      "chunk number: 93 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7416 - acc: 0.7143 - val_loss: 0.8737 - val_acc: 0.6406\n",
      "chunk number: 94 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7435 - acc: 0.7221 - val_loss: 0.7109 - val_acc: 0.7188\n",
      "chunk number: 95 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7020 - acc: 0.7210 - val_loss: 0.6779 - val_acc: 0.7344\n",
      "chunk number: 96 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7433 - acc: 0.7020 - val_loss: 0.6272 - val_acc: 0.7266\n",
      "chunk number: 97 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7228 - acc: 0.7087 - val_loss: 0.7935 - val_acc: 0.7031\n",
      "chunk number: 98 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7229 - acc: 0.7310 - val_loss: 0.7859 - val_acc: 0.7031\n",
      "chunk number: 99 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7252 - acc: 0.7310 - val_loss: 0.6295 - val_acc: 0.7656\n",
      "chunk number: 100 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7519 - acc: 0.7143 - val_loss: 0.7299 - val_acc: 0.7344\n",
      "chunk number: 101 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7007 - acc: 0.7388 - val_loss: 0.7450 - val_acc: 0.7266\n",
      "chunk number: 102 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7543 - acc: 0.7154 - val_loss: 0.7553 - val_acc: 0.6875\n",
      "chunk number: 103 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7032 - acc: 0.7121 - val_loss: 0.6851 - val_acc: 0.7344\n",
      "chunk number: 104 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6884 - acc: 0.7344 - val_loss: 0.6711 - val_acc: 0.7734\n",
      "chunk number: 105 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7628 - acc: 0.6998 - val_loss: 0.8723 - val_acc: 0.6641\n",
      "chunk number: 106 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7107 - acc: 0.7344 - val_loss: 0.7023 - val_acc: 0.7734\n",
      "chunk number: 107 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6986 - acc: 0.7388 - val_loss: 0.7299 - val_acc: 0.7266\n",
      "chunk number: 108 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7162 - acc: 0.7411 - val_loss: 0.6789 - val_acc: 0.7109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 109 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6943 - acc: 0.7433 - val_loss: 0.6524 - val_acc: 0.7266\n",
      "chunk number: 110 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7116 - acc: 0.7333 - val_loss: 0.7440 - val_acc: 0.7188\n",
      "chunk number: 111 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7649 - acc: 0.7042 - val_loss: 0.7591 - val_acc: 0.7266\n",
      "chunk number: 112 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7602 - acc: 0.6920 - val_loss: 0.6195 - val_acc: 0.7891\n",
      "chunk number: 113 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7062 - acc: 0.7266 - val_loss: 0.7248 - val_acc: 0.7266\n",
      "chunk number: 114 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7562 - acc: 0.7176 - val_loss: 0.6875 - val_acc: 0.7109\n",
      "chunk number: 115 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7311 - acc: 0.7254 - val_loss: 0.6903 - val_acc: 0.7500\n",
      "chunk number: 116 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6956 - acc: 0.7277 - val_loss: 0.8305 - val_acc: 0.6875\n",
      "chunk number: 117 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7219 - acc: 0.7344 - val_loss: 0.6865 - val_acc: 0.7031\n",
      "chunk number: 118 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7269 - acc: 0.7210 - val_loss: 0.7124 - val_acc: 0.7188\n",
      "chunk number: 119 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7181 - acc: 0.7221 - val_loss: 0.7987 - val_acc: 0.6328\n",
      "chunk number: 120 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7804 - acc: 0.7020 - val_loss: 0.7375 - val_acc: 0.7109\n",
      "chunk number: 121 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6821 - acc: 0.7377 - val_loss: 0.6720 - val_acc: 0.7500\n",
      "chunk number: 122 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7037 - acc: 0.7199 - val_loss: 0.7686 - val_acc: 0.6484\n",
      "chunk number: 123 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6871 - acc: 0.7522 - val_loss: 0.6138 - val_acc: 0.7656\n",
      "chunk number: 124 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7330 - acc: 0.7254 - val_loss: 0.7084 - val_acc: 0.7188\n",
      "chunk number: 125 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6511 - acc: 0.7478 - val_loss: 0.7426 - val_acc: 0.7344\n",
      "chunk number: 126 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7046 - acc: 0.7121 - val_loss: 0.8118 - val_acc: 0.7266\n",
      "chunk number: 127 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6867 - acc: 0.7243 - val_loss: 0.5839 - val_acc: 0.7969\n",
      "chunk number: 128 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7121 - acc: 0.7254 - val_loss: 0.7201 - val_acc: 0.7188\n",
      "chunk number: 129 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7077 - acc: 0.7444 - val_loss: 0.6703 - val_acc: 0.7812\n",
      "chunk number: 130 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7295 - acc: 0.7154 - val_loss: 0.8858 - val_acc: 0.6875\n",
      "chunk number: 131 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7345 - acc: 0.7165 - val_loss: 0.7394 - val_acc: 0.6562\n",
      "chunk number: 132 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7351 - acc: 0.7232 - val_loss: 0.7482 - val_acc: 0.7266\n",
      "chunk number: 133 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7231 - acc: 0.7266 - val_loss: 0.6003 - val_acc: 0.7422\n",
      "chunk number: 134 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7062 - acc: 0.7288 - val_loss: 0.7006 - val_acc: 0.7266\n",
      "chunk number: 135 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7483 - acc: 0.7221 - val_loss: 0.8245 - val_acc: 0.6875\n",
      "chunk number: 136 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7040 - acc: 0.7277 - val_loss: 0.6321 - val_acc: 0.7578\n",
      "chunk number: 137 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7189 - acc: 0.7366 - val_loss: 0.6156 - val_acc: 0.8125\n",
      "chunk number: 138 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7069 - acc: 0.7344 - val_loss: 0.7208 - val_acc: 0.7812\n",
      "chunk number: 139 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6953 - acc: 0.7478 - val_loss: 0.5977 - val_acc: 0.7812\n",
      "chunk number: 140 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7213 - acc: 0.7199 - val_loss: 0.6461 - val_acc: 0.7266\n",
      "chunk number: 141 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6908 - acc: 0.7299 - val_loss: 0.7449 - val_acc: 0.7344\n",
      "chunk number: 142 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6936 - acc: 0.7388 - val_loss: 0.7834 - val_acc: 0.6641\n",
      "chunk number: 143 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7123 - acc: 0.7199 - val_loss: 0.6032 - val_acc: 0.7500\n",
      "chunk number: 144 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6657 - acc: 0.7533 - val_loss: 0.6586 - val_acc: 0.7578\n",
      "chunk number: 145 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7174 - acc: 0.7165 - val_loss: 0.5995 - val_acc: 0.7266\n",
      "chunk number: 146 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7249 - acc: 0.7199 - val_loss: 0.7466 - val_acc: 0.7500\n",
      "chunk number: 147 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6266 - acc: 0.7623 - val_loss: 0.6583 - val_acc: 0.7578\n",
      "chunk number: 148 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7194 - acc: 0.7266 - val_loss: 0.7700 - val_acc: 0.7422\n",
      "chunk number: 149 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6557 - acc: 0.7344 - val_loss: 0.7762 - val_acc: 0.7266\n",
      "chunk number: 150 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7128 - acc: 0.7098 - val_loss: 0.7588 - val_acc: 0.7188\n",
      "chunk number: 151 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6915 - acc: 0.7321 - val_loss: 0.7317 - val_acc: 0.7031\n",
      "chunk number: 152 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6659 - acc: 0.7522 - val_loss: 0.6177 - val_acc: 0.7344\n",
      "chunk number: 153 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7108 - acc: 0.7277 - val_loss: 0.7062 - val_acc: 0.7266\n",
      "chunk number: 154 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7125 - acc: 0.7154 - val_loss: 0.6387 - val_acc: 0.7891\n",
      "chunk number: 155 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7059 - acc: 0.7355 - val_loss: 0.6244 - val_acc: 0.7578\n",
      "chunk number: 156 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7483 - acc: 0.7188 - val_loss: 0.6977 - val_acc: 0.6953\n",
      "chunk number: 157 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7046 - acc: 0.7321 - val_loss: 0.7105 - val_acc: 0.7031\n",
      "chunk number: 158 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6632 - acc: 0.7366 - val_loss: 0.5820 - val_acc: 0.7891\n",
      "chunk number: 159 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6557 - acc: 0.7489 - val_loss: 0.5922 - val_acc: 0.7578\n",
      "chunk number: 160 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7484 - acc: 0.7176 - val_loss: 0.6759 - val_acc: 0.7500\n",
      "chunk number: 161 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6612 - acc: 0.7366 - val_loss: 0.6021 - val_acc: 0.7891\n",
      "chunk number: 162 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6922 - acc: 0.7310 - val_loss: 0.6363 - val_acc: 0.7188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 163 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7109 - acc: 0.7221 - val_loss: 0.7946 - val_acc: 0.7188\n",
      "chunk number: 164 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6260 - acc: 0.7801 - val_loss: 0.7196 - val_acc: 0.7109\n",
      "chunk number: 165 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7211 - acc: 0.7254 - val_loss: 0.6279 - val_acc: 0.7188\n",
      "chunk number: 166 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7045 - acc: 0.7076 - val_loss: 0.6833 - val_acc: 0.7422\n",
      "chunk number: 167 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7085 - acc: 0.7243 - val_loss: 0.6878 - val_acc: 0.7109\n",
      "chunk number: 168 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7162 - acc: 0.7288 - val_loss: 0.7479 - val_acc: 0.7422\n",
      "chunk number: 169 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7281 - acc: 0.7154 - val_loss: 0.6325 - val_acc: 0.7578\n",
      "chunk number: 170 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7027 - acc: 0.7254 - val_loss: 0.7728 - val_acc: 0.7344\n",
      "chunk number: 171 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6407 - acc: 0.7478 - val_loss: 0.6846 - val_acc: 0.7031\n",
      "chunk number: 172 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6388 - acc: 0.7556 - val_loss: 0.7021 - val_acc: 0.7812\n",
      "chunk number: 173 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6290 - acc: 0.7467 - val_loss: 0.7440 - val_acc: 0.7422\n",
      "chunk number: 174 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6714 - acc: 0.7511 - val_loss: 0.7845 - val_acc: 0.7109\n",
      "chunk number: 175 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6669 - acc: 0.7433 - val_loss: 0.5589 - val_acc: 0.7891\n",
      "chunk number: 176 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6632 - acc: 0.7589 - val_loss: 0.6752 - val_acc: 0.7734\n",
      "chunk number: 177 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6704 - acc: 0.7422 - val_loss: 0.6658 - val_acc: 0.7188\n",
      "chunk number: 178 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6706 - acc: 0.7388 - val_loss: 0.8590 - val_acc: 0.6953\n",
      "chunk number: 179 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6565 - acc: 0.7511 - val_loss: 0.5491 - val_acc: 0.8125\n",
      "chunk number: 180 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6590 - acc: 0.7623 - val_loss: 0.6635 - val_acc: 0.7422\n",
      "chunk number: 181 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6573 - acc: 0.7489 - val_loss: 0.5647 - val_acc: 0.7422\n",
      "chunk number: 182 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6565 - acc: 0.7656 - val_loss: 0.5779 - val_acc: 0.7812\n",
      "chunk number: 183 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7146 - acc: 0.7221 - val_loss: 0.6629 - val_acc: 0.7188\n",
      "chunk number: 184 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6451 - acc: 0.7623 - val_loss: 0.5935 - val_acc: 0.7500\n",
      "chunk number: 185 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6872 - acc: 0.7377 - val_loss: 0.5978 - val_acc: 0.7578\n",
      "chunk number: 186 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6853 - acc: 0.7299 - val_loss: 0.6333 - val_acc: 0.7969\n",
      "chunk number: 187 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6831 - acc: 0.7433 - val_loss: 0.7703 - val_acc: 0.7188\n",
      "chunk number: 188 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6956 - acc: 0.7355 - val_loss: 0.5689 - val_acc: 0.7578\n",
      "chunk number: 189 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6773 - acc: 0.7511 - val_loss: 0.6395 - val_acc: 0.7500\n",
      "chunk number: 190 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6645 - acc: 0.7545 - val_loss: 0.5441 - val_acc: 0.7578\n",
      "chunk number: 191 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6707 - acc: 0.7411 - val_loss: 0.7001 - val_acc: 0.7578\n",
      "chunk number: 192 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6390 - acc: 0.7400 - val_loss: 0.6076 - val_acc: 0.7422\n",
      "chunk number: 193 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6270 - acc: 0.7478 - val_loss: 0.7817 - val_acc: 0.6953\n",
      "chunk number: 194 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6941 - acc: 0.7333 - val_loss: 0.7111 - val_acc: 0.7422\n",
      "chunk number: 195 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6411 - acc: 0.7634 - val_loss: 0.5830 - val_acc: 0.7656\n",
      "chunk number: 196 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6760 - acc: 0.7422 - val_loss: 0.5970 - val_acc: 0.7344\n",
      "chunk number: 197 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6909 - acc: 0.7254 - val_loss: 0.6232 - val_acc: 0.7891\n",
      "chunk number: 198 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6972 - acc: 0.7232 - val_loss: 0.7129 - val_acc: 0.7578\n",
      "chunk number: 199 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6551 - acc: 0.7377 - val_loss: 0.6062 - val_acc: 0.7812\n",
      "chunk number: 200 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6823 - acc: 0.7433 - val_loss: 0.6308 - val_acc: 0.7188\n",
      "chunk number: 201 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6566 - acc: 0.7645 - val_loss: 0.6854 - val_acc: 0.7109\n",
      "chunk number: 202 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6898 - acc: 0.7333 - val_loss: 0.7594 - val_acc: 0.7031\n",
      "chunk number: 203 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6980 - acc: 0.6987 - val_loss: 0.5947 - val_acc: 0.7656\n",
      "chunk number: 204 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6258 - acc: 0.7422 - val_loss: 0.6544 - val_acc: 0.7500\n",
      "chunk number: 205 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6688 - acc: 0.7411 - val_loss: 0.7352 - val_acc: 0.7188\n",
      "chunk number: 206 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6108 - acc: 0.7589 - val_loss: 0.7088 - val_acc: 0.7109\n",
      "chunk number: 207 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6587 - acc: 0.7455 - val_loss: 0.6406 - val_acc: 0.7500\n",
      "chunk number: 208 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6339 - acc: 0.7634 - val_loss: 0.5757 - val_acc: 0.7734\n",
      "chunk number: 209 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6485 - acc: 0.7522 - val_loss: 0.5892 - val_acc: 0.7578\n",
      "chunk number: 210 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6292 - acc: 0.7790 - val_loss: 0.6142 - val_acc: 0.7891\n",
      "chunk number: 211 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6828 - acc: 0.7266 - val_loss: 0.6922 - val_acc: 0.7578\n",
      "chunk number: 212 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6510 - acc: 0.7411 - val_loss: 0.6226 - val_acc: 0.7188\n",
      "chunk number: 213 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6359 - acc: 0.7578 - val_loss: 0.6880 - val_acc: 0.7422\n",
      "chunk number: 214 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6792 - acc: 0.7444 - val_loss: 0.5653 - val_acc: 0.7969\n",
      "chunk number: 215 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6405 - acc: 0.7623 - val_loss: 0.6494 - val_acc: 0.7422\n",
      "chunk number: 216 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6006 - acc: 0.7600 - val_loss: 0.7934 - val_acc: 0.6797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 217 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6456 - acc: 0.7645 - val_loss: 0.5816 - val_acc: 0.8125\n",
      "chunk number: 218 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6475 - acc: 0.7567 - val_loss: 0.6463 - val_acc: 0.7266\n",
      "chunk number: 219 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6471 - acc: 0.7545 - val_loss: 0.6842 - val_acc: 0.6953\n",
      "chunk number: 220 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6742 - acc: 0.7388 - val_loss: 0.6604 - val_acc: 0.7812\n",
      "chunk number: 221 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6088 - acc: 0.7746 - val_loss: 0.6078 - val_acc: 0.7578\n",
      "chunk number: 222 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6617 - acc: 0.7444 - val_loss: 0.7011 - val_acc: 0.7109\n",
      "chunk number: 223 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6124 - acc: 0.7801 - val_loss: 0.5918 - val_acc: 0.7812\n",
      "chunk number: 224 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6992 - acc: 0.7288 - val_loss: 0.6447 - val_acc: 0.7734\n",
      "chunk number: 225 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6274 - acc: 0.7679 - val_loss: 0.7418 - val_acc: 0.7578\n",
      "chunk number: 226 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6618 - acc: 0.7366 - val_loss: 0.7451 - val_acc: 0.7656\n",
      "chunk number: 227 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6730 - acc: 0.7210 - val_loss: 0.5860 - val_acc: 0.8203\n",
      "chunk number: 228 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6639 - acc: 0.7411 - val_loss: 0.6871 - val_acc: 0.7266\n",
      "chunk number: 229 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6538 - acc: 0.7533 - val_loss: 0.6729 - val_acc: 0.7578\n",
      "chunk number: 230 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6461 - acc: 0.7556 - val_loss: 0.7912 - val_acc: 0.7031\n",
      "chunk number: 231 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6527 - acc: 0.7533 - val_loss: 0.6709 - val_acc: 0.7578\n",
      "chunk number: 232 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6680 - acc: 0.7444 - val_loss: 0.7221 - val_acc: 0.7031\n",
      "chunk number: 233 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6705 - acc: 0.7299 - val_loss: 0.5685 - val_acc: 0.7812\n",
      "chunk number: 234 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6729 - acc: 0.7433 - val_loss: 0.6654 - val_acc: 0.7500\n",
      "chunk number: 235 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6538 - acc: 0.7623 - val_loss: 0.7425 - val_acc: 0.7109\n",
      "chunk number: 236 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6722 - acc: 0.7478 - val_loss: 0.6373 - val_acc: 0.7578\n",
      "chunk number: 237 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6616 - acc: 0.7589 - val_loss: 0.5977 - val_acc: 0.8047\n",
      "chunk number: 238 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6201 - acc: 0.7712 - val_loss: 0.6209 - val_acc: 0.7969\n",
      "chunk number: 239 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6823 - acc: 0.7433 - val_loss: 0.6922 - val_acc: 0.7734\n",
      "chunk number: 240 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6802 - acc: 0.7411 - val_loss: 0.6340 - val_acc: 0.7344\n",
      "chunk number: 241 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6196 - acc: 0.7656 - val_loss: 0.6956 - val_acc: 0.7188\n",
      "chunk number: 242 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6278 - acc: 0.7746 - val_loss: 0.6876 - val_acc: 0.6953\n",
      "chunk number: 243 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6611 - acc: 0.7388 - val_loss: 0.6104 - val_acc: 0.7578\n",
      "chunk number: 244 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6002 - acc: 0.7801 - val_loss: 0.6927 - val_acc: 0.7500\n",
      "chunk number: 245 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6511 - acc: 0.7422 - val_loss: 0.5747 - val_acc: 0.7578\n",
      "chunk number: 246 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6569 - acc: 0.7656 - val_loss: 0.7515 - val_acc: 0.7109\n",
      "chunk number: 247 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5902 - acc: 0.7734 - val_loss: 0.6535 - val_acc: 0.7344\n",
      "chunk number: 248 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6374 - acc: 0.7489 - val_loss: 0.7953 - val_acc: 0.7500\n",
      "chunk number: 249 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6116 - acc: 0.7612 - val_loss: 0.6932 - val_acc: 0.7266\n",
      "chunk number: 250 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6966 - acc: 0.7310 - val_loss: 0.7228 - val_acc: 0.7266\n",
      "chunk number: 251 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6582 - acc: 0.7400 - val_loss: 0.6689 - val_acc: 0.7578\n",
      "chunk number: 252 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6065 - acc: 0.7679 - val_loss: 0.5908 - val_acc: 0.7422\n",
      "chunk number: 253 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6591 - acc: 0.7444 - val_loss: 0.6658 - val_acc: 0.7422\n",
      "chunk number: 254 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6510 - acc: 0.7444 - val_loss: 0.5224 - val_acc: 0.8047\n",
      "chunk number: 255 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6277 - acc: 0.7578 - val_loss: 0.5433 - val_acc: 0.7891\n",
      "chunk number: 256 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6448 - acc: 0.7444 - val_loss: 0.6177 - val_acc: 0.7422\n",
      "chunk number: 257 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6458 - acc: 0.7578 - val_loss: 0.5740 - val_acc: 0.7812\n",
      "chunk number: 258 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5860 - acc: 0.7857 - val_loss: 0.5439 - val_acc: 0.7969\n",
      "chunk number: 259 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5972 - acc: 0.7600 - val_loss: 0.5562 - val_acc: 0.8047\n",
      "chunk number: 260 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7128 - acc: 0.7165 - val_loss: 0.6569 - val_acc: 0.7188\n",
      "chunk number: 261 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6413 - acc: 0.7567 - val_loss: 0.5569 - val_acc: 0.8047\n",
      "chunk number: 262 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6167 - acc: 0.7835 - val_loss: 0.5035 - val_acc: 0.8125\n",
      "chunk number: 263 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6167 - acc: 0.7545 - val_loss: 0.7729 - val_acc: 0.7188\n",
      "chunk number: 264 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5994 - acc: 0.7612 - val_loss: 0.6276 - val_acc: 0.7578\n",
      "chunk number: 265 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6603 - acc: 0.7545 - val_loss: 0.5576 - val_acc: 0.7734\n",
      "chunk number: 266 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6407 - acc: 0.7455 - val_loss: 0.6939 - val_acc: 0.7266\n",
      "chunk number: 267 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6435 - acc: 0.7467 - val_loss: 0.5886 - val_acc: 0.7734\n",
      "chunk number: 268 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6725 - acc: 0.7422 - val_loss: 0.7116 - val_acc: 0.7188\n",
      "chunk number: 269 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6662 - acc: 0.7422 - val_loss: 0.5765 - val_acc: 0.7812\n",
      "chunk number: 270 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6461 - acc: 0.7578 - val_loss: 0.7139 - val_acc: 0.7578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 271 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5812 - acc: 0.7734 - val_loss: 0.6185 - val_acc: 0.7656\n",
      "chunk number: 272 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6399 - acc: 0.7600 - val_loss: 0.7043 - val_acc: 0.7266\n",
      "chunk number: 273 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5961 - acc: 0.7946 - val_loss: 0.6424 - val_acc: 0.7656\n",
      "chunk number: 274 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6183 - acc: 0.7455 - val_loss: 0.7511 - val_acc: 0.7422\n",
      "chunk number: 275 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6481 - acc: 0.7455 - val_loss: 0.5345 - val_acc: 0.7891\n",
      "chunk number: 276 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5918 - acc: 0.7835 - val_loss: 0.5901 - val_acc: 0.7500\n",
      "chunk number: 277 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6028 - acc: 0.7679 - val_loss: 0.6417 - val_acc: 0.7656\n",
      "chunk number: 278 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6258 - acc: 0.7489 - val_loss: 0.7703 - val_acc: 0.7500\n",
      "chunk number: 279 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6244 - acc: 0.7645 - val_loss: 0.5414 - val_acc: 0.8047\n",
      "chunk number: 280 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6224 - acc: 0.7712 - val_loss: 0.5945 - val_acc: 0.7656\n",
      "chunk number: 281 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5721 - acc: 0.7656 - val_loss: 0.5134 - val_acc: 0.8281\n",
      "chunk number: 282 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6300 - acc: 0.7556 - val_loss: 0.5442 - val_acc: 0.7578\n",
      "chunk number: 283 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6552 - acc: 0.7489 - val_loss: 0.5759 - val_acc: 0.7500\n",
      "chunk number: 284 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5741 - acc: 0.7779 - val_loss: 0.5644 - val_acc: 0.7656\n",
      "chunk number: 285 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6014 - acc: 0.7779 - val_loss: 0.5528 - val_acc: 0.7422\n",
      "chunk number: 286 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6171 - acc: 0.7600 - val_loss: 0.5651 - val_acc: 0.7734\n",
      "chunk number: 287 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6055 - acc: 0.7723 - val_loss: 0.6554 - val_acc: 0.7656\n",
      "chunk number: 288 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6328 - acc: 0.7489 - val_loss: 0.5076 - val_acc: 0.7812\n",
      "chunk number: 289 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5965 - acc: 0.7667 - val_loss: 0.6239 - val_acc: 0.7812\n",
      "chunk number: 290 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5906 - acc: 0.7656 - val_loss: 0.5828 - val_acc: 0.7500\n",
      "chunk number: 291 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6229 - acc: 0.7690 - val_loss: 0.6175 - val_acc: 0.8047\n",
      "chunk number: 292 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5932 - acc: 0.7768 - val_loss: 0.5696 - val_acc: 0.7734\n",
      "chunk number: 293 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5835 - acc: 0.7600 - val_loss: 0.6330 - val_acc: 0.7656\n",
      "chunk number: 294 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5782 - acc: 0.7690 - val_loss: 0.6221 - val_acc: 0.7734\n",
      "chunk number: 295 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5213 - acc: 0.8069 - val_loss: 0.4919 - val_acc: 0.8281\n",
      "chunk number: 296 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6224 - acc: 0.7533 - val_loss: 0.5169 - val_acc: 0.8047\n",
      "chunk number: 297 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6010 - acc: 0.7589 - val_loss: 0.4932 - val_acc: 0.8438\n",
      "chunk number: 298 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6111 - acc: 0.7612 - val_loss: 0.6770 - val_acc: 0.7422\n",
      "chunk number: 299 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5964 - acc: 0.7701 - val_loss: 0.5093 - val_acc: 0.8125\n",
      "chunk number: 300 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6133 - acc: 0.7500 - val_loss: 0.5847 - val_acc: 0.7500\n",
      "chunk number: 301 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5584 - acc: 0.7768 - val_loss: 0.5260 - val_acc: 0.7891\n",
      "chunk number: 302 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6314 - acc: 0.7545 - val_loss: 0.6240 - val_acc: 0.8047\n",
      "chunk number: 303 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5935 - acc: 0.7545 - val_loss: 0.5422 - val_acc: 0.7734\n",
      "chunk number: 304 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5926 - acc: 0.7679 - val_loss: 0.5820 - val_acc: 0.7891\n",
      "chunk number: 305 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6708 - acc: 0.7511 - val_loss: 0.7067 - val_acc: 0.7500\n",
      "chunk number: 306 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5870 - acc: 0.7701 - val_loss: 0.7029 - val_acc: 0.7422\n",
      "chunk number: 307 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5836 - acc: 0.7790 - val_loss: 0.6243 - val_acc: 0.7734\n",
      "chunk number: 308 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5864 - acc: 0.7734 - val_loss: 0.6119 - val_acc: 0.7656\n",
      "chunk number: 309 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5846 - acc: 0.7667 - val_loss: 0.5745 - val_acc: 0.7422\n",
      "chunk number: 310 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5943 - acc: 0.7757 - val_loss: 0.6560 - val_acc: 0.7422\n",
      "chunk number: 311 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6649 - acc: 0.7467 - val_loss: 0.6766 - val_acc: 0.7422\n",
      "chunk number: 312 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6359 - acc: 0.7455 - val_loss: 0.5640 - val_acc: 0.7969\n",
      "chunk number: 313 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6075 - acc: 0.7679 - val_loss: 0.7048 - val_acc: 0.7734\n",
      "chunk number: 314 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6529 - acc: 0.7522 - val_loss: 0.5732 - val_acc: 0.7656\n",
      "chunk number: 315 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6146 - acc: 0.7656 - val_loss: 0.6047 - val_acc: 0.7734\n",
      "chunk number: 316 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5555 - acc: 0.7902 - val_loss: 0.6743 - val_acc: 0.7344\n",
      "chunk number: 317 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6084 - acc: 0.7567 - val_loss: 0.5700 - val_acc: 0.8125\n",
      "chunk number: 318 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6121 - acc: 0.7779 - val_loss: 0.5984 - val_acc: 0.7891\n",
      "chunk number: 319 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5768 - acc: 0.7801 - val_loss: 0.5910 - val_acc: 0.7266\n",
      "chunk number: 320 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6096 - acc: 0.7667 - val_loss: 0.6418 - val_acc: 0.7344\n",
      "chunk number: 321 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5792 - acc: 0.7779 - val_loss: 0.4793 - val_acc: 0.8203\n",
      "chunk number: 322 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5878 - acc: 0.7612 - val_loss: 0.6403 - val_acc: 0.7734\n",
      "chunk number: 323 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5796 - acc: 0.7902 - val_loss: 0.6474 - val_acc: 0.7812\n",
      "chunk number: 324 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6286 - acc: 0.7623 - val_loss: 0.5963 - val_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 325 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5359 - acc: 0.7879 - val_loss: 0.5799 - val_acc: 0.8125\n",
      "chunk number: 326 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5850 - acc: 0.7746 - val_loss: 0.6665 - val_acc: 0.7422\n",
      "chunk number: 327 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5782 - acc: 0.7734 - val_loss: 0.4914 - val_acc: 0.8281\n",
      "chunk number: 328 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5553 - acc: 0.7980 - val_loss: 0.6364 - val_acc: 0.7656\n",
      "chunk number: 329 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5960 - acc: 0.7824 - val_loss: 0.5551 - val_acc: 0.7969\n",
      "chunk number: 330 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5898 - acc: 0.7734 - val_loss: 0.7005 - val_acc: 0.7031\n",
      "chunk number: 331 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5883 - acc: 0.7734 - val_loss: 0.6483 - val_acc: 0.7344\n",
      "chunk number: 332 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6169 - acc: 0.7656 - val_loss: 0.6914 - val_acc: 0.7344\n",
      "chunk number: 333 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5887 - acc: 0.7790 - val_loss: 0.4735 - val_acc: 0.8047\n",
      "chunk number: 334 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5991 - acc: 0.7667 - val_loss: 0.6447 - val_acc: 0.7656\n",
      "chunk number: 335 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5817 - acc: 0.7623 - val_loss: 0.6543 - val_acc: 0.7422\n",
      "chunk number: 336 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5697 - acc: 0.7667 - val_loss: 0.4726 - val_acc: 0.8125\n",
      "chunk number: 337 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5661 - acc: 0.7846 - val_loss: 0.4667 - val_acc: 0.8203\n",
      "chunk number: 338 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5620 - acc: 0.8013 - val_loss: 0.5937 - val_acc: 0.7891\n",
      "chunk number: 339 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5837 - acc: 0.7701 - val_loss: 0.6086 - val_acc: 0.7422\n",
      "chunk number: 340 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5980 - acc: 0.7746 - val_loss: 0.5704 - val_acc: 0.7266\n",
      "chunk number: 341 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5487 - acc: 0.7857 - val_loss: 0.5828 - val_acc: 0.7969\n",
      "chunk number: 342 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5514 - acc: 0.7969 - val_loss: 0.6455 - val_acc: 0.7578\n",
      "chunk number: 343 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5615 - acc: 0.7801 - val_loss: 0.5596 - val_acc: 0.7969\n",
      "chunk number: 344 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5709 - acc: 0.7801 - val_loss: 0.5917 - val_acc: 0.7500\n",
      "chunk number: 345 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5916 - acc: 0.7667 - val_loss: 0.5690 - val_acc: 0.7656\n",
      "chunk number: 346 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5960 - acc: 0.7701 - val_loss: 0.7061 - val_acc: 0.7734\n",
      "chunk number: 347 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5905 - acc: 0.7846 - val_loss: 0.6420 - val_acc: 0.7188\n",
      "chunk number: 348 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5896 - acc: 0.7801 - val_loss: 0.6804 - val_acc: 0.7734\n",
      "chunk number: 349 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5692 - acc: 0.7857 - val_loss: 0.6178 - val_acc: 0.7656\n",
      "chunk number: 350 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6179 - acc: 0.7589 - val_loss: 0.7134 - val_acc: 0.7266\n",
      "chunk number: 351 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5819 - acc: 0.7667 - val_loss: 0.6544 - val_acc: 0.7422\n",
      "chunk number: 352 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5496 - acc: 0.7812 - val_loss: 0.5297 - val_acc: 0.7656\n",
      "chunk number: 353 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5838 - acc: 0.7757 - val_loss: 0.6204 - val_acc: 0.7891\n",
      "chunk number: 354 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5990 - acc: 0.7690 - val_loss: 0.5214 - val_acc: 0.8203\n",
      "chunk number: 355 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5627 - acc: 0.7879 - val_loss: 0.4972 - val_acc: 0.8125\n",
      "chunk number: 356 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5991 - acc: 0.7812 - val_loss: 0.5669 - val_acc: 0.7422\n",
      "chunk number: 357 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6054 - acc: 0.7578 - val_loss: 0.5714 - val_acc: 0.7812\n",
      "chunk number: 358 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5273 - acc: 0.8002 - val_loss: 0.5617 - val_acc: 0.7812\n",
      "chunk number: 359 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5316 - acc: 0.8103 - val_loss: 0.5449 - val_acc: 0.8203\n",
      "chunk number: 360 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6488 - acc: 0.7533 - val_loss: 0.5571 - val_acc: 0.7656\n",
      "chunk number: 361 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5501 - acc: 0.8080 - val_loss: 0.5015 - val_acc: 0.8281\n",
      "chunk number: 362 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5723 - acc: 0.8002 - val_loss: 0.4527 - val_acc: 0.8203\n",
      "chunk number: 363 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5650 - acc: 0.7891 - val_loss: 0.5888 - val_acc: 0.7500\n",
      "chunk number: 364 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5225 - acc: 0.7946 - val_loss: 0.5641 - val_acc: 0.7344\n",
      "chunk number: 365 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5927 - acc: 0.7567 - val_loss: 0.5731 - val_acc: 0.7656\n",
      "chunk number: 366 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5812 - acc: 0.7824 - val_loss: 0.6434 - val_acc: 0.7734\n",
      "chunk number: 367 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5324 - acc: 0.8147 - val_loss: 0.5846 - val_acc: 0.7812\n",
      "chunk number: 368 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6139 - acc: 0.7489 - val_loss: 0.6097 - val_acc: 0.7891\n",
      "chunk number: 369 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6267 - acc: 0.7467 - val_loss: 0.5422 - val_acc: 0.7578\n",
      "chunk number: 370 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5909 - acc: 0.7846 - val_loss: 0.6965 - val_acc: 0.7344\n",
      "chunk number: 371 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5435 - acc: 0.7902 - val_loss: 0.4714 - val_acc: 0.7812\n",
      "chunk number: 372 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5748 - acc: 0.7768 - val_loss: 0.6620 - val_acc: 0.7500\n",
      "chunk number: 373 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5229 - acc: 0.8058 - val_loss: 0.6414 - val_acc: 0.7266\n",
      "chunk number: 374 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5959 - acc: 0.7746 - val_loss: 0.6482 - val_acc: 0.7734\n",
      "chunk number: 375 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5629 - acc: 0.7667 - val_loss: 0.5195 - val_acc: 0.7891\n",
      "chunk number: 376 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5495 - acc: 0.7790 - val_loss: 0.5524 - val_acc: 0.7891\n",
      "chunk number: 377 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5288 - acc: 0.7969 - val_loss: 0.5884 - val_acc: 0.7812\n",
      "chunk number: 378 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5885 - acc: 0.7746 - val_loss: 0.7876 - val_acc: 0.7188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 379 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5549 - acc: 0.7958 - val_loss: 0.4998 - val_acc: 0.7969\n",
      "chunk number: 380 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5580 - acc: 0.7980 - val_loss: 0.5183 - val_acc: 0.8047\n",
      "chunk number: 381 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5414 - acc: 0.7891 - val_loss: 0.5001 - val_acc: 0.8125\n",
      "chunk number: 382 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5413 - acc: 0.7868 - val_loss: 0.4511 - val_acc: 0.8203\n",
      "chunk number: 383 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5940 - acc: 0.7656 - val_loss: 0.5553 - val_acc: 0.7891\n",
      "chunk number: 384 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5584 - acc: 0.7835 - val_loss: 0.5475 - val_acc: 0.7656\n",
      "chunk number: 385 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5474 - acc: 0.7980 - val_loss: 0.5029 - val_acc: 0.8047\n",
      "chunk number: 386 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5785 - acc: 0.7846 - val_loss: 0.4936 - val_acc: 0.7891\n",
      "chunk number: 387 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5726 - acc: 0.8013 - val_loss: 0.6735 - val_acc: 0.7578\n",
      "chunk number: 388 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5782 - acc: 0.7846 - val_loss: 0.5126 - val_acc: 0.7656\n",
      "chunk number: 389 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5744 - acc: 0.7824 - val_loss: 0.5357 - val_acc: 0.8047\n",
      "chunk number: 390 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5508 - acc: 0.7935 - val_loss: 0.5424 - val_acc: 0.7578\n",
      "chunk number: 391 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5772 - acc: 0.7701 - val_loss: 0.5940 - val_acc: 0.8047\n",
      "chunk number: 392 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5694 - acc: 0.7790 - val_loss: 0.5988 - val_acc: 0.7891\n",
      "chunk number: 393 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5186 - acc: 0.7891 - val_loss: 0.6730 - val_acc: 0.7500\n",
      "chunk number: 394 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5559 - acc: 0.7857 - val_loss: 0.5488 - val_acc: 0.7812\n",
      "chunk number: 395 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5016 - acc: 0.8103 - val_loss: 0.4758 - val_acc: 0.8203\n",
      "chunk number: 396 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6231 - acc: 0.7589 - val_loss: 0.4593 - val_acc: 0.8203\n",
      "chunk number: 397 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5894 - acc: 0.7790 - val_loss: 0.4999 - val_acc: 0.8203\n",
      "chunk number: 398 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5800 - acc: 0.7701 - val_loss: 0.5912 - val_acc: 0.7656\n",
      "chunk number: 399 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5626 - acc: 0.7790 - val_loss: 0.4764 - val_acc: 0.8203\n",
      "chunk number: 400 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5523 - acc: 0.7846 - val_loss: 0.5232 - val_acc: 0.7891\n",
      "chunk number: 401 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5129 - acc: 0.7969 - val_loss: 0.4979 - val_acc: 0.8281\n",
      "chunk number: 402 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5706 - acc: 0.7779 - val_loss: 0.6108 - val_acc: 0.7500\n",
      "chunk number: 403 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5483 - acc: 0.7857 - val_loss: 0.5468 - val_acc: 0.7812\n",
      "chunk number: 404 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5959 - acc: 0.7679 - val_loss: 0.5692 - val_acc: 0.8047\n",
      "chunk number: 405 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5866 - acc: 0.7801 - val_loss: 0.6767 - val_acc: 0.7812\n",
      "chunk number: 406 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5202 - acc: 0.7946 - val_loss: 0.6634 - val_acc: 0.7812\n",
      "chunk number: 407 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5679 - acc: 0.7891 - val_loss: 0.5834 - val_acc: 0.7969\n",
      "chunk number: 408 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5236 - acc: 0.7969 - val_loss: 0.5071 - val_acc: 0.7891\n",
      "chunk number: 409 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5397 - acc: 0.8025 - val_loss: 0.5447 - val_acc: 0.7969\n",
      "chunk number: 410 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5520 - acc: 0.7902 - val_loss: 0.5211 - val_acc: 0.7969\n",
      "chunk number: 411 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5884 - acc: 0.7734 - val_loss: 0.5815 - val_acc: 0.7891\n",
      "chunk number: 412 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5654 - acc: 0.7757 - val_loss: 0.4496 - val_acc: 0.8125\n",
      "chunk number: 413 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5099 - acc: 0.8025 - val_loss: 0.6318 - val_acc: 0.7578\n",
      "chunk number: 414 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6099 - acc: 0.7623 - val_loss: 0.4860 - val_acc: 0.8203\n",
      "chunk number: 415 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5649 - acc: 0.7835 - val_loss: 0.6018 - val_acc: 0.7656\n",
      "chunk number: 416 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5465 - acc: 0.7868 - val_loss: 0.6559 - val_acc: 0.7500\n",
      "chunk number: 417 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5587 - acc: 0.7824 - val_loss: 0.5980 - val_acc: 0.7734\n",
      "chunk number: 418 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5430 - acc: 0.7980 - val_loss: 0.5487 - val_acc: 0.7734\n",
      "chunk number: 419 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5400 - acc: 0.7924 - val_loss: 0.5969 - val_acc: 0.7344\n",
      "chunk number: 420 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5529 - acc: 0.7879 - val_loss: 0.5441 - val_acc: 0.8516\n",
      "chunk number: 421 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5131 - acc: 0.7946 - val_loss: 0.4478 - val_acc: 0.8281\n",
      "chunk number: 422 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5322 - acc: 0.7958 - val_loss: 0.4988 - val_acc: 0.7891\n",
      "chunk number: 423 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5029 - acc: 0.8304 - val_loss: 0.5234 - val_acc: 0.8203\n",
      "chunk number: 424 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5713 - acc: 0.7824 - val_loss: 0.5438 - val_acc: 0.8047\n",
      "chunk number: 425 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5028 - acc: 0.8080 - val_loss: 0.5242 - val_acc: 0.8047\n",
      "chunk number: 426 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5231 - acc: 0.7924 - val_loss: 0.6778 - val_acc: 0.7500\n",
      "chunk number: 427 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5279 - acc: 0.7980 - val_loss: 0.4438 - val_acc: 0.8516\n",
      "chunk number: 428 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5355 - acc: 0.7991 - val_loss: 0.6097 - val_acc: 0.7891\n",
      "chunk number: 429 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5440 - acc: 0.7868 - val_loss: 0.4757 - val_acc: 0.8047\n",
      "chunk number: 430 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5460 - acc: 0.7913 - val_loss: 0.6614 - val_acc: 0.7656\n",
      "chunk number: 431 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5540 - acc: 0.7768 - val_loss: 0.5641 - val_acc: 0.8125\n",
      "chunk number: 432 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5463 - acc: 0.7924 - val_loss: 0.6128 - val_acc: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 433 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5404 - acc: 0.7879 - val_loss: 0.5154 - val_acc: 0.7812\n",
      "chunk number: 434 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5574 - acc: 0.7879 - val_loss: 0.5757 - val_acc: 0.7500\n",
      "chunk number: 435 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5644 - acc: 0.7812 - val_loss: 0.6792 - val_acc: 0.7188\n",
      "chunk number: 436 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5366 - acc: 0.7958 - val_loss: 0.4971 - val_acc: 0.7812\n",
      "chunk number: 437 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5408 - acc: 0.8002 - val_loss: 0.4774 - val_acc: 0.8047\n",
      "chunk number: 438 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5342 - acc: 0.8025 - val_loss: 0.6830 - val_acc: 0.7656\n",
      "chunk number: 439 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5616 - acc: 0.7891 - val_loss: 0.6336 - val_acc: 0.7656\n",
      "chunk number: 440 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6097 - acc: 0.7612 - val_loss: 0.5246 - val_acc: 0.7891\n",
      "chunk number: 441 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5351 - acc: 0.7891 - val_loss: 0.5523 - val_acc: 0.7969\n",
      "chunk number: 442 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5298 - acc: 0.7879 - val_loss: 0.5536 - val_acc: 0.7812\n",
      "chunk number: 443 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5233 - acc: 0.7924 - val_loss: 0.4979 - val_acc: 0.7891\n",
      "chunk number: 444 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5381 - acc: 0.8103 - val_loss: 0.5987 - val_acc: 0.7656\n",
      "chunk number: 445 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5247 - acc: 0.7902 - val_loss: 0.4980 - val_acc: 0.7891\n",
      "chunk number: 446 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5555 - acc: 0.8103 - val_loss: 0.6758 - val_acc: 0.7656\n",
      "chunk number: 447 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5153 - acc: 0.7969 - val_loss: 0.6668 - val_acc: 0.7188\n",
      "chunk number: 448 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5691 - acc: 0.7857 - val_loss: 0.5960 - val_acc: 0.7812\n",
      "chunk number: 449 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4955 - acc: 0.8103 - val_loss: 0.5979 - val_acc: 0.7969\n",
      "chunk number: 450 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5873 - acc: 0.7634 - val_loss: 0.5624 - val_acc: 0.7969\n",
      "chunk number: 451 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5726 - acc: 0.7824 - val_loss: 0.6879 - val_acc: 0.7891\n",
      "chunk number: 452 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4884 - acc: 0.7980 - val_loss: 0.5316 - val_acc: 0.8047\n",
      "chunk number: 453 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5575 - acc: 0.7824 - val_loss: 0.5761 - val_acc: 0.7578\n",
      "chunk number: 454 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5502 - acc: 0.7969 - val_loss: 0.4890 - val_acc: 0.8203\n",
      "chunk number: 455 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5201 - acc: 0.8047 - val_loss: 0.4610 - val_acc: 0.8047\n",
      "chunk number: 456 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5574 - acc: 0.7846 - val_loss: 0.5725 - val_acc: 0.7891\n",
      "chunk number: 457 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5512 - acc: 0.7835 - val_loss: 0.5119 - val_acc: 0.7656\n",
      "chunk number: 458 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5229 - acc: 0.8125 - val_loss: 0.4614 - val_acc: 0.8516\n",
      "chunk number: 459 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5498 - acc: 0.7935 - val_loss: 0.4663 - val_acc: 0.8281\n",
      "chunk number: 460 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6078 - acc: 0.7835 - val_loss: 0.4921 - val_acc: 0.8047\n",
      "chunk number: 461 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5156 - acc: 0.8047 - val_loss: 0.5424 - val_acc: 0.7891\n",
      "chunk number: 462 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5293 - acc: 0.8069 - val_loss: 0.4478 - val_acc: 0.8359\n",
      "chunk number: 463 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5445 - acc: 0.7879 - val_loss: 0.6316 - val_acc: 0.7266\n",
      "chunk number: 464 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4707 - acc: 0.8170 - val_loss: 0.5088 - val_acc: 0.8125\n",
      "chunk number: 465 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5490 - acc: 0.7924 - val_loss: 0.4935 - val_acc: 0.7734\n",
      "chunk number: 466 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5379 - acc: 0.7879 - val_loss: 0.6421 - val_acc: 0.7812\n",
      "chunk number: 467 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5073 - acc: 0.8114 - val_loss: 0.5164 - val_acc: 0.7812\n",
      "chunk number: 468 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5486 - acc: 0.7746 - val_loss: 0.6126 - val_acc: 0.7891\n",
      "chunk number: 469 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5724 - acc: 0.7868 - val_loss: 0.5158 - val_acc: 0.7812\n",
      "chunk number: 470 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5512 - acc: 0.7913 - val_loss: 0.6302 - val_acc: 0.7734\n",
      "chunk number: 471 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4917 - acc: 0.8013 - val_loss: 0.5165 - val_acc: 0.7656\n",
      "chunk number: 472 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5540 - acc: 0.7935 - val_loss: 0.6780 - val_acc: 0.7578\n",
      "chunk number: 473 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4985 - acc: 0.8192 - val_loss: 0.6314 - val_acc: 0.7734\n",
      "chunk number: 474 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5083 - acc: 0.7969 - val_loss: 0.7234 - val_acc: 0.7500\n",
      "chunk number: 475 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5393 - acc: 0.7969 - val_loss: 0.5330 - val_acc: 0.7891\n",
      "chunk number: 476 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5284 - acc: 0.7991 - val_loss: 0.5585 - val_acc: 0.7969\n",
      "chunk number: 477 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5271 - acc: 0.7902 - val_loss: 0.5244 - val_acc: 0.7891\n",
      "chunk number: 478 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5435 - acc: 0.7991 - val_loss: 0.7267 - val_acc: 0.7266\n",
      "chunk number: 479 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5083 - acc: 0.8047 - val_loss: 0.4107 - val_acc: 0.8203\n",
      "chunk number: 480 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5276 - acc: 0.8136 - val_loss: 0.5450 - val_acc: 0.8047\n",
      "chunk number: 481 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5208 - acc: 0.8103 - val_loss: 0.4996 - val_acc: 0.8047\n",
      "chunk number: 482 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5112 - acc: 0.8036 - val_loss: 0.5061 - val_acc: 0.7891\n",
      "chunk number: 483 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5670 - acc: 0.7946 - val_loss: 0.5157 - val_acc: 0.7969\n",
      "chunk number: 484 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4929 - acc: 0.8114 - val_loss: 0.4991 - val_acc: 0.7891\n",
      "chunk number: 485 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5331 - acc: 0.7902 - val_loss: 0.4447 - val_acc: 0.7812\n",
      "chunk number: 486 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5365 - acc: 0.8025 - val_loss: 0.4634 - val_acc: 0.7969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 487 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5431 - acc: 0.8013 - val_loss: 0.5375 - val_acc: 0.7891\n",
      "chunk number: 488 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5739 - acc: 0.7645 - val_loss: 0.4272 - val_acc: 0.8359\n",
      "chunk number: 489 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5220 - acc: 0.8047 - val_loss: 0.4788 - val_acc: 0.8047\n",
      "chunk number: 490 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5330 - acc: 0.8025 - val_loss: 0.5006 - val_acc: 0.8047\n",
      "chunk number: 491 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5628 - acc: 0.7824 - val_loss: 0.5801 - val_acc: 0.8125\n",
      "chunk number: 492 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5412 - acc: 0.7790 - val_loss: 0.4721 - val_acc: 0.8047\n",
      "chunk number: 493 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4806 - acc: 0.8047 - val_loss: 0.6145 - val_acc: 0.7656\n",
      "chunk number: 494 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5035 - acc: 0.7980 - val_loss: 0.5484 - val_acc: 0.8047\n",
      "chunk number: 495 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4857 - acc: 0.8114 - val_loss: 0.4800 - val_acc: 0.8125\n",
      "chunk number: 496 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5330 - acc: 0.7857 - val_loss: 0.4580 - val_acc: 0.7891\n",
      "chunk number: 497 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5172 - acc: 0.7891 - val_loss: 0.4160 - val_acc: 0.8672\n",
      "chunk number: 498 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5103 - acc: 0.7913 - val_loss: 0.5020 - val_acc: 0.7969\n",
      "chunk number: 499 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5058 - acc: 0.7991 - val_loss: 0.4248 - val_acc: 0.8281\n",
      "chunk number: 500 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5015 - acc: 0.8192 - val_loss: 0.4934 - val_acc: 0.7969\n",
      "chunk number: 501 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4832 - acc: 0.8147 - val_loss: 0.4923 - val_acc: 0.8203\n",
      "chunk number: 502 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5330 - acc: 0.7958 - val_loss: 0.6010 - val_acc: 0.7656\n",
      "chunk number: 503 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5222 - acc: 0.7946 - val_loss: 0.4756 - val_acc: 0.8516\n",
      "chunk number: 504 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5024 - acc: 0.8103 - val_loss: 0.5012 - val_acc: 0.8281\n",
      "chunk number: 505 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5280 - acc: 0.7991 - val_loss: 0.5858 - val_acc: 0.7656\n",
      "chunk number: 506 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4916 - acc: 0.8103 - val_loss: 0.5483 - val_acc: 0.8125\n",
      "chunk number: 507 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4948 - acc: 0.8013 - val_loss: 0.5766 - val_acc: 0.7734\n",
      "chunk number: 508 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4981 - acc: 0.7958 - val_loss: 0.4365 - val_acc: 0.8828\n",
      "chunk number: 509 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4476 - acc: 0.8393 - val_loss: 0.4682 - val_acc: 0.8125\n",
      "chunk number: 510 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5299 - acc: 0.8025 - val_loss: 0.5613 - val_acc: 0.7656\n",
      "chunk number: 511 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5845 - acc: 0.7790 - val_loss: 0.6389 - val_acc: 0.7656\n",
      "chunk number: 512 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5976 - acc: 0.7846 - val_loss: 0.5980 - val_acc: 0.7734\n",
      "chunk number: 513 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5332 - acc: 0.7891 - val_loss: 0.5295 - val_acc: 0.7891\n",
      "chunk number: 514 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5546 - acc: 0.7857 - val_loss: 0.4887 - val_acc: 0.8438\n",
      "chunk number: 515 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5592 - acc: 0.7902 - val_loss: 0.5773 - val_acc: 0.7734\n",
      "chunk number: 516 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4939 - acc: 0.8069 - val_loss: 0.6389 - val_acc: 0.7578\n",
      "chunk number: 517 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5304 - acc: 0.7902 - val_loss: 0.5494 - val_acc: 0.7656\n",
      "chunk number: 518 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5079 - acc: 0.8047 - val_loss: 0.5083 - val_acc: 0.8281\n",
      "chunk number: 519 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5084 - acc: 0.8025 - val_loss: 0.5493 - val_acc: 0.7656\n",
      "chunk number: 520 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5584 - acc: 0.7768 - val_loss: 0.5233 - val_acc: 0.8203\n",
      "chunk number: 521 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4991 - acc: 0.8092 - val_loss: 0.4756 - val_acc: 0.7891\n",
      "chunk number: 522 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5446 - acc: 0.7779 - val_loss: 0.4709 - val_acc: 0.7812\n",
      "chunk number: 523 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4975 - acc: 0.8170 - val_loss: 0.5076 - val_acc: 0.8359\n",
      "chunk number: 524 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5341 - acc: 0.7924 - val_loss: 0.5242 - val_acc: 0.8047\n",
      "chunk number: 525 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4685 - acc: 0.8125 - val_loss: 0.4646 - val_acc: 0.8359\n",
      "chunk number: 526 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5198 - acc: 0.7902 - val_loss: 0.6385 - val_acc: 0.7812\n",
      "chunk number: 527 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4851 - acc: 0.8136 - val_loss: 0.3938 - val_acc: 0.8906\n",
      "chunk number: 528 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4838 - acc: 0.8080 - val_loss: 0.5755 - val_acc: 0.8203\n",
      "chunk number: 529 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5345 - acc: 0.7980 - val_loss: 0.5199 - val_acc: 0.7891\n",
      "chunk number: 530 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5153 - acc: 0.7991 - val_loss: 0.6013 - val_acc: 0.7344\n",
      "chunk number: 531 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5469 - acc: 0.7857 - val_loss: 0.5890 - val_acc: 0.7578\n",
      "chunk number: 532 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5860 - acc: 0.7879 - val_loss: 0.5923 - val_acc: 0.7500\n",
      "chunk number: 533 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5339 - acc: 0.7924 - val_loss: 0.4266 - val_acc: 0.8359\n",
      "chunk number: 534 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5396 - acc: 0.7824 - val_loss: 0.6076 - val_acc: 0.7891\n",
      "chunk number: 535 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5478 - acc: 0.7835 - val_loss: 0.6344 - val_acc: 0.7578\n",
      "chunk number: 536 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5288 - acc: 0.7924 - val_loss: 0.5539 - val_acc: 0.7812\n",
      "chunk number: 537 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5179 - acc: 0.7902 - val_loss: 0.4647 - val_acc: 0.8281\n",
      "chunk number: 538 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4875 - acc: 0.8237 - val_loss: 0.5632 - val_acc: 0.7969\n",
      "chunk number: 539 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5443 - acc: 0.7879 - val_loss: 0.5437 - val_acc: 0.8047\n",
      "chunk number: 540 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5937 - acc: 0.7857 - val_loss: 0.5182 - val_acc: 0.8281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 541 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4960 - acc: 0.8170 - val_loss: 0.4871 - val_acc: 0.8047\n",
      "chunk number: 542 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5026 - acc: 0.8069 - val_loss: 0.5508 - val_acc: 0.7578\n",
      "chunk number: 543 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4976 - acc: 0.8158 - val_loss: 0.4467 - val_acc: 0.8203\n",
      "chunk number: 544 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4653 - acc: 0.8214 - val_loss: 0.5299 - val_acc: 0.7812\n",
      "chunk number: 545 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5108 - acc: 0.7946 - val_loss: 0.4502 - val_acc: 0.8203\n",
      "chunk number: 546 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5008 - acc: 0.8214 - val_loss: 0.6300 - val_acc: 0.7969\n",
      "chunk number: 547 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4856 - acc: 0.8181 - val_loss: 0.6073 - val_acc: 0.7812\n",
      "chunk number: 548 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4993 - acc: 0.8058 - val_loss: 0.6589 - val_acc: 0.7656\n",
      "chunk number: 549 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4824 - acc: 0.8136 - val_loss: 0.6303 - val_acc: 0.7969\n",
      "chunk number: 550 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5573 - acc: 0.7868 - val_loss: 0.6517 - val_acc: 0.7656\n",
      "chunk number: 551 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5261 - acc: 0.7958 - val_loss: 0.5303 - val_acc: 0.8281\n",
      "chunk number: 552 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4736 - acc: 0.8125 - val_loss: 0.4759 - val_acc: 0.8281\n",
      "chunk number: 553 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5203 - acc: 0.8025 - val_loss: 0.6215 - val_acc: 0.7734\n",
      "chunk number: 554 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5319 - acc: 0.7980 - val_loss: 0.4531 - val_acc: 0.8281\n",
      "chunk number: 555 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4902 - acc: 0.8136 - val_loss: 0.4004 - val_acc: 0.8281\n",
      "chunk number: 556 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5404 - acc: 0.7946 - val_loss: 0.5289 - val_acc: 0.7578\n",
      "chunk number: 557 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5269 - acc: 0.8002 - val_loss: 0.4661 - val_acc: 0.8047\n",
      "chunk number: 558 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4828 - acc: 0.8248 - val_loss: 0.4256 - val_acc: 0.8516\n",
      "chunk number: 559 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4914 - acc: 0.8092 - val_loss: 0.4066 - val_acc: 0.8516\n",
      "chunk number: 560 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5938 - acc: 0.7790 - val_loss: 0.4992 - val_acc: 0.7969\n",
      "chunk number: 561 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5232 - acc: 0.8080 - val_loss: 0.4855 - val_acc: 0.8438\n",
      "chunk number: 562 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4910 - acc: 0.8259 - val_loss: 0.3909 - val_acc: 0.8516\n",
      "chunk number: 563 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5100 - acc: 0.8047 - val_loss: 0.6263 - val_acc: 0.7734\n",
      "chunk number: 564 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4511 - acc: 0.8270 - val_loss: 0.5968 - val_acc: 0.7656\n",
      "chunk number: 565 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5204 - acc: 0.7935 - val_loss: 0.5408 - val_acc: 0.7734\n",
      "chunk number: 566 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5110 - acc: 0.8013 - val_loss: 0.6225 - val_acc: 0.7656\n",
      "chunk number: 567 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4699 - acc: 0.8203 - val_loss: 0.5629 - val_acc: 0.7578\n",
      "chunk number: 568 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5217 - acc: 0.7801 - val_loss: 0.5942 - val_acc: 0.7969\n",
      "chunk number: 569 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5560 - acc: 0.7980 - val_loss: 0.4591 - val_acc: 0.8125\n",
      "chunk number: 570 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5213 - acc: 0.8013 - val_loss: 0.6406 - val_acc: 0.8203\n",
      "chunk number: 571 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5151 - acc: 0.7946 - val_loss: 0.4849 - val_acc: 0.8281\n",
      "chunk number: 572 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5471 - acc: 0.7946 - val_loss: 0.6085 - val_acc: 0.7500\n",
      "chunk number: 573 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4640 - acc: 0.8259 - val_loss: 0.6511 - val_acc: 0.7500\n",
      "chunk number: 574 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4958 - acc: 0.8125 - val_loss: 0.6171 - val_acc: 0.7422\n",
      "chunk number: 575 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4964 - acc: 0.8080 - val_loss: 0.4896 - val_acc: 0.7891\n",
      "chunk number: 576 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4553 - acc: 0.8304 - val_loss: 0.5414 - val_acc: 0.8125\n",
      "chunk number: 577 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4834 - acc: 0.8036 - val_loss: 0.5150 - val_acc: 0.8125\n",
      "chunk number: 578 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5242 - acc: 0.8025 - val_loss: 0.6557 - val_acc: 0.7578\n",
      "chunk number: 579 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4731 - acc: 0.8248 - val_loss: 0.4478 - val_acc: 0.8438\n",
      "chunk number: 580 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5034 - acc: 0.8170 - val_loss: 0.4661 - val_acc: 0.8438\n",
      "chunk number: 581 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5114 - acc: 0.8025 - val_loss: 0.4229 - val_acc: 0.8516\n",
      "chunk number: 582 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4625 - acc: 0.8237 - val_loss: 0.4145 - val_acc: 0.8203\n",
      "chunk number: 583 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5140 - acc: 0.8047 - val_loss: 0.4644 - val_acc: 0.8047\n",
      "chunk number: 584 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4982 - acc: 0.8047 - val_loss: 0.4941 - val_acc: 0.7812\n",
      "chunk number: 585 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4928 - acc: 0.8214 - val_loss: 0.4771 - val_acc: 0.8281\n",
      "chunk number: 586 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4942 - acc: 0.8237 - val_loss: 0.4599 - val_acc: 0.8047\n",
      "chunk number: 587 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5161 - acc: 0.8036 - val_loss: 0.5431 - val_acc: 0.8281\n",
      "chunk number: 588 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4800 - acc: 0.8058 - val_loss: 0.4468 - val_acc: 0.8203\n",
      "chunk number: 589 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4820 - acc: 0.8170 - val_loss: 0.4705 - val_acc: 0.8281\n",
      "chunk number: 590 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4851 - acc: 0.8036 - val_loss: 0.5059 - val_acc: 0.7891\n",
      "chunk number: 591 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4719 - acc: 0.8147 - val_loss: 0.5438 - val_acc: 0.8047\n",
      "chunk number: 592 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5227 - acc: 0.7902 - val_loss: 0.4974 - val_acc: 0.8047\n",
      "chunk number: 593 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4531 - acc: 0.8281 - val_loss: 0.5910 - val_acc: 0.7656\n",
      "chunk number: 594 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4835 - acc: 0.8114 - val_loss: 0.5329 - val_acc: 0.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 595 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4631 - acc: 0.8192 - val_loss: 0.4811 - val_acc: 0.8125\n",
      "chunk number: 596 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5271 - acc: 0.7980 - val_loss: 0.4218 - val_acc: 0.8125\n",
      "chunk number: 597 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4919 - acc: 0.8013 - val_loss: 0.4572 - val_acc: 0.8359\n",
      "chunk number: 598 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5109 - acc: 0.8036 - val_loss: 0.4645 - val_acc: 0.8281\n",
      "chunk number: 599 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4790 - acc: 0.8069 - val_loss: 0.4302 - val_acc: 0.8594\n",
      "chunk number: 600 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4729 - acc: 0.8281 - val_loss: 0.4973 - val_acc: 0.8203\n",
      "chunk number: 601 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4630 - acc: 0.8292 - val_loss: 0.3674 - val_acc: 0.8672\n",
      "chunk number: 602 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5365 - acc: 0.7835 - val_loss: 0.5685 - val_acc: 0.7969\n",
      "chunk number: 603 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4930 - acc: 0.8025 - val_loss: 0.4444 - val_acc: 0.8516\n",
      "chunk number: 604 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4906 - acc: 0.8092 - val_loss: 0.4994 - val_acc: 0.8359\n",
      "chunk number: 605 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4859 - acc: 0.8058 - val_loss: 0.5893 - val_acc: 0.7500\n",
      "chunk number: 606 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4852 - acc: 0.8125 - val_loss: 0.5629 - val_acc: 0.7734\n",
      "chunk number: 607 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4943 - acc: 0.8103 - val_loss: 0.5093 - val_acc: 0.7734\n",
      "chunk number: 608 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4552 - acc: 0.8315 - val_loss: 0.4645 - val_acc: 0.8594\n",
      "chunk number: 609 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4389 - acc: 0.8359 - val_loss: 0.3905 - val_acc: 0.8516\n",
      "chunk number: 610 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4841 - acc: 0.8114 - val_loss: 0.5153 - val_acc: 0.8125\n",
      "chunk number: 611 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5184 - acc: 0.8047 - val_loss: 0.4968 - val_acc: 0.7969\n",
      "chunk number: 612 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5088 - acc: 0.8069 - val_loss: 0.4373 - val_acc: 0.8359\n",
      "chunk number: 613 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4594 - acc: 0.8315 - val_loss: 0.6004 - val_acc: 0.7891\n",
      "chunk number: 614 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5398 - acc: 0.7980 - val_loss: 0.4102 - val_acc: 0.8516\n",
      "chunk number: 615 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4934 - acc: 0.8147 - val_loss: 0.5361 - val_acc: 0.7891\n",
      "chunk number: 616 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4568 - acc: 0.8304 - val_loss: 0.6190 - val_acc: 0.7812\n",
      "chunk number: 617 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5045 - acc: 0.7913 - val_loss: 0.5372 - val_acc: 0.8125\n",
      "chunk number: 618 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4913 - acc: 0.8136 - val_loss: 0.5485 - val_acc: 0.8047\n",
      "chunk number: 619 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4868 - acc: 0.8147 - val_loss: 0.5053 - val_acc: 0.7969\n",
      "chunk number: 620 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4796 - acc: 0.8136 - val_loss: 0.4808 - val_acc: 0.8672\n",
      "chunk number: 621 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4392 - acc: 0.8248 - val_loss: 0.4436 - val_acc: 0.8281\n",
      "chunk number: 622 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4699 - acc: 0.8158 - val_loss: 0.4629 - val_acc: 0.8125\n",
      "chunk number: 623 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4652 - acc: 0.8404 - val_loss: 0.5398 - val_acc: 0.7891\n",
      "chunk number: 624 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5389 - acc: 0.7969 - val_loss: 0.5466 - val_acc: 0.7578\n",
      "chunk number: 625 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4699 - acc: 0.8147 - val_loss: 0.4760 - val_acc: 0.8281\n",
      "chunk number: 626 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4770 - acc: 0.8103 - val_loss: 0.6930 - val_acc: 0.7969\n",
      "chunk number: 627 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4521 - acc: 0.8270 - val_loss: 0.3814 - val_acc: 0.8672\n",
      "chunk number: 628 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4838 - acc: 0.8225 - val_loss: 0.6021 - val_acc: 0.7969\n",
      "chunk number: 629 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5096 - acc: 0.8192 - val_loss: 0.4142 - val_acc: 0.8438\n",
      "chunk number: 630 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4984 - acc: 0.8125 - val_loss: 0.5930 - val_acc: 0.7578\n",
      "chunk number: 631 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4903 - acc: 0.8147 - val_loss: 0.5489 - val_acc: 0.7891\n",
      "chunk number: 632 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5143 - acc: 0.7935 - val_loss: 0.5455 - val_acc: 0.7578\n",
      "chunk number: 633 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5037 - acc: 0.8158 - val_loss: 0.4310 - val_acc: 0.8281\n",
      "chunk number: 634 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5086 - acc: 0.8002 - val_loss: 0.5369 - val_acc: 0.8281\n",
      "chunk number: 635 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4916 - acc: 0.8158 - val_loss: 0.6124 - val_acc: 0.7656\n",
      "chunk number: 636 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4969 - acc: 0.8002 - val_loss: 0.4293 - val_acc: 0.8281\n",
      "chunk number: 637 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4995 - acc: 0.8080 - val_loss: 0.5036 - val_acc: 0.7891\n",
      "chunk number: 638 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4754 - acc: 0.8192 - val_loss: 0.5581 - val_acc: 0.7891\n",
      "chunk number: 639 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5128 - acc: 0.7980 - val_loss: 0.5213 - val_acc: 0.7969\n",
      "chunk number: 640 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5210 - acc: 0.7924 - val_loss: 0.4756 - val_acc: 0.7891\n",
      "chunk number: 641 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4626 - acc: 0.8337 - val_loss: 0.4501 - val_acc: 0.8047\n",
      "chunk number: 642 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4463 - acc: 0.8259 - val_loss: 0.5574 - val_acc: 0.7969\n",
      "chunk number: 643 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4739 - acc: 0.8125 - val_loss: 0.4757 - val_acc: 0.7812\n",
      "chunk number: 644 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4538 - acc: 0.8181 - val_loss: 0.5466 - val_acc: 0.8047\n",
      "chunk number: 645 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4800 - acc: 0.8025 - val_loss: 0.5394 - val_acc: 0.7812\n",
      "chunk number: 646 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5101 - acc: 0.8069 - val_loss: 0.5981 - val_acc: 0.7734\n",
      "chunk number: 647 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4756 - acc: 0.8181 - val_loss: 0.6250 - val_acc: 0.7734\n",
      "chunk number: 648 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5030 - acc: 0.7980 - val_loss: 0.6186 - val_acc: 0.7734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 649 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5117 - acc: 0.8114 - val_loss: 0.5793 - val_acc: 0.8047\n",
      "chunk number: 650 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5076 - acc: 0.8069 - val_loss: 0.5225 - val_acc: 0.8125\n",
      "chunk number: 651 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4944 - acc: 0.7891 - val_loss: 0.5480 - val_acc: 0.7969\n",
      "chunk number: 652 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4470 - acc: 0.8192 - val_loss: 0.4211 - val_acc: 0.8047\n",
      "chunk number: 653 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5319 - acc: 0.7891 - val_loss: 0.5633 - val_acc: 0.7656\n",
      "chunk number: 654 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4750 - acc: 0.8237 - val_loss: 0.4988 - val_acc: 0.8125\n",
      "chunk number: 655 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4534 - acc: 0.8393 - val_loss: 0.4647 - val_acc: 0.8125\n",
      "chunk number: 656 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5039 - acc: 0.8092 - val_loss: 0.5414 - val_acc: 0.7656\n",
      "chunk number: 657 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5324 - acc: 0.7879 - val_loss: 0.4714 - val_acc: 0.8047\n",
      "chunk number: 658 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4372 - acc: 0.8426 - val_loss: 0.4455 - val_acc: 0.8203\n",
      "chunk number: 659 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4744 - acc: 0.8203 - val_loss: 0.4258 - val_acc: 0.8438\n",
      "chunk number: 660 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6035 - acc: 0.7824 - val_loss: 0.4834 - val_acc: 0.8516\n",
      "chunk number: 661 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4941 - acc: 0.8237 - val_loss: 0.4707 - val_acc: 0.8516\n",
      "chunk number: 662 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4913 - acc: 0.8259 - val_loss: 0.4084 - val_acc: 0.8672\n",
      "chunk number: 663 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5002 - acc: 0.8170 - val_loss: 0.6448 - val_acc: 0.7266\n",
      "chunk number: 664 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4418 - acc: 0.8382 - val_loss: 0.5338 - val_acc: 0.7734\n",
      "chunk number: 665 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4898 - acc: 0.8114 - val_loss: 0.4742 - val_acc: 0.8125\n",
      "chunk number: 666 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4878 - acc: 0.8114 - val_loss: 0.5618 - val_acc: 0.7734\n",
      "chunk number: 667 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4421 - acc: 0.8371 - val_loss: 0.4727 - val_acc: 0.7891\n",
      "chunk number: 668 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4751 - acc: 0.8114 - val_loss: 0.5649 - val_acc: 0.8125\n",
      "chunk number: 669 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5003 - acc: 0.8125 - val_loss: 0.4712 - val_acc: 0.8359\n",
      "chunk number: 670 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4634 - acc: 0.8248 - val_loss: 0.6226 - val_acc: 0.7812\n",
      "chunk number: 671 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4653 - acc: 0.8158 - val_loss: 0.4326 - val_acc: 0.8281\n",
      "chunk number: 672 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4753 - acc: 0.8181 - val_loss: 0.6193 - val_acc: 0.7578\n",
      "chunk number: 673 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4418 - acc: 0.8203 - val_loss: 0.6422 - val_acc: 0.7578\n",
      "chunk number: 674 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4753 - acc: 0.8281 - val_loss: 0.5924 - val_acc: 0.7812\n",
      "chunk number: 675 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4744 - acc: 0.8214 - val_loss: 0.5777 - val_acc: 0.7656\n",
      "chunk number: 676 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4778 - acc: 0.8158 - val_loss: 0.5608 - val_acc: 0.8047\n",
      "chunk number: 677 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4543 - acc: 0.8248 - val_loss: 0.4138 - val_acc: 0.8125\n",
      "chunk number: 678 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4471 - acc: 0.8203 - val_loss: 0.6145 - val_acc: 0.7812\n",
      "chunk number: 679 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4527 - acc: 0.8292 - val_loss: 0.3540 - val_acc: 0.8750\n",
      "chunk number: 680 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4492 - acc: 0.8292 - val_loss: 0.4690 - val_acc: 0.8359\n",
      "chunk number: 681 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4629 - acc: 0.8192 - val_loss: 0.4296 - val_acc: 0.8047\n",
      "chunk number: 682 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4715 - acc: 0.8371 - val_loss: 0.4322 - val_acc: 0.8125\n",
      "chunk number: 683 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4970 - acc: 0.8158 - val_loss: 0.4855 - val_acc: 0.7812\n",
      "chunk number: 684 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4470 - acc: 0.8292 - val_loss: 0.5609 - val_acc: 0.7266\n",
      "chunk number: 685 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4810 - acc: 0.8147 - val_loss: 0.4545 - val_acc: 0.8047\n",
      "chunk number: 686 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4959 - acc: 0.7991 - val_loss: 0.4367 - val_acc: 0.8203\n",
      "chunk number: 687 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4932 - acc: 0.8281 - val_loss: 0.5044 - val_acc: 0.7812\n",
      "chunk number: 688 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5156 - acc: 0.8181 - val_loss: 0.4050 - val_acc: 0.8359\n",
      "chunk number: 689 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4556 - acc: 0.8158 - val_loss: 0.4492 - val_acc: 0.8516\n",
      "chunk number: 690 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4550 - acc: 0.8192 - val_loss: 0.5310 - val_acc: 0.8047\n",
      "chunk number: 691 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4833 - acc: 0.8203 - val_loss: 0.5149 - val_acc: 0.8438\n",
      "chunk number: 692 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4708 - acc: 0.8103 - val_loss: 0.4391 - val_acc: 0.8203\n",
      "chunk number: 693 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4428 - acc: 0.8326 - val_loss: 0.5602 - val_acc: 0.7969\n",
      "chunk number: 694 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4662 - acc: 0.8225 - val_loss: 0.5252 - val_acc: 0.7812\n",
      "chunk number: 695 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4278 - acc: 0.8415 - val_loss: 0.5079 - val_acc: 0.7891\n",
      "chunk number: 696 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5122 - acc: 0.8002 - val_loss: 0.5141 - val_acc: 0.7734\n",
      "chunk number: 697 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4549 - acc: 0.8225 - val_loss: 0.3919 - val_acc: 0.8516\n",
      "chunk number: 698 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4888 - acc: 0.8080 - val_loss: 0.5084 - val_acc: 0.7812\n",
      "chunk number: 699 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4530 - acc: 0.8125 - val_loss: 0.4619 - val_acc: 0.8047\n",
      "chunk number: 700 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4832 - acc: 0.8036 - val_loss: 0.4283 - val_acc: 0.8281\n",
      "chunk number: 701 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4403 - acc: 0.8281 - val_loss: 0.4325 - val_acc: 0.8203\n",
      "chunk number: 702 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5262 - acc: 0.7980 - val_loss: 0.5947 - val_acc: 0.7969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 703 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4598 - acc: 0.8125 - val_loss: 0.5091 - val_acc: 0.8047\n",
      "chunk number: 704 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4906 - acc: 0.8192 - val_loss: 0.4930 - val_acc: 0.8438\n",
      "chunk number: 705 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5128 - acc: 0.8013 - val_loss: 0.5150 - val_acc: 0.8047\n",
      "chunk number: 706 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4788 - acc: 0.8181 - val_loss: 0.6214 - val_acc: 0.7891\n",
      "chunk number: 707 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5083 - acc: 0.8237 - val_loss: 0.5051 - val_acc: 0.7656\n",
      "chunk number: 708 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4799 - acc: 0.8192 - val_loss: 0.4440 - val_acc: 0.8438\n",
      "chunk number: 709 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4120 - acc: 0.8426 - val_loss: 0.4510 - val_acc: 0.8281\n",
      "chunk number: 710 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4933 - acc: 0.8147 - val_loss: 0.5298 - val_acc: 0.8047\n",
      "chunk number: 711 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5377 - acc: 0.7824 - val_loss: 0.7135 - val_acc: 0.7578\n",
      "chunk number: 712 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4832 - acc: 0.7958 - val_loss: 0.4747 - val_acc: 0.7969\n",
      "chunk number: 713 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4711 - acc: 0.8237 - val_loss: 0.5411 - val_acc: 0.8438\n",
      "chunk number: 714 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5000 - acc: 0.8080 - val_loss: 0.4959 - val_acc: 0.8516\n",
      "chunk number: 715 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5059 - acc: 0.8181 - val_loss: 0.5319 - val_acc: 0.7812\n",
      "chunk number: 716 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4547 - acc: 0.8092 - val_loss: 0.6329 - val_acc: 0.7422\n",
      "chunk number: 717 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4793 - acc: 0.8069 - val_loss: 0.5757 - val_acc: 0.7656\n",
      "chunk number: 718 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4807 - acc: 0.8092 - val_loss: 0.4845 - val_acc: 0.8281\n",
      "chunk number: 719 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4786 - acc: 0.8158 - val_loss: 0.4884 - val_acc: 0.7891\n",
      "chunk number: 720 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4893 - acc: 0.8147 - val_loss: 0.4616 - val_acc: 0.8672\n",
      "chunk number: 721 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4205 - acc: 0.8426 - val_loss: 0.4739 - val_acc: 0.8047\n",
      "chunk number: 722 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4658 - acc: 0.8237 - val_loss: 0.4946 - val_acc: 0.7812\n",
      "chunk number: 723 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4678 - acc: 0.8337 - val_loss: 0.4834 - val_acc: 0.8359\n",
      "chunk number: 724 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4956 - acc: 0.8080 - val_loss: 0.5606 - val_acc: 0.7422\n",
      "chunk number: 725 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4034 - acc: 0.8493 - val_loss: 0.4804 - val_acc: 0.8203\n",
      "chunk number: 726 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4664 - acc: 0.8080 - val_loss: 0.6400 - val_acc: 0.7500\n",
      "chunk number: 727 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4351 - acc: 0.8304 - val_loss: 0.3669 - val_acc: 0.8594\n",
      "chunk number: 728 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5118 - acc: 0.8125 - val_loss: 0.5309 - val_acc: 0.8203\n",
      "chunk number: 729 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4708 - acc: 0.8270 - val_loss: 0.4879 - val_acc: 0.7891\n",
      "chunk number: 730 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5109 - acc: 0.8114 - val_loss: 0.5491 - val_acc: 0.7734\n",
      "chunk number: 731 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4855 - acc: 0.8047 - val_loss: 0.5275 - val_acc: 0.7969\n",
      "chunk number: 732 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4680 - acc: 0.8192 - val_loss: 0.5081 - val_acc: 0.7734\n",
      "chunk number: 733 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4601 - acc: 0.8192 - val_loss: 0.4826 - val_acc: 0.8125\n",
      "chunk number: 734 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4555 - acc: 0.8214 - val_loss: 0.4858 - val_acc: 0.8125\n",
      "chunk number: 735 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4616 - acc: 0.8426 - val_loss: 0.5463 - val_acc: 0.7812\n",
      "chunk number: 736 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4654 - acc: 0.8125 - val_loss: 0.4459 - val_acc: 0.7969\n",
      "chunk number: 737 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4712 - acc: 0.8170 - val_loss: 0.4591 - val_acc: 0.8047\n",
      "chunk number: 738 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4305 - acc: 0.8371 - val_loss: 0.5247 - val_acc: 0.8047\n",
      "chunk number: 739 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4742 - acc: 0.8192 - val_loss: 0.5225 - val_acc: 0.7969\n",
      "chunk number: 740 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5026 - acc: 0.8002 - val_loss: 0.5216 - val_acc: 0.7891\n",
      "chunk number: 741 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4553 - acc: 0.8203 - val_loss: 0.5100 - val_acc: 0.8203\n",
      "chunk number: 742 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4580 - acc: 0.8259 - val_loss: 0.5765 - val_acc: 0.7891\n",
      "chunk number: 743 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4536 - acc: 0.8147 - val_loss: 0.4743 - val_acc: 0.7891\n",
      "chunk number: 744 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4660 - acc: 0.8270 - val_loss: 0.5312 - val_acc: 0.8203\n",
      "chunk number: 745 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4571 - acc: 0.8136 - val_loss: 0.4709 - val_acc: 0.7891\n",
      "chunk number: 746 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4627 - acc: 0.8248 - val_loss: 0.6686 - val_acc: 0.7656\n",
      "chunk number: 747 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4496 - acc: 0.8292 - val_loss: 0.5640 - val_acc: 0.7812\n",
      "chunk number: 748 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4571 - acc: 0.8170 - val_loss: 0.6527 - val_acc: 0.7578\n",
      "chunk number: 749 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4338 - acc: 0.8471 - val_loss: 0.5419 - val_acc: 0.8047\n",
      "chunk number: 750 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4955 - acc: 0.8092 - val_loss: 0.5555 - val_acc: 0.7891\n",
      "chunk number: 751 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5084 - acc: 0.8114 - val_loss: 0.4895 - val_acc: 0.8359\n",
      "chunk number: 752 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4306 - acc: 0.8382 - val_loss: 0.4303 - val_acc: 0.8125\n",
      "chunk number: 753 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5171 - acc: 0.7935 - val_loss: 0.4993 - val_acc: 0.8281\n",
      "chunk number: 754 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4791 - acc: 0.7958 - val_loss: 0.4507 - val_acc: 0.8203\n",
      "chunk number: 755 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4467 - acc: 0.8304 - val_loss: 0.4482 - val_acc: 0.8359\n",
      "chunk number: 756 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4604 - acc: 0.8203 - val_loss: 0.4411 - val_acc: 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 757 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4637 - acc: 0.8136 - val_loss: 0.4886 - val_acc: 0.8281\n",
      "chunk number: 758 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4459 - acc: 0.8326 - val_loss: 0.4347 - val_acc: 0.8438\n",
      "chunk number: 759 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4614 - acc: 0.8237 - val_loss: 0.5014 - val_acc: 0.8281\n",
      "chunk number: 760 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5140 - acc: 0.8103 - val_loss: 0.6309 - val_acc: 0.7812\n",
      "chunk number: 761 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5002 - acc: 0.8170 - val_loss: 0.4868 - val_acc: 0.7969\n",
      "chunk number: 762 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4477 - acc: 0.8248 - val_loss: 0.3396 - val_acc: 0.8906\n",
      "chunk number: 763 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5127 - acc: 0.8058 - val_loss: 0.5659 - val_acc: 0.7969\n",
      "chunk number: 764 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4152 - acc: 0.8482 - val_loss: 0.4293 - val_acc: 0.8828\n",
      "chunk number: 765 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4818 - acc: 0.8248 - val_loss: 0.4834 - val_acc: 0.7734\n",
      "chunk number: 766 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4909 - acc: 0.8080 - val_loss: 0.5344 - val_acc: 0.8047\n",
      "chunk number: 767 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4505 - acc: 0.8304 - val_loss: 0.5377 - val_acc: 0.7812\n",
      "chunk number: 768 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4756 - acc: 0.8047 - val_loss: 0.6337 - val_acc: 0.7734\n",
      "chunk number: 769 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4920 - acc: 0.8170 - val_loss: 0.4809 - val_acc: 0.7891\n",
      "chunk number: 770 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4379 - acc: 0.8393 - val_loss: 0.6116 - val_acc: 0.7812\n",
      "chunk number: 771 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4424 - acc: 0.8259 - val_loss: 0.4162 - val_acc: 0.8281\n",
      "chunk number: 772 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4517 - acc: 0.8270 - val_loss: 0.5309 - val_acc: 0.8047\n",
      "chunk number: 773 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3951 - acc: 0.8538 - val_loss: 0.6521 - val_acc: 0.7422\n",
      "chunk number: 774 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4714 - acc: 0.8248 - val_loss: 0.5818 - val_acc: 0.8281\n",
      "chunk number: 775 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4465 - acc: 0.8393 - val_loss: 0.5255 - val_acc: 0.8047\n",
      "chunk number: 776 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4154 - acc: 0.8281 - val_loss: 0.5547 - val_acc: 0.7969\n",
      "chunk number: 777 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4141 - acc: 0.8326 - val_loss: 0.4118 - val_acc: 0.8281\n",
      "chunk number: 778 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4388 - acc: 0.8237 - val_loss: 0.6177 - val_acc: 0.7969\n",
      "chunk number: 779 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4152 - acc: 0.8415 - val_loss: 0.3508 - val_acc: 0.8359\n",
      "chunk number: 780 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4355 - acc: 0.8426 - val_loss: 0.4376 - val_acc: 0.8281\n",
      "chunk number: 781 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4867 - acc: 0.8047 - val_loss: 0.4201 - val_acc: 0.8438\n",
      "chunk number: 782 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4811 - acc: 0.8214 - val_loss: 0.4452 - val_acc: 0.7969\n",
      "chunk number: 783 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4920 - acc: 0.8069 - val_loss: 0.5168 - val_acc: 0.8047\n",
      "chunk number: 784 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4617 - acc: 0.8315 - val_loss: 0.5184 - val_acc: 0.7578\n",
      "chunk number: 785 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4587 - acc: 0.8393 - val_loss: 0.4618 - val_acc: 0.8125\n",
      "chunk number: 786 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4549 - acc: 0.8248 - val_loss: 0.4327 - val_acc: 0.8281\n",
      "chunk number: 787 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4891 - acc: 0.8270 - val_loss: 0.4957 - val_acc: 0.8438\n",
      "chunk number: 788 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4606 - acc: 0.8170 - val_loss: 0.4598 - val_acc: 0.8281\n",
      "chunk number: 789 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4572 - acc: 0.8281 - val_loss: 0.4017 - val_acc: 0.8828\n",
      "chunk number: 790 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4400 - acc: 0.8359 - val_loss: 0.4574 - val_acc: 0.8125\n",
      "chunk number: 791 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4353 - acc: 0.8304 - val_loss: 0.5173 - val_acc: 0.8516\n",
      "chunk number: 792 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4631 - acc: 0.8259 - val_loss: 0.4976 - val_acc: 0.8203\n",
      "chunk number: 793 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4418 - acc: 0.8292 - val_loss: 0.5719 - val_acc: 0.8125\n",
      "chunk number: 794 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4590 - acc: 0.8281 - val_loss: 0.5070 - val_acc: 0.8125\n",
      "chunk number: 795 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4011 - acc: 0.8404 - val_loss: 0.4722 - val_acc: 0.8359\n",
      "chunk number: 796 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4755 - acc: 0.8181 - val_loss: 0.4747 - val_acc: 0.7812\n",
      "chunk number: 797 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4483 - acc: 0.8225 - val_loss: 0.3811 - val_acc: 0.8594\n",
      "chunk number: 798 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4440 - acc: 0.8203 - val_loss: 0.5139 - val_acc: 0.8203\n",
      "chunk number: 799 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4530 - acc: 0.8214 - val_loss: 0.3465 - val_acc: 0.8516\n",
      "chunk number: 800 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4593 - acc: 0.8192 - val_loss: 0.4518 - val_acc: 0.7969\n",
      "chunk number: 801 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4120 - acc: 0.8527 - val_loss: 0.4081 - val_acc: 0.8281\n",
      "chunk number: 802 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5076 - acc: 0.8225 - val_loss: 0.5490 - val_acc: 0.8125\n",
      "chunk number: 803 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4460 - acc: 0.8315 - val_loss: 0.4628 - val_acc: 0.8281\n",
      "chunk number: 804 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4458 - acc: 0.8237 - val_loss: 0.4913 - val_acc: 0.8281\n",
      "chunk number: 805 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4259 - acc: 0.8415 - val_loss: 0.5044 - val_acc: 0.7891\n",
      "chunk number: 806 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4178 - acc: 0.8438 - val_loss: 0.6327 - val_acc: 0.7812\n",
      "chunk number: 807 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4608 - acc: 0.8415 - val_loss: 0.3876 - val_acc: 0.8672\n",
      "chunk number: 808 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4383 - acc: 0.8393 - val_loss: 0.3678 - val_acc: 0.8516\n",
      "chunk number: 809 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4148 - acc: 0.8359 - val_loss: 0.4449 - val_acc: 0.8672\n",
      "chunk number: 810 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4403 - acc: 0.8348 - val_loss: 0.4783 - val_acc: 0.8203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 811 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4669 - acc: 0.8237 - val_loss: 0.4228 - val_acc: 0.8047\n",
      "chunk number: 812 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4771 - acc: 0.8170 - val_loss: 0.5050 - val_acc: 0.7812\n",
      "chunk number: 813 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4255 - acc: 0.8315 - val_loss: 0.5907 - val_acc: 0.7969\n",
      "chunk number: 814 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4865 - acc: 0.8103 - val_loss: 0.4494 - val_acc: 0.8516\n",
      "chunk number: 815 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4883 - acc: 0.8170 - val_loss: 0.5228 - val_acc: 0.7891\n",
      "chunk number: 816 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4475 - acc: 0.8281 - val_loss: 0.6071 - val_acc: 0.7656\n",
      "chunk number: 817 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4720 - acc: 0.8125 - val_loss: 0.5350 - val_acc: 0.7578\n",
      "chunk number: 818 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4352 - acc: 0.8237 - val_loss: 0.5242 - val_acc: 0.7969\n",
      "chunk number: 819 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4481 - acc: 0.8292 - val_loss: 0.5038 - val_acc: 0.8125\n",
      "chunk number: 820 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4318 - acc: 0.8315 - val_loss: 0.4784 - val_acc: 0.8672\n",
      "chunk number: 821 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3982 - acc: 0.8460 - val_loss: 0.4909 - val_acc: 0.8047\n",
      "chunk number: 822 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4577 - acc: 0.8237 - val_loss: 0.4268 - val_acc: 0.8359\n",
      "chunk number: 823 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4276 - acc: 0.8449 - val_loss: 0.4229 - val_acc: 0.8438\n",
      "chunk number: 824 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4917 - acc: 0.8036 - val_loss: 0.4578 - val_acc: 0.7891\n",
      "chunk number: 825 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4101 - acc: 0.8482 - val_loss: 0.4295 - val_acc: 0.8359\n",
      "chunk number: 826 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4314 - acc: 0.8292 - val_loss: 0.5860 - val_acc: 0.7578\n",
      "chunk number: 827 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4040 - acc: 0.8371 - val_loss: 0.4162 - val_acc: 0.8203\n",
      "chunk number: 828 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4528 - acc: 0.8304 - val_loss: 0.5760 - val_acc: 0.8281\n",
      "chunk number: 829 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4578 - acc: 0.8292 - val_loss: 0.4531 - val_acc: 0.8125\n",
      "chunk number: 830 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4559 - acc: 0.8248 - val_loss: 0.5580 - val_acc: 0.7891\n",
      "chunk number: 831 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4811 - acc: 0.7991 - val_loss: 0.5013 - val_acc: 0.8125\n",
      "chunk number: 832 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4782 - acc: 0.8181 - val_loss: 0.5249 - val_acc: 0.8047\n",
      "chunk number: 833 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4562 - acc: 0.8371 - val_loss: 0.4371 - val_acc: 0.8203\n",
      "chunk number: 834 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4577 - acc: 0.8158 - val_loss: 0.5210 - val_acc: 0.7891\n",
      "chunk number: 835 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4207 - acc: 0.8438 - val_loss: 0.6146 - val_acc: 0.7734\n",
      "chunk number: 836 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4375 - acc: 0.8304 - val_loss: 0.4384 - val_acc: 0.8281\n",
      "chunk number: 837 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4603 - acc: 0.8214 - val_loss: 0.4654 - val_acc: 0.8359\n",
      "chunk number: 838 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4222 - acc: 0.8270 - val_loss: 0.4497 - val_acc: 0.8203\n",
      "chunk number: 839 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4653 - acc: 0.8225 - val_loss: 0.5288 - val_acc: 0.7812\n",
      "chunk number: 840 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4669 - acc: 0.8237 - val_loss: 0.4712 - val_acc: 0.8047\n",
      "chunk number: 841 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4186 - acc: 0.8326 - val_loss: 0.4630 - val_acc: 0.7969\n",
      "chunk number: 842 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4076 - acc: 0.8583 - val_loss: 0.5258 - val_acc: 0.8047\n",
      "chunk number: 843 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4167 - acc: 0.8471 - val_loss: 0.4272 - val_acc: 0.8438\n",
      "chunk number: 844 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4134 - acc: 0.8426 - val_loss: 0.5571 - val_acc: 0.7812\n",
      "chunk number: 845 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4266 - acc: 0.8348 - val_loss: 0.4351 - val_acc: 0.8125\n",
      "chunk number: 846 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4389 - acc: 0.8359 - val_loss: 0.5277 - val_acc: 0.7969\n",
      "chunk number: 847 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4308 - acc: 0.8237 - val_loss: 0.6701 - val_acc: 0.7422\n",
      "chunk number: 848 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4404 - acc: 0.8337 - val_loss: 0.6266 - val_acc: 0.7656\n",
      "chunk number: 849 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4149 - acc: 0.8438 - val_loss: 0.4750 - val_acc: 0.8281\n",
      "chunk number: 850 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4510 - acc: 0.8181 - val_loss: 0.5400 - val_acc: 0.8203\n",
      "chunk number: 851 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4485 - acc: 0.8248 - val_loss: 0.5472 - val_acc: 0.7891\n",
      "chunk number: 852 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4035 - acc: 0.8393 - val_loss: 0.3770 - val_acc: 0.8359\n",
      "chunk number: 853 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4976 - acc: 0.8237 - val_loss: 0.4652 - val_acc: 0.8125\n",
      "chunk number: 854 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4437 - acc: 0.8337 - val_loss: 0.4457 - val_acc: 0.8359\n",
      "chunk number: 855 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4129 - acc: 0.8527 - val_loss: 0.4430 - val_acc: 0.8516\n",
      "chunk number: 856 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4533 - acc: 0.8170 - val_loss: 0.5171 - val_acc: 0.7812\n",
      "chunk number: 857 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4392 - acc: 0.8404 - val_loss: 0.4255 - val_acc: 0.8125\n",
      "chunk number: 858 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4191 - acc: 0.8527 - val_loss: 0.4220 - val_acc: 0.8594\n",
      "chunk number: 859 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4462 - acc: 0.8393 - val_loss: 0.4505 - val_acc: 0.8359\n",
      "chunk number: 860 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5080 - acc: 0.8170 - val_loss: 0.5155 - val_acc: 0.8359\n",
      "chunk number: 861 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4795 - acc: 0.8214 - val_loss: 0.4816 - val_acc: 0.8203\n",
      "chunk number: 862 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4669 - acc: 0.8181 - val_loss: 0.3991 - val_acc: 0.8906\n",
      "chunk number: 863 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4815 - acc: 0.8237 - val_loss: 0.5821 - val_acc: 0.7812\n",
      "chunk number: 864 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4231 - acc: 0.8426 - val_loss: 0.5717 - val_acc: 0.8047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 865 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4835 - acc: 0.8103 - val_loss: 0.5405 - val_acc: 0.8047\n",
      "chunk number: 866 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4538 - acc: 0.8181 - val_loss: 0.5518 - val_acc: 0.7344\n",
      "chunk number: 867 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4471 - acc: 0.8382 - val_loss: 0.5601 - val_acc: 0.7656\n",
      "chunk number: 868 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4494 - acc: 0.8270 - val_loss: 0.6311 - val_acc: 0.7734\n",
      "chunk number: 869 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5123 - acc: 0.8047 - val_loss: 0.5094 - val_acc: 0.8047\n",
      "chunk number: 870 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4234 - acc: 0.8292 - val_loss: 0.5541 - val_acc: 0.7969\n",
      "chunk number: 871 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4157 - acc: 0.8326 - val_loss: 0.4368 - val_acc: 0.7969\n",
      "chunk number: 872 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4407 - acc: 0.8214 - val_loss: 0.5718 - val_acc: 0.7812\n",
      "chunk number: 873 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3772 - acc: 0.8571 - val_loss: 0.5849 - val_acc: 0.7266\n",
      "chunk number: 874 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4700 - acc: 0.8237 - val_loss: 0.5901 - val_acc: 0.7578\n",
      "chunk number: 875 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4149 - acc: 0.8482 - val_loss: 0.4936 - val_acc: 0.8203\n",
      "chunk number: 876 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4074 - acc: 0.8304 - val_loss: 0.4855 - val_acc: 0.8516\n",
      "chunk number: 877 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4286 - acc: 0.8382 - val_loss: 0.4203 - val_acc: 0.8359\n",
      "chunk number: 878 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3894 - acc: 0.8404 - val_loss: 0.6546 - val_acc: 0.7812\n",
      "chunk number: 879 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3946 - acc: 0.8571 - val_loss: 0.3246 - val_acc: 0.8906\n",
      "chunk number: 880 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4031 - acc: 0.8393 - val_loss: 0.4675 - val_acc: 0.8516\n",
      "chunk number: 881 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3975 - acc: 0.8482 - val_loss: 0.4478 - val_acc: 0.8359\n",
      "chunk number: 882 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4200 - acc: 0.8292 - val_loss: 0.3924 - val_acc: 0.8125\n",
      "chunk number: 883 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4939 - acc: 0.8248 - val_loss: 0.4365 - val_acc: 0.8516\n",
      "chunk number: 884 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4218 - acc: 0.8527 - val_loss: 0.5649 - val_acc: 0.7344\n",
      "chunk number: 885 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4336 - acc: 0.8337 - val_loss: 0.4502 - val_acc: 0.8516\n",
      "chunk number: 886 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4438 - acc: 0.8326 - val_loss: 0.4697 - val_acc: 0.8125\n",
      "chunk number: 887 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4557 - acc: 0.8237 - val_loss: 0.5147 - val_acc: 0.8125\n",
      "chunk number: 888 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4314 - acc: 0.8259 - val_loss: 0.4029 - val_acc: 0.8281\n",
      "chunk number: 889 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4364 - acc: 0.8393 - val_loss: 0.4957 - val_acc: 0.8203\n",
      "chunk number: 890 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4302 - acc: 0.8214 - val_loss: 0.4297 - val_acc: 0.8516\n",
      "chunk number: 891 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4437 - acc: 0.8371 - val_loss: 0.4698 - val_acc: 0.8750\n",
      "chunk number: 892 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4613 - acc: 0.8136 - val_loss: 0.4696 - val_acc: 0.8281\n",
      "chunk number: 893 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4261 - acc: 0.8181 - val_loss: 0.5391 - val_acc: 0.7812\n",
      "chunk number: 894 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4530 - acc: 0.8404 - val_loss: 0.4839 - val_acc: 0.7734\n",
      "chunk number: 895 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4272 - acc: 0.8382 - val_loss: 0.4023 - val_acc: 0.8047\n",
      "chunk number: 896 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4708 - acc: 0.8259 - val_loss: 0.5160 - val_acc: 0.7812\n",
      "chunk number: 897 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4118 - acc: 0.8404 - val_loss: 0.4278 - val_acc: 0.8359\n",
      "chunk number: 898 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4079 - acc: 0.8315 - val_loss: 0.5046 - val_acc: 0.7812\n",
      "chunk number: 899 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4205 - acc: 0.8292 - val_loss: 0.3851 - val_acc: 0.8516\n",
      "chunk number: 900 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4141 - acc: 0.8393 - val_loss: 0.4138 - val_acc: 0.8281\n",
      "chunk number: 901 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3941 - acc: 0.8571 - val_loss: 0.4135 - val_acc: 0.8359\n",
      "chunk number: 902 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4497 - acc: 0.8103 - val_loss: 0.5025 - val_acc: 0.8047\n",
      "chunk number: 903 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4591 - acc: 0.8181 - val_loss: 0.4689 - val_acc: 0.8281\n",
      "chunk number: 904 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3973 - acc: 0.8516 - val_loss: 0.4512 - val_acc: 0.8438\n",
      "chunk number: 905 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4246 - acc: 0.8471 - val_loss: 0.5262 - val_acc: 0.7969\n",
      "chunk number: 906 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3904 - acc: 0.8516 - val_loss: 0.4986 - val_acc: 0.8125\n",
      "chunk number: 907 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3943 - acc: 0.8415 - val_loss: 0.5174 - val_acc: 0.8203\n",
      "chunk number: 908 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4108 - acc: 0.8304 - val_loss: 0.3797 - val_acc: 0.8359\n",
      "chunk number: 909 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3853 - acc: 0.8594 - val_loss: 0.3597 - val_acc: 0.8516\n",
      "chunk number: 910 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4161 - acc: 0.8493 - val_loss: 0.4628 - val_acc: 0.8516\n",
      "chunk number: 911 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4545 - acc: 0.8114 - val_loss: 0.4817 - val_acc: 0.8281\n",
      "chunk number: 912 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4343 - acc: 0.8315 - val_loss: 0.4166 - val_acc: 0.8125\n",
      "chunk number: 913 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4288 - acc: 0.8438 - val_loss: 0.6820 - val_acc: 0.7969\n",
      "chunk number: 914 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4550 - acc: 0.8292 - val_loss: 0.3659 - val_acc: 0.9062\n",
      "chunk number: 915 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4610 - acc: 0.8393 - val_loss: 0.5289 - val_acc: 0.7734\n",
      "chunk number: 916 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3793 - acc: 0.8571 - val_loss: 0.5801 - val_acc: 0.7812\n",
      "chunk number: 917 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4471 - acc: 0.8158 - val_loss: 0.5162 - val_acc: 0.7969\n",
      "chunk number: 918 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4286 - acc: 0.8426 - val_loss: 0.5140 - val_acc: 0.8438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 919 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4054 - acc: 0.8348 - val_loss: 0.4929 - val_acc: 0.7656\n",
      "chunk number: 920 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4491 - acc: 0.8203 - val_loss: 0.5469 - val_acc: 0.7969\n",
      "chunk number: 921 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4184 - acc: 0.8449 - val_loss: 0.4837 - val_acc: 0.7969\n",
      "chunk number: 922 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4143 - acc: 0.8382 - val_loss: 0.4363 - val_acc: 0.8438\n",
      "chunk number: 923 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3879 - acc: 0.8516 - val_loss: 0.4656 - val_acc: 0.8516\n",
      "chunk number: 924 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4460 - acc: 0.8393 - val_loss: 0.4760 - val_acc: 0.7812\n",
      "chunk number: 925 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3946 - acc: 0.8504 - val_loss: 0.4516 - val_acc: 0.8438\n",
      "chunk number: 926 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4679 - acc: 0.8214 - val_loss: 0.6776 - val_acc: 0.7656\n",
      "chunk number: 927 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4122 - acc: 0.8516 - val_loss: 0.3689 - val_acc: 0.8594\n",
      "chunk number: 928 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4335 - acc: 0.8393 - val_loss: 0.5647 - val_acc: 0.8125\n",
      "chunk number: 929 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4564 - acc: 0.8292 - val_loss: 0.4360 - val_acc: 0.8203\n",
      "chunk number: 930 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4564 - acc: 0.8270 - val_loss: 0.5157 - val_acc: 0.7656\n",
      "chunk number: 931 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4245 - acc: 0.8348 - val_loss: 0.4861 - val_acc: 0.7969\n",
      "chunk number: 932 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4330 - acc: 0.8371 - val_loss: 0.5134 - val_acc: 0.8203\n",
      "chunk number: 933 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4341 - acc: 0.8359 - val_loss: 0.3786 - val_acc: 0.8438\n",
      "chunk number: 934 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4293 - acc: 0.8326 - val_loss: 0.5228 - val_acc: 0.8047\n",
      "chunk number: 935 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4269 - acc: 0.8426 - val_loss: 0.5525 - val_acc: 0.7812\n",
      "chunk number: 936 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4361 - acc: 0.8326 - val_loss: 0.4295 - val_acc: 0.8438\n",
      "chunk number: 937 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4220 - acc: 0.8348 - val_loss: 0.4749 - val_acc: 0.7734\n",
      "chunk number: 938 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3870 - acc: 0.8493 - val_loss: 0.5527 - val_acc: 0.8125\n",
      "chunk number: 939 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4700 - acc: 0.8214 - val_loss: 0.5856 - val_acc: 0.7969\n",
      "chunk number: 940 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5086 - acc: 0.8025 - val_loss: 0.5190 - val_acc: 0.7266\n",
      "chunk number: 941 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4252 - acc: 0.8248 - val_loss: 0.4963 - val_acc: 0.8125\n",
      "chunk number: 942 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3958 - acc: 0.8538 - val_loss: 0.4955 - val_acc: 0.8203\n",
      "chunk number: 943 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4639 - acc: 0.8147 - val_loss: 0.4596 - val_acc: 0.7891\n",
      "chunk number: 944 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4150 - acc: 0.8404 - val_loss: 0.5571 - val_acc: 0.8203\n",
      "chunk number: 945 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4101 - acc: 0.8438 - val_loss: 0.4558 - val_acc: 0.8516\n",
      "chunk number: 946 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4126 - acc: 0.8292 - val_loss: 0.5605 - val_acc: 0.7812\n",
      "chunk number: 947 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4007 - acc: 0.8337 - val_loss: 0.5998 - val_acc: 0.8047\n",
      "chunk number: 948 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3885 - acc: 0.8460 - val_loss: 0.5776 - val_acc: 0.7578\n",
      "chunk number: 949 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4121 - acc: 0.8460 - val_loss: 0.4821 - val_acc: 0.8281\n",
      "chunk number: 950 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4383 - acc: 0.8192 - val_loss: 0.5077 - val_acc: 0.8203\n",
      "chunk number: 951 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4371 - acc: 0.8337 - val_loss: 0.4442 - val_acc: 0.8359\n",
      "chunk number: 952 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3992 - acc: 0.8460 - val_loss: 0.3822 - val_acc: 0.8438\n",
      "chunk number: 953 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4655 - acc: 0.8147 - val_loss: 0.5204 - val_acc: 0.7734\n",
      "chunk number: 954 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4389 - acc: 0.8248 - val_loss: 0.4561 - val_acc: 0.8516\n",
      "chunk number: 955 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4181 - acc: 0.8471 - val_loss: 0.4305 - val_acc: 0.8203\n",
      "chunk number: 956 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4544 - acc: 0.8248 - val_loss: 0.4751 - val_acc: 0.8125\n",
      "chunk number: 957 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4111 - acc: 0.8438 - val_loss: 0.4507 - val_acc: 0.7969\n",
      "chunk number: 958 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4052 - acc: 0.8482 - val_loss: 0.4378 - val_acc: 0.8594\n",
      "chunk number: 959 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4494 - acc: 0.8304 - val_loss: 0.4525 - val_acc: 0.8594\n",
      "chunk number: 960 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4988 - acc: 0.8147 - val_loss: 0.4432 - val_acc: 0.8750\n",
      "chunk number: 961 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4378 - acc: 0.8471 - val_loss: 0.4803 - val_acc: 0.8281\n",
      "chunk number: 962 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4233 - acc: 0.8438 - val_loss: 0.3288 - val_acc: 0.9141\n",
      "chunk number: 963 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4854 - acc: 0.8047 - val_loss: 0.4747 - val_acc: 0.7812\n",
      "chunk number: 964 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3686 - acc: 0.8616 - val_loss: 0.4413 - val_acc: 0.8516\n",
      "chunk number: 965 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4498 - acc: 0.8270 - val_loss: 0.4356 - val_acc: 0.8203\n",
      "chunk number: 966 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4237 - acc: 0.8359 - val_loss: 0.4683 - val_acc: 0.8359\n",
      "chunk number: 967 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4180 - acc: 0.8583 - val_loss: 0.4391 - val_acc: 0.8203\n",
      "chunk number: 968 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4271 - acc: 0.8225 - val_loss: 0.6085 - val_acc: 0.7812\n",
      "chunk number: 969 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4474 - acc: 0.8259 - val_loss: 0.4211 - val_acc: 0.8516\n",
      "chunk number: 970 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4387 - acc: 0.8382 - val_loss: 0.5621 - val_acc: 0.7734\n",
      "chunk number: 971 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4034 - acc: 0.8371 - val_loss: 0.4181 - val_acc: 0.8281\n",
      "chunk number: 972 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4142 - acc: 0.8337 - val_loss: 0.5276 - val_acc: 0.8359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 973 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3755 - acc: 0.8594 - val_loss: 0.6076 - val_acc: 0.7578\n",
      "chunk number: 974 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4367 - acc: 0.8404 - val_loss: 0.5391 - val_acc: 0.7812\n",
      "chunk number: 975 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4049 - acc: 0.8516 - val_loss: 0.4894 - val_acc: 0.8281\n",
      "chunk number: 976 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3790 - acc: 0.8571 - val_loss: 0.6124 - val_acc: 0.7891\n",
      "chunk number: 977 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3899 - acc: 0.8404 - val_loss: 0.5031 - val_acc: 0.8047\n",
      "chunk number: 978 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3654 - acc: 0.8638 - val_loss: 0.6297 - val_acc: 0.7969\n",
      "chunk number: 979 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3905 - acc: 0.8538 - val_loss: 0.3722 - val_acc: 0.8672\n",
      "chunk number: 980 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3979 - acc: 0.8538 - val_loss: 0.3916 - val_acc: 0.8828\n",
      "chunk number: 981 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3632 - acc: 0.8627 - val_loss: 0.3893 - val_acc: 0.8594\n",
      "chunk number: 982 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4438 - acc: 0.8315 - val_loss: 0.3667 - val_acc: 0.8438\n",
      "chunk number: 983 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4454 - acc: 0.8326 - val_loss: 0.4592 - val_acc: 0.7812\n",
      "chunk number: 984 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4364 - acc: 0.8415 - val_loss: 0.5494 - val_acc: 0.8125\n",
      "chunk number: 985 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4494 - acc: 0.8482 - val_loss: 0.4888 - val_acc: 0.7891\n",
      "chunk number: 986 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4175 - acc: 0.8426 - val_loss: 0.4196 - val_acc: 0.8203\n",
      "chunk number: 987 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4153 - acc: 0.8549 - val_loss: 0.4896 - val_acc: 0.8125\n",
      "chunk number: 988 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4687 - acc: 0.8281 - val_loss: 0.4193 - val_acc: 0.8125\n",
      "chunk number: 989 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4252 - acc: 0.8348 - val_loss: 0.4538 - val_acc: 0.8359\n",
      "chunk number: 990 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4048 - acc: 0.8404 - val_loss: 0.4184 - val_acc: 0.8281\n",
      "chunk number: 991 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4513 - acc: 0.8170 - val_loss: 0.5995 - val_acc: 0.7969\n",
      "chunk number: 992 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4573 - acc: 0.8092 - val_loss: 0.4585 - val_acc: 0.8359\n",
      "chunk number: 993 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4121 - acc: 0.8281 - val_loss: 0.5752 - val_acc: 0.7969\n",
      "chunk number: 994 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4407 - acc: 0.8348 - val_loss: 0.5383 - val_acc: 0.8203\n",
      "chunk number: 995 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4107 - acc: 0.8460 - val_loss: 0.4967 - val_acc: 0.7969\n",
      "chunk number: 996 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4344 - acc: 0.8225 - val_loss: 0.4630 - val_acc: 0.8281\n",
      "chunk number: 997 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3897 - acc: 0.8493 - val_loss: 0.3965 - val_acc: 0.8203\n",
      "chunk number: 998 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4166 - acc: 0.8493 - val_loss: 0.4578 - val_acc: 0.8359\n",
      "chunk number: 999 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4094 - acc: 0.8371 - val_loss: 0.4029 - val_acc: 0.8281\n",
      "chunk number: 1000 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4004 - acc: 0.8449 - val_loss: 0.4053 - val_acc: 0.8359\n",
      "chunk number: 1001 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3943 - acc: 0.8504 - val_loss: 0.4216 - val_acc: 0.8203\n",
      "chunk number: 1002 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4238 - acc: 0.8460 - val_loss: 0.6530 - val_acc: 0.7500\n",
      "chunk number: 1003 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4069 - acc: 0.8404 - val_loss: 0.4635 - val_acc: 0.8125\n",
      "chunk number: 1004 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3973 - acc: 0.8571 - val_loss: 0.4341 - val_acc: 0.8594\n",
      "chunk number: 1005 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3934 - acc: 0.8438 - val_loss: 0.5295 - val_acc: 0.7812\n",
      "chunk number: 1006 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3879 - acc: 0.8504 - val_loss: 0.5286 - val_acc: 0.8047\n",
      "chunk number: 1007 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3921 - acc: 0.8549 - val_loss: 0.4413 - val_acc: 0.8281\n",
      "chunk number: 1008 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3894 - acc: 0.8594 - val_loss: 0.4206 - val_acc: 0.8359\n",
      "chunk number: 1009 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3811 - acc: 0.8571 - val_loss: 0.3733 - val_acc: 0.8438\n",
      "chunk number: 1010 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4471 - acc: 0.8225 - val_loss: 0.4889 - val_acc: 0.8281\n",
      "chunk number: 1011 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4552 - acc: 0.8237 - val_loss: 0.5651 - val_acc: 0.7969\n",
      "chunk number: 1012 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3997 - acc: 0.8382 - val_loss: 0.4221 - val_acc: 0.8047\n",
      "chunk number: 1013 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3917 - acc: 0.8449 - val_loss: 0.5677 - val_acc: 0.7812\n",
      "chunk number: 1014 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4583 - acc: 0.8315 - val_loss: 0.4372 - val_acc: 0.8359\n",
      "chunk number: 1015 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4454 - acc: 0.8304 - val_loss: 0.6090 - val_acc: 0.7344\n",
      "chunk number: 1016 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3880 - acc: 0.8482 - val_loss: 0.6324 - val_acc: 0.7812\n",
      "chunk number: 1017 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4645 - acc: 0.8181 - val_loss: 0.4983 - val_acc: 0.7812\n",
      "chunk number: 1018 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4135 - acc: 0.8304 - val_loss: 0.5077 - val_acc: 0.8203\n",
      "chunk number: 1019 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4199 - acc: 0.8304 - val_loss: 0.5453 - val_acc: 0.8047\n",
      "chunk number: 1020 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4210 - acc: 0.8337 - val_loss: 0.4671 - val_acc: 0.8750\n",
      "chunk number: 1021 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3856 - acc: 0.8449 - val_loss: 0.4691 - val_acc: 0.8203\n",
      "chunk number: 1022 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3895 - acc: 0.8426 - val_loss: 0.4258 - val_acc: 0.8047\n",
      "chunk number: 1023 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3825 - acc: 0.8549 - val_loss: 0.3928 - val_acc: 0.8516\n",
      "chunk number: 1024 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4301 - acc: 0.8460 - val_loss: 0.4717 - val_acc: 0.7969\n",
      "chunk number: 1025 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4178 - acc: 0.8516 - val_loss: 0.4777 - val_acc: 0.8125\n",
      "chunk number: 1026 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4107 - acc: 0.8504 - val_loss: 0.5952 - val_acc: 0.7969\n",
      "chunk number: 1027 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3789 - acc: 0.8527 - val_loss: 0.3691 - val_acc: 0.8438\n",
      "chunk number: 1028 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3950 - acc: 0.8415 - val_loss: 0.5777 - val_acc: 0.8047\n",
      "chunk number: 1029 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3911 - acc: 0.8571 - val_loss: 0.4605 - val_acc: 0.8203\n",
      "chunk number: 1030 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4199 - acc: 0.8415 - val_loss: 0.4735 - val_acc: 0.8125\n",
      "chunk number: 1031 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4398 - acc: 0.8382 - val_loss: 0.5673 - val_acc: 0.7891\n",
      "chunk number: 1032 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4042 - acc: 0.8571 - val_loss: 0.4956 - val_acc: 0.8125\n",
      "chunk number: 1033 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3907 - acc: 0.8449 - val_loss: 0.3813 - val_acc: 0.8359\n",
      "chunk number: 1034 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4168 - acc: 0.8449 - val_loss: 0.5357 - val_acc: 0.8047\n",
      "chunk number: 1035 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3967 - acc: 0.8583 - val_loss: 0.5674 - val_acc: 0.7734\n",
      "chunk number: 1036 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4008 - acc: 0.8471 - val_loss: 0.4196 - val_acc: 0.8281\n",
      "chunk number: 1037 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4524 - acc: 0.8125 - val_loss: 0.4055 - val_acc: 0.8281\n",
      "chunk number: 1038 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3889 - acc: 0.8549 - val_loss: 0.4749 - val_acc: 0.8125\n",
      "chunk number: 1039 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4263 - acc: 0.8426 - val_loss: 0.4708 - val_acc: 0.8516\n",
      "chunk number: 1040 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4270 - acc: 0.8438 - val_loss: 0.4812 - val_acc: 0.7734\n",
      "chunk number: 1041 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3739 - acc: 0.8571 - val_loss: 0.4540 - val_acc: 0.8281\n",
      "chunk number: 1042 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3901 - acc: 0.8583 - val_loss: 0.6177 - val_acc: 0.7656\n",
      "chunk number: 1043 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3822 - acc: 0.8482 - val_loss: 0.5245 - val_acc: 0.7734\n",
      "chunk number: 1044 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3778 - acc: 0.8560 - val_loss: 0.5400 - val_acc: 0.8125\n",
      "chunk number: 1045 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3778 - acc: 0.8516 - val_loss: 0.4629 - val_acc: 0.8203\n",
      "chunk number: 1046 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4018 - acc: 0.8549 - val_loss: 0.5523 - val_acc: 0.8047\n",
      "chunk number: 1047 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3768 - acc: 0.8527 - val_loss: 0.5108 - val_acc: 0.8047\n",
      "chunk number: 1048 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3509 - acc: 0.8605 - val_loss: 0.5703 - val_acc: 0.8359\n",
      "chunk number: 1049 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3643 - acc: 0.8560 - val_loss: 0.5381 - val_acc: 0.8125\n",
      "chunk number: 1050 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4049 - acc: 0.8415 - val_loss: 0.5086 - val_acc: 0.8125\n",
      "chunk number: 1051 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3945 - acc: 0.8516 - val_loss: 0.5012 - val_acc: 0.7812\n",
      "chunk number: 1052 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4241 - acc: 0.8359 - val_loss: 0.3630 - val_acc: 0.8203\n",
      "chunk number: 1053 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4630 - acc: 0.8181 - val_loss: 0.5870 - val_acc: 0.7734\n",
      "chunk number: 1054 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4332 - acc: 0.8304 - val_loss: 0.5211 - val_acc: 0.8281\n",
      "chunk number: 1055 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4290 - acc: 0.8516 - val_loss: 0.4731 - val_acc: 0.8359\n",
      "chunk number: 1056 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4347 - acc: 0.8359 - val_loss: 0.5278 - val_acc: 0.7578\n",
      "chunk number: 1057 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3953 - acc: 0.8516 - val_loss: 0.4603 - val_acc: 0.8359\n",
      "chunk number: 1058 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3682 - acc: 0.8549 - val_loss: 0.5148 - val_acc: 0.8047\n",
      "chunk number: 1059 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4156 - acc: 0.8504 - val_loss: 0.4818 - val_acc: 0.8203\n",
      "chunk number: 1060 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4742 - acc: 0.8170 - val_loss: 0.4929 - val_acc: 0.8203\n",
      "chunk number: 1061 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3812 - acc: 0.8560 - val_loss: 0.5112 - val_acc: 0.8125\n",
      "chunk number: 1062 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3699 - acc: 0.8594 - val_loss: 0.3421 - val_acc: 0.8906\n",
      "chunk number: 1063 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4734 - acc: 0.8259 - val_loss: 0.5878 - val_acc: 0.8203\n",
      "chunk number: 1064 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3954 - acc: 0.8605 - val_loss: 0.4927 - val_acc: 0.8359\n",
      "chunk number: 1065 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4255 - acc: 0.8471 - val_loss: 0.4771 - val_acc: 0.8125\n",
      "chunk number: 1066 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3989 - acc: 0.8616 - val_loss: 0.4681 - val_acc: 0.8125\n",
      "chunk number: 1067 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3960 - acc: 0.8426 - val_loss: 0.4992 - val_acc: 0.8203\n",
      "chunk number: 1068 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3856 - acc: 0.8438 - val_loss: 0.6461 - val_acc: 0.8047\n",
      "chunk number: 1069 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4400 - acc: 0.8337 - val_loss: 0.4021 - val_acc: 0.8828\n",
      "chunk number: 1070 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3528 - acc: 0.8739 - val_loss: 0.6041 - val_acc: 0.7734\n",
      "chunk number: 1071 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4089 - acc: 0.8471 - val_loss: 0.3526 - val_acc: 0.8516\n",
      "chunk number: 1072 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3865 - acc: 0.8571 - val_loss: 0.6190 - val_acc: 0.8203\n",
      "chunk number: 1073 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3492 - acc: 0.8806 - val_loss: 0.6320 - val_acc: 0.7500\n",
      "chunk number: 1074 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4192 - acc: 0.8404 - val_loss: 0.6000 - val_acc: 0.7500\n",
      "chunk number: 1075 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3596 - acc: 0.8594 - val_loss: 0.4907 - val_acc: 0.8047\n",
      "chunk number: 1076 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3769 - acc: 0.8538 - val_loss: 0.4869 - val_acc: 0.8125\n",
      "chunk number: 1077 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3685 - acc: 0.8594 - val_loss: 0.4337 - val_acc: 0.8203\n",
      "chunk number: 1078 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3607 - acc: 0.8761 - val_loss: 0.5567 - val_acc: 0.7812\n",
      "chunk number: 1079 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3727 - acc: 0.8460 - val_loss: 0.3585 - val_acc: 0.8672\n",
      "chunk number: 1080 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3838 - acc: 0.8583 - val_loss: 0.4248 - val_acc: 0.8672\n",
      "chunk number: 1081 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3785 - acc: 0.8560 - val_loss: 0.3839 - val_acc: 0.8438\n",
      "chunk number: 1082 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4127 - acc: 0.8471 - val_loss: 0.4728 - val_acc: 0.7734\n",
      "chunk number: 1083 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4355 - acc: 0.8292 - val_loss: 0.4037 - val_acc: 0.8750\n",
      "chunk number: 1084 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4095 - acc: 0.8471 - val_loss: 0.5136 - val_acc: 0.7656\n",
      "chunk number: 1085 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4144 - acc: 0.8504 - val_loss: 0.4920 - val_acc: 0.8125\n",
      "chunk number: 1086 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3939 - acc: 0.8538 - val_loss: 0.4238 - val_acc: 0.8516\n",
      "chunk number: 1087 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3931 - acc: 0.8650 - val_loss: 0.5223 - val_acc: 0.8203\n",
      "chunk number: 1088 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4206 - acc: 0.8438 - val_loss: 0.3515 - val_acc: 0.8594\n",
      "chunk number: 1089 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4188 - acc: 0.8326 - val_loss: 0.4919 - val_acc: 0.8281\n",
      "chunk number: 1090 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3777 - acc: 0.8538 - val_loss: 0.5016 - val_acc: 0.8047\n",
      "chunk number: 1091 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3492 - acc: 0.8627 - val_loss: 0.4639 - val_acc: 0.8047\n",
      "chunk number: 1092 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4144 - acc: 0.8270 - val_loss: 0.4394 - val_acc: 0.8359\n",
      "chunk number: 1093 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3690 - acc: 0.8415 - val_loss: 0.5804 - val_acc: 0.7734\n",
      "chunk number: 1094 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4088 - acc: 0.8560 - val_loss: 0.5290 - val_acc: 0.8203\n",
      "chunk number: 1095 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3765 - acc: 0.8527 - val_loss: 0.5024 - val_acc: 0.8047\n",
      "chunk number: 1096 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4512 - acc: 0.8270 - val_loss: 0.4937 - val_acc: 0.7891\n",
      "chunk number: 1097 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4018 - acc: 0.8214 - val_loss: 0.4822 - val_acc: 0.8203\n",
      "chunk number: 1098 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3997 - acc: 0.8438 - val_loss: 0.4827 - val_acc: 0.8281\n",
      "chunk number: 1099 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3716 - acc: 0.8683 - val_loss: 0.3860 - val_acc: 0.8672\n",
      "chunk number: 1100 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3789 - acc: 0.8538 - val_loss: 0.3908 - val_acc: 0.8594\n",
      "chunk number: 1101 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3747 - acc: 0.8638 - val_loss: 0.3594 - val_acc: 0.8359\n",
      "chunk number: 1102 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3748 - acc: 0.8516 - val_loss: 0.6034 - val_acc: 0.7969\n",
      "chunk number: 1103 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3724 - acc: 0.8605 - val_loss: 0.4766 - val_acc: 0.8594\n",
      "chunk number: 1104 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3611 - acc: 0.8594 - val_loss: 0.4719 - val_acc: 0.8516\n",
      "chunk number: 1105 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3872 - acc: 0.8650 - val_loss: 0.5247 - val_acc: 0.7656\n",
      "chunk number: 1106 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3542 - acc: 0.8571 - val_loss: 0.5565 - val_acc: 0.7812\n",
      "chunk number: 1107 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3724 - acc: 0.8750 - val_loss: 0.4114 - val_acc: 0.8203\n",
      "chunk number: 1108 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3669 - acc: 0.8516 - val_loss: 0.3845 - val_acc: 0.8750\n",
      "chunk number: 1109 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3435 - acc: 0.8627 - val_loss: 0.4507 - val_acc: 0.8281\n",
      "chunk number: 1110 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4140 - acc: 0.8415 - val_loss: 0.4699 - val_acc: 0.8047\n",
      "chunk number: 1111 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4468 - acc: 0.8348 - val_loss: 0.4578 - val_acc: 0.7812\n",
      "chunk number: 1112 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4147 - acc: 0.8382 - val_loss: 0.4462 - val_acc: 0.7812\n",
      "chunk number: 1113 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3677 - acc: 0.8538 - val_loss: 0.7029 - val_acc: 0.7734\n",
      "chunk number: 1114 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4037 - acc: 0.8371 - val_loss: 0.3684 - val_acc: 0.8828\n",
      "chunk number: 1115 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4183 - acc: 0.8493 - val_loss: 0.5379 - val_acc: 0.8047\n",
      "chunk number: 1116 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3697 - acc: 0.8460 - val_loss: 0.6134 - val_acc: 0.7656\n",
      "chunk number: 1117 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4156 - acc: 0.8449 - val_loss: 0.4623 - val_acc: 0.7891\n",
      "chunk number: 1118 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4165 - acc: 0.8438 - val_loss: 0.4589 - val_acc: 0.8359\n",
      "chunk number: 1119 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3814 - acc: 0.8371 - val_loss: 0.4879 - val_acc: 0.8203\n",
      "chunk number: 1120 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3954 - acc: 0.8471 - val_loss: 0.4412 - val_acc: 0.8594\n",
      "chunk number: 1121 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3767 - acc: 0.8594 - val_loss: 0.4410 - val_acc: 0.8516\n",
      "chunk number: 1122 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3886 - acc: 0.8449 - val_loss: 0.3839 - val_acc: 0.8438\n",
      "chunk number: 1123 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3780 - acc: 0.8717 - val_loss: 0.4236 - val_acc: 0.8672\n",
      "chunk number: 1124 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3707 - acc: 0.8538 - val_loss: 0.5525 - val_acc: 0.7734\n",
      "chunk number: 1125 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3568 - acc: 0.8583 - val_loss: 0.4814 - val_acc: 0.7891\n",
      "chunk number: 1126 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4037 - acc: 0.8415 - val_loss: 0.5600 - val_acc: 0.7812\n",
      "chunk number: 1127 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3814 - acc: 0.8482 - val_loss: 0.3353 - val_acc: 0.8828\n",
      "chunk number: 1128 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3821 - acc: 0.8449 - val_loss: 0.5190 - val_acc: 0.8203\n",
      "chunk number: 1129 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4056 - acc: 0.8571 - val_loss: 0.4188 - val_acc: 0.8281\n",
      "chunk number: 1130 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4132 - acc: 0.8504 - val_loss: 0.5897 - val_acc: 0.7500\n",
      "chunk number: 1131 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4091 - acc: 0.8560 - val_loss: 0.4667 - val_acc: 0.7969\n",
      "chunk number: 1132 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4036 - acc: 0.8426 - val_loss: 0.5113 - val_acc: 0.7969\n",
      "chunk number: 1133 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3968 - acc: 0.8583 - val_loss: 0.4171 - val_acc: 0.8281\n",
      "chunk number: 1134 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3697 - acc: 0.8594 - val_loss: 0.5555 - val_acc: 0.8203\n",
      "chunk number: 1135 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4094 - acc: 0.8538 - val_loss: 0.5171 - val_acc: 0.7656\n",
      "chunk number: 1136 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4038 - acc: 0.8527 - val_loss: 0.4089 - val_acc: 0.8281\n",
      "chunk number: 1137 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3875 - acc: 0.8348 - val_loss: 0.5013 - val_acc: 0.8047\n",
      "chunk number: 1138 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4046 - acc: 0.8560 - val_loss: 0.4826 - val_acc: 0.8125\n",
      "chunk number: 1139 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4032 - acc: 0.8460 - val_loss: 0.4983 - val_acc: 0.8125\n",
      "chunk number: 1140 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4147 - acc: 0.8504 - val_loss: 0.4665 - val_acc: 0.7891\n",
      "chunk number: 1141 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3519 - acc: 0.8650 - val_loss: 0.4812 - val_acc: 0.8047\n",
      "chunk number: 1142 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3712 - acc: 0.8538 - val_loss: 0.5548 - val_acc: 0.7969\n",
      "chunk number: 1143 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3492 - acc: 0.8616 - val_loss: 0.5263 - val_acc: 0.8047\n",
      "chunk number: 1144 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3633 - acc: 0.8638 - val_loss: 0.5807 - val_acc: 0.8047\n",
      "chunk number: 1145 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3665 - acc: 0.8694 - val_loss: 0.5116 - val_acc: 0.8281\n",
      "chunk number: 1146 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3720 - acc: 0.8638 - val_loss: 0.6490 - val_acc: 0.7500\n",
      "chunk number: 1147 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3678 - acc: 0.8449 - val_loss: 0.4606 - val_acc: 0.8281\n",
      "chunk number: 1148 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3626 - acc: 0.8538 - val_loss: 0.5786 - val_acc: 0.8047\n",
      "chunk number: 1149 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3894 - acc: 0.8493 - val_loss: 0.5314 - val_acc: 0.7656\n",
      "chunk number: 1150 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3820 - acc: 0.8482 - val_loss: 0.5148 - val_acc: 0.8281\n",
      "chunk number: 1151 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4017 - acc: 0.8493 - val_loss: 0.3972 - val_acc: 0.8438\n",
      "chunk number: 1152 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3682 - acc: 0.8650 - val_loss: 0.4270 - val_acc: 0.8203\n",
      "chunk number: 1153 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4192 - acc: 0.8382 - val_loss: 0.5532 - val_acc: 0.7969\n",
      "chunk number: 1154 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3848 - acc: 0.8527 - val_loss: 0.3995 - val_acc: 0.8594\n",
      "chunk number: 1155 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3593 - acc: 0.8705 - val_loss: 0.4234 - val_acc: 0.8359\n",
      "chunk number: 1156 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4102 - acc: 0.8404 - val_loss: 0.5248 - val_acc: 0.7812\n",
      "chunk number: 1157 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3960 - acc: 0.8471 - val_loss: 0.4565 - val_acc: 0.8047\n",
      "chunk number: 1158 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3758 - acc: 0.8627 - val_loss: 0.4932 - val_acc: 0.8516\n",
      "chunk number: 1159 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3747 - acc: 0.8516 - val_loss: 0.4860 - val_acc: 0.8281\n",
      "chunk number: 1160 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4852 - acc: 0.8192 - val_loss: 0.4874 - val_acc: 0.8125\n",
      "chunk number: 1161 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3994 - acc: 0.8493 - val_loss: 0.4216 - val_acc: 0.8516\n",
      "chunk number: 1162 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3770 - acc: 0.8438 - val_loss: 0.3510 - val_acc: 0.8516\n",
      "chunk number: 1163 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4406 - acc: 0.8203 - val_loss: 0.5651 - val_acc: 0.7734\n",
      "chunk number: 1164 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3490 - acc: 0.8728 - val_loss: 0.4595 - val_acc: 0.8125\n",
      "chunk number: 1165 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4109 - acc: 0.8404 - val_loss: 0.4375 - val_acc: 0.8359\n",
      "chunk number: 1166 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3988 - acc: 0.8426 - val_loss: 0.4269 - val_acc: 0.8281\n",
      "chunk number: 1167 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4086 - acc: 0.8393 - val_loss: 0.5132 - val_acc: 0.8203\n",
      "chunk number: 1168 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4116 - acc: 0.8460 - val_loss: 0.6305 - val_acc: 0.8047\n",
      "chunk number: 1169 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4553 - acc: 0.8404 - val_loss: 0.4790 - val_acc: 0.8281\n",
      "chunk number: 1170 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4120 - acc: 0.8527 - val_loss: 0.6654 - val_acc: 0.7578\n",
      "chunk number: 1171 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3990 - acc: 0.8404 - val_loss: 0.3667 - val_acc: 0.8203\n",
      "chunk number: 1172 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4321 - acc: 0.8237 - val_loss: 0.5786 - val_acc: 0.7812\n",
      "chunk number: 1173 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3379 - acc: 0.8783 - val_loss: 0.5523 - val_acc: 0.7891\n",
      "chunk number: 1174 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3610 - acc: 0.8728 - val_loss: 0.6131 - val_acc: 0.7734\n",
      "chunk number: 1175 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3696 - acc: 0.8694 - val_loss: 0.4161 - val_acc: 0.8672\n",
      "chunk number: 1176 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3415 - acc: 0.8683 - val_loss: 0.5669 - val_acc: 0.8281\n",
      "chunk number: 1177 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3470 - acc: 0.8672 - val_loss: 0.4012 - val_acc: 0.8438\n",
      "chunk number: 1178 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3559 - acc: 0.8616 - val_loss: 0.5653 - val_acc: 0.8125\n",
      "chunk number: 1179 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3395 - acc: 0.8638 - val_loss: 0.3268 - val_acc: 0.8984\n",
      "chunk number: 1180 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3748 - acc: 0.8717 - val_loss: 0.4184 - val_acc: 0.8516\n",
      "chunk number: 1181 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3723 - acc: 0.8460 - val_loss: 0.4045 - val_acc: 0.8594\n",
      "chunk number: 1182 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3660 - acc: 0.8516 - val_loss: 0.3754 - val_acc: 0.8516\n",
      "chunk number: 1183 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3964 - acc: 0.8471 - val_loss: 0.5154 - val_acc: 0.8047\n",
      "chunk number: 1184 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3591 - acc: 0.8616 - val_loss: 0.4855 - val_acc: 0.8359\n",
      "chunk number: 1185 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4155 - acc: 0.8382 - val_loss: 0.4850 - val_acc: 0.8281\n",
      "chunk number: 1186 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4117 - acc: 0.8493 - val_loss: 0.3879 - val_acc: 0.8594\n",
      "chunk number: 1187 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4038 - acc: 0.8415 - val_loss: 0.4558 - val_acc: 0.7891\n",
      "chunk number: 1188 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3816 - acc: 0.8438 - val_loss: 0.3954 - val_acc: 0.8516\n",
      "chunk number: 1189 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3596 - acc: 0.8493 - val_loss: 0.4820 - val_acc: 0.7969\n",
      "chunk number: 1190 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3744 - acc: 0.8583 - val_loss: 0.4579 - val_acc: 0.8281\n",
      "chunk number: 1191 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3755 - acc: 0.8549 - val_loss: 0.4694 - val_acc: 0.8594\n",
      "chunk number: 1192 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3918 - acc: 0.8449 - val_loss: 0.4527 - val_acc: 0.8516\n",
      "chunk number: 1193 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3413 - acc: 0.8594 - val_loss: 0.6142 - val_acc: 0.7500\n",
      "chunk number: 1194 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3908 - acc: 0.8594 - val_loss: 0.5458 - val_acc: 0.7969\n",
      "chunk number: 1195 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3887 - acc: 0.8538 - val_loss: 0.4949 - val_acc: 0.8047\n",
      "chunk number: 1196 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4153 - acc: 0.8337 - val_loss: 0.4735 - val_acc: 0.8125\n",
      "chunk number: 1197 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3506 - acc: 0.8672 - val_loss: 0.3935 - val_acc: 0.8516\n",
      "chunk number: 1198 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3684 - acc: 0.8717 - val_loss: 0.5357 - val_acc: 0.7891\n",
      "chunk number: 1199 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3560 - acc: 0.8661 - val_loss: 0.3673 - val_acc: 0.8516\n",
      "chunk number: 1200 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3911 - acc: 0.8493 - val_loss: 0.4986 - val_acc: 0.8047\n",
      "chunk number: 1201 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3368 - acc: 0.8795 - val_loss: 0.4593 - val_acc: 0.8047\n",
      "chunk number: 1202 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3898 - acc: 0.8527 - val_loss: 0.5498 - val_acc: 0.8359\n",
      "chunk number: 1203 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3600 - acc: 0.8583 - val_loss: 0.3956 - val_acc: 0.8438\n",
      "chunk number: 1204 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3446 - acc: 0.8739 - val_loss: 0.5417 - val_acc: 0.8359\n",
      "chunk number: 1205 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3781 - acc: 0.8538 - val_loss: 0.5664 - val_acc: 0.7734\n",
      "chunk number: 1206 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3047 - acc: 0.8783 - val_loss: 0.5077 - val_acc: 0.8125\n",
      "chunk number: 1207 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3764 - acc: 0.8683 - val_loss: 0.5081 - val_acc: 0.8281\n",
      "chunk number: 1208 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3965 - acc: 0.8426 - val_loss: 0.3908 - val_acc: 0.8516\n",
      "chunk number: 1209 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3524 - acc: 0.8750 - val_loss: 0.3672 - val_acc: 0.8281\n",
      "chunk number: 1210 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4014 - acc: 0.8527 - val_loss: 0.4266 - val_acc: 0.8359\n",
      "chunk number: 1211 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3801 - acc: 0.8516 - val_loss: 0.3656 - val_acc: 0.8438\n",
      "chunk number: 1212 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4051 - acc: 0.8371 - val_loss: 0.4013 - val_acc: 0.8203\n",
      "chunk number: 1213 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3592 - acc: 0.8650 - val_loss: 0.5734 - val_acc: 0.8281\n",
      "chunk number: 1214 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3826 - acc: 0.8616 - val_loss: 0.3924 - val_acc: 0.8750\n",
      "chunk number: 1215 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3764 - acc: 0.8616 - val_loss: 0.4713 - val_acc: 0.8359\n",
      "chunk number: 1216 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3271 - acc: 0.8627 - val_loss: 0.5681 - val_acc: 0.7734\n",
      "chunk number: 1217 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4231 - acc: 0.8348 - val_loss: 0.5163 - val_acc: 0.8203\n",
      "chunk number: 1218 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3777 - acc: 0.8516 - val_loss: 0.5297 - val_acc: 0.8281\n",
      "chunk number: 1219 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3924 - acc: 0.8404 - val_loss: 0.4786 - val_acc: 0.7969\n",
      "chunk number: 1220 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3695 - acc: 0.8683 - val_loss: 0.4325 - val_acc: 0.9141\n",
      "chunk number: 1221 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3498 - acc: 0.8672 - val_loss: 0.4527 - val_acc: 0.8438\n",
      "chunk number: 1222 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3614 - acc: 0.8627 - val_loss: 0.4017 - val_acc: 0.8047\n",
      "chunk number: 1223 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3688 - acc: 0.8650 - val_loss: 0.5125 - val_acc: 0.7969\n",
      "chunk number: 1224 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3733 - acc: 0.8493 - val_loss: 0.5230 - val_acc: 0.7891\n",
      "chunk number: 1225 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3217 - acc: 0.8750 - val_loss: 0.4358 - val_acc: 0.8047\n",
      "chunk number: 1226 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3802 - acc: 0.8583 - val_loss: 0.5529 - val_acc: 0.8281\n",
      "chunk number: 1227 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3663 - acc: 0.8549 - val_loss: 0.2770 - val_acc: 0.8906\n",
      "chunk number: 1228 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3833 - acc: 0.8571 - val_loss: 0.5051 - val_acc: 0.8203\n",
      "chunk number: 1229 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4111 - acc: 0.8471 - val_loss: 0.4527 - val_acc: 0.8047\n",
      "chunk number: 1230 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3928 - acc: 0.8426 - val_loss: 0.5415 - val_acc: 0.7812\n",
      "chunk number: 1231 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3754 - acc: 0.8482 - val_loss: 0.4827 - val_acc: 0.7891\n",
      "chunk number: 1232 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3689 - acc: 0.8538 - val_loss: 0.5590 - val_acc: 0.7812\n",
      "chunk number: 1233 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3665 - acc: 0.8594 - val_loss: 0.4136 - val_acc: 0.8125\n",
      "chunk number: 1234 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3694 - acc: 0.8504 - val_loss: 0.4873 - val_acc: 0.8047\n",
      "chunk number: 1235 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3693 - acc: 0.8549 - val_loss: 0.6060 - val_acc: 0.7656\n",
      "chunk number: 1236 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3747 - acc: 0.8571 - val_loss: 0.4135 - val_acc: 0.8125\n",
      "chunk number: 1237 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4232 - acc: 0.8270 - val_loss: 0.4864 - val_acc: 0.7891\n",
      "chunk number: 1238 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3856 - acc: 0.8627 - val_loss: 0.4007 - val_acc: 0.8672\n",
      "chunk number: 1239 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3678 - acc: 0.8571 - val_loss: 0.4837 - val_acc: 0.8281\n",
      "chunk number: 1240 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4082 - acc: 0.8393 - val_loss: 0.5178 - val_acc: 0.7891\n",
      "chunk number: 1241 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3437 - acc: 0.8694 - val_loss: 0.4941 - val_acc: 0.8125\n",
      "chunk number: 1242 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3267 - acc: 0.8795 - val_loss: 0.5768 - val_acc: 0.7734\n",
      "chunk number: 1243 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3356 - acc: 0.8661 - val_loss: 0.5292 - val_acc: 0.7812\n",
      "chunk number: 1244 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3399 - acc: 0.8705 - val_loss: 0.5312 - val_acc: 0.8047\n",
      "chunk number: 1245 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3776 - acc: 0.8616 - val_loss: 0.3726 - val_acc: 0.8203\n",
      "chunk number: 1246 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4040 - acc: 0.8527 - val_loss: 0.6202 - val_acc: 0.7266\n",
      "chunk number: 1247 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3866 - acc: 0.8616 - val_loss: 0.5548 - val_acc: 0.7969\n",
      "chunk number: 1248 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3836 - acc: 0.8571 - val_loss: 0.6382 - val_acc: 0.7656\n",
      "chunk number: 1249 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3662 - acc: 0.8661 - val_loss: 0.5789 - val_acc: 0.7969\n",
      "chunk number: 1250 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3751 - acc: 0.8326 - val_loss: 0.4762 - val_acc: 0.8125\n",
      "chunk number: 1251 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3726 - acc: 0.8460 - val_loss: 0.5198 - val_acc: 0.8203\n",
      "chunk number: 1252 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3712 - acc: 0.8482 - val_loss: 0.3726 - val_acc: 0.8594\n",
      "chunk number: 1253 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4143 - acc: 0.8382 - val_loss: 0.5311 - val_acc: 0.7656\n",
      "chunk number: 1254 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3968 - acc: 0.8404 - val_loss: 0.4180 - val_acc: 0.8594\n",
      "chunk number: 1255 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3559 - acc: 0.8638 - val_loss: 0.4147 - val_acc: 0.8359\n",
      "chunk number: 1256 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3740 - acc: 0.8638 - val_loss: 0.5812 - val_acc: 0.7734\n",
      "chunk number: 1257 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3760 - acc: 0.8538 - val_loss: 0.4297 - val_acc: 0.8281\n",
      "chunk number: 1258 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3420 - acc: 0.8672 - val_loss: 0.4865 - val_acc: 0.8125\n",
      "chunk number: 1259 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3580 - acc: 0.8705 - val_loss: 0.3699 - val_acc: 0.8828\n",
      "chunk number: 1260 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4145 - acc: 0.8449 - val_loss: 0.4316 - val_acc: 0.8750\n",
      "chunk number: 1261 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3758 - acc: 0.8516 - val_loss: 0.5068 - val_acc: 0.8516\n",
      "chunk number: 1262 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3485 - acc: 0.8717 - val_loss: 0.3109 - val_acc: 0.8984\n",
      "chunk number: 1263 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4352 - acc: 0.8393 - val_loss: 0.5769 - val_acc: 0.7891\n",
      "chunk number: 1264 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3214 - acc: 0.8750 - val_loss: 0.3979 - val_acc: 0.8438\n",
      "chunk number: 1265 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3917 - acc: 0.8438 - val_loss: 0.3937 - val_acc: 0.8203\n",
      "chunk number: 1266 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3930 - acc: 0.8426 - val_loss: 0.4991 - val_acc: 0.7969\n",
      "chunk number: 1267 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3978 - acc: 0.8527 - val_loss: 0.5080 - val_acc: 0.8047\n",
      "chunk number: 1268 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3771 - acc: 0.8516 - val_loss: 0.5408 - val_acc: 0.8125\n",
      "chunk number: 1269 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4213 - acc: 0.8504 - val_loss: 0.4392 - val_acc: 0.8516\n",
      "chunk number: 1270 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3776 - acc: 0.8594 - val_loss: 0.6129 - val_acc: 0.7734\n",
      "chunk number: 1271 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3221 - acc: 0.8672 - val_loss: 0.3823 - val_acc: 0.8594\n",
      "chunk number: 1272 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3660 - acc: 0.8627 - val_loss: 0.5404 - val_acc: 0.7891\n",
      "chunk number: 1273 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3392 - acc: 0.8627 - val_loss: 0.5790 - val_acc: 0.7969\n",
      "chunk number: 1274 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4374 - acc: 0.8415 - val_loss: 0.5227 - val_acc: 0.7812\n",
      "chunk number: 1275 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3633 - acc: 0.8672 - val_loss: 0.5017 - val_acc: 0.8125\n",
      "chunk number: 1276 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3800 - acc: 0.8605 - val_loss: 0.5986 - val_acc: 0.7969\n",
      "chunk number: 1277 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3794 - acc: 0.8538 - val_loss: 0.4590 - val_acc: 0.8203\n",
      "chunk number: 1278 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3231 - acc: 0.8839 - val_loss: 0.6494 - val_acc: 0.7734\n",
      "chunk number: 1279 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3693 - acc: 0.8605 - val_loss: 0.4213 - val_acc: 0.8438\n",
      "chunk number: 1280 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3417 - acc: 0.8783 - val_loss: 0.3898 - val_acc: 0.8750\n",
      "chunk number: 1281 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3835 - acc: 0.8583 - val_loss: 0.5400 - val_acc: 0.8047\n",
      "chunk number: 1282 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3768 - acc: 0.8438 - val_loss: 0.4724 - val_acc: 0.7812\n",
      "chunk number: 1283 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3924 - acc: 0.8460 - val_loss: 0.5253 - val_acc: 0.7969\n",
      "chunk number: 1284 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3709 - acc: 0.8538 - val_loss: 0.5544 - val_acc: 0.7812\n",
      "chunk number: 1285 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3865 - acc: 0.8549 - val_loss: 0.5045 - val_acc: 0.8125\n",
      "chunk number: 1286 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3603 - acc: 0.8583 - val_loss: 0.4105 - val_acc: 0.7969\n",
      "chunk number: 1287 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3840 - acc: 0.8594 - val_loss: 0.5226 - val_acc: 0.8047\n",
      "chunk number: 1288 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3709 - acc: 0.8571 - val_loss: 0.4408 - val_acc: 0.8203\n",
      "chunk number: 1289 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3573 - acc: 0.8460 - val_loss: 0.4734 - val_acc: 0.8281\n",
      "chunk number: 1290 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3697 - acc: 0.8538 - val_loss: 0.4709 - val_acc: 0.8516\n",
      "chunk number: 1291 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3820 - acc: 0.8449 - val_loss: 0.5242 - val_acc: 0.8047\n",
      "chunk number: 1292 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3983 - acc: 0.8438 - val_loss: 0.4823 - val_acc: 0.8516\n",
      "chunk number: 1293 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2993 - acc: 0.8839 - val_loss: 0.5870 - val_acc: 0.7969\n",
      "chunk number: 1294 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3821 - acc: 0.8616 - val_loss: 0.5183 - val_acc: 0.8047\n",
      "chunk number: 1295 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3488 - acc: 0.8761 - val_loss: 0.4906 - val_acc: 0.8047\n",
      "chunk number: 1296 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3623 - acc: 0.8605 - val_loss: 0.4606 - val_acc: 0.8281\n",
      "chunk number: 1297 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3490 - acc: 0.8583 - val_loss: 0.3904 - val_acc: 0.8594\n",
      "chunk number: 1298 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3657 - acc: 0.8605 - val_loss: 0.4850 - val_acc: 0.8125\n",
      "chunk number: 1299 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3740 - acc: 0.8605 - val_loss: 0.3821 - val_acc: 0.8516\n",
      "chunk number: 1300 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3912 - acc: 0.8583 - val_loss: 0.3749 - val_acc: 0.8203\n",
      "chunk number: 1301 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3342 - acc: 0.8761 - val_loss: 0.3866 - val_acc: 0.8359\n",
      "chunk number: 1302 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3556 - acc: 0.8616 - val_loss: 0.5771 - val_acc: 0.7969\n",
      "chunk number: 1303 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3478 - acc: 0.8650 - val_loss: 0.4530 - val_acc: 0.8047\n",
      "chunk number: 1304 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3341 - acc: 0.8739 - val_loss: 0.4918 - val_acc: 0.8438\n",
      "chunk number: 1305 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3576 - acc: 0.8549 - val_loss: 0.6357 - val_acc: 0.8125\n",
      "chunk number: 1306 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3565 - acc: 0.8616 - val_loss: 0.5669 - val_acc: 0.8203\n",
      "chunk number: 1307 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3607 - acc: 0.8638 - val_loss: 0.5862 - val_acc: 0.7969\n",
      "chunk number: 1308 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3342 - acc: 0.8839 - val_loss: 0.4476 - val_acc: 0.8672\n",
      "chunk number: 1309 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3318 - acc: 0.8683 - val_loss: 0.3677 - val_acc: 0.8594\n",
      "chunk number: 1310 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3571 - acc: 0.8638 - val_loss: 0.5046 - val_acc: 0.7969\n",
      "chunk number: 1311 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3766 - acc: 0.8594 - val_loss: 0.4352 - val_acc: 0.8281\n",
      "chunk number: 1312 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3581 - acc: 0.8705 - val_loss: 0.4335 - val_acc: 0.7969\n",
      "chunk number: 1313 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3296 - acc: 0.8728 - val_loss: 0.6870 - val_acc: 0.7656\n",
      "chunk number: 1314 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4186 - acc: 0.8426 - val_loss: 0.4129 - val_acc: 0.8438\n",
      "chunk number: 1315 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3997 - acc: 0.8449 - val_loss: 0.4692 - val_acc: 0.7891\n",
      "chunk number: 1316 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3646 - acc: 0.8538 - val_loss: 0.6359 - val_acc: 0.7969\n",
      "chunk number: 1317 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3597 - acc: 0.8538 - val_loss: 0.4113 - val_acc: 0.8203\n",
      "chunk number: 1318 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3955 - acc: 0.8471 - val_loss: 0.5161 - val_acc: 0.8281\n",
      "chunk number: 1319 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3463 - acc: 0.8705 - val_loss: 0.5113 - val_acc: 0.7891\n",
      "chunk number: 1320 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3562 - acc: 0.8694 - val_loss: 0.4402 - val_acc: 0.8750\n",
      "chunk number: 1321 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3330 - acc: 0.8650 - val_loss: 0.3823 - val_acc: 0.8672\n",
      "chunk number: 1322 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3429 - acc: 0.8661 - val_loss: 0.3987 - val_acc: 0.8516\n",
      "chunk number: 1323 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3570 - acc: 0.8683 - val_loss: 0.5615 - val_acc: 0.8281\n",
      "chunk number: 1324 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3407 - acc: 0.8650 - val_loss: 0.4596 - val_acc: 0.8281\n",
      "chunk number: 1325 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3240 - acc: 0.8683 - val_loss: 0.4607 - val_acc: 0.8203\n",
      "chunk number: 1326 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3968 - acc: 0.8538 - val_loss: 0.5652 - val_acc: 0.8281\n",
      "chunk number: 1327 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3507 - acc: 0.8560 - val_loss: 0.3011 - val_acc: 0.8750\n",
      "chunk number: 1328 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4059 - acc: 0.8270 - val_loss: 0.5291 - val_acc: 0.8281\n",
      "chunk number: 1329 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3594 - acc: 0.8705 - val_loss: 0.4258 - val_acc: 0.8438\n",
      "chunk number: 1330 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3676 - acc: 0.8583 - val_loss: 0.4618 - val_acc: 0.8203\n",
      "chunk number: 1331 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4062 - acc: 0.8382 - val_loss: 0.5357 - val_acc: 0.8047\n",
      "chunk number: 1332 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3823 - acc: 0.8538 - val_loss: 0.4723 - val_acc: 0.8203\n",
      "chunk number: 1333 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3718 - acc: 0.8471 - val_loss: 0.4021 - val_acc: 0.8281\n",
      "chunk number: 1334 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3435 - acc: 0.8583 - val_loss: 0.5303 - val_acc: 0.8125\n",
      "chunk number: 1335 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3387 - acc: 0.8806 - val_loss: 0.5700 - val_acc: 0.7969\n",
      "chunk number: 1336 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3873 - acc: 0.8594 - val_loss: 0.3982 - val_acc: 0.8203\n",
      "chunk number: 1337 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3964 - acc: 0.8583 - val_loss: 0.4926 - val_acc: 0.7969\n",
      "chunk number: 1338 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3352 - acc: 0.8750 - val_loss: 0.3913 - val_acc: 0.8359\n",
      "chunk number: 1339 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3742 - acc: 0.8571 - val_loss: 0.4765 - val_acc: 0.8125\n",
      "chunk number: 1340 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3751 - acc: 0.8560 - val_loss: 0.4940 - val_acc: 0.8047\n",
      "chunk number: 1341 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3308 - acc: 0.8728 - val_loss: 0.4973 - val_acc: 0.8281\n",
      "chunk number: 1342 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3260 - acc: 0.8772 - val_loss: 0.5942 - val_acc: 0.7812\n",
      "chunk number: 1343 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3394 - acc: 0.8627 - val_loss: 0.4764 - val_acc: 0.8047\n",
      "chunk number: 1344 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3465 - acc: 0.8605 - val_loss: 0.5886 - val_acc: 0.8047\n",
      "chunk number: 1345 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3408 - acc: 0.8661 - val_loss: 0.4350 - val_acc: 0.8516\n",
      "chunk number: 1346 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3440 - acc: 0.8538 - val_loss: 0.7221 - val_acc: 0.7734\n",
      "chunk number: 1347 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3434 - acc: 0.8471 - val_loss: 0.4883 - val_acc: 0.8281\n",
      "chunk number: 1348 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3350 - acc: 0.8560 - val_loss: 0.6325 - val_acc: 0.7812\n",
      "chunk number: 1349 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3260 - acc: 0.8705 - val_loss: 0.4178 - val_acc: 0.8516\n",
      "chunk number: 1350 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3483 - acc: 0.8661 - val_loss: 0.4993 - val_acc: 0.8438\n",
      "chunk number: 1351 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4168 - acc: 0.8527 - val_loss: 0.4355 - val_acc: 0.8125\n",
      "chunk number: 1352 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3238 - acc: 0.8772 - val_loss: 0.3697 - val_acc: 0.8750\n",
      "chunk number: 1353 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4161 - acc: 0.8259 - val_loss: 0.5114 - val_acc: 0.7891\n",
      "chunk number: 1354 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3972 - acc: 0.8315 - val_loss: 0.4054 - val_acc: 0.8516\n",
      "chunk number: 1355 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3584 - acc: 0.8616 - val_loss: 0.3912 - val_acc: 0.8516\n",
      "chunk number: 1356 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3479 - acc: 0.8761 - val_loss: 0.5097 - val_acc: 0.7734\n",
      "chunk number: 1357 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3888 - acc: 0.8571 - val_loss: 0.4553 - val_acc: 0.8594\n",
      "chunk number: 1358 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3469 - acc: 0.8728 - val_loss: 0.4776 - val_acc: 0.8281\n",
      "chunk number: 1359 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3713 - acc: 0.8783 - val_loss: 0.3877 - val_acc: 0.8594\n",
      "chunk number: 1360 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4109 - acc: 0.8538 - val_loss: 0.4662 - val_acc: 0.8672\n",
      "chunk number: 1361 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3465 - acc: 0.8705 - val_loss: 0.4415 - val_acc: 0.8438\n",
      "chunk number: 1362 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3391 - acc: 0.8772 - val_loss: 0.3247 - val_acc: 0.8672\n",
      "chunk number: 1363 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3729 - acc: 0.8661 - val_loss: 0.5253 - val_acc: 0.8281\n",
      "chunk number: 1364 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3423 - acc: 0.8683 - val_loss: 0.5313 - val_acc: 0.7891\n",
      "chunk number: 1365 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4075 - acc: 0.8538 - val_loss: 0.4574 - val_acc: 0.7812\n",
      "chunk number: 1366 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3702 - acc: 0.8527 - val_loss: 0.5088 - val_acc: 0.8281\n",
      "chunk number: 1367 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3487 - acc: 0.8806 - val_loss: 0.3965 - val_acc: 0.8359\n",
      "chunk number: 1368 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3900 - acc: 0.8449 - val_loss: 0.5350 - val_acc: 0.7969\n",
      "chunk number: 1369 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3709 - acc: 0.8661 - val_loss: 0.3784 - val_acc: 0.8672\n",
      "chunk number: 1370 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3473 - acc: 0.8482 - val_loss: 0.6041 - val_acc: 0.7656\n",
      "chunk number: 1371 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3422 - acc: 0.8761 - val_loss: 0.3840 - val_acc: 0.8438\n",
      "chunk number: 1372 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3694 - acc: 0.8549 - val_loss: 0.5363 - val_acc: 0.7891\n",
      "chunk number: 1373 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3143 - acc: 0.8772 - val_loss: 0.6332 - val_acc: 0.7969\n",
      "chunk number: 1374 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3655 - acc: 0.8761 - val_loss: 0.5537 - val_acc: 0.7734\n",
      "chunk number: 1375 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3187 - acc: 0.8806 - val_loss: 0.4329 - val_acc: 0.8516\n",
      "chunk number: 1376 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3454 - acc: 0.8739 - val_loss: 0.4659 - val_acc: 0.8594\n",
      "chunk number: 1377 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3648 - acc: 0.8527 - val_loss: 0.5336 - val_acc: 0.8047\n",
      "chunk number: 1378 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3281 - acc: 0.8772 - val_loss: 0.6469 - val_acc: 0.7969\n",
      "chunk number: 1379 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3538 - acc: 0.8672 - val_loss: 0.3372 - val_acc: 0.8750\n",
      "chunk number: 1380 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3381 - acc: 0.8806 - val_loss: 0.4303 - val_acc: 0.8672\n",
      "chunk number: 1381 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3259 - acc: 0.8806 - val_loss: 0.3653 - val_acc: 0.8828\n",
      "chunk number: 1382 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3344 - acc: 0.8795 - val_loss: 0.4037 - val_acc: 0.8125\n",
      "chunk number: 1383 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3675 - acc: 0.8672 - val_loss: 0.4946 - val_acc: 0.8203\n",
      "chunk number: 1384 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3576 - acc: 0.8694 - val_loss: 0.4626 - val_acc: 0.7891\n",
      "chunk number: 1385 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3942 - acc: 0.8493 - val_loss: 0.5089 - val_acc: 0.8438\n",
      "chunk number: 1386 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3592 - acc: 0.8728 - val_loss: 0.2900 - val_acc: 0.8906\n",
      "chunk number: 1387 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3854 - acc: 0.8538 - val_loss: 0.4928 - val_acc: 0.8359\n",
      "chunk number: 1388 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3927 - acc: 0.8527 - val_loss: 0.4479 - val_acc: 0.8516\n",
      "chunk number: 1389 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3758 - acc: 0.8438 - val_loss: 0.3884 - val_acc: 0.8672\n",
      "chunk number: 1390 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3302 - acc: 0.8683 - val_loss: 0.5247 - val_acc: 0.7969\n",
      "chunk number: 1391 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3601 - acc: 0.8739 - val_loss: 0.5106 - val_acc: 0.8438\n",
      "chunk number: 1392 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3372 - acc: 0.8571 - val_loss: 0.4986 - val_acc: 0.8438\n",
      "chunk number: 1393 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3108 - acc: 0.8862 - val_loss: 0.5560 - val_acc: 0.8125\n",
      "chunk number: 1394 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3548 - acc: 0.8672 - val_loss: 0.5841 - val_acc: 0.7734\n",
      "chunk number: 1395 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3645 - acc: 0.8661 - val_loss: 0.4670 - val_acc: 0.8203\n",
      "chunk number: 1396 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3754 - acc: 0.8549 - val_loss: 0.4752 - val_acc: 0.7969\n",
      "chunk number: 1397 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3413 - acc: 0.8728 - val_loss: 0.3729 - val_acc: 0.8438\n",
      "chunk number: 1398 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3525 - acc: 0.8504 - val_loss: 0.4987 - val_acc: 0.8203\n",
      "chunk number: 1399 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3214 - acc: 0.8717 - val_loss: 0.3779 - val_acc: 0.8516\n",
      "chunk number: 1400 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3358 - acc: 0.8761 - val_loss: 0.4568 - val_acc: 0.8203\n",
      "chunk number: 1401 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3108 - acc: 0.8984 - val_loss: 0.3673 - val_acc: 0.8594\n",
      "chunk number: 1402 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3321 - acc: 0.8739 - val_loss: 0.5684 - val_acc: 0.8203\n",
      "chunk number: 1403 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3243 - acc: 0.8705 - val_loss: 0.4422 - val_acc: 0.8359\n",
      "chunk number: 1404 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3346 - acc: 0.8761 - val_loss: 0.4720 - val_acc: 0.8438\n",
      "chunk number: 1405 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3305 - acc: 0.8694 - val_loss: 0.5961 - val_acc: 0.7969\n",
      "chunk number: 1406 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2993 - acc: 0.8694 - val_loss: 0.5213 - val_acc: 0.8359\n",
      "chunk number: 1407 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3261 - acc: 0.8717 - val_loss: 0.4817 - val_acc: 0.8125\n",
      "chunk number: 1408 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3860 - acc: 0.8348 - val_loss: 0.4106 - val_acc: 0.8281\n",
      "chunk number: 1409 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3167 - acc: 0.8850 - val_loss: 0.3986 - val_acc: 0.8594\n",
      "chunk number: 1410 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3760 - acc: 0.8638 - val_loss: 0.5520 - val_acc: 0.8281\n",
      "chunk number: 1411 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3753 - acc: 0.8672 - val_loss: 0.5543 - val_acc: 0.8125\n",
      "chunk number: 1412 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3699 - acc: 0.8627 - val_loss: 0.4390 - val_acc: 0.8047\n",
      "chunk number: 1413 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3102 - acc: 0.8828 - val_loss: 0.6534 - val_acc: 0.8203\n",
      "chunk number: 1414 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3372 - acc: 0.8661 - val_loss: 0.3909 - val_acc: 0.8594\n",
      "chunk number: 1415 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3698 - acc: 0.8571 - val_loss: 0.4769 - val_acc: 0.7969\n",
      "chunk number: 1416 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3273 - acc: 0.8728 - val_loss: 0.6502 - val_acc: 0.7891\n",
      "chunk number: 1417 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3967 - acc: 0.8583 - val_loss: 0.5676 - val_acc: 0.8047\n",
      "chunk number: 1418 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3981 - acc: 0.8471 - val_loss: 0.5077 - val_acc: 0.8047\n",
      "chunk number: 1419 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3324 - acc: 0.8839 - val_loss: 0.5318 - val_acc: 0.7578\n",
      "chunk number: 1420 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3707 - acc: 0.8438 - val_loss: 0.4901 - val_acc: 0.8828\n",
      "chunk number: 1421 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3610 - acc: 0.8661 - val_loss: 0.4841 - val_acc: 0.8359\n",
      "chunk number: 1422 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3725 - acc: 0.8516 - val_loss: 0.3869 - val_acc: 0.8516\n",
      "chunk number: 1423 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3445 - acc: 0.8739 - val_loss: 0.4174 - val_acc: 0.8281\n",
      "chunk number: 1424 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3528 - acc: 0.8672 - val_loss: 0.5164 - val_acc: 0.8125\n",
      "chunk number: 1425 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3543 - acc: 0.8605 - val_loss: 0.4085 - val_acc: 0.8359\n",
      "chunk number: 1426 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3981 - acc: 0.8326 - val_loss: 0.5810 - val_acc: 0.7891\n",
      "chunk number: 1427 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3539 - acc: 0.8616 - val_loss: 0.3438 - val_acc: 0.8672\n",
      "chunk number: 1428 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3961 - acc: 0.8426 - val_loss: 0.4881 - val_acc: 0.8281\n",
      "chunk number: 1429 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3500 - acc: 0.8638 - val_loss: 0.5033 - val_acc: 0.7656\n",
      "chunk number: 1430 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3829 - acc: 0.8527 - val_loss: 0.4994 - val_acc: 0.7734\n",
      "chunk number: 1431 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3348 - acc: 0.8728 - val_loss: 0.5048 - val_acc: 0.7812\n",
      "chunk number: 1432 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3659 - acc: 0.8594 - val_loss: 0.4695 - val_acc: 0.8125\n",
      "chunk number: 1433 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3537 - acc: 0.8672 - val_loss: 0.4150 - val_acc: 0.8359\n",
      "chunk number: 1434 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3092 - acc: 0.8694 - val_loss: 0.6184 - val_acc: 0.8047\n",
      "chunk number: 1435 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3401 - acc: 0.8783 - val_loss: 0.4989 - val_acc: 0.8203\n",
      "chunk number: 1436 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3355 - acc: 0.8661 - val_loss: 0.3916 - val_acc: 0.8438\n",
      "chunk number: 1437 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3747 - acc: 0.8560 - val_loss: 0.5049 - val_acc: 0.8125\n",
      "chunk number: 1438 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3241 - acc: 0.8828 - val_loss: 0.4335 - val_acc: 0.8594\n",
      "chunk number: 1439 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3471 - acc: 0.8728 - val_loss: 0.4383 - val_acc: 0.8359\n",
      "chunk number: 1440 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3470 - acc: 0.8650 - val_loss: 0.4697 - val_acc: 0.7969\n",
      "chunk number: 1441 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3314 - acc: 0.8605 - val_loss: 0.5468 - val_acc: 0.8203\n",
      "chunk number: 1442 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3103 - acc: 0.8761 - val_loss: 0.5955 - val_acc: 0.7500\n",
      "chunk number: 1443 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3257 - acc: 0.8817 - val_loss: 0.4497 - val_acc: 0.8203\n",
      "chunk number: 1444 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3094 - acc: 0.8850 - val_loss: 0.5279 - val_acc: 0.8281\n",
      "chunk number: 1445 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3417 - acc: 0.8672 - val_loss: 0.4989 - val_acc: 0.8125\n",
      "chunk number: 1446 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3208 - acc: 0.8884 - val_loss: 0.6370 - val_acc: 0.7891\n",
      "chunk number: 1447 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3419 - acc: 0.8728 - val_loss: 0.5470 - val_acc: 0.8047\n",
      "chunk number: 1448 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3256 - acc: 0.8728 - val_loss: 0.5910 - val_acc: 0.8125\n",
      "chunk number: 1449 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2913 - acc: 0.8783 - val_loss: 0.4945 - val_acc: 0.8125\n",
      "chunk number: 1450 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3406 - acc: 0.8783 - val_loss: 0.5344 - val_acc: 0.8672\n",
      "chunk number: 1451 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3382 - acc: 0.8594 - val_loss: 0.5175 - val_acc: 0.8203\n",
      "chunk number: 1452 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3344 - acc: 0.8772 - val_loss: 0.3651 - val_acc: 0.8281\n",
      "chunk number: 1453 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3674 - acc: 0.8504 - val_loss: 0.4460 - val_acc: 0.8203\n",
      "chunk number: 1454 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3720 - acc: 0.8605 - val_loss: 0.3241 - val_acc: 0.8672\n",
      "chunk number: 1455 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3716 - acc: 0.8661 - val_loss: 0.4475 - val_acc: 0.8125\n",
      "chunk number: 1456 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3434 - acc: 0.8728 - val_loss: 0.5200 - val_acc: 0.7969\n",
      "chunk number: 1457 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3736 - acc: 0.8527 - val_loss: 0.3792 - val_acc: 0.8125\n",
      "chunk number: 1458 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3336 - acc: 0.8783 - val_loss: 0.3870 - val_acc: 0.8594\n",
      "chunk number: 1459 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3217 - acc: 0.8817 - val_loss: 0.3817 - val_acc: 0.8750\n",
      "chunk number: 1460 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3853 - acc: 0.8482 - val_loss: 0.4698 - val_acc: 0.8516\n",
      "chunk number: 1461 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3514 - acc: 0.8616 - val_loss: 0.4842 - val_acc: 0.8359\n",
      "chunk number: 1462 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3363 - acc: 0.8828 - val_loss: 0.3507 - val_acc: 0.8750\n",
      "chunk number: 1463 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3990 - acc: 0.8404 - val_loss: 0.6590 - val_acc: 0.7344\n",
      "chunk number: 1464 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2886 - acc: 0.8962 - val_loss: 0.4353 - val_acc: 0.8125\n",
      "chunk number: 1465 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3585 - acc: 0.8482 - val_loss: 0.3918 - val_acc: 0.8438\n",
      "chunk number: 1466 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3710 - acc: 0.8717 - val_loss: 0.4577 - val_acc: 0.8281\n",
      "chunk number: 1467 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3504 - acc: 0.8672 - val_loss: 0.4930 - val_acc: 0.8203\n",
      "chunk number: 1468 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3575 - acc: 0.8616 - val_loss: 0.5749 - val_acc: 0.7891\n",
      "chunk number: 1469 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3783 - acc: 0.8538 - val_loss: 0.5566 - val_acc: 0.8203\n",
      "chunk number: 1470 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3503 - acc: 0.8594 - val_loss: 0.5141 - val_acc: 0.8203\n",
      "chunk number: 1471 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3233 - acc: 0.8850 - val_loss: 0.3686 - val_acc: 0.8672\n",
      "chunk number: 1472 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3372 - acc: 0.8717 - val_loss: 0.5669 - val_acc: 0.8047\n",
      "chunk number: 1473 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3017 - acc: 0.8817 - val_loss: 0.5880 - val_acc: 0.7969\n",
      "chunk number: 1474 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3547 - acc: 0.8795 - val_loss: 0.5477 - val_acc: 0.7734\n",
      "chunk number: 1475 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3214 - acc: 0.8806 - val_loss: 0.4233 - val_acc: 0.8125\n",
      "chunk number: 1476 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3010 - acc: 0.8750 - val_loss: 0.5774 - val_acc: 0.8047\n",
      "chunk number: 1477 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3124 - acc: 0.8917 - val_loss: 0.4302 - val_acc: 0.8359\n",
      "chunk number: 1478 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3038 - acc: 0.8806 - val_loss: 0.6371 - val_acc: 0.8047\n",
      "chunk number: 1479 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3488 - acc: 0.8493 - val_loss: 0.2961 - val_acc: 0.8828\n",
      "chunk number: 1480 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3422 - acc: 0.8705 - val_loss: 0.3968 - val_acc: 0.8750\n",
      "chunk number: 1481 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3302 - acc: 0.8806 - val_loss: 0.3874 - val_acc: 0.8438\n",
      "chunk number: 1482 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3130 - acc: 0.8583 - val_loss: 0.4304 - val_acc: 0.8203\n",
      "chunk number: 1483 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3835 - acc: 0.8627 - val_loss: 0.5159 - val_acc: 0.8125\n",
      "chunk number: 1484 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3257 - acc: 0.8717 - val_loss: 0.4522 - val_acc: 0.7969\n",
      "chunk number: 1485 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3231 - acc: 0.8817 - val_loss: 0.4959 - val_acc: 0.8203\n",
      "chunk number: 1486 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3141 - acc: 0.8828 - val_loss: 0.4359 - val_acc: 0.8125\n",
      "chunk number: 1487 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3931 - acc: 0.8549 - val_loss: 0.5224 - val_acc: 0.7969\n",
      "chunk number: 1488 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3458 - acc: 0.8728 - val_loss: 0.4453 - val_acc: 0.8359\n",
      "chunk number: 1489 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3427 - acc: 0.8627 - val_loss: 0.5301 - val_acc: 0.8438\n",
      "chunk number: 1490 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3447 - acc: 0.8638 - val_loss: 0.4968 - val_acc: 0.8359\n",
      "chunk number: 1491 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3181 - acc: 0.8717 - val_loss: 0.4908 - val_acc: 0.8594\n",
      "chunk number: 1492 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3430 - acc: 0.8772 - val_loss: 0.5500 - val_acc: 0.8359\n",
      "chunk number: 1493 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3385 - acc: 0.8616 - val_loss: 0.6287 - val_acc: 0.8125\n",
      "chunk number: 1494 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3449 - acc: 0.8705 - val_loss: 0.5409 - val_acc: 0.8047\n",
      "chunk number: 1495 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3048 - acc: 0.8783 - val_loss: 0.4642 - val_acc: 0.8203\n",
      "chunk number: 1496 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3518 - acc: 0.8516 - val_loss: 0.4438 - val_acc: 0.8281\n",
      "chunk number: 1497 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3308 - acc: 0.8873 - val_loss: 0.4083 - val_acc: 0.8594\n",
      "chunk number: 1498 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3376 - acc: 0.8594 - val_loss: 0.4238 - val_acc: 0.8125\n",
      "chunk number: 1499 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3112 - acc: 0.8761 - val_loss: 0.3750 - val_acc: 0.8281\n",
      "chunk number: 1500 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3161 - acc: 0.8850 - val_loss: 0.4553 - val_acc: 0.8125\n",
      "chunk number: 1501 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2990 - acc: 0.8929 - val_loss: 0.4099 - val_acc: 0.8125\n",
      "chunk number: 1502 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3272 - acc: 0.8717 - val_loss: 0.6139 - val_acc: 0.8125\n",
      "chunk number: 1503 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3003 - acc: 0.8951 - val_loss: 0.4697 - val_acc: 0.7891\n",
      "chunk number: 1504 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3022 - acc: 0.8750 - val_loss: 0.4827 - val_acc: 0.8828\n",
      "chunk number: 1505 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3396 - acc: 0.8638 - val_loss: 0.5649 - val_acc: 0.7812\n",
      "chunk number: 1506 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2630 - acc: 0.8984 - val_loss: 0.4991 - val_acc: 0.7969\n",
      "chunk number: 1507 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3354 - acc: 0.8750 - val_loss: 0.5339 - val_acc: 0.7969\n",
      "chunk number: 1508 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3274 - acc: 0.8783 - val_loss: 0.4085 - val_acc: 0.8516\n",
      "chunk number: 1509 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2865 - acc: 0.8884 - val_loss: 0.3852 - val_acc: 0.8594\n",
      "chunk number: 1510 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3337 - acc: 0.8661 - val_loss: 0.5381 - val_acc: 0.8359\n",
      "chunk number: 1511 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3617 - acc: 0.8728 - val_loss: 0.4880 - val_acc: 0.8125\n",
      "chunk number: 1512 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3733 - acc: 0.8694 - val_loss: 0.4629 - val_acc: 0.7969\n",
      "chunk number: 1513 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3346 - acc: 0.8772 - val_loss: 0.6158 - val_acc: 0.8125\n",
      "chunk number: 1514 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3360 - acc: 0.8638 - val_loss: 0.3036 - val_acc: 0.9062\n",
      "chunk number: 1515 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3378 - acc: 0.8694 - val_loss: 0.5232 - val_acc: 0.7891\n",
      "chunk number: 1516 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3262 - acc: 0.8571 - val_loss: 0.6594 - val_acc: 0.7500\n",
      "chunk number: 1517 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3471 - acc: 0.8605 - val_loss: 0.5229 - val_acc: 0.8125\n",
      "chunk number: 1518 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3307 - acc: 0.8705 - val_loss: 0.4331 - val_acc: 0.8516\n",
      "chunk number: 1519 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3323 - acc: 0.8638 - val_loss: 0.4756 - val_acc: 0.7734\n",
      "chunk number: 1520 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2792 - acc: 0.8895 - val_loss: 0.4548 - val_acc: 0.8750\n",
      "chunk number: 1521 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3345 - acc: 0.8783 - val_loss: 0.5090 - val_acc: 0.7969\n",
      "chunk number: 1522 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3122 - acc: 0.8783 - val_loss: 0.4510 - val_acc: 0.8438\n",
      "chunk number: 1523 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3307 - acc: 0.8795 - val_loss: 0.4409 - val_acc: 0.8438\n",
      "chunk number: 1524 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3437 - acc: 0.8650 - val_loss: 0.4844 - val_acc: 0.8125\n",
      "chunk number: 1525 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2877 - acc: 0.8951 - val_loss: 0.4913 - val_acc: 0.8125\n",
      "chunk number: 1526 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3185 - acc: 0.8661 - val_loss: 0.6604 - val_acc: 0.8047\n",
      "chunk number: 1527 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3135 - acc: 0.8638 - val_loss: 0.3550 - val_acc: 0.8594\n",
      "chunk number: 1528 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3470 - acc: 0.8728 - val_loss: 0.5141 - val_acc: 0.8281\n",
      "chunk number: 1529 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3433 - acc: 0.8873 - val_loss: 0.5110 - val_acc: 0.8047\n",
      "chunk number: 1530 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3582 - acc: 0.8549 - val_loss: 0.5576 - val_acc: 0.7734\n",
      "chunk number: 1531 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3543 - acc: 0.8705 - val_loss: 0.5025 - val_acc: 0.8125\n",
      "chunk number: 1532 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3346 - acc: 0.8728 - val_loss: 0.4871 - val_acc: 0.8281\n",
      "chunk number: 1533 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2957 - acc: 0.8973 - val_loss: 0.3591 - val_acc: 0.8516\n",
      "chunk number: 1534 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3674 - acc: 0.8638 - val_loss: 0.4486 - val_acc: 0.8203\n",
      "chunk number: 1535 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3653 - acc: 0.8571 - val_loss: 0.6110 - val_acc: 0.8047\n",
      "chunk number: 1536 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3523 - acc: 0.8616 - val_loss: 0.4783 - val_acc: 0.8359\n",
      "chunk number: 1537 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3718 - acc: 0.8549 - val_loss: 0.4782 - val_acc: 0.8203\n",
      "chunk number: 1538 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3132 - acc: 0.8929 - val_loss: 0.4410 - val_acc: 0.8438\n",
      "chunk number: 1539 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2983 - acc: 0.8850 - val_loss: 0.5103 - val_acc: 0.7812\n",
      "chunk number: 1540 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3376 - acc: 0.8705 - val_loss: 0.4840 - val_acc: 0.7891\n",
      "chunk number: 1541 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2768 - acc: 0.8996 - val_loss: 0.4543 - val_acc: 0.8359\n",
      "chunk number: 1542 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3083 - acc: 0.8828 - val_loss: 0.5735 - val_acc: 0.7812\n",
      "chunk number: 1543 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2801 - acc: 0.8996 - val_loss: 0.5530 - val_acc: 0.7656\n",
      "chunk number: 1544 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3157 - acc: 0.8839 - val_loss: 0.5769 - val_acc: 0.8047\n",
      "chunk number: 1545 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3343 - acc: 0.8783 - val_loss: 0.3950 - val_acc: 0.8203\n",
      "chunk number: 1546 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3402 - acc: 0.8728 - val_loss: 0.7207 - val_acc: 0.7422\n",
      "chunk number: 1547 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2741 - acc: 0.8917 - val_loss: 0.4750 - val_acc: 0.8203\n",
      "chunk number: 1548 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3452 - acc: 0.8571 - val_loss: 0.6665 - val_acc: 0.7891\n",
      "chunk number: 1549 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3226 - acc: 0.8605 - val_loss: 0.4595 - val_acc: 0.8203\n",
      "chunk number: 1550 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3563 - acc: 0.8616 - val_loss: 0.5555 - val_acc: 0.8125\n",
      "chunk number: 1551 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3406 - acc: 0.8761 - val_loss: 0.5694 - val_acc: 0.8125\n",
      "chunk number: 1552 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3390 - acc: 0.8806 - val_loss: 0.3426 - val_acc: 0.8750\n",
      "chunk number: 1553 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3642 - acc: 0.8482 - val_loss: 0.5100 - val_acc: 0.8438\n",
      "chunk number: 1554 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3373 - acc: 0.8705 - val_loss: 0.3751 - val_acc: 0.8594\n",
      "chunk number: 1555 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3476 - acc: 0.8750 - val_loss: 0.3198 - val_acc: 0.8594\n",
      "chunk number: 1556 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3498 - acc: 0.8761 - val_loss: 0.4991 - val_acc: 0.7969\n",
      "chunk number: 1557 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3463 - acc: 0.8739 - val_loss: 0.4542 - val_acc: 0.8359\n",
      "chunk number: 1558 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3138 - acc: 0.8873 - val_loss: 0.4538 - val_acc: 0.8594\n",
      "chunk number: 1559 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3373 - acc: 0.8817 - val_loss: 0.3936 - val_acc: 0.8125\n",
      "chunk number: 1560 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3778 - acc: 0.8705 - val_loss: 0.5462 - val_acc: 0.8203\n",
      "chunk number: 1561 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3112 - acc: 0.8895 - val_loss: 0.5258 - val_acc: 0.8281\n",
      "chunk number: 1562 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2909 - acc: 0.8962 - val_loss: 0.3020 - val_acc: 0.8750\n",
      "chunk number: 1563 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3882 - acc: 0.8449 - val_loss: 0.5225 - val_acc: 0.7422\n",
      "chunk number: 1564 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2994 - acc: 0.8895 - val_loss: 0.4473 - val_acc: 0.8125\n",
      "chunk number: 1565 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3223 - acc: 0.8772 - val_loss: 0.4997 - val_acc: 0.7969\n",
      "chunk number: 1566 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3509 - acc: 0.8583 - val_loss: 0.5207 - val_acc: 0.8047\n",
      "chunk number: 1567 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3217 - acc: 0.8817 - val_loss: 0.4690 - val_acc: 0.8203\n",
      "chunk number: 1568 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3135 - acc: 0.8638 - val_loss: 0.6232 - val_acc: 0.7969\n",
      "chunk number: 1569 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3490 - acc: 0.8650 - val_loss: 0.4521 - val_acc: 0.8516\n",
      "chunk number: 1570 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3511 - acc: 0.8705 - val_loss: 0.5808 - val_acc: 0.7969\n",
      "chunk number: 1571 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3130 - acc: 0.8850 - val_loss: 0.4332 - val_acc: 0.8438\n",
      "chunk number: 1572 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3196 - acc: 0.8783 - val_loss: 0.6772 - val_acc: 0.7812\n",
      "chunk number: 1573 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3216 - acc: 0.8917 - val_loss: 0.6102 - val_acc: 0.7969\n",
      "chunk number: 1574 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3405 - acc: 0.8906 - val_loss: 0.5424 - val_acc: 0.8047\n",
      "chunk number: 1575 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3190 - acc: 0.8973 - val_loss: 0.4634 - val_acc: 0.8359\n",
      "chunk number: 1576 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3117 - acc: 0.8772 - val_loss: 0.4996 - val_acc: 0.8281\n",
      "chunk number: 1577 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2995 - acc: 0.8728 - val_loss: 0.4438 - val_acc: 0.8438\n",
      "chunk number: 1578 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2793 - acc: 0.8929 - val_loss: 0.7182 - val_acc: 0.7734\n",
      "chunk number: 1579 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3228 - acc: 0.8717 - val_loss: 0.3515 - val_acc: 0.8828\n",
      "chunk number: 1580 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3055 - acc: 0.8951 - val_loss: 0.4022 - val_acc: 0.8828\n",
      "chunk number: 1581 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3272 - acc: 0.8761 - val_loss: 0.3780 - val_acc: 0.8438\n",
      "chunk number: 1582 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3200 - acc: 0.8839 - val_loss: 0.3906 - val_acc: 0.8516\n",
      "chunk number: 1583 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3458 - acc: 0.8638 - val_loss: 0.4801 - val_acc: 0.8359\n",
      "chunk number: 1584 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3110 - acc: 0.8795 - val_loss: 0.4419 - val_acc: 0.8047\n",
      "chunk number: 1585 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3585 - acc: 0.8705 - val_loss: 0.4998 - val_acc: 0.8438\n",
      "chunk number: 1586 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3162 - acc: 0.8705 - val_loss: 0.4121 - val_acc: 0.8281\n",
      "chunk number: 1587 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3216 - acc: 0.8839 - val_loss: 0.4287 - val_acc: 0.8750\n",
      "chunk number: 1588 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3244 - acc: 0.8761 - val_loss: 0.4822 - val_acc: 0.8203\n",
      "chunk number: 1589 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3008 - acc: 0.8783 - val_loss: 0.5556 - val_acc: 0.7812\n",
      "chunk number: 1590 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3138 - acc: 0.8795 - val_loss: 0.5024 - val_acc: 0.8281\n",
      "chunk number: 1591 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3190 - acc: 0.8705 - val_loss: 0.5179 - val_acc: 0.8516\n",
      "chunk number: 1592 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3098 - acc: 0.8650 - val_loss: 0.6118 - val_acc: 0.8203\n",
      "chunk number: 1593 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3248 - acc: 0.8828 - val_loss: 0.6891 - val_acc: 0.7656\n",
      "chunk number: 1594 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3314 - acc: 0.8806 - val_loss: 0.5398 - val_acc: 0.8125\n",
      "chunk number: 1595 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2889 - acc: 0.8917 - val_loss: 0.4740 - val_acc: 0.8125\n",
      "chunk number: 1596 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3554 - acc: 0.8627 - val_loss: 0.4517 - val_acc: 0.8281\n",
      "chunk number: 1597 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3030 - acc: 0.8839 - val_loss: 0.3988 - val_acc: 0.8281\n",
      "chunk number: 1598 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3742 - acc: 0.8638 - val_loss: 0.4101 - val_acc: 0.8359\n",
      "chunk number: 1599 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3034 - acc: 0.8795 - val_loss: 0.4249 - val_acc: 0.8359\n",
      "chunk number: 1600 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3233 - acc: 0.8895 - val_loss: 0.3606 - val_acc: 0.8594\n",
      "chunk number: 1601 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2851 - acc: 0.8973 - val_loss: 0.4123 - val_acc: 0.8281\n",
      "chunk number: 1602 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2999 - acc: 0.8884 - val_loss: 0.6258 - val_acc: 0.8047\n",
      "chunk number: 1603 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3037 - acc: 0.8772 - val_loss: 0.4237 - val_acc: 0.8438\n",
      "chunk number: 1604 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3014 - acc: 0.8828 - val_loss: 0.5333 - val_acc: 0.8438\n",
      "chunk number: 1605 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2892 - acc: 0.8951 - val_loss: 0.6898 - val_acc: 0.7812\n",
      "chunk number: 1606 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2584 - acc: 0.9051 - val_loss: 0.4426 - val_acc: 0.8125\n",
      "chunk number: 1607 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2989 - acc: 0.8895 - val_loss: 0.4036 - val_acc: 0.8672\n",
      "chunk number: 1608 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3114 - acc: 0.8862 - val_loss: 0.4261 - val_acc: 0.8750\n",
      "chunk number: 1609 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2992 - acc: 0.8862 - val_loss: 0.3880 - val_acc: 0.8672\n",
      "chunk number: 1610 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2893 - acc: 0.8895 - val_loss: 0.5640 - val_acc: 0.8125\n",
      "chunk number: 1611 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3325 - acc: 0.8862 - val_loss: 0.4109 - val_acc: 0.8359\n",
      "chunk number: 1612 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3653 - acc: 0.8717 - val_loss: 0.4353 - val_acc: 0.7891\n",
      "chunk number: 1613 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3037 - acc: 0.8984 - val_loss: 0.7071 - val_acc: 0.8125\n",
      "chunk number: 1614 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3197 - acc: 0.8806 - val_loss: 0.3414 - val_acc: 0.8984\n",
      "chunk number: 1615 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3556 - acc: 0.8806 - val_loss: 0.5551 - val_acc: 0.8203\n",
      "chunk number: 1616 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3049 - acc: 0.8683 - val_loss: 0.7435 - val_acc: 0.7578\n",
      "chunk number: 1617 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3020 - acc: 0.8783 - val_loss: 0.4207 - val_acc: 0.8281\n",
      "chunk number: 1618 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3194 - acc: 0.8705 - val_loss: 0.5264 - val_acc: 0.8203\n",
      "chunk number: 1619 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3128 - acc: 0.8795 - val_loss: 0.5099 - val_acc: 0.7891\n",
      "chunk number: 1620 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3399 - acc: 0.8672 - val_loss: 0.4894 - val_acc: 0.8828\n",
      "chunk number: 1621 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3349 - acc: 0.8850 - val_loss: 0.3931 - val_acc: 0.8750\n",
      "chunk number: 1622 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3335 - acc: 0.8717 - val_loss: 0.5014 - val_acc: 0.8047\n",
      "chunk number: 1623 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3551 - acc: 0.8761 - val_loss: 0.4463 - val_acc: 0.8438\n",
      "chunk number: 1624 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3613 - acc: 0.8672 - val_loss: 0.4767 - val_acc: 0.7969\n",
      "chunk number: 1625 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3018 - acc: 0.8873 - val_loss: 0.4160 - val_acc: 0.8281\n",
      "chunk number: 1626 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3318 - acc: 0.8772 - val_loss: 0.7317 - val_acc: 0.7812\n",
      "chunk number: 1627 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3042 - acc: 0.8884 - val_loss: 0.3654 - val_acc: 0.8359\n",
      "chunk number: 1628 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3306 - acc: 0.8661 - val_loss: 0.4360 - val_acc: 0.8438\n",
      "chunk number: 1629 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3286 - acc: 0.8761 - val_loss: 0.3521 - val_acc: 0.8672\n",
      "chunk number: 1630 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3341 - acc: 0.8683 - val_loss: 0.4325 - val_acc: 0.7891\n",
      "chunk number: 1631 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3526 - acc: 0.8650 - val_loss: 0.4387 - val_acc: 0.8438\n",
      "chunk number: 1632 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3601 - acc: 0.8761 - val_loss: 0.5057 - val_acc: 0.8047\n",
      "chunk number: 1633 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3299 - acc: 0.8750 - val_loss: 0.4685 - val_acc: 0.8203\n",
      "chunk number: 1634 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3225 - acc: 0.8750 - val_loss: 0.6351 - val_acc: 0.7656\n",
      "chunk number: 1635 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3404 - acc: 0.8795 - val_loss: 0.5458 - val_acc: 0.8047\n",
      "chunk number: 1636 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3237 - acc: 0.8694 - val_loss: 0.4284 - val_acc: 0.8359\n",
      "chunk number: 1637 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3333 - acc: 0.8650 - val_loss: 0.3939 - val_acc: 0.8594\n",
      "chunk number: 1638 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2692 - acc: 0.8984 - val_loss: 0.4360 - val_acc: 0.8281\n",
      "chunk number: 1639 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2972 - acc: 0.8806 - val_loss: 0.5486 - val_acc: 0.8047\n",
      "chunk number: 1640 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3199 - acc: 0.8728 - val_loss: 0.4926 - val_acc: 0.7969\n",
      "chunk number: 1641 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2916 - acc: 0.8750 - val_loss: 0.5191 - val_acc: 0.8125\n",
      "chunk number: 1642 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3177 - acc: 0.8750 - val_loss: 0.5408 - val_acc: 0.8203\n",
      "chunk number: 1643 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3137 - acc: 0.8739 - val_loss: 0.4447 - val_acc: 0.8281\n",
      "chunk number: 1644 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2815 - acc: 0.9007 - val_loss: 0.6103 - val_acc: 0.7891\n",
      "chunk number: 1645 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3301 - acc: 0.8560 - val_loss: 0.5189 - val_acc: 0.8359\n",
      "chunk number: 1646 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3288 - acc: 0.8772 - val_loss: 0.7271 - val_acc: 0.7578\n",
      "chunk number: 1647 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2935 - acc: 0.8895 - val_loss: 0.5053 - val_acc: 0.8125\n",
      "chunk number: 1648 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2897 - acc: 0.8917 - val_loss: 0.6685 - val_acc: 0.7969\n",
      "chunk number: 1649 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3445 - acc: 0.8705 - val_loss: 0.5091 - val_acc: 0.8359\n",
      "chunk number: 1650 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3337 - acc: 0.8683 - val_loss: 0.4809 - val_acc: 0.8828\n",
      "chunk number: 1651 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2930 - acc: 0.8828 - val_loss: 0.5140 - val_acc: 0.8203\n",
      "chunk number: 1652 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3145 - acc: 0.8895 - val_loss: 0.4017 - val_acc: 0.8594\n",
      "chunk number: 1653 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3437 - acc: 0.8583 - val_loss: 0.5345 - val_acc: 0.8203\n",
      "chunk number: 1654 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3358 - acc: 0.8750 - val_loss: 0.3508 - val_acc: 0.8672\n",
      "chunk number: 1655 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3063 - acc: 0.8795 - val_loss: 0.4342 - val_acc: 0.8125\n",
      "chunk number: 1656 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2985 - acc: 0.8973 - val_loss: 0.4457 - val_acc: 0.8203\n",
      "chunk number: 1657 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3402 - acc: 0.8717 - val_loss: 0.4313 - val_acc: 0.8047\n",
      "chunk number: 1658 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2872 - acc: 0.8973 - val_loss: 0.5688 - val_acc: 0.8438\n",
      "chunk number: 1659 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2976 - acc: 0.8884 - val_loss: 0.3853 - val_acc: 0.8438\n",
      "chunk number: 1660 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3558 - acc: 0.8638 - val_loss: 0.5110 - val_acc: 0.8125\n",
      "chunk number: 1661 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3155 - acc: 0.8772 - val_loss: 0.4420 - val_acc: 0.8672\n",
      "chunk number: 1662 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3010 - acc: 0.8795 - val_loss: 0.2975 - val_acc: 0.8906\n",
      "chunk number: 1663 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3742 - acc: 0.8605 - val_loss: 0.5460 - val_acc: 0.7656\n",
      "chunk number: 1664 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2905 - acc: 0.8929 - val_loss: 0.4131 - val_acc: 0.7969\n",
      "chunk number: 1665 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3249 - acc: 0.8638 - val_loss: 0.4023 - val_acc: 0.8281\n",
      "chunk number: 1666 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3531 - acc: 0.8672 - val_loss: 0.4738 - val_acc: 0.7969\n",
      "chunk number: 1667 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3023 - acc: 0.8895 - val_loss: 0.4823 - val_acc: 0.7891\n",
      "chunk number: 1668 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3411 - acc: 0.8549 - val_loss: 0.6235 - val_acc: 0.7812\n",
      "chunk number: 1669 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3515 - acc: 0.8661 - val_loss: 0.5923 - val_acc: 0.8359\n",
      "chunk number: 1670 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3339 - acc: 0.8683 - val_loss: 0.6751 - val_acc: 0.7500\n",
      "chunk number: 1671 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3110 - acc: 0.8750 - val_loss: 0.3954 - val_acc: 0.8281\n",
      "chunk number: 1672 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3346 - acc: 0.8583 - val_loss: 0.6553 - val_acc: 0.7812\n",
      "chunk number: 1673 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3190 - acc: 0.8739 - val_loss: 0.5973 - val_acc: 0.7812\n",
      "chunk number: 1674 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3318 - acc: 0.8594 - val_loss: 0.4768 - val_acc: 0.7812\n",
      "chunk number: 1675 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3110 - acc: 0.8962 - val_loss: 0.4588 - val_acc: 0.8281\n",
      "chunk number: 1676 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2911 - acc: 0.8962 - val_loss: 0.5490 - val_acc: 0.8203\n",
      "chunk number: 1677 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2893 - acc: 0.8895 - val_loss: 0.3823 - val_acc: 0.8516\n",
      "chunk number: 1678 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3130 - acc: 0.8951 - val_loss: 0.7447 - val_acc: 0.8047\n",
      "chunk number: 1679 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2974 - acc: 0.8828 - val_loss: 0.4228 - val_acc: 0.8438\n",
      "chunk number: 1680 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3473 - acc: 0.8795 - val_loss: 0.4413 - val_acc: 0.8672\n",
      "chunk number: 1681 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3065 - acc: 0.8806 - val_loss: 0.5096 - val_acc: 0.8203\n",
      "chunk number: 1682 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3215 - acc: 0.8850 - val_loss: 0.4639 - val_acc: 0.7969\n",
      "chunk number: 1683 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3495 - acc: 0.8750 - val_loss: 0.4506 - val_acc: 0.7969\n",
      "chunk number: 1684 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3054 - acc: 0.8739 - val_loss: 0.4932 - val_acc: 0.8047\n",
      "chunk number: 1685 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3292 - acc: 0.8839 - val_loss: 0.5691 - val_acc: 0.8125\n",
      "chunk number: 1686 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3262 - acc: 0.8806 - val_loss: 0.3317 - val_acc: 0.8594\n",
      "chunk number: 1687 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3437 - acc: 0.8795 - val_loss: 0.6083 - val_acc: 0.7969\n",
      "chunk number: 1688 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3712 - acc: 0.8605 - val_loss: 0.4837 - val_acc: 0.8047\n",
      "chunk number: 1689 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3030 - acc: 0.8929 - val_loss: 0.4369 - val_acc: 0.8203\n",
      "chunk number: 1690 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2843 - acc: 0.8973 - val_loss: 0.4739 - val_acc: 0.8125\n",
      "chunk number: 1691 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2902 - acc: 0.8884 - val_loss: 0.5428 - val_acc: 0.8047\n",
      "chunk number: 1692 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3337 - acc: 0.8828 - val_loss: 0.5843 - val_acc: 0.8438\n",
      "chunk number: 1693 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2558 - acc: 0.9107 - val_loss: 0.6803 - val_acc: 0.7812\n",
      "chunk number: 1694 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2882 - acc: 0.8862 - val_loss: 0.5786 - val_acc: 0.7812\n",
      "chunk number: 1695 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2824 - acc: 0.9118 - val_loss: 0.4471 - val_acc: 0.8281\n",
      "chunk number: 1696 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3514 - acc: 0.8661 - val_loss: 0.4683 - val_acc: 0.8750\n",
      "chunk number: 1697 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2937 - acc: 0.8783 - val_loss: 0.3852 - val_acc: 0.8672\n",
      "chunk number: 1698 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3092 - acc: 0.8705 - val_loss: 0.4102 - val_acc: 0.8281\n",
      "chunk number: 1699 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3274 - acc: 0.8761 - val_loss: 0.4376 - val_acc: 0.8594\n",
      "chunk number: 1700 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3405 - acc: 0.8806 - val_loss: 0.4238 - val_acc: 0.8359\n",
      "chunk number: 1701 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2912 - acc: 0.8984 - val_loss: 0.3949 - val_acc: 0.8203\n",
      "chunk number: 1702 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3124 - acc: 0.8750 - val_loss: 0.5770 - val_acc: 0.8125\n",
      "chunk number: 1703 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3194 - acc: 0.8750 - val_loss: 0.5669 - val_acc: 0.8047\n",
      "chunk number: 1704 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2789 - acc: 0.8951 - val_loss: 0.5055 - val_acc: 0.8438\n",
      "chunk number: 1705 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2996 - acc: 0.8884 - val_loss: 0.7369 - val_acc: 0.8047\n",
      "chunk number: 1706 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2765 - acc: 0.8895 - val_loss: 0.5864 - val_acc: 0.8125\n",
      "chunk number: 1707 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2668 - acc: 0.9163 - val_loss: 0.5800 - val_acc: 0.8359\n",
      "chunk number: 1708 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2575 - acc: 0.9029 - val_loss: 0.3721 - val_acc: 0.8516\n",
      "chunk number: 1709 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2789 - acc: 0.9074 - val_loss: 0.3818 - val_acc: 0.8359\n",
      "chunk number: 1710 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2781 - acc: 0.8940 - val_loss: 0.5689 - val_acc: 0.8359\n",
      "chunk number: 1711 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3601 - acc: 0.8672 - val_loss: 0.4442 - val_acc: 0.8359\n",
      "chunk number: 1712 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3119 - acc: 0.8862 - val_loss: 0.4812 - val_acc: 0.7812\n",
      "chunk number: 1713 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2954 - acc: 0.8996 - val_loss: 0.7344 - val_acc: 0.7969\n",
      "chunk number: 1714 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2748 - acc: 0.8973 - val_loss: 0.3806 - val_acc: 0.8672\n",
      "chunk number: 1715 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3385 - acc: 0.8795 - val_loss: 0.4692 - val_acc: 0.8281\n",
      "chunk number: 1716 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2992 - acc: 0.8873 - val_loss: 0.6012 - val_acc: 0.7812\n",
      "chunk number: 1717 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3404 - acc: 0.8638 - val_loss: 0.5321 - val_acc: 0.7578\n",
      "chunk number: 1718 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3532 - acc: 0.8828 - val_loss: 0.4041 - val_acc: 0.8203\n",
      "chunk number: 1719 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3359 - acc: 0.8694 - val_loss: 0.4639 - val_acc: 0.7891\n",
      "chunk number: 1720 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3050 - acc: 0.8839 - val_loss: 0.4701 - val_acc: 0.8828\n",
      "chunk number: 1721 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2978 - acc: 0.8929 - val_loss: 0.4403 - val_acc: 0.8281\n",
      "chunk number: 1722 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3175 - acc: 0.8850 - val_loss: 0.3942 - val_acc: 0.8125\n",
      "chunk number: 1723 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3297 - acc: 0.8895 - val_loss: 0.4292 - val_acc: 0.8203\n",
      "chunk number: 1724 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3170 - acc: 0.8884 - val_loss: 0.4601 - val_acc: 0.7969\n",
      "chunk number: 1725 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2725 - acc: 0.9096 - val_loss: 0.4176 - val_acc: 0.8438\n",
      "chunk number: 1726 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2992 - acc: 0.8951 - val_loss: 0.6246 - val_acc: 0.7656\n",
      "chunk number: 1727 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3272 - acc: 0.8895 - val_loss: 0.3176 - val_acc: 0.8359\n",
      "chunk number: 1728 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3133 - acc: 0.8850 - val_loss: 0.6101 - val_acc: 0.8359\n",
      "chunk number: 1729 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3374 - acc: 0.8828 - val_loss: 0.4613 - val_acc: 0.8047\n",
      "chunk number: 1730 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3021 - acc: 0.8884 - val_loss: 0.4835 - val_acc: 0.7656\n",
      "chunk number: 1731 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3273 - acc: 0.8783 - val_loss: 0.4884 - val_acc: 0.8281\n",
      "chunk number: 1732 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2998 - acc: 0.8862 - val_loss: 0.4783 - val_acc: 0.8047\n",
      "chunk number: 1733 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3188 - acc: 0.8739 - val_loss: 0.4867 - val_acc: 0.7969\n",
      "chunk number: 1734 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2954 - acc: 0.8873 - val_loss: 0.5640 - val_acc: 0.7891\n",
      "chunk number: 1735 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3215 - acc: 0.8783 - val_loss: 0.5480 - val_acc: 0.7969\n",
      "chunk number: 1736 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3226 - acc: 0.8806 - val_loss: 0.3665 - val_acc: 0.8125\n",
      "chunk number: 1737 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3234 - acc: 0.8694 - val_loss: 0.4535 - val_acc: 0.8281\n",
      "chunk number: 1738 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3031 - acc: 0.8973 - val_loss: 0.4089 - val_acc: 0.8594\n",
      "chunk number: 1739 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3339 - acc: 0.8627 - val_loss: 0.4622 - val_acc: 0.8516\n",
      "chunk number: 1740 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3895 - acc: 0.8605 - val_loss: 0.5081 - val_acc: 0.7812\n",
      "chunk number: 1741 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2642 - acc: 0.8951 - val_loss: 0.4778 - val_acc: 0.8516\n",
      "chunk number: 1742 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2789 - acc: 0.8996 - val_loss: 0.6112 - val_acc: 0.8047\n",
      "chunk number: 1743 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2881 - acc: 0.8996 - val_loss: 0.6455 - val_acc: 0.7656\n",
      "chunk number: 1744 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2719 - acc: 0.8929 - val_loss: 0.6648 - val_acc: 0.8203\n",
      "chunk number: 1745 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3273 - acc: 0.8761 - val_loss: 0.4150 - val_acc: 0.8125\n",
      "chunk number: 1746 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3441 - acc: 0.8661 - val_loss: 0.6306 - val_acc: 0.7969\n",
      "chunk number: 1747 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3103 - acc: 0.8761 - val_loss: 0.4718 - val_acc: 0.8203\n",
      "chunk number: 1748 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3378 - acc: 0.8806 - val_loss: 0.5822 - val_acc: 0.7891\n",
      "chunk number: 1749 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2859 - acc: 0.8984 - val_loss: 0.5161 - val_acc: 0.8516\n",
      "chunk number: 1750 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3024 - acc: 0.8717 - val_loss: 0.5338 - val_acc: 0.8125\n",
      "chunk number: 1751 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3119 - acc: 0.8917 - val_loss: 0.5456 - val_acc: 0.8438\n",
      "chunk number: 1752 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3117 - acc: 0.8895 - val_loss: 0.4109 - val_acc: 0.8281\n",
      "chunk number: 1753 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3371 - acc: 0.8672 - val_loss: 0.5180 - val_acc: 0.7812\n",
      "chunk number: 1754 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3034 - acc: 0.8761 - val_loss: 0.3486 - val_acc: 0.8672\n",
      "chunk number: 1755 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3217 - acc: 0.8761 - val_loss: 0.4492 - val_acc: 0.8438\n",
      "chunk number: 1756 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3141 - acc: 0.8828 - val_loss: 0.5309 - val_acc: 0.7812\n",
      "chunk number: 1757 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2854 - acc: 0.9007 - val_loss: 0.6935 - val_acc: 0.8125\n",
      "chunk number: 1758 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2837 - acc: 0.8973 - val_loss: 0.4489 - val_acc: 0.8359\n",
      "chunk number: 1759 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3409 - acc: 0.8806 - val_loss: 0.5532 - val_acc: 0.8359\n",
      "chunk number: 1760 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3620 - acc: 0.8616 - val_loss: 0.5392 - val_acc: 0.8359\n",
      "chunk number: 1761 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3403 - acc: 0.8850 - val_loss: 0.4924 - val_acc: 0.8516\n",
      "chunk number: 1762 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2921 - acc: 0.8884 - val_loss: 0.2959 - val_acc: 0.9062\n",
      "chunk number: 1763 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3331 - acc: 0.8694 - val_loss: 0.6033 - val_acc: 0.7656\n",
      "chunk number: 1764 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2841 - acc: 0.8996 - val_loss: 0.4623 - val_acc: 0.8281\n",
      "chunk number: 1765 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3422 - acc: 0.8739 - val_loss: 0.3921 - val_acc: 0.8594\n",
      "chunk number: 1766 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3374 - acc: 0.8806 - val_loss: 0.5765 - val_acc: 0.8125\n",
      "chunk number: 1767 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2941 - acc: 0.9062 - val_loss: 0.4711 - val_acc: 0.8125\n",
      "chunk number: 1768 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2681 - acc: 0.8917 - val_loss: 0.6641 - val_acc: 0.7969\n",
      "chunk number: 1769 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2839 - acc: 0.8884 - val_loss: 0.5001 - val_acc: 0.8438\n",
      "chunk number: 1770 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3258 - acc: 0.8917 - val_loss: 0.5802 - val_acc: 0.7969\n",
      "chunk number: 1771 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2974 - acc: 0.8884 - val_loss: 0.4203 - val_acc: 0.8359\n",
      "chunk number: 1772 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3148 - acc: 0.8862 - val_loss: 0.6734 - val_acc: 0.7891\n",
      "chunk number: 1773 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2781 - acc: 0.8996 - val_loss: 0.6781 - val_acc: 0.7812\n",
      "chunk number: 1774 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3155 - acc: 0.8862 - val_loss: 0.4973 - val_acc: 0.7812\n",
      "chunk number: 1775 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2607 - acc: 0.9007 - val_loss: 0.4815 - val_acc: 0.7812\n",
      "chunk number: 1776 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2574 - acc: 0.8996 - val_loss: 0.5197 - val_acc: 0.8281\n",
      "chunk number: 1777 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2992 - acc: 0.8839 - val_loss: 0.5127 - val_acc: 0.8125\n",
      "chunk number: 1778 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3006 - acc: 0.8806 - val_loss: 0.7053 - val_acc: 0.8125\n",
      "chunk number: 1779 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3006 - acc: 0.8650 - val_loss: 0.2923 - val_acc: 0.8516\n",
      "chunk number: 1780 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2788 - acc: 0.9007 - val_loss: 0.4596 - val_acc: 0.8750\n",
      "chunk number: 1781 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3034 - acc: 0.8728 - val_loss: 0.4173 - val_acc: 0.8125\n",
      "chunk number: 1782 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2963 - acc: 0.9040 - val_loss: 0.4374 - val_acc: 0.8125\n",
      "chunk number: 1783 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3110 - acc: 0.8806 - val_loss: 0.4618 - val_acc: 0.8359\n",
      "chunk number: 1784 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3176 - acc: 0.8817 - val_loss: 0.5340 - val_acc: 0.8125\n",
      "chunk number: 1785 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3371 - acc: 0.8728 - val_loss: 0.5429 - val_acc: 0.8281\n",
      "chunk number: 1786 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2728 - acc: 0.9007 - val_loss: 0.3854 - val_acc: 0.8672\n",
      "chunk number: 1787 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3555 - acc: 0.8694 - val_loss: 0.5324 - val_acc: 0.8047\n",
      "chunk number: 1788 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3181 - acc: 0.8850 - val_loss: 0.3707 - val_acc: 0.8359\n",
      "chunk number: 1789 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3189 - acc: 0.8761 - val_loss: 0.4578 - val_acc: 0.8438\n",
      "chunk number: 1790 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2885 - acc: 0.8761 - val_loss: 0.6009 - val_acc: 0.7891\n",
      "chunk number: 1791 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2657 - acc: 0.8929 - val_loss: 0.5449 - val_acc: 0.8281\n",
      "chunk number: 1792 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3019 - acc: 0.8783 - val_loss: 0.5501 - val_acc: 0.8281\n",
      "chunk number: 1793 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2476 - acc: 0.9085 - val_loss: 0.8807 - val_acc: 0.7656\n",
      "chunk number: 1794 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3185 - acc: 0.8783 - val_loss: 0.6386 - val_acc: 0.7891\n",
      "chunk number: 1795 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2703 - acc: 0.8940 - val_loss: 0.4129 - val_acc: 0.8672\n",
      "chunk number: 1796 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3050 - acc: 0.8862 - val_loss: 0.4206 - val_acc: 0.8516\n",
      "chunk number: 1797 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3098 - acc: 0.8895 - val_loss: 0.3805 - val_acc: 0.8359\n",
      "chunk number: 1798 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3271 - acc: 0.8761 - val_loss: 0.4429 - val_acc: 0.8281\n",
      "chunk number: 1799 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2708 - acc: 0.8996 - val_loss: 0.4632 - val_acc: 0.7812\n",
      "chunk number: 1800 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2971 - acc: 0.8850 - val_loss: 0.4594 - val_acc: 0.8672\n",
      "chunk number: 1801 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3039 - acc: 0.8996 - val_loss: 0.3904 - val_acc: 0.8125\n",
      "chunk number: 1802 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2906 - acc: 0.8862 - val_loss: 0.6971 - val_acc: 0.7578\n",
      "chunk number: 1803 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2827 - acc: 0.8940 - val_loss: 0.5372 - val_acc: 0.8125\n",
      "chunk number: 1804 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2601 - acc: 0.9074 - val_loss: 0.4397 - val_acc: 0.8594\n",
      "chunk number: 1805 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2526 - acc: 0.9129 - val_loss: 0.6754 - val_acc: 0.7812\n",
      "chunk number: 1806 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2413 - acc: 0.9174 - val_loss: 0.5302 - val_acc: 0.8203\n",
      "chunk number: 1807 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2489 - acc: 0.9051 - val_loss: 0.5945 - val_acc: 0.7969\n",
      "chunk number: 1808 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2847 - acc: 0.8962 - val_loss: 0.3301 - val_acc: 0.8750\n",
      "chunk number: 1809 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2644 - acc: 0.9040 - val_loss: 0.3986 - val_acc: 0.8125\n",
      "chunk number: 1810 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2663 - acc: 0.9074 - val_loss: 0.5214 - val_acc: 0.8516\n",
      "chunk number: 1811 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3437 - acc: 0.8661 - val_loss: 0.4428 - val_acc: 0.8359\n",
      "chunk number: 1812 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3335 - acc: 0.8929 - val_loss: 0.5078 - val_acc: 0.8047\n",
      "chunk number: 1813 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2986 - acc: 0.8862 - val_loss: 0.7426 - val_acc: 0.7734\n",
      "chunk number: 1814 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2944 - acc: 0.8828 - val_loss: 0.3625 - val_acc: 0.8906\n",
      "chunk number: 1815 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3126 - acc: 0.8828 - val_loss: 0.5550 - val_acc: 0.8047\n",
      "chunk number: 1816 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2726 - acc: 0.8895 - val_loss: 0.6582 - val_acc: 0.7656\n",
      "chunk number: 1817 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3148 - acc: 0.8828 - val_loss: 0.5210 - val_acc: 0.8281\n",
      "chunk number: 1818 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2928 - acc: 0.8917 - val_loss: 0.4719 - val_acc: 0.8125\n",
      "chunk number: 1819 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3383 - acc: 0.8739 - val_loss: 0.4919 - val_acc: 0.7969\n",
      "chunk number: 1820 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3200 - acc: 0.8795 - val_loss: 0.5180 - val_acc: 0.8672\n",
      "chunk number: 1821 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2932 - acc: 0.8828 - val_loss: 0.4123 - val_acc: 0.8516\n",
      "chunk number: 1822 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3359 - acc: 0.8806 - val_loss: 0.3712 - val_acc: 0.8359\n",
      "chunk number: 1823 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2948 - acc: 0.8929 - val_loss: 0.4734 - val_acc: 0.8125\n",
      "chunk number: 1824 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3140 - acc: 0.8862 - val_loss: 0.4941 - val_acc: 0.8047\n",
      "chunk number: 1825 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2729 - acc: 0.9007 - val_loss: 0.4420 - val_acc: 0.8516\n",
      "chunk number: 1826 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3161 - acc: 0.8917 - val_loss: 0.6134 - val_acc: 0.8516\n",
      "chunk number: 1827 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2950 - acc: 0.8862 - val_loss: 0.3431 - val_acc: 0.8594\n",
      "chunk number: 1828 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3076 - acc: 0.8828 - val_loss: 0.6421 - val_acc: 0.7891\n",
      "chunk number: 1829 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2998 - acc: 0.8884 - val_loss: 0.4019 - val_acc: 0.8516\n",
      "chunk number: 1830 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3309 - acc: 0.8594 - val_loss: 0.6322 - val_acc: 0.7812\n",
      "chunk number: 1831 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3256 - acc: 0.8806 - val_loss: 0.4457 - val_acc: 0.8672\n",
      "chunk number: 1832 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3052 - acc: 0.8772 - val_loss: 0.5197 - val_acc: 0.8047\n",
      "chunk number: 1833 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3251 - acc: 0.8728 - val_loss: 0.5062 - val_acc: 0.8125\n",
      "chunk number: 1834 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3094 - acc: 0.8884 - val_loss: 0.6696 - val_acc: 0.7812\n",
      "chunk number: 1835 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2996 - acc: 0.8929 - val_loss: 0.7072 - val_acc: 0.7969\n",
      "chunk number: 1836 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3389 - acc: 0.8761 - val_loss: 0.3284 - val_acc: 0.8281\n",
      "chunk number: 1837 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3034 - acc: 0.8873 - val_loss: 0.4243 - val_acc: 0.8203\n",
      "chunk number: 1838 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2977 - acc: 0.8951 - val_loss: 0.3976 - val_acc: 0.8359\n",
      "chunk number: 1839 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3050 - acc: 0.8917 - val_loss: 0.5108 - val_acc: 0.8047\n",
      "chunk number: 1840 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3227 - acc: 0.8783 - val_loss: 0.5282 - val_acc: 0.7969\n",
      "chunk number: 1841 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2747 - acc: 0.8884 - val_loss: 0.5296 - val_acc: 0.8047\n",
      "chunk number: 1842 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2674 - acc: 0.8962 - val_loss: 0.6013 - val_acc: 0.8203\n",
      "chunk number: 1843 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2473 - acc: 0.9085 - val_loss: 0.5449 - val_acc: 0.7812\n",
      "chunk number: 1844 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2859 - acc: 0.9018 - val_loss: 0.5006 - val_acc: 0.8594\n",
      "chunk number: 1845 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2953 - acc: 0.8940 - val_loss: 0.4179 - val_acc: 0.8438\n",
      "chunk number: 1846 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2868 - acc: 0.9040 - val_loss: 0.7520 - val_acc: 0.7656\n",
      "chunk number: 1847 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2446 - acc: 0.9018 - val_loss: 0.4682 - val_acc: 0.8125\n",
      "chunk number: 1848 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3085 - acc: 0.8862 - val_loss: 0.4837 - val_acc: 0.8125\n",
      "chunk number: 1849 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2738 - acc: 0.9029 - val_loss: 0.5488 - val_acc: 0.8047\n",
      "chunk number: 1850 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2933 - acc: 0.8906 - val_loss: 0.6129 - val_acc: 0.8047\n",
      "chunk number: 1851 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2983 - acc: 0.8895 - val_loss: 0.4319 - val_acc: 0.8281\n",
      "chunk number: 1852 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2957 - acc: 0.8873 - val_loss: 0.4847 - val_acc: 0.8281\n",
      "chunk number: 1853 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3494 - acc: 0.8605 - val_loss: 0.5531 - val_acc: 0.8125\n",
      "chunk number: 1854 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3144 - acc: 0.8795 - val_loss: 0.3996 - val_acc: 0.8438\n",
      "chunk number: 1855 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3031 - acc: 0.8873 - val_loss: 0.4099 - val_acc: 0.8047\n",
      "chunk number: 1856 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3013 - acc: 0.8873 - val_loss: 0.6837 - val_acc: 0.7422\n",
      "chunk number: 1857 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3064 - acc: 0.8917 - val_loss: 0.4725 - val_acc: 0.8438\n",
      "chunk number: 1858 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3004 - acc: 0.8839 - val_loss: 0.5735 - val_acc: 0.8281\n",
      "chunk number: 1859 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3216 - acc: 0.8806 - val_loss: 0.4076 - val_acc: 0.8594\n",
      "chunk number: 1860 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3765 - acc: 0.8583 - val_loss: 0.4712 - val_acc: 0.8516\n",
      "chunk number: 1861 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3082 - acc: 0.9007 - val_loss: 0.4797 - val_acc: 0.8594\n",
      "chunk number: 1862 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3113 - acc: 0.8862 - val_loss: 0.2851 - val_acc: 0.8984\n",
      "chunk number: 1863 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3583 - acc: 0.8683 - val_loss: 0.5261 - val_acc: 0.8047\n",
      "chunk number: 1864 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2902 - acc: 0.9007 - val_loss: 0.4573 - val_acc: 0.8438\n",
      "chunk number: 1865 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3086 - acc: 0.8850 - val_loss: 0.4510 - val_acc: 0.8047\n",
      "chunk number: 1866 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2980 - acc: 0.8828 - val_loss: 0.5184 - val_acc: 0.7969\n",
      "chunk number: 1867 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2664 - acc: 0.8984 - val_loss: 0.4614 - val_acc: 0.8125\n",
      "chunk number: 1868 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3124 - acc: 0.8828 - val_loss: 0.6171 - val_acc: 0.7969\n",
      "chunk number: 1869 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2969 - acc: 0.8895 - val_loss: 0.4023 - val_acc: 0.8359\n",
      "chunk number: 1870 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3072 - acc: 0.8783 - val_loss: 0.5004 - val_acc: 0.7578\n",
      "chunk number: 1871 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3014 - acc: 0.8984 - val_loss: 0.3819 - val_acc: 0.8281\n",
      "chunk number: 1872 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3568 - acc: 0.8806 - val_loss: 0.6472 - val_acc: 0.7969\n",
      "chunk number: 1873 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2867 - acc: 0.8973 - val_loss: 0.5705 - val_acc: 0.8125\n",
      "chunk number: 1874 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3143 - acc: 0.8940 - val_loss: 0.4646 - val_acc: 0.7812\n",
      "chunk number: 1875 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2824 - acc: 0.8873 - val_loss: 0.4277 - val_acc: 0.8516\n",
      "chunk number: 1876 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2762 - acc: 0.8873 - val_loss: 0.5670 - val_acc: 0.8125\n",
      "chunk number: 1877 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2814 - acc: 0.8895 - val_loss: 0.5104 - val_acc: 0.8281\n",
      "chunk number: 1878 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2619 - acc: 0.9062 - val_loss: 0.7762 - val_acc: 0.7812\n",
      "chunk number: 1879 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3240 - acc: 0.8828 - val_loss: 0.4260 - val_acc: 0.8203\n",
      "chunk number: 1880 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3189 - acc: 0.8895 - val_loss: 0.3203 - val_acc: 0.8594\n",
      "chunk number: 1881 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3217 - acc: 0.8806 - val_loss: 0.4425 - val_acc: 0.8203\n",
      "chunk number: 1882 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2647 - acc: 0.9018 - val_loss: 0.4052 - val_acc: 0.8438\n",
      "chunk number: 1883 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3303 - acc: 0.8817 - val_loss: 0.4763 - val_acc: 0.8359\n",
      "chunk number: 1884 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3118 - acc: 0.8828 - val_loss: 0.5570 - val_acc: 0.7812\n",
      "chunk number: 1885 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3306 - acc: 0.8672 - val_loss: 0.5663 - val_acc: 0.7812\n",
      "chunk number: 1886 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3433 - acc: 0.8694 - val_loss: 0.3732 - val_acc: 0.8594\n",
      "chunk number: 1887 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2936 - acc: 0.8884 - val_loss: 0.5297 - val_acc: 0.7969\n",
      "chunk number: 1888 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2984 - acc: 0.8884 - val_loss: 0.3456 - val_acc: 0.8750\n",
      "chunk number: 1889 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2891 - acc: 0.8850 - val_loss: 0.4917 - val_acc: 0.8516\n",
      "chunk number: 1890 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3004 - acc: 0.8884 - val_loss: 0.4340 - val_acc: 0.8594\n",
      "chunk number: 1891 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2883 - acc: 0.8951 - val_loss: 0.5486 - val_acc: 0.7734\n",
      "chunk number: 1892 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2745 - acc: 0.8951 - val_loss: 0.5725 - val_acc: 0.8594\n",
      "chunk number: 1893 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2262 - acc: 0.9196 - val_loss: 0.6423 - val_acc: 0.7891\n",
      "chunk number: 1894 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2757 - acc: 0.9118 - val_loss: 0.6370 - val_acc: 0.8125\n",
      "chunk number: 1895 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2509 - acc: 0.8984 - val_loss: 0.3134 - val_acc: 0.8672\n",
      "chunk number: 1896 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3000 - acc: 0.8772 - val_loss: 0.5135 - val_acc: 0.8359\n",
      "chunk number: 1897 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2937 - acc: 0.8917 - val_loss: 0.4477 - val_acc: 0.8203\n",
      "chunk number: 1898 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3127 - acc: 0.8817 - val_loss: 0.4181 - val_acc: 0.8125\n",
      "chunk number: 1899 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2776 - acc: 0.9007 - val_loss: 0.3185 - val_acc: 0.8672\n",
      "chunk number: 1900 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2689 - acc: 0.8962 - val_loss: 0.4509 - val_acc: 0.7969\n",
      "chunk number: 1901 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2641 - acc: 0.8929 - val_loss: 0.3389 - val_acc: 0.8438\n",
      "chunk number: 1902 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2803 - acc: 0.8917 - val_loss: 0.6003 - val_acc: 0.8125\n",
      "chunk number: 1903 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2994 - acc: 0.8862 - val_loss: 0.4724 - val_acc: 0.8359\n",
      "chunk number: 1904 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2500 - acc: 0.8984 - val_loss: 0.4584 - val_acc: 0.8516\n",
      "chunk number: 1905 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2735 - acc: 0.9074 - val_loss: 0.6854 - val_acc: 0.7734\n",
      "chunk number: 1906 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2315 - acc: 0.9174 - val_loss: 0.4788 - val_acc: 0.8203\n",
      "chunk number: 1907 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2367 - acc: 0.9074 - val_loss: 0.4565 - val_acc: 0.8516\n",
      "chunk number: 1908 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2541 - acc: 0.9141 - val_loss: 0.4324 - val_acc: 0.8828\n",
      "chunk number: 1909 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2665 - acc: 0.9051 - val_loss: 0.3630 - val_acc: 0.8516\n",
      "chunk number: 1910 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3154 - acc: 0.8917 - val_loss: 0.7522 - val_acc: 0.7812\n",
      "chunk number: 1911 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3195 - acc: 0.8761 - val_loss: 0.5014 - val_acc: 0.8125\n",
      "chunk number: 1912 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3563 - acc: 0.8538 - val_loss: 0.6123 - val_acc: 0.7578\n",
      "chunk number: 1913 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2932 - acc: 0.8929 - val_loss: 0.7592 - val_acc: 0.7891\n",
      "chunk number: 1914 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3387 - acc: 0.8772 - val_loss: 0.4223 - val_acc: 0.8359\n",
      "chunk number: 1915 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3067 - acc: 0.8850 - val_loss: 0.6030 - val_acc: 0.8203\n",
      "chunk number: 1916 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2729 - acc: 0.8929 - val_loss: 0.6500 - val_acc: 0.7734\n",
      "chunk number: 1917 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3066 - acc: 0.8929 - val_loss: 0.4952 - val_acc: 0.8125\n",
      "chunk number: 1918 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3166 - acc: 0.8940 - val_loss: 0.5604 - val_acc: 0.8438\n",
      "chunk number: 1919 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2985 - acc: 0.8996 - val_loss: 0.5284 - val_acc: 0.7891\n",
      "chunk number: 1920 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3004 - acc: 0.8984 - val_loss: 0.5328 - val_acc: 0.8594\n",
      "chunk number: 1921 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2817 - acc: 0.8929 - val_loss: 0.3660 - val_acc: 0.8750\n",
      "chunk number: 1922 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2686 - acc: 0.8906 - val_loss: 0.4556 - val_acc: 0.7969\n",
      "chunk number: 1923 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2919 - acc: 0.9029 - val_loss: 0.4985 - val_acc: 0.8594\n",
      "chunk number: 1924 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3000 - acc: 0.8962 - val_loss: 0.4876 - val_acc: 0.8359\n",
      "chunk number: 1925 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2643 - acc: 0.9007 - val_loss: 0.5562 - val_acc: 0.8438\n",
      "chunk number: 1926 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3422 - acc: 0.8884 - val_loss: 0.7501 - val_acc: 0.7422\n",
      "chunk number: 1927 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2706 - acc: 0.8984 - val_loss: 0.3066 - val_acc: 0.8828\n",
      "chunk number: 1928 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3189 - acc: 0.8850 - val_loss: 0.6328 - val_acc: 0.7969\n",
      "chunk number: 1929 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2933 - acc: 0.8895 - val_loss: 0.4123 - val_acc: 0.8203\n",
      "chunk number: 1930 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3387 - acc: 0.8594 - val_loss: 0.6903 - val_acc: 0.7969\n",
      "chunk number: 1931 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2879 - acc: 0.8996 - val_loss: 0.5055 - val_acc: 0.8125\n",
      "chunk number: 1932 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3024 - acc: 0.8973 - val_loss: 0.4055 - val_acc: 0.8438\n",
      "chunk number: 1933 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2776 - acc: 0.8906 - val_loss: 0.3942 - val_acc: 0.8047\n",
      "chunk number: 1934 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2883 - acc: 0.8996 - val_loss: 0.6166 - val_acc: 0.7500\n",
      "chunk number: 1935 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2746 - acc: 0.8917 - val_loss: 0.6604 - val_acc: 0.8047\n",
      "chunk number: 1936 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3155 - acc: 0.8917 - val_loss: 0.4211 - val_acc: 0.8672\n",
      "chunk number: 1937 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3226 - acc: 0.8672 - val_loss: 0.4038 - val_acc: 0.8594\n",
      "chunk number: 1938 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2931 - acc: 0.9007 - val_loss: 0.5158 - val_acc: 0.8047\n",
      "chunk number: 1939 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3028 - acc: 0.8940 - val_loss: 0.4624 - val_acc: 0.8203\n",
      "chunk number: 1940 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2984 - acc: 0.8962 - val_loss: 0.4781 - val_acc: 0.8203\n",
      "chunk number: 1941 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2492 - acc: 0.9118 - val_loss: 0.5643 - val_acc: 0.7969\n",
      "chunk number: 1942 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3175 - acc: 0.8873 - val_loss: 0.5766 - val_acc: 0.8047\n",
      "chunk number: 1943 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2415 - acc: 0.9163 - val_loss: 0.6123 - val_acc: 0.7656\n",
      "chunk number: 1944 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2411 - acc: 0.9062 - val_loss: 0.6466 - val_acc: 0.8125\n",
      "chunk number: 1945 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3132 - acc: 0.8895 - val_loss: 0.5173 - val_acc: 0.8203\n",
      "chunk number: 1946 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3144 - acc: 0.8917 - val_loss: 0.6849 - val_acc: 0.7812\n",
      "chunk number: 1947 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3005 - acc: 0.8895 - val_loss: 0.4875 - val_acc: 0.7812\n",
      "chunk number: 1948 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2640 - acc: 0.8973 - val_loss: 0.6744 - val_acc: 0.7891\n",
      "chunk number: 1949 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2625 - acc: 0.9096 - val_loss: 0.4829 - val_acc: 0.8438\n",
      "chunk number: 1950 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2816 - acc: 0.9029 - val_loss: 0.6308 - val_acc: 0.8438\n",
      "chunk number: 1951 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2755 - acc: 0.8973 - val_loss: 0.4247 - val_acc: 0.8438\n",
      "chunk number: 1952 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2884 - acc: 0.8962 - val_loss: 0.3995 - val_acc: 0.8359\n",
      "chunk number: 1953 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2756 - acc: 0.8839 - val_loss: 0.5490 - val_acc: 0.8203\n",
      "chunk number: 1954 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3071 - acc: 0.8884 - val_loss: 0.4428 - val_acc: 0.8359\n",
      "chunk number: 1955 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3129 - acc: 0.8850 - val_loss: 0.3836 - val_acc: 0.8516\n",
      "chunk number: 1956 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2923 - acc: 0.8929 - val_loss: 0.5346 - val_acc: 0.7969\n",
      "chunk number: 1957 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3358 - acc: 0.8828 - val_loss: 0.4914 - val_acc: 0.8359\n",
      "chunk number: 1958 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2468 - acc: 0.9141 - val_loss: 0.5078 - val_acc: 0.8047\n",
      "chunk number: 1959 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3096 - acc: 0.8772 - val_loss: 0.4529 - val_acc: 0.8594\n",
      "chunk number: 1960 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3173 - acc: 0.8739 - val_loss: 0.4563 - val_acc: 0.8594\n",
      "chunk number: 1961 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3174 - acc: 0.8806 - val_loss: 0.4663 - val_acc: 0.8516\n",
      "chunk number: 1962 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2703 - acc: 0.8951 - val_loss: 0.3751 - val_acc: 0.8828\n",
      "chunk number: 1963 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3052 - acc: 0.8783 - val_loss: 0.5171 - val_acc: 0.7969\n",
      "chunk number: 1964 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2180 - acc: 0.9364 - val_loss: 0.5016 - val_acc: 0.8047\n",
      "chunk number: 1965 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2989 - acc: 0.8828 - val_loss: 0.4543 - val_acc: 0.8125\n",
      "chunk number: 1966 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2634 - acc: 0.9051 - val_loss: 0.5107 - val_acc: 0.8281\n",
      "chunk number: 1967 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2899 - acc: 0.8962 - val_loss: 0.4740 - val_acc: 0.8047\n",
      "chunk number: 1968 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2686 - acc: 0.8973 - val_loss: 0.6108 - val_acc: 0.8359\n",
      "chunk number: 1969 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2643 - acc: 0.9029 - val_loss: 0.4187 - val_acc: 0.8594\n",
      "chunk number: 1970 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2960 - acc: 0.8996 - val_loss: 0.7288 - val_acc: 0.7812\n",
      "chunk number: 1971 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2809 - acc: 0.8973 - val_loss: 0.4060 - val_acc: 0.8281\n",
      "chunk number: 1972 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2974 - acc: 0.8884 - val_loss: 0.5330 - val_acc: 0.7891\n",
      "chunk number: 1973 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2575 - acc: 0.9107 - val_loss: 0.6677 - val_acc: 0.8047\n",
      "chunk number: 1974 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3185 - acc: 0.8783 - val_loss: 0.5602 - val_acc: 0.8203\n",
      "chunk number: 1975 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2867 - acc: 0.8828 - val_loss: 0.4969 - val_acc: 0.8281\n",
      "chunk number: 1976 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2645 - acc: 0.8984 - val_loss: 0.4582 - val_acc: 0.8438\n",
      "chunk number: 1977 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2547 - acc: 0.8951 - val_loss: 0.4628 - val_acc: 0.8672\n",
      "chunk number: 1978 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2289 - acc: 0.9074 - val_loss: 0.7107 - val_acc: 0.7734\n",
      "chunk number: 1979 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2808 - acc: 0.8996 - val_loss: 0.3655 - val_acc: 0.8359\n",
      "chunk number: 1980 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2509 - acc: 0.9196 - val_loss: 0.4336 - val_acc: 0.8828\n",
      "chunk number: 1981 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2579 - acc: 0.8984 - val_loss: 0.4025 - val_acc: 0.8516\n",
      "chunk number: 1982 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3081 - acc: 0.8839 - val_loss: 0.3994 - val_acc: 0.8516\n",
      "chunk number: 1983 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3314 - acc: 0.8750 - val_loss: 0.4829 - val_acc: 0.8203\n",
      "chunk number: 1984 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2830 - acc: 0.8895 - val_loss: 0.5094 - val_acc: 0.7812\n",
      "chunk number: 1985 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3059 - acc: 0.8895 - val_loss: 0.5864 - val_acc: 0.7969\n",
      "chunk number: 1986 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3214 - acc: 0.8884 - val_loss: 0.3253 - val_acc: 0.8828\n",
      "chunk number: 1987 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3076 - acc: 0.8728 - val_loss: 0.5604 - val_acc: 0.8203\n",
      "chunk number: 1988 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3494 - acc: 0.8683 - val_loss: 0.3561 - val_acc: 0.8281\n",
      "chunk number: 1989 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3046 - acc: 0.8739 - val_loss: 0.4049 - val_acc: 0.8594\n",
      "chunk number: 1990 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2516 - acc: 0.9007 - val_loss: 0.5040 - val_acc: 0.8438\n",
      "chunk number: 1991 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2898 - acc: 0.8906 - val_loss: 0.6037 - val_acc: 0.8203\n",
      "chunk number: 1992 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2901 - acc: 0.8895 - val_loss: 0.5654 - val_acc: 0.8281\n",
      "chunk number: 1993 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2544 - acc: 0.9118 - val_loss: 0.7431 - val_acc: 0.7422\n",
      "chunk number: 1994 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2861 - acc: 0.8996 - val_loss: 0.7399 - val_acc: 0.7578\n",
      "chunk number: 1995 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2441 - acc: 0.8973 - val_loss: 0.4778 - val_acc: 0.8047\n",
      "chunk number: 1996 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2988 - acc: 0.8828 - val_loss: 0.5026 - val_acc: 0.8203\n",
      "chunk number: 1997 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2559 - acc: 0.8973 - val_loss: 0.4370 - val_acc: 0.8594\n",
      "chunk number: 1998 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3296 - acc: 0.8761 - val_loss: 0.3853 - val_acc: 0.8203\n",
      "chunk number: 1999 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2642 - acc: 0.8962 - val_loss: 0.3461 - val_acc: 0.8438\n",
      "chunk number: 2000 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2826 - acc: 0.8996 - val_loss: 0.5169 - val_acc: 0.8438\n"
     ]
    }
   ],
   "source": [
    "X_files = sorted(os.listdir(pickle_path + \"Spectra\"))\n",
    "y_files = sorted(os.listdir(pickle_path + \"Targets\"))\n",
    "\n",
    "num_chunks = len(y_files)\n",
    "iteration = 0\n",
    "\n",
    "acc=[]\n",
    "loss=[]\n",
    "\n",
    "val_loss=[]\n",
    "val_acc=[]\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "for _ in range(num_epochs):\n",
    "    \n",
    "    for X_file, y_file in zip(X_files,y_files):\n",
    "\n",
    "        iteration +=1\n",
    "        print('chunk number: ' + str(iteration) + \" of \" + str(num_chunks*num_epochs))\n",
    "\n",
    "        X,y = Data_Gen(X_file, y_file, mean_log_amplitude, threshold = 0.5, h_shift_range=(-30,30))\n",
    "\n",
    "        history=model.fit(X, y, batch_size=128, epochs=1, validation_split=1/8, verbose=2)\n",
    "\n",
    "        val_acc.append(history.history['val_acc'])\n",
    "        acc.append(history.history['acc'])\n",
    "        \n",
    "        loss.append(history.history['loss'])\n",
    "        val_loss.append(history.history['val_loss'])\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc02d848ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.plot(acc)\n",
    "plt.plot(val_acc, alpha=0.5)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss, alpha=0.5)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.subplots_adjust(right=1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Much better than before, and at twice the epochs! Still room for improvement..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: Do same as above but augment data 100% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(4, 4), strides=(1, 1), activation='relu', input_shape=(129,129,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (4, 4), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (4, 4), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 1 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 3.6287 - acc: 0.2087 - val_loss: 1.7268 - val_acc: 0.2656\n",
      "chunk number: 2 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.5722 - acc: 0.3527 - val_loss: 1.2781 - val_acc: 0.4766\n",
      "chunk number: 3 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.2681 - acc: 0.4554 - val_loss: 1.1969 - val_acc: 0.5547\n",
      "chunk number: 4 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1182 - acc: 0.5547 - val_loss: 1.0197 - val_acc: 0.6172\n",
      "chunk number: 5 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1794 - acc: 0.5324 - val_loss: 1.1574 - val_acc: 0.5469\n",
      "chunk number: 6 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0832 - acc: 0.5804 - val_loss: 0.9985 - val_acc: 0.5234\n",
      "chunk number: 7 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0321 - acc: 0.5904 - val_loss: 1.0515 - val_acc: 0.5859\n",
      "chunk number: 8 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0418 - acc: 0.5971 - val_loss: 1.0148 - val_acc: 0.5625\n",
      "chunk number: 9 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9834 - acc: 0.6183 - val_loss: 0.9558 - val_acc: 0.6016\n",
      "chunk number: 10 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9949 - acc: 0.6071 - val_loss: 0.9735 - val_acc: 0.6016\n",
      "chunk number: 11 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0040 - acc: 0.6027 - val_loss: 0.9329 - val_acc: 0.6172\n",
      "chunk number: 12 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9658 - acc: 0.6060 - val_loss: 0.9236 - val_acc: 0.6562\n",
      "chunk number: 13 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9368 - acc: 0.6194 - val_loss: 0.9002 - val_acc: 0.6250\n",
      "chunk number: 14 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0532 - acc: 0.6038 - val_loss: 1.0435 - val_acc: 0.6094\n",
      "chunk number: 15 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0097 - acc: 0.6060 - val_loss: 0.8829 - val_acc: 0.6797\n",
      "chunk number: 16 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9215 - acc: 0.6317 - val_loss: 1.0583 - val_acc: 0.6172\n",
      "chunk number: 17 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9532 - acc: 0.6183 - val_loss: 0.9090 - val_acc: 0.6406\n",
      "chunk number: 18 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9442 - acc: 0.6183 - val_loss: 0.8952 - val_acc: 0.6797\n",
      "chunk number: 19 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9643 - acc: 0.6016 - val_loss: 0.9808 - val_acc: 0.6406\n",
      "chunk number: 20 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9531 - acc: 0.6328 - val_loss: 0.9968 - val_acc: 0.5859\n",
      "chunk number: 21 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8902 - acc: 0.6562 - val_loss: 0.8076 - val_acc: 0.7109\n",
      "chunk number: 22 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8865 - acc: 0.6417 - val_loss: 0.9607 - val_acc: 0.6016\n",
      "chunk number: 23 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8568 - acc: 0.6864 - val_loss: 0.7888 - val_acc: 0.7109\n",
      "chunk number: 24 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9177 - acc: 0.6172 - val_loss: 0.8630 - val_acc: 0.6641\n",
      "chunk number: 25 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8313 - acc: 0.6696 - val_loss: 0.8480 - val_acc: 0.6641\n",
      "chunk number: 26 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8775 - acc: 0.6451 - val_loss: 0.8368 - val_acc: 0.7188\n",
      "chunk number: 27 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8649 - acc: 0.6529 - val_loss: 0.8081 - val_acc: 0.7266\n",
      "chunk number: 28 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8719 - acc: 0.6417 - val_loss: 0.9274 - val_acc: 0.6328\n",
      "chunk number: 29 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8910 - acc: 0.6440 - val_loss: 0.8708 - val_acc: 0.6875\n",
      "chunk number: 30 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9000 - acc: 0.6596 - val_loss: 1.0610 - val_acc: 0.5469\n",
      "chunk number: 31 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8894 - acc: 0.6306 - val_loss: 0.8557 - val_acc: 0.6875\n",
      "chunk number: 32 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8647 - acc: 0.6551 - val_loss: 0.9256 - val_acc: 0.6328\n",
      "chunk number: 33 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8760 - acc: 0.6484 - val_loss: 0.7530 - val_acc: 0.7109\n",
      "chunk number: 34 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8564 - acc: 0.6629 - val_loss: 0.9015 - val_acc: 0.6562\n",
      "chunk number: 35 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8458 - acc: 0.6696 - val_loss: 0.9529 - val_acc: 0.6250\n",
      "chunk number: 36 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8488 - acc: 0.6842 - val_loss: 0.7759 - val_acc: 0.6875\n",
      "chunk number: 37 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8440 - acc: 0.6842 - val_loss: 0.7603 - val_acc: 0.7188\n",
      "chunk number: 38 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8054 - acc: 0.6931 - val_loss: 0.7331 - val_acc: 0.7656\n",
      "chunk number: 39 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7714 - acc: 0.7109 - val_loss: 0.7269 - val_acc: 0.7031\n",
      "chunk number: 40 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8470 - acc: 0.6708 - val_loss: 0.8494 - val_acc: 0.6719\n",
      "chunk number: 41 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8227 - acc: 0.6797 - val_loss: 0.7821 - val_acc: 0.6719\n",
      "chunk number: 42 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8017 - acc: 0.7054 - val_loss: 0.8131 - val_acc: 0.6484\n",
      "chunk number: 43 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8156 - acc: 0.6908 - val_loss: 0.7596 - val_acc: 0.6406\n",
      "chunk number: 44 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7688 - acc: 0.7031 - val_loss: 0.6938 - val_acc: 0.7578\n",
      "chunk number: 45 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8592 - acc: 0.6529 - val_loss: 0.6576 - val_acc: 0.7109\n",
      "chunk number: 46 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8349 - acc: 0.6719 - val_loss: 0.7476 - val_acc: 0.7266\n",
      "chunk number: 47 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7605 - acc: 0.7143 - val_loss: 0.8299 - val_acc: 0.6719\n",
      "chunk number: 48 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8206 - acc: 0.6730 - val_loss: 0.8989 - val_acc: 0.6562\n",
      "chunk number: 49 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7345 - acc: 0.7288 - val_loss: 0.8590 - val_acc: 0.7188\n",
      "chunk number: 50 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8658 - acc: 0.6842 - val_loss: 0.8342 - val_acc: 0.7188\n",
      "chunk number: 51 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8110 - acc: 0.6808 - val_loss: 0.7945 - val_acc: 0.7266\n",
      "chunk number: 52 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7896 - acc: 0.6886 - val_loss: 0.6981 - val_acc: 0.7500\n",
      "chunk number: 53 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8019 - acc: 0.6842 - val_loss: 0.7961 - val_acc: 0.6875\n",
      "chunk number: 54 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7888 - acc: 0.6897 - val_loss: 0.7499 - val_acc: 0.7109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 55 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7719 - acc: 0.6964 - val_loss: 0.7532 - val_acc: 0.6875\n",
      "chunk number: 56 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7646 - acc: 0.6987 - val_loss: 0.6732 - val_acc: 0.7344\n",
      "chunk number: 57 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7849 - acc: 0.6875 - val_loss: 0.6702 - val_acc: 0.7344\n",
      "chunk number: 58 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7824 - acc: 0.6886 - val_loss: 0.6891 - val_acc: 0.7578\n",
      "chunk number: 59 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7599 - acc: 0.7020 - val_loss: 0.7329 - val_acc: 0.7500\n",
      "chunk number: 60 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8647 - acc: 0.6730 - val_loss: 0.7301 - val_acc: 0.7188\n",
      "chunk number: 61 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7491 - acc: 0.7221 - val_loss: 0.6385 - val_acc: 0.7891\n",
      "chunk number: 62 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7390 - acc: 0.7221 - val_loss: 0.6402 - val_acc: 0.7422\n",
      "chunk number: 63 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7904 - acc: 0.6730 - val_loss: 0.7504 - val_acc: 0.6328\n",
      "chunk number: 64 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6821 - acc: 0.7355 - val_loss: 0.7854 - val_acc: 0.7188\n",
      "chunk number: 65 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7421 - acc: 0.7333 - val_loss: 0.6427 - val_acc: 0.7656\n",
      "chunk number: 66 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7507 - acc: 0.6987 - val_loss: 0.8094 - val_acc: 0.6875\n",
      "chunk number: 67 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7150 - acc: 0.7333 - val_loss: 0.7204 - val_acc: 0.6719\n",
      "chunk number: 68 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7665 - acc: 0.6931 - val_loss: 0.8983 - val_acc: 0.6953\n",
      "chunk number: 69 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7617 - acc: 0.7132 - val_loss: 0.7129 - val_acc: 0.7266\n",
      "chunk number: 70 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7681 - acc: 0.6920 - val_loss: 0.8188 - val_acc: 0.6719\n",
      "chunk number: 71 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7152 - acc: 0.7221 - val_loss: 0.8045 - val_acc: 0.6797\n",
      "chunk number: 72 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6784 - acc: 0.7388 - val_loss: 0.7309 - val_acc: 0.7812\n",
      "chunk number: 73 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6926 - acc: 0.7377 - val_loss: 0.7025 - val_acc: 0.6719\n",
      "chunk number: 74 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7142 - acc: 0.7400 - val_loss: 0.8771 - val_acc: 0.6094\n",
      "chunk number: 75 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7701 - acc: 0.7042 - val_loss: 0.6654 - val_acc: 0.7578\n",
      "chunk number: 76 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7061 - acc: 0.7299 - val_loss: 0.7422 - val_acc: 0.7344\n",
      "chunk number: 77 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7419 - acc: 0.6875 - val_loss: 0.6517 - val_acc: 0.7500\n",
      "chunk number: 78 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6701 - acc: 0.7455 - val_loss: 0.9303 - val_acc: 0.5781\n",
      "chunk number: 79 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7198 - acc: 0.7143 - val_loss: 0.5996 - val_acc: 0.7891\n",
      "chunk number: 80 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7416 - acc: 0.7098 - val_loss: 0.7204 - val_acc: 0.7188\n",
      "chunk number: 81 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7395 - acc: 0.6942 - val_loss: 0.6024 - val_acc: 0.7734\n",
      "chunk number: 82 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6896 - acc: 0.7377 - val_loss: 0.6503 - val_acc: 0.7578\n",
      "chunk number: 83 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7381 - acc: 0.7087 - val_loss: 0.8138 - val_acc: 0.6641\n",
      "chunk number: 84 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6763 - acc: 0.7411 - val_loss: 0.6414 - val_acc: 0.7422\n",
      "chunk number: 85 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7490 - acc: 0.7254 - val_loss: 0.5875 - val_acc: 0.7891\n",
      "chunk number: 86 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7260 - acc: 0.7210 - val_loss: 0.7023 - val_acc: 0.7422\n",
      "chunk number: 87 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7151 - acc: 0.7455 - val_loss: 0.7439 - val_acc: 0.7500\n",
      "chunk number: 88 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7951 - acc: 0.6953 - val_loss: 0.5632 - val_acc: 0.7969\n",
      "chunk number: 89 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7300 - acc: 0.7232 - val_loss: 0.6083 - val_acc: 0.7734\n",
      "chunk number: 90 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7210 - acc: 0.7433 - val_loss: 0.7023 - val_acc: 0.7266\n",
      "chunk number: 91 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6860 - acc: 0.7422 - val_loss: 0.7739 - val_acc: 0.7188\n",
      "chunk number: 92 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6662 - acc: 0.7254 - val_loss: 0.5932 - val_acc: 0.7891\n",
      "chunk number: 93 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6359 - acc: 0.7511 - val_loss: 0.7844 - val_acc: 0.7500\n",
      "chunk number: 94 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6749 - acc: 0.7377 - val_loss: 0.7363 - val_acc: 0.7188\n",
      "chunk number: 95 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6789 - acc: 0.7333 - val_loss: 0.5451 - val_acc: 0.7891\n",
      "chunk number: 96 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6885 - acc: 0.7087 - val_loss: 0.6582 - val_acc: 0.7578\n",
      "chunk number: 97 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6785 - acc: 0.7299 - val_loss: 0.6672 - val_acc: 0.7578\n",
      "chunk number: 98 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6893 - acc: 0.7377 - val_loss: 0.6525 - val_acc: 0.7656\n",
      "chunk number: 99 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6877 - acc: 0.7522 - val_loss: 0.6271 - val_acc: 0.7969\n",
      "chunk number: 100 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7241 - acc: 0.7098 - val_loss: 0.6013 - val_acc: 0.7812\n",
      "chunk number: 101 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6544 - acc: 0.7589 - val_loss: 0.5948 - val_acc: 0.7422\n",
      "chunk number: 102 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6998 - acc: 0.7266 - val_loss: 0.6887 - val_acc: 0.7344\n",
      "chunk number: 103 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6790 - acc: 0.7400 - val_loss: 0.6418 - val_acc: 0.7500\n",
      "chunk number: 104 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6587 - acc: 0.7467 - val_loss: 0.6721 - val_acc: 0.7500\n",
      "chunk number: 105 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7451 - acc: 0.7076 - val_loss: 0.7602 - val_acc: 0.7188\n",
      "chunk number: 106 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6730 - acc: 0.7612 - val_loss: 0.6742 - val_acc: 0.7500\n",
      "chunk number: 107 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6571 - acc: 0.7511 - val_loss: 0.7121 - val_acc: 0.7031\n",
      "chunk number: 108 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6572 - acc: 0.7511 - val_loss: 0.5735 - val_acc: 0.7734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 109 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6419 - acc: 0.7779 - val_loss: 0.6111 - val_acc: 0.7031\n",
      "chunk number: 110 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6750 - acc: 0.7333 - val_loss: 0.6839 - val_acc: 0.7578\n",
      "chunk number: 111 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7257 - acc: 0.7232 - val_loss: 0.7713 - val_acc: 0.7031\n",
      "chunk number: 112 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7377 - acc: 0.7266 - val_loss: 0.5894 - val_acc: 0.7656\n",
      "chunk number: 113 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6732 - acc: 0.7433 - val_loss: 0.7079 - val_acc: 0.7266\n",
      "chunk number: 114 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7234 - acc: 0.7243 - val_loss: 0.6336 - val_acc: 0.7891\n",
      "chunk number: 115 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6857 - acc: 0.7333 - val_loss: 0.6921 - val_acc: 0.7188\n",
      "chunk number: 116 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6217 - acc: 0.7600 - val_loss: 0.7491 - val_acc: 0.6953\n",
      "chunk number: 117 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6665 - acc: 0.7388 - val_loss: 0.6438 - val_acc: 0.7656\n",
      "chunk number: 118 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6467 - acc: 0.7433 - val_loss: 0.6821 - val_acc: 0.7188\n",
      "chunk number: 119 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6252 - acc: 0.7656 - val_loss: 0.7896 - val_acc: 0.6875\n",
      "chunk number: 120 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7121 - acc: 0.7422 - val_loss: 0.6929 - val_acc: 0.7734\n",
      "chunk number: 121 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6139 - acc: 0.7634 - val_loss: 0.5518 - val_acc: 0.7969\n",
      "chunk number: 122 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6410 - acc: 0.7533 - val_loss: 0.7012 - val_acc: 0.7344\n",
      "chunk number: 123 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6130 - acc: 0.7790 - val_loss: 0.5432 - val_acc: 0.7969\n",
      "chunk number: 124 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7037 - acc: 0.7411 - val_loss: 0.6728 - val_acc: 0.7500\n",
      "chunk number: 125 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6405 - acc: 0.7578 - val_loss: 0.6856 - val_acc: 0.7500\n",
      "chunk number: 126 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6718 - acc: 0.7411 - val_loss: 0.6972 - val_acc: 0.7500\n",
      "chunk number: 127 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6593 - acc: 0.7467 - val_loss: 0.4845 - val_acc: 0.8281\n",
      "chunk number: 128 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6503 - acc: 0.7478 - val_loss: 0.6506 - val_acc: 0.7578\n",
      "chunk number: 129 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6535 - acc: 0.7478 - val_loss: 0.6104 - val_acc: 0.7656\n",
      "chunk number: 130 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6751 - acc: 0.7500 - val_loss: 0.7597 - val_acc: 0.7031\n",
      "chunk number: 131 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6641 - acc: 0.7400 - val_loss: 0.7092 - val_acc: 0.7031\n",
      "chunk number: 132 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6375 - acc: 0.7533 - val_loss: 0.8067 - val_acc: 0.6797\n",
      "chunk number: 133 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6928 - acc: 0.7165 - val_loss: 0.5416 - val_acc: 0.7422\n",
      "chunk number: 134 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6832 - acc: 0.7210 - val_loss: 0.6910 - val_acc: 0.7266\n",
      "chunk number: 135 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6907 - acc: 0.7321 - val_loss: 0.6715 - val_acc: 0.7656\n",
      "chunk number: 136 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6718 - acc: 0.7679 - val_loss: 0.6435 - val_acc: 0.7578\n",
      "chunk number: 137 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7000 - acc: 0.7143 - val_loss: 0.5033 - val_acc: 0.8047\n",
      "chunk number: 138 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6426 - acc: 0.7522 - val_loss: 0.6513 - val_acc: 0.7656\n",
      "chunk number: 139 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6482 - acc: 0.7556 - val_loss: 0.6209 - val_acc: 0.7500\n",
      "chunk number: 140 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6799 - acc: 0.7411 - val_loss: 0.6416 - val_acc: 0.7500\n",
      "chunk number: 141 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6274 - acc: 0.7578 - val_loss: 0.6176 - val_acc: 0.7500\n",
      "chunk number: 142 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6257 - acc: 0.7757 - val_loss: 0.5907 - val_acc: 0.7734\n",
      "chunk number: 143 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6237 - acc: 0.7645 - val_loss: 0.5779 - val_acc: 0.7422\n",
      "chunk number: 144 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5765 - acc: 0.7790 - val_loss: 0.6177 - val_acc: 0.7422\n",
      "chunk number: 145 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6432 - acc: 0.7522 - val_loss: 0.6094 - val_acc: 0.7266\n",
      "chunk number: 146 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6595 - acc: 0.7556 - val_loss: 0.7676 - val_acc: 0.7188\n",
      "chunk number: 147 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6324 - acc: 0.7645 - val_loss: 0.6151 - val_acc: 0.7969\n",
      "chunk number: 148 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6746 - acc: 0.7545 - val_loss: 0.8229 - val_acc: 0.6797\n",
      "chunk number: 149 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5887 - acc: 0.7600 - val_loss: 0.6839 - val_acc: 0.7891\n",
      "chunk number: 150 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6617 - acc: 0.7411 - val_loss: 0.6794 - val_acc: 0.7344\n",
      "chunk number: 151 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6572 - acc: 0.7522 - val_loss: 0.7421 - val_acc: 0.7031\n",
      "chunk number: 152 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5904 - acc: 0.7712 - val_loss: 0.5524 - val_acc: 0.7734\n",
      "chunk number: 153 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6514 - acc: 0.7321 - val_loss: 0.6817 - val_acc: 0.7734\n",
      "chunk number: 154 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6208 - acc: 0.7500 - val_loss: 0.5244 - val_acc: 0.8047\n",
      "chunk number: 155 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6208 - acc: 0.7623 - val_loss: 0.6401 - val_acc: 0.7578\n",
      "chunk number: 156 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6546 - acc: 0.7400 - val_loss: 0.5923 - val_acc: 0.7344\n",
      "chunk number: 157 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6532 - acc: 0.7411 - val_loss: 0.5877 - val_acc: 0.7969\n",
      "chunk number: 158 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6231 - acc: 0.7600 - val_loss: 0.5720 - val_acc: 0.7969\n",
      "chunk number: 159 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6144 - acc: 0.7768 - val_loss: 0.5217 - val_acc: 0.8125\n",
      "chunk number: 160 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7234 - acc: 0.7344 - val_loss: 0.6022 - val_acc: 0.7578\n",
      "chunk number: 161 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6384 - acc: 0.7589 - val_loss: 0.5714 - val_acc: 0.8203\n",
      "chunk number: 162 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6119 - acc: 0.7679 - val_loss: 0.5245 - val_acc: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 163 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6428 - acc: 0.7455 - val_loss: 0.6632 - val_acc: 0.7266\n",
      "chunk number: 164 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5399 - acc: 0.8114 - val_loss: 0.6542 - val_acc: 0.7656\n",
      "chunk number: 165 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6600 - acc: 0.7556 - val_loss: 0.5277 - val_acc: 0.8125\n",
      "chunk number: 166 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6436 - acc: 0.7467 - val_loss: 0.7414 - val_acc: 0.6875\n",
      "chunk number: 167 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6021 - acc: 0.7690 - val_loss: 0.6067 - val_acc: 0.7812\n",
      "chunk number: 168 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6493 - acc: 0.7500 - val_loss: 0.7246 - val_acc: 0.6953\n",
      "chunk number: 169 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6452 - acc: 0.7511 - val_loss: 0.5845 - val_acc: 0.7500\n",
      "chunk number: 170 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6125 - acc: 0.7812 - val_loss: 0.7191 - val_acc: 0.7578\n",
      "chunk number: 171 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5877 - acc: 0.7824 - val_loss: 0.5953 - val_acc: 0.7109\n",
      "chunk number: 172 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5862 - acc: 0.7612 - val_loss: 0.6258 - val_acc: 0.7812\n",
      "chunk number: 173 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5618 - acc: 0.7801 - val_loss: 0.6566 - val_acc: 0.7422\n",
      "chunk number: 174 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6318 - acc: 0.7701 - val_loss: 0.7689 - val_acc: 0.7109\n",
      "chunk number: 175 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6239 - acc: 0.7567 - val_loss: 0.5802 - val_acc: 0.7578\n",
      "chunk number: 176 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5771 - acc: 0.7857 - val_loss: 0.6264 - val_acc: 0.7500\n",
      "chunk number: 177 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5880 - acc: 0.7589 - val_loss: 0.5435 - val_acc: 0.7734\n",
      "chunk number: 178 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5967 - acc: 0.7612 - val_loss: 0.7700 - val_acc: 0.6953\n",
      "chunk number: 179 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5924 - acc: 0.7835 - val_loss: 0.4793 - val_acc: 0.8047\n",
      "chunk number: 180 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5723 - acc: 0.7969 - val_loss: 0.5834 - val_acc: 0.8281\n",
      "chunk number: 181 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5976 - acc: 0.7656 - val_loss: 0.5677 - val_acc: 0.7578\n",
      "chunk number: 182 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6017 - acc: 0.7690 - val_loss: 0.5494 - val_acc: 0.7578\n",
      "chunk number: 183 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6190 - acc: 0.7589 - val_loss: 0.6425 - val_acc: 0.7578\n",
      "chunk number: 184 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5707 - acc: 0.7801 - val_loss: 0.5453 - val_acc: 0.7734\n",
      "chunk number: 185 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6135 - acc: 0.7757 - val_loss: 0.5961 - val_acc: 0.7812\n",
      "chunk number: 186 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6149 - acc: 0.7634 - val_loss: 0.5307 - val_acc: 0.7812\n",
      "chunk number: 187 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6102 - acc: 0.7690 - val_loss: 0.5814 - val_acc: 0.7656\n",
      "chunk number: 188 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6428 - acc: 0.7567 - val_loss: 0.5108 - val_acc: 0.8047\n",
      "chunk number: 189 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6248 - acc: 0.7600 - val_loss: 0.5896 - val_acc: 0.8125\n",
      "chunk number: 190 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5640 - acc: 0.7734 - val_loss: 0.5113 - val_acc: 0.8125\n",
      "chunk number: 191 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6262 - acc: 0.7645 - val_loss: 0.6077 - val_acc: 0.8203\n",
      "chunk number: 192 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5818 - acc: 0.7835 - val_loss: 0.5906 - val_acc: 0.7500\n",
      "chunk number: 193 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5842 - acc: 0.7734 - val_loss: 0.7048 - val_acc: 0.7266\n",
      "chunk number: 194 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5728 - acc: 0.7757 - val_loss: 0.6689 - val_acc: 0.6953\n",
      "chunk number: 195 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5690 - acc: 0.7757 - val_loss: 0.4731 - val_acc: 0.8125\n",
      "chunk number: 196 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6000 - acc: 0.7746 - val_loss: 0.5318 - val_acc: 0.7812\n",
      "chunk number: 197 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6104 - acc: 0.7545 - val_loss: 0.5422 - val_acc: 0.7734\n",
      "chunk number: 198 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6275 - acc: 0.7589 - val_loss: 0.5906 - val_acc: 0.7812\n",
      "chunk number: 199 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5838 - acc: 0.7779 - val_loss: 0.5772 - val_acc: 0.7812\n",
      "chunk number: 200 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6039 - acc: 0.7667 - val_loss: 0.4926 - val_acc: 0.7812\n",
      "chunk number: 201 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5274 - acc: 0.7991 - val_loss: 0.5675 - val_acc: 0.7812\n",
      "chunk number: 202 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6333 - acc: 0.7690 - val_loss: 0.6358 - val_acc: 0.7422\n",
      "chunk number: 203 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5932 - acc: 0.7455 - val_loss: 0.5749 - val_acc: 0.7422\n",
      "chunk number: 204 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5785 - acc: 0.7734 - val_loss: 0.5044 - val_acc: 0.8203\n",
      "chunk number: 205 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5992 - acc: 0.7857 - val_loss: 0.5551 - val_acc: 0.7734\n",
      "chunk number: 206 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5287 - acc: 0.7935 - val_loss: 0.6996 - val_acc: 0.7578\n",
      "chunk number: 207 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5953 - acc: 0.7690 - val_loss: 0.6714 - val_acc: 0.7500\n",
      "chunk number: 208 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5728 - acc: 0.7879 - val_loss: 0.5077 - val_acc: 0.7500\n",
      "chunk number: 209 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5612 - acc: 0.8136 - val_loss: 0.5792 - val_acc: 0.7344\n",
      "chunk number: 210 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5923 - acc: 0.7768 - val_loss: 0.5941 - val_acc: 0.7812\n",
      "chunk number: 211 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6122 - acc: 0.7701 - val_loss: 0.6767 - val_acc: 0.7656\n",
      "chunk number: 212 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6147 - acc: 0.7790 - val_loss: 0.5824 - val_acc: 0.7578\n",
      "chunk number: 213 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5509 - acc: 0.8047 - val_loss: 0.5924 - val_acc: 0.7656\n",
      "chunk number: 214 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6072 - acc: 0.7712 - val_loss: 0.5565 - val_acc: 0.8438\n",
      "chunk number: 215 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6099 - acc: 0.7656 - val_loss: 0.5494 - val_acc: 0.7969\n",
      "chunk number: 216 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5166 - acc: 0.8080 - val_loss: 0.6799 - val_acc: 0.7266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 217 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5705 - acc: 0.7779 - val_loss: 0.5503 - val_acc: 0.7891\n",
      "chunk number: 218 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5662 - acc: 0.7891 - val_loss: 0.6572 - val_acc: 0.7734\n",
      "chunk number: 219 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5620 - acc: 0.7891 - val_loss: 0.5981 - val_acc: 0.7500\n",
      "chunk number: 220 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6133 - acc: 0.7734 - val_loss: 0.5945 - val_acc: 0.7812\n",
      "chunk number: 221 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5422 - acc: 0.7824 - val_loss: 0.5161 - val_acc: 0.8203\n",
      "chunk number: 222 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6008 - acc: 0.7656 - val_loss: 0.5457 - val_acc: 0.7891\n",
      "chunk number: 223 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5692 - acc: 0.7902 - val_loss: 0.4789 - val_acc: 0.8047\n",
      "chunk number: 224 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6101 - acc: 0.7690 - val_loss: 0.5850 - val_acc: 0.7578\n",
      "chunk number: 225 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5092 - acc: 0.7924 - val_loss: 0.5778 - val_acc: 0.8047\n",
      "chunk number: 226 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5877 - acc: 0.7612 - val_loss: 0.7215 - val_acc: 0.7422\n",
      "chunk number: 227 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5960 - acc: 0.7701 - val_loss: 0.5159 - val_acc: 0.8125\n",
      "chunk number: 228 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5566 - acc: 0.7980 - val_loss: 0.6821 - val_acc: 0.7422\n",
      "chunk number: 229 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5929 - acc: 0.7801 - val_loss: 0.5379 - val_acc: 0.7969\n",
      "chunk number: 230 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6241 - acc: 0.7578 - val_loss: 0.6594 - val_acc: 0.7266\n",
      "chunk number: 231 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5850 - acc: 0.7846 - val_loss: 0.5579 - val_acc: 0.7656\n",
      "chunk number: 232 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5952 - acc: 0.7667 - val_loss: 0.7097 - val_acc: 0.7500\n",
      "chunk number: 233 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5777 - acc: 0.7801 - val_loss: 0.4933 - val_acc: 0.7656\n",
      "chunk number: 234 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5712 - acc: 0.7824 - val_loss: 0.6546 - val_acc: 0.7500\n",
      "chunk number: 235 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5453 - acc: 0.7891 - val_loss: 0.5589 - val_acc: 0.7969\n",
      "chunk number: 236 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5697 - acc: 0.7835 - val_loss: 0.5366 - val_acc: 0.8203\n",
      "chunk number: 237 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5499 - acc: 0.7902 - val_loss: 0.4932 - val_acc: 0.8359\n",
      "chunk number: 238 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5550 - acc: 0.7779 - val_loss: 0.5151 - val_acc: 0.8203\n",
      "chunk number: 239 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5628 - acc: 0.7924 - val_loss: 0.5709 - val_acc: 0.7812\n",
      "chunk number: 240 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5759 - acc: 0.7812 - val_loss: 0.5068 - val_acc: 0.7812\n",
      "chunk number: 241 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5284 - acc: 0.7902 - val_loss: 0.5325 - val_acc: 0.7891\n",
      "chunk number: 242 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5406 - acc: 0.8013 - val_loss: 0.5996 - val_acc: 0.8047\n",
      "chunk number: 243 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5250 - acc: 0.7946 - val_loss: 0.5494 - val_acc: 0.7422\n",
      "chunk number: 244 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5153 - acc: 0.8181 - val_loss: 0.6011 - val_acc: 0.7656\n",
      "chunk number: 245 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5573 - acc: 0.8002 - val_loss: 0.5479 - val_acc: 0.7734\n",
      "chunk number: 246 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5678 - acc: 0.7879 - val_loss: 0.6627 - val_acc: 0.7656\n",
      "chunk number: 247 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5199 - acc: 0.7879 - val_loss: 0.5829 - val_acc: 0.8125\n",
      "chunk number: 248 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5724 - acc: 0.7924 - val_loss: 0.6971 - val_acc: 0.7734\n",
      "chunk number: 249 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5475 - acc: 0.7879 - val_loss: 0.6500 - val_acc: 0.7656\n",
      "chunk number: 250 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5819 - acc: 0.7522 - val_loss: 0.5974 - val_acc: 0.7891\n",
      "chunk number: 251 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5935 - acc: 0.7634 - val_loss: 0.6447 - val_acc: 0.7578\n",
      "chunk number: 252 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5577 - acc: 0.7946 - val_loss: 0.5439 - val_acc: 0.8047\n",
      "chunk number: 253 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6428 - acc: 0.7600 - val_loss: 0.5906 - val_acc: 0.7734\n",
      "chunk number: 254 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5779 - acc: 0.7879 - val_loss: 0.4771 - val_acc: 0.7969\n",
      "chunk number: 255 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5506 - acc: 0.7946 - val_loss: 0.5505 - val_acc: 0.7734\n",
      "chunk number: 256 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5811 - acc: 0.7790 - val_loss: 0.4878 - val_acc: 0.7891\n",
      "chunk number: 257 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5688 - acc: 0.7958 - val_loss: 0.5271 - val_acc: 0.8125\n",
      "chunk number: 258 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5463 - acc: 0.7891 - val_loss: 0.5120 - val_acc: 0.8125\n",
      "chunk number: 259 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5745 - acc: 0.7846 - val_loss: 0.4962 - val_acc: 0.8359\n",
      "chunk number: 260 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6189 - acc: 0.7757 - val_loss: 0.5036 - val_acc: 0.8203\n",
      "chunk number: 261 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5636 - acc: 0.7924 - val_loss: 0.4882 - val_acc: 0.8281\n",
      "chunk number: 262 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5509 - acc: 0.7723 - val_loss: 0.5028 - val_acc: 0.8203\n",
      "chunk number: 263 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6062 - acc: 0.7634 - val_loss: 0.6365 - val_acc: 0.7188\n",
      "chunk number: 264 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5318 - acc: 0.8114 - val_loss: 0.5249 - val_acc: 0.8047\n",
      "chunk number: 265 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5618 - acc: 0.7935 - val_loss: 0.4873 - val_acc: 0.8203\n",
      "chunk number: 266 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5613 - acc: 0.7835 - val_loss: 0.5756 - val_acc: 0.7969\n",
      "chunk number: 267 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5378 - acc: 0.7946 - val_loss: 0.5348 - val_acc: 0.7812\n",
      "chunk number: 268 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5734 - acc: 0.7779 - val_loss: 0.6880 - val_acc: 0.7656\n",
      "chunk number: 269 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5903 - acc: 0.7690 - val_loss: 0.4888 - val_acc: 0.8047\n",
      "chunk number: 270 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5389 - acc: 0.8013 - val_loss: 0.6018 - val_acc: 0.7969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 271 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5421 - acc: 0.7846 - val_loss: 0.5975 - val_acc: 0.7734\n",
      "chunk number: 272 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5352 - acc: 0.7913 - val_loss: 0.5839 - val_acc: 0.8125\n",
      "chunk number: 273 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4960 - acc: 0.8092 - val_loss: 0.5442 - val_acc: 0.8125\n",
      "chunk number: 274 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5595 - acc: 0.7757 - val_loss: 0.7601 - val_acc: 0.7188\n",
      "chunk number: 275 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5503 - acc: 0.7924 - val_loss: 0.4513 - val_acc: 0.8516\n",
      "chunk number: 276 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4852 - acc: 0.8292 - val_loss: 0.6389 - val_acc: 0.7500\n",
      "chunk number: 277 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5207 - acc: 0.7891 - val_loss: 0.4178 - val_acc: 0.8438\n",
      "chunk number: 278 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5102 - acc: 0.7991 - val_loss: 0.7028 - val_acc: 0.7344\n",
      "chunk number: 279 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5053 - acc: 0.7969 - val_loss: 0.4337 - val_acc: 0.8359\n",
      "chunk number: 280 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5387 - acc: 0.7935 - val_loss: 0.4819 - val_acc: 0.8047\n",
      "chunk number: 281 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5418 - acc: 0.7746 - val_loss: 0.4777 - val_acc: 0.8281\n",
      "chunk number: 282 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5474 - acc: 0.7779 - val_loss: 0.5093 - val_acc: 0.7812\n",
      "chunk number: 283 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5526 - acc: 0.7868 - val_loss: 0.6350 - val_acc: 0.7188\n",
      "chunk number: 284 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5542 - acc: 0.7879 - val_loss: 0.5229 - val_acc: 0.7734\n",
      "chunk number: 285 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5519 - acc: 0.8025 - val_loss: 0.5201 - val_acc: 0.7891\n",
      "chunk number: 286 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5665 - acc: 0.7812 - val_loss: 0.4842 - val_acc: 0.7969\n",
      "chunk number: 287 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5372 - acc: 0.8047 - val_loss: 0.5225 - val_acc: 0.7969\n",
      "chunk number: 288 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5963 - acc: 0.7612 - val_loss: 0.4765 - val_acc: 0.8203\n",
      "chunk number: 289 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5155 - acc: 0.7924 - val_loss: 0.4758 - val_acc: 0.8516\n",
      "chunk number: 290 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4936 - acc: 0.8058 - val_loss: 0.5572 - val_acc: 0.7734\n",
      "chunk number: 291 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5370 - acc: 0.7879 - val_loss: 0.5303 - val_acc: 0.8125\n",
      "chunk number: 292 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5367 - acc: 0.7790 - val_loss: 0.4561 - val_acc: 0.7891\n",
      "chunk number: 293 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5373 - acc: 0.8025 - val_loss: 0.6963 - val_acc: 0.7109\n",
      "chunk number: 294 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5778 - acc: 0.7790 - val_loss: 0.5362 - val_acc: 0.7969\n",
      "chunk number: 295 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5041 - acc: 0.8170 - val_loss: 0.5200 - val_acc: 0.7734\n",
      "chunk number: 296 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5438 - acc: 0.8025 - val_loss: 0.4992 - val_acc: 0.7969\n",
      "chunk number: 297 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5559 - acc: 0.7857 - val_loss: 0.4392 - val_acc: 0.8438\n",
      "chunk number: 298 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5480 - acc: 0.7980 - val_loss: 0.5176 - val_acc: 0.8047\n",
      "chunk number: 299 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5494 - acc: 0.7812 - val_loss: 0.4443 - val_acc: 0.8047\n",
      "chunk number: 300 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5071 - acc: 0.8114 - val_loss: 0.5078 - val_acc: 0.7969\n",
      "chunk number: 301 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4652 - acc: 0.8192 - val_loss: 0.4337 - val_acc: 0.8203\n",
      "chunk number: 302 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5670 - acc: 0.7868 - val_loss: 0.5573 - val_acc: 0.7656\n",
      "chunk number: 303 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5129 - acc: 0.7924 - val_loss: 0.5557 - val_acc: 0.7734\n",
      "chunk number: 304 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5176 - acc: 0.8058 - val_loss: 0.4777 - val_acc: 0.8281\n",
      "chunk number: 305 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5166 - acc: 0.7879 - val_loss: 0.5834 - val_acc: 0.7969\n",
      "chunk number: 306 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4689 - acc: 0.8337 - val_loss: 0.6205 - val_acc: 0.7812\n",
      "chunk number: 307 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5545 - acc: 0.7835 - val_loss: 0.5321 - val_acc: 0.7969\n",
      "chunk number: 308 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5115 - acc: 0.8058 - val_loss: 0.4266 - val_acc: 0.8125\n",
      "chunk number: 309 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4886 - acc: 0.8393 - val_loss: 0.4372 - val_acc: 0.8359\n",
      "chunk number: 310 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5208 - acc: 0.8125 - val_loss: 0.5373 - val_acc: 0.7656\n",
      "chunk number: 311 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5725 - acc: 0.7812 - val_loss: 0.5756 - val_acc: 0.7734\n",
      "chunk number: 312 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5599 - acc: 0.7712 - val_loss: 0.5087 - val_acc: 0.8125\n",
      "chunk number: 313 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5069 - acc: 0.8114 - val_loss: 0.5996 - val_acc: 0.7891\n",
      "chunk number: 314 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5788 - acc: 0.7835 - val_loss: 0.5296 - val_acc: 0.8203\n",
      "chunk number: 315 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5579 - acc: 0.7835 - val_loss: 0.5790 - val_acc: 0.7656\n",
      "chunk number: 316 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4524 - acc: 0.8170 - val_loss: 0.6037 - val_acc: 0.7500\n",
      "chunk number: 317 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5577 - acc: 0.7690 - val_loss: 0.5113 - val_acc: 0.7969\n",
      "chunk number: 318 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5136 - acc: 0.8170 - val_loss: 0.6047 - val_acc: 0.7656\n",
      "chunk number: 319 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5426 - acc: 0.8013 - val_loss: 0.5874 - val_acc: 0.7812\n",
      "chunk number: 320 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5826 - acc: 0.7812 - val_loss: 0.5660 - val_acc: 0.7969\n",
      "chunk number: 321 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5009 - acc: 0.8036 - val_loss: 0.5135 - val_acc: 0.8516\n",
      "chunk number: 322 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5538 - acc: 0.7935 - val_loss: 0.5102 - val_acc: 0.7891\n",
      "chunk number: 323 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5170 - acc: 0.8114 - val_loss: 0.4493 - val_acc: 0.8359\n",
      "chunk number: 324 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5550 - acc: 0.7902 - val_loss: 0.6074 - val_acc: 0.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 325 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4663 - acc: 0.8181 - val_loss: 0.6020 - val_acc: 0.7656\n",
      "chunk number: 326 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5328 - acc: 0.7913 - val_loss: 0.5322 - val_acc: 0.7969\n",
      "chunk number: 327 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5120 - acc: 0.8125 - val_loss: 0.4279 - val_acc: 0.8281\n",
      "chunk number: 328 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4871 - acc: 0.8092 - val_loss: 0.6284 - val_acc: 0.7422\n",
      "chunk number: 329 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5223 - acc: 0.8069 - val_loss: 0.4819 - val_acc: 0.8125\n",
      "chunk number: 330 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5433 - acc: 0.7969 - val_loss: 0.6141 - val_acc: 0.7500\n",
      "chunk number: 331 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5291 - acc: 0.7812 - val_loss: 0.5580 - val_acc: 0.7891\n",
      "chunk number: 332 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5628 - acc: 0.7969 - val_loss: 0.5795 - val_acc: 0.7891\n",
      "chunk number: 333 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5693 - acc: 0.7812 - val_loss: 0.4697 - val_acc: 0.8203\n",
      "chunk number: 334 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5538 - acc: 0.7824 - val_loss: 0.5554 - val_acc: 0.7969\n",
      "chunk number: 335 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4833 - acc: 0.8281 - val_loss: 0.5863 - val_acc: 0.7578\n",
      "chunk number: 336 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5250 - acc: 0.7991 - val_loss: 0.4549 - val_acc: 0.7969\n",
      "chunk number: 337 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5325 - acc: 0.7924 - val_loss: 0.4447 - val_acc: 0.8359\n",
      "chunk number: 338 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4984 - acc: 0.8058 - val_loss: 0.5379 - val_acc: 0.8438\n",
      "chunk number: 339 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5196 - acc: 0.7991 - val_loss: 0.4840 - val_acc: 0.8125\n",
      "chunk number: 340 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5582 - acc: 0.7812 - val_loss: 0.5262 - val_acc: 0.7734\n",
      "chunk number: 341 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4672 - acc: 0.8002 - val_loss: 0.4697 - val_acc: 0.7891\n",
      "chunk number: 342 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4962 - acc: 0.8158 - val_loss: 0.5161 - val_acc: 0.8047\n",
      "chunk number: 343 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4883 - acc: 0.7958 - val_loss: 0.5730 - val_acc: 0.7656\n",
      "chunk number: 344 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4806 - acc: 0.8147 - val_loss: 0.5873 - val_acc: 0.7812\n",
      "chunk number: 345 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5219 - acc: 0.8092 - val_loss: 0.5311 - val_acc: 0.7344\n",
      "chunk number: 346 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5662 - acc: 0.7846 - val_loss: 0.7238 - val_acc: 0.7812\n",
      "chunk number: 347 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5244 - acc: 0.7913 - val_loss: 0.5460 - val_acc: 0.8516\n",
      "chunk number: 348 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4809 - acc: 0.8203 - val_loss: 0.6267 - val_acc: 0.7500\n",
      "chunk number: 349 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4702 - acc: 0.8158 - val_loss: 0.5663 - val_acc: 0.7812\n",
      "chunk number: 350 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5440 - acc: 0.7812 - val_loss: 0.5604 - val_acc: 0.7734\n",
      "chunk number: 351 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5436 - acc: 0.7991 - val_loss: 0.5721 - val_acc: 0.7812\n",
      "chunk number: 352 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5075 - acc: 0.8114 - val_loss: 0.4488 - val_acc: 0.8359\n",
      "chunk number: 353 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5460 - acc: 0.7734 - val_loss: 0.6365 - val_acc: 0.7734\n",
      "chunk number: 354 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5248 - acc: 0.8013 - val_loss: 0.3888 - val_acc: 0.8438\n",
      "chunk number: 355 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5167 - acc: 0.8114 - val_loss: 0.4870 - val_acc: 0.8438\n",
      "chunk number: 356 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5029 - acc: 0.8025 - val_loss: 0.4992 - val_acc: 0.8047\n",
      "chunk number: 357 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5162 - acc: 0.8013 - val_loss: 0.4959 - val_acc: 0.8125\n",
      "chunk number: 358 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4513 - acc: 0.8337 - val_loss: 0.4485 - val_acc: 0.8438\n",
      "chunk number: 359 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5090 - acc: 0.8203 - val_loss: 0.4681 - val_acc: 0.8438\n",
      "chunk number: 360 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5912 - acc: 0.7746 - val_loss: 0.5393 - val_acc: 0.8125\n",
      "chunk number: 361 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4831 - acc: 0.8371 - val_loss: 0.4348 - val_acc: 0.7969\n",
      "chunk number: 362 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5118 - acc: 0.8192 - val_loss: 0.4002 - val_acc: 0.8438\n",
      "chunk number: 363 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5315 - acc: 0.7969 - val_loss: 0.6565 - val_acc: 0.7422\n",
      "chunk number: 364 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4579 - acc: 0.8348 - val_loss: 0.4941 - val_acc: 0.8125\n",
      "chunk number: 365 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5281 - acc: 0.7991 - val_loss: 0.4978 - val_acc: 0.8281\n",
      "chunk number: 366 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4943 - acc: 0.8103 - val_loss: 0.5546 - val_acc: 0.7266\n",
      "chunk number: 367 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5232 - acc: 0.8069 - val_loss: 0.4985 - val_acc: 0.7656\n",
      "chunk number: 368 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5247 - acc: 0.7835 - val_loss: 0.6569 - val_acc: 0.7812\n",
      "chunk number: 369 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5660 - acc: 0.7801 - val_loss: 0.4645 - val_acc: 0.8047\n",
      "chunk number: 370 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5136 - acc: 0.8069 - val_loss: 0.6226 - val_acc: 0.7891\n",
      "chunk number: 371 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4744 - acc: 0.8214 - val_loss: 0.4710 - val_acc: 0.7656\n",
      "chunk number: 372 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4986 - acc: 0.8092 - val_loss: 0.5732 - val_acc: 0.7891\n",
      "chunk number: 373 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4631 - acc: 0.8304 - val_loss: 0.5756 - val_acc: 0.8359\n",
      "chunk number: 374 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5028 - acc: 0.8214 - val_loss: 0.5532 - val_acc: 0.7500\n",
      "chunk number: 375 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4729 - acc: 0.8292 - val_loss: 0.4531 - val_acc: 0.8281\n",
      "chunk number: 376 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4632 - acc: 0.8147 - val_loss: 0.5290 - val_acc: 0.7734\n",
      "chunk number: 377 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4646 - acc: 0.8147 - val_loss: 0.4281 - val_acc: 0.8516\n",
      "chunk number: 378 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4951 - acc: 0.8036 - val_loss: 0.6847 - val_acc: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 379 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5041 - acc: 0.8013 - val_loss: 0.4754 - val_acc: 0.7969\n",
      "chunk number: 380 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4652 - acc: 0.8181 - val_loss: 0.4851 - val_acc: 0.8281\n",
      "chunk number: 381 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5011 - acc: 0.8036 - val_loss: 0.4496 - val_acc: 0.8203\n",
      "chunk number: 382 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5071 - acc: 0.8181 - val_loss: 0.4696 - val_acc: 0.7969\n",
      "chunk number: 383 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5316 - acc: 0.7824 - val_loss: 0.5306 - val_acc: 0.7969\n",
      "chunk number: 384 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5012 - acc: 0.8002 - val_loss: 0.4728 - val_acc: 0.7656\n",
      "chunk number: 385 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5050 - acc: 0.8147 - val_loss: 0.4452 - val_acc: 0.8047\n",
      "chunk number: 386 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5348 - acc: 0.8036 - val_loss: 0.4893 - val_acc: 0.8516\n",
      "chunk number: 387 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5419 - acc: 0.8047 - val_loss: 0.5253 - val_acc: 0.7891\n",
      "chunk number: 388 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5219 - acc: 0.7913 - val_loss: 0.4270 - val_acc: 0.8281\n",
      "chunk number: 389 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4975 - acc: 0.8047 - val_loss: 0.4866 - val_acc: 0.8438\n",
      "chunk number: 390 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4637 - acc: 0.8203 - val_loss: 0.4890 - val_acc: 0.8047\n",
      "chunk number: 391 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5304 - acc: 0.8002 - val_loss: 0.5948 - val_acc: 0.8047\n",
      "chunk number: 392 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5144 - acc: 0.8013 - val_loss: 0.4497 - val_acc: 0.8047\n",
      "chunk number: 393 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4712 - acc: 0.8092 - val_loss: 0.6104 - val_acc: 0.7891\n",
      "chunk number: 394 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5034 - acc: 0.8103 - val_loss: 0.5422 - val_acc: 0.7500\n",
      "chunk number: 395 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4404 - acc: 0.8337 - val_loss: 0.4539 - val_acc: 0.8047\n",
      "chunk number: 396 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4924 - acc: 0.8080 - val_loss: 0.4332 - val_acc: 0.8359\n",
      "chunk number: 397 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4711 - acc: 0.8248 - val_loss: 0.4526 - val_acc: 0.8203\n",
      "chunk number: 398 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5150 - acc: 0.8025 - val_loss: 0.5465 - val_acc: 0.7734\n",
      "chunk number: 399 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4862 - acc: 0.8080 - val_loss: 0.4670 - val_acc: 0.8359\n",
      "chunk number: 400 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5191 - acc: 0.7946 - val_loss: 0.4456 - val_acc: 0.7969\n",
      "chunk number: 401 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4604 - acc: 0.8225 - val_loss: 0.3930 - val_acc: 0.8438\n",
      "chunk number: 402 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5621 - acc: 0.7746 - val_loss: 0.5667 - val_acc: 0.7891\n",
      "chunk number: 403 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5502 - acc: 0.7835 - val_loss: 0.5343 - val_acc: 0.7578\n",
      "chunk number: 404 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4969 - acc: 0.8125 - val_loss: 0.5125 - val_acc: 0.8438\n",
      "chunk number: 405 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5260 - acc: 0.8092 - val_loss: 0.5387 - val_acc: 0.8047\n",
      "chunk number: 406 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4592 - acc: 0.8382 - val_loss: 0.5758 - val_acc: 0.7812\n",
      "chunk number: 407 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5359 - acc: 0.7969 - val_loss: 0.5792 - val_acc: 0.8047\n",
      "chunk number: 408 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4951 - acc: 0.8125 - val_loss: 0.4534 - val_acc: 0.7891\n",
      "chunk number: 409 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4589 - acc: 0.8337 - val_loss: 0.4437 - val_acc: 0.7812\n",
      "chunk number: 410 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4612 - acc: 0.8214 - val_loss: 0.4760 - val_acc: 0.8047\n",
      "chunk number: 411 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5345 - acc: 0.7924 - val_loss: 0.5142 - val_acc: 0.8203\n",
      "chunk number: 412 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5221 - acc: 0.8058 - val_loss: 0.4623 - val_acc: 0.7969\n",
      "chunk number: 413 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4787 - acc: 0.8158 - val_loss: 0.6052 - val_acc: 0.7969\n",
      "chunk number: 414 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5284 - acc: 0.7924 - val_loss: 0.4366 - val_acc: 0.8594\n",
      "chunk number: 415 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4863 - acc: 0.8281 - val_loss: 0.4772 - val_acc: 0.8203\n",
      "chunk number: 416 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4214 - acc: 0.8337 - val_loss: 0.6734 - val_acc: 0.7422\n",
      "chunk number: 417 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5146 - acc: 0.8058 - val_loss: 0.4851 - val_acc: 0.8047\n",
      "chunk number: 418 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4642 - acc: 0.8281 - val_loss: 0.5455 - val_acc: 0.8438\n",
      "chunk number: 419 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4888 - acc: 0.8069 - val_loss: 0.4917 - val_acc: 0.8125\n",
      "chunk number: 420 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5163 - acc: 0.8114 - val_loss: 0.5449 - val_acc: 0.8594\n",
      "chunk number: 421 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4163 - acc: 0.8315 - val_loss: 0.4168 - val_acc: 0.8438\n",
      "chunk number: 422 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4667 - acc: 0.8214 - val_loss: 0.5395 - val_acc: 0.8047\n",
      "chunk number: 423 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4814 - acc: 0.8304 - val_loss: 0.5079 - val_acc: 0.8047\n",
      "chunk number: 424 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5142 - acc: 0.7991 - val_loss: 0.4834 - val_acc: 0.7891\n",
      "chunk number: 425 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4229 - acc: 0.8404 - val_loss: 0.5272 - val_acc: 0.8203\n",
      "chunk number: 426 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4895 - acc: 0.7991 - val_loss: 0.5367 - val_acc: 0.8125\n",
      "chunk number: 427 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4630 - acc: 0.8047 - val_loss: 0.3833 - val_acc: 0.8594\n",
      "chunk number: 428 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5012 - acc: 0.8114 - val_loss: 0.6142 - val_acc: 0.7656\n",
      "chunk number: 429 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5077 - acc: 0.8036 - val_loss: 0.5778 - val_acc: 0.7578\n",
      "chunk number: 430 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5347 - acc: 0.7891 - val_loss: 0.5704 - val_acc: 0.7578\n",
      "chunk number: 431 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4634 - acc: 0.8259 - val_loss: 0.4403 - val_acc: 0.8281\n",
      "chunk number: 432 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4901 - acc: 0.8114 - val_loss: 0.5730 - val_acc: 0.8203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 433 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4968 - acc: 0.8013 - val_loss: 0.4343 - val_acc: 0.8047\n",
      "chunk number: 434 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4997 - acc: 0.8047 - val_loss: 0.5167 - val_acc: 0.7891\n",
      "chunk number: 435 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4511 - acc: 0.8326 - val_loss: 0.5957 - val_acc: 0.7969\n",
      "chunk number: 436 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5151 - acc: 0.8069 - val_loss: 0.5002 - val_acc: 0.7812\n",
      "chunk number: 437 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4842 - acc: 0.8158 - val_loss: 0.3711 - val_acc: 0.8750\n",
      "chunk number: 438 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4601 - acc: 0.8304 - val_loss: 0.5565 - val_acc: 0.8516\n",
      "chunk number: 439 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5192 - acc: 0.8047 - val_loss: 0.5242 - val_acc: 0.7969\n",
      "chunk number: 440 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5116 - acc: 0.7991 - val_loss: 0.4783 - val_acc: 0.7500\n",
      "chunk number: 441 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4487 - acc: 0.8270 - val_loss: 0.4494 - val_acc: 0.8125\n",
      "chunk number: 442 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4267 - acc: 0.8438 - val_loss: 0.5003 - val_acc: 0.7969\n",
      "chunk number: 443 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4431 - acc: 0.8415 - val_loss: 0.4076 - val_acc: 0.8203\n",
      "chunk number: 444 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4852 - acc: 0.8181 - val_loss: 0.5433 - val_acc: 0.7812\n",
      "chunk number: 445 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4623 - acc: 0.8225 - val_loss: 0.4934 - val_acc: 0.8047\n",
      "chunk number: 446 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4809 - acc: 0.8069 - val_loss: 0.5759 - val_acc: 0.7734\n",
      "chunk number: 447 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4379 - acc: 0.8214 - val_loss: 0.5150 - val_acc: 0.8359\n",
      "chunk number: 448 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4420 - acc: 0.8248 - val_loss: 0.6030 - val_acc: 0.7109\n",
      "chunk number: 449 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4537 - acc: 0.8147 - val_loss: 0.5811 - val_acc: 0.7969\n",
      "chunk number: 450 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4754 - acc: 0.8058 - val_loss: 0.5399 - val_acc: 0.7891\n",
      "chunk number: 451 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5174 - acc: 0.8002 - val_loss: 0.5767 - val_acc: 0.8047\n",
      "chunk number: 452 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4612 - acc: 0.8192 - val_loss: 0.4145 - val_acc: 0.7969\n",
      "chunk number: 453 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5164 - acc: 0.7946 - val_loss: 0.5595 - val_acc: 0.8047\n",
      "chunk number: 454 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4921 - acc: 0.8103 - val_loss: 0.3907 - val_acc: 0.8672\n",
      "chunk number: 455 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4688 - acc: 0.8214 - val_loss: 0.4466 - val_acc: 0.8359\n",
      "chunk number: 456 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4869 - acc: 0.8136 - val_loss: 0.4840 - val_acc: 0.8047\n",
      "chunk number: 457 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4850 - acc: 0.8248 - val_loss: 0.4069 - val_acc: 0.8281\n",
      "chunk number: 458 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4520 - acc: 0.8326 - val_loss: 0.4497 - val_acc: 0.8047\n",
      "chunk number: 459 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4714 - acc: 0.8147 - val_loss: 0.4803 - val_acc: 0.8594\n",
      "chunk number: 460 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5324 - acc: 0.7991 - val_loss: 0.5048 - val_acc: 0.8438\n",
      "chunk number: 461 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4913 - acc: 0.8147 - val_loss: 0.3793 - val_acc: 0.8438\n",
      "chunk number: 462 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4571 - acc: 0.8304 - val_loss: 0.4641 - val_acc: 0.7969\n",
      "chunk number: 463 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5308 - acc: 0.7846 - val_loss: 0.5762 - val_acc: 0.7812\n",
      "chunk number: 464 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4617 - acc: 0.8415 - val_loss: 0.5361 - val_acc: 0.7656\n",
      "chunk number: 465 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5495 - acc: 0.8013 - val_loss: 0.4385 - val_acc: 0.8438\n",
      "chunk number: 466 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5017 - acc: 0.7991 - val_loss: 0.5622 - val_acc: 0.7891\n",
      "chunk number: 467 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4660 - acc: 0.8326 - val_loss: 0.5708 - val_acc: 0.7656\n",
      "chunk number: 468 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5052 - acc: 0.7969 - val_loss: 0.5652 - val_acc: 0.8047\n",
      "chunk number: 469 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5265 - acc: 0.7946 - val_loss: 0.4763 - val_acc: 0.8047\n",
      "chunk number: 470 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4404 - acc: 0.8371 - val_loss: 0.5282 - val_acc: 0.8047\n",
      "chunk number: 471 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4654 - acc: 0.7991 - val_loss: 0.4373 - val_acc: 0.7969\n",
      "chunk number: 472 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5279 - acc: 0.7835 - val_loss: 0.5722 - val_acc: 0.7891\n",
      "chunk number: 473 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4539 - acc: 0.8270 - val_loss: 0.5689 - val_acc: 0.7891\n",
      "chunk number: 474 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5084 - acc: 0.8103 - val_loss: 0.5865 - val_acc: 0.7734\n",
      "chunk number: 475 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4644 - acc: 0.8304 - val_loss: 0.4948 - val_acc: 0.8047\n",
      "chunk number: 476 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4731 - acc: 0.8080 - val_loss: 0.4310 - val_acc: 0.8203\n",
      "chunk number: 477 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4430 - acc: 0.8225 - val_loss: 0.4089 - val_acc: 0.8516\n",
      "chunk number: 478 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4345 - acc: 0.8259 - val_loss: 0.6226 - val_acc: 0.7656\n",
      "chunk number: 479 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4489 - acc: 0.8292 - val_loss: 0.3920 - val_acc: 0.8281\n",
      "chunk number: 480 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4521 - acc: 0.8371 - val_loss: 0.4262 - val_acc: 0.8281\n",
      "chunk number: 481 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4542 - acc: 0.8136 - val_loss: 0.4176 - val_acc: 0.8516\n",
      "chunk number: 482 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4441 - acc: 0.8359 - val_loss: 0.4461 - val_acc: 0.8203\n",
      "chunk number: 483 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4955 - acc: 0.8125 - val_loss: 0.5355 - val_acc: 0.7812\n",
      "chunk number: 484 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4732 - acc: 0.8114 - val_loss: 0.3869 - val_acc: 0.8281\n",
      "chunk number: 485 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4822 - acc: 0.8058 - val_loss: 0.4408 - val_acc: 0.8359\n",
      "chunk number: 486 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5013 - acc: 0.8136 - val_loss: 0.4035 - val_acc: 0.8438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 487 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4757 - acc: 0.8281 - val_loss: 0.5680 - val_acc: 0.7656\n",
      "chunk number: 488 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4962 - acc: 0.8103 - val_loss: 0.3958 - val_acc: 0.8516\n",
      "chunk number: 489 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4539 - acc: 0.8259 - val_loss: 0.4339 - val_acc: 0.8359\n",
      "chunk number: 490 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4355 - acc: 0.8281 - val_loss: 0.5018 - val_acc: 0.8203\n",
      "chunk number: 491 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4812 - acc: 0.8125 - val_loss: 0.5492 - val_acc: 0.8203\n",
      "chunk number: 492 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4703 - acc: 0.8069 - val_loss: 0.3687 - val_acc: 0.8047\n",
      "chunk number: 493 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4212 - acc: 0.8449 - val_loss: 0.5941 - val_acc: 0.7500\n",
      "chunk number: 494 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4634 - acc: 0.8225 - val_loss: 0.5198 - val_acc: 0.8125\n",
      "chunk number: 495 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4411 - acc: 0.8248 - val_loss: 0.4242 - val_acc: 0.8594\n",
      "chunk number: 496 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4632 - acc: 0.8270 - val_loss: 0.4010 - val_acc: 0.8281\n",
      "chunk number: 497 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4474 - acc: 0.8348 - val_loss: 0.4354 - val_acc: 0.8125\n",
      "chunk number: 498 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4620 - acc: 0.8248 - val_loss: 0.4843 - val_acc: 0.8047\n",
      "chunk number: 499 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4399 - acc: 0.8281 - val_loss: 0.4917 - val_acc: 0.8047\n",
      "chunk number: 500 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4592 - acc: 0.8181 - val_loss: 0.3610 - val_acc: 0.8672\n",
      "chunk number: 501 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4263 - acc: 0.8504 - val_loss: 0.3833 - val_acc: 0.8359\n",
      "chunk number: 502 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4920 - acc: 0.8047 - val_loss: 0.5690 - val_acc: 0.7422\n",
      "chunk number: 503 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4658 - acc: 0.8192 - val_loss: 0.3742 - val_acc: 0.8750\n",
      "chunk number: 504 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4622 - acc: 0.8214 - val_loss: 0.4069 - val_acc: 0.8359\n",
      "chunk number: 505 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4542 - acc: 0.8225 - val_loss: 0.5373 - val_acc: 0.8047\n",
      "chunk number: 506 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4188 - acc: 0.8304 - val_loss: 0.5269 - val_acc: 0.8281\n",
      "chunk number: 507 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4754 - acc: 0.8259 - val_loss: 0.4837 - val_acc: 0.8359\n",
      "chunk number: 508 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4449 - acc: 0.8225 - val_loss: 0.4537 - val_acc: 0.8047\n",
      "chunk number: 509 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4282 - acc: 0.8460 - val_loss: 0.3938 - val_acc: 0.8125\n",
      "chunk number: 510 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4793 - acc: 0.8214 - val_loss: 0.4460 - val_acc: 0.8281\n",
      "chunk number: 511 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4790 - acc: 0.8092 - val_loss: 0.5286 - val_acc: 0.8047\n",
      "chunk number: 512 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4846 - acc: 0.8013 - val_loss: 0.4627 - val_acc: 0.8047\n",
      "chunk number: 513 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4297 - acc: 0.8237 - val_loss: 0.5291 - val_acc: 0.8203\n",
      "chunk number: 514 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4964 - acc: 0.8114 - val_loss: 0.3964 - val_acc: 0.8750\n",
      "chunk number: 515 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4881 - acc: 0.8225 - val_loss: 0.4278 - val_acc: 0.8281\n",
      "chunk number: 516 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3822 - acc: 0.8571 - val_loss: 0.6627 - val_acc: 0.7500\n",
      "chunk number: 517 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4889 - acc: 0.8114 - val_loss: 0.4514 - val_acc: 0.7969\n",
      "chunk number: 518 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4531 - acc: 0.8326 - val_loss: 0.5387 - val_acc: 0.7812\n",
      "chunk number: 519 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4454 - acc: 0.8304 - val_loss: 0.5388 - val_acc: 0.7578\n",
      "chunk number: 520 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4825 - acc: 0.8069 - val_loss: 0.4717 - val_acc: 0.8594\n",
      "chunk number: 521 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4112 - acc: 0.8292 - val_loss: 0.4717 - val_acc: 0.8203\n",
      "chunk number: 522 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4634 - acc: 0.8192 - val_loss: 0.5358 - val_acc: 0.7891\n",
      "chunk number: 523 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5049 - acc: 0.8181 - val_loss: 0.3934 - val_acc: 0.8516\n",
      "chunk number: 524 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4840 - acc: 0.8058 - val_loss: 0.5172 - val_acc: 0.7500\n",
      "chunk number: 525 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4305 - acc: 0.8326 - val_loss: 0.4715 - val_acc: 0.8203\n",
      "chunk number: 526 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4617 - acc: 0.8203 - val_loss: 0.4838 - val_acc: 0.8203\n",
      "chunk number: 527 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4589 - acc: 0.8080 - val_loss: 0.4131 - val_acc: 0.8125\n",
      "chunk number: 528 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4653 - acc: 0.8103 - val_loss: 0.5597 - val_acc: 0.8125\n",
      "chunk number: 529 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4518 - acc: 0.8393 - val_loss: 0.5432 - val_acc: 0.8125\n",
      "chunk number: 530 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4464 - acc: 0.8237 - val_loss: 0.5316 - val_acc: 0.8047\n",
      "chunk number: 531 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4407 - acc: 0.8281 - val_loss: 0.4576 - val_acc: 0.7969\n",
      "chunk number: 532 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4744 - acc: 0.8136 - val_loss: 0.5154 - val_acc: 0.8047\n",
      "chunk number: 533 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4853 - acc: 0.8103 - val_loss: 0.4234 - val_acc: 0.8047\n",
      "chunk number: 534 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4357 - acc: 0.8225 - val_loss: 0.4863 - val_acc: 0.8203\n",
      "chunk number: 535 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4497 - acc: 0.8426 - val_loss: 0.4635 - val_acc: 0.7812\n",
      "chunk number: 536 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4890 - acc: 0.8125 - val_loss: 0.3823 - val_acc: 0.8516\n",
      "chunk number: 537 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4527 - acc: 0.8292 - val_loss: 0.4065 - val_acc: 0.8594\n",
      "chunk number: 538 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4354 - acc: 0.8326 - val_loss: 0.4713 - val_acc: 0.8594\n",
      "chunk number: 539 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4692 - acc: 0.8203 - val_loss: 0.4305 - val_acc: 0.8516\n",
      "chunk number: 540 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4878 - acc: 0.8058 - val_loss: 0.4279 - val_acc: 0.8438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 541 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4246 - acc: 0.8382 - val_loss: 0.4623 - val_acc: 0.8125\n",
      "chunk number: 542 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4335 - acc: 0.8404 - val_loss: 0.5198 - val_acc: 0.8047\n",
      "chunk number: 543 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4113 - acc: 0.8348 - val_loss: 0.4328 - val_acc: 0.7891\n",
      "chunk number: 544 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4332 - acc: 0.8281 - val_loss: 0.6070 - val_acc: 0.7891\n",
      "chunk number: 545 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4379 - acc: 0.8270 - val_loss: 0.5331 - val_acc: 0.7578\n",
      "chunk number: 546 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4669 - acc: 0.8170 - val_loss: 0.4579 - val_acc: 0.8594\n",
      "chunk number: 547 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4190 - acc: 0.8348 - val_loss: 0.4810 - val_acc: 0.8750\n",
      "chunk number: 548 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4538 - acc: 0.8114 - val_loss: 0.5802 - val_acc: 0.7656\n",
      "chunk number: 549 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4562 - acc: 0.8248 - val_loss: 0.5087 - val_acc: 0.8359\n",
      "chunk number: 550 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4556 - acc: 0.8214 - val_loss: 0.4746 - val_acc: 0.8281\n",
      "chunk number: 551 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4790 - acc: 0.8136 - val_loss: 0.5381 - val_acc: 0.7969\n",
      "chunk number: 552 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4445 - acc: 0.8225 - val_loss: 0.3589 - val_acc: 0.8750\n",
      "chunk number: 553 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4931 - acc: 0.7958 - val_loss: 0.5347 - val_acc: 0.8203\n",
      "chunk number: 554 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4369 - acc: 0.8259 - val_loss: 0.3371 - val_acc: 0.8516\n",
      "chunk number: 555 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4381 - acc: 0.8315 - val_loss: 0.4598 - val_acc: 0.8047\n",
      "chunk number: 556 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4390 - acc: 0.8315 - val_loss: 0.5160 - val_acc: 0.8047\n",
      "chunk number: 557 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4412 - acc: 0.8281 - val_loss: 0.3904 - val_acc: 0.8359\n",
      "chunk number: 558 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4073 - acc: 0.8471 - val_loss: 0.4270 - val_acc: 0.8359\n",
      "chunk number: 559 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4696 - acc: 0.8214 - val_loss: 0.4616 - val_acc: 0.8203\n",
      "chunk number: 560 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4912 - acc: 0.8025 - val_loss: 0.4699 - val_acc: 0.8438\n",
      "chunk number: 561 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4701 - acc: 0.8203 - val_loss: 0.3648 - val_acc: 0.8672\n",
      "chunk number: 562 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4397 - acc: 0.8304 - val_loss: 0.4230 - val_acc: 0.8516\n",
      "chunk number: 563 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5024 - acc: 0.8047 - val_loss: 0.4914 - val_acc: 0.8516\n",
      "chunk number: 564 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4075 - acc: 0.8560 - val_loss: 0.4774 - val_acc: 0.8281\n",
      "chunk number: 565 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4867 - acc: 0.8192 - val_loss: 0.4891 - val_acc: 0.7656\n",
      "chunk number: 566 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4655 - acc: 0.8259 - val_loss: 0.4749 - val_acc: 0.8125\n",
      "chunk number: 567 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4414 - acc: 0.8292 - val_loss: 0.4129 - val_acc: 0.8438\n",
      "chunk number: 568 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4978 - acc: 0.8080 - val_loss: 0.6376 - val_acc: 0.7812\n",
      "chunk number: 569 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4842 - acc: 0.8125 - val_loss: 0.4272 - val_acc: 0.8281\n",
      "chunk number: 570 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4143 - acc: 0.8337 - val_loss: 0.4964 - val_acc: 0.8281\n",
      "chunk number: 571 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4258 - acc: 0.8426 - val_loss: 0.4495 - val_acc: 0.8125\n",
      "chunk number: 572 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4618 - acc: 0.8170 - val_loss: 0.5329 - val_acc: 0.8047\n",
      "chunk number: 573 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4104 - acc: 0.8638 - val_loss: 0.5315 - val_acc: 0.8047\n",
      "chunk number: 574 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4654 - acc: 0.8203 - val_loss: 0.6120 - val_acc: 0.7578\n",
      "chunk number: 575 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4136 - acc: 0.8493 - val_loss: 0.5025 - val_acc: 0.7891\n",
      "chunk number: 576 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4187 - acc: 0.8404 - val_loss: 0.4956 - val_acc: 0.8203\n",
      "chunk number: 577 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4283 - acc: 0.8348 - val_loss: 0.4335 - val_acc: 0.8047\n",
      "chunk number: 578 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4460 - acc: 0.8270 - val_loss: 0.6200 - val_acc: 0.7656\n",
      "chunk number: 579 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4434 - acc: 0.8248 - val_loss: 0.4116 - val_acc: 0.8594\n",
      "chunk number: 580 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4449 - acc: 0.8270 - val_loss: 0.3514 - val_acc: 0.9062\n",
      "chunk number: 581 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4680 - acc: 0.8158 - val_loss: 0.4126 - val_acc: 0.8125\n",
      "chunk number: 582 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4247 - acc: 0.8337 - val_loss: 0.4411 - val_acc: 0.7969\n",
      "chunk number: 583 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4490 - acc: 0.8214 - val_loss: 0.4864 - val_acc: 0.7969\n",
      "chunk number: 584 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4735 - acc: 0.8203 - val_loss: 0.3902 - val_acc: 0.8125\n",
      "chunk number: 585 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4557 - acc: 0.8359 - val_loss: 0.5113 - val_acc: 0.8125\n",
      "chunk number: 586 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4706 - acc: 0.8225 - val_loss: 0.3824 - val_acc: 0.8359\n",
      "chunk number: 587 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4584 - acc: 0.8315 - val_loss: 0.4830 - val_acc: 0.8203\n",
      "chunk number: 588 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4701 - acc: 0.8147 - val_loss: 0.3820 - val_acc: 0.8438\n",
      "chunk number: 589 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4484 - acc: 0.8304 - val_loss: 0.4447 - val_acc: 0.8438\n",
      "chunk number: 590 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4270 - acc: 0.8281 - val_loss: 0.4383 - val_acc: 0.8359\n",
      "chunk number: 591 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4640 - acc: 0.8292 - val_loss: 0.5271 - val_acc: 0.8203\n",
      "chunk number: 592 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4650 - acc: 0.8103 - val_loss: 0.3606 - val_acc: 0.8359\n",
      "chunk number: 593 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4534 - acc: 0.8080 - val_loss: 0.6530 - val_acc: 0.7578\n",
      "chunk number: 594 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4114 - acc: 0.8393 - val_loss: 0.4606 - val_acc: 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 595 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4049 - acc: 0.8605 - val_loss: 0.3674 - val_acc: 0.8672\n",
      "chunk number: 596 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4351 - acc: 0.8404 - val_loss: 0.4188 - val_acc: 0.8516\n",
      "chunk number: 597 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4173 - acc: 0.8348 - val_loss: 0.3886 - val_acc: 0.8359\n",
      "chunk number: 598 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4393 - acc: 0.8326 - val_loss: 0.4388 - val_acc: 0.8203\n",
      "chunk number: 599 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3861 - acc: 0.8482 - val_loss: 0.4555 - val_acc: 0.8047\n",
      "chunk number: 600 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4543 - acc: 0.8136 - val_loss: 0.3545 - val_acc: 0.8516\n",
      "chunk number: 601 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4067 - acc: 0.8493 - val_loss: 0.4528 - val_acc: 0.8359\n",
      "chunk number: 602 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4327 - acc: 0.8237 - val_loss: 0.5431 - val_acc: 0.7812\n",
      "chunk number: 603 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4352 - acc: 0.8304 - val_loss: 0.3701 - val_acc: 0.8516\n",
      "chunk number: 604 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4496 - acc: 0.8371 - val_loss: 0.4102 - val_acc: 0.8516\n",
      "chunk number: 605 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4332 - acc: 0.8382 - val_loss: 0.5189 - val_acc: 0.8047\n",
      "chunk number: 606 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4139 - acc: 0.8304 - val_loss: 0.5168 - val_acc: 0.8281\n",
      "chunk number: 607 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4777 - acc: 0.8315 - val_loss: 0.5675 - val_acc: 0.7891\n",
      "chunk number: 608 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4241 - acc: 0.8359 - val_loss: 0.4628 - val_acc: 0.7656\n",
      "chunk number: 609 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3997 - acc: 0.8583 - val_loss: 0.3679 - val_acc: 0.8359\n",
      "chunk number: 610 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4260 - acc: 0.8337 - val_loss: 0.4168 - val_acc: 0.8203\n",
      "chunk number: 611 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5397 - acc: 0.7879 - val_loss: 0.4159 - val_acc: 0.8516\n",
      "chunk number: 612 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4812 - acc: 0.8002 - val_loss: 0.4686 - val_acc: 0.7969\n",
      "chunk number: 613 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4374 - acc: 0.8315 - val_loss: 0.5704 - val_acc: 0.7500\n",
      "chunk number: 614 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5074 - acc: 0.8103 - val_loss: 0.3338 - val_acc: 0.9062\n",
      "chunk number: 615 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4576 - acc: 0.8248 - val_loss: 0.4307 - val_acc: 0.8125\n",
      "chunk number: 616 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3872 - acc: 0.8438 - val_loss: 0.5453 - val_acc: 0.8125\n",
      "chunk number: 617 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4505 - acc: 0.8304 - val_loss: 0.3848 - val_acc: 0.8750\n",
      "chunk number: 618 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4522 - acc: 0.8170 - val_loss: 0.5624 - val_acc: 0.7891\n",
      "chunk number: 619 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4468 - acc: 0.8415 - val_loss: 0.4868 - val_acc: 0.7734\n",
      "chunk number: 620 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4340 - acc: 0.8214 - val_loss: 0.4685 - val_acc: 0.8281\n",
      "chunk number: 621 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3892 - acc: 0.8516 - val_loss: 0.3978 - val_acc: 0.8281\n",
      "chunk number: 622 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4310 - acc: 0.8315 - val_loss: 0.4561 - val_acc: 0.7969\n",
      "chunk number: 623 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4697 - acc: 0.8527 - val_loss: 0.4214 - val_acc: 0.8594\n",
      "chunk number: 624 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4929 - acc: 0.8158 - val_loss: 0.4877 - val_acc: 0.7812\n",
      "chunk number: 625 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4263 - acc: 0.8304 - val_loss: 0.5068 - val_acc: 0.8359\n",
      "chunk number: 626 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4813 - acc: 0.8147 - val_loss: 0.5567 - val_acc: 0.7891\n",
      "chunk number: 627 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4172 - acc: 0.8304 - val_loss: 0.3469 - val_acc: 0.8672\n",
      "chunk number: 628 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4417 - acc: 0.8382 - val_loss: 0.5131 - val_acc: 0.8125\n",
      "chunk number: 629 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4587 - acc: 0.8259 - val_loss: 0.4838 - val_acc: 0.8125\n",
      "chunk number: 630 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4500 - acc: 0.8281 - val_loss: 0.5776 - val_acc: 0.7344\n",
      "chunk number: 631 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4532 - acc: 0.8248 - val_loss: 0.4952 - val_acc: 0.7812\n",
      "chunk number: 632 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4700 - acc: 0.8225 - val_loss: 0.5067 - val_acc: 0.7734\n",
      "chunk number: 633 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4418 - acc: 0.8259 - val_loss: 0.3604 - val_acc: 0.8594\n",
      "chunk number: 634 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4240 - acc: 0.8315 - val_loss: 0.5112 - val_acc: 0.8047\n",
      "chunk number: 635 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4213 - acc: 0.8259 - val_loss: 0.5401 - val_acc: 0.7500\n",
      "chunk number: 636 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4472 - acc: 0.8315 - val_loss: 0.4184 - val_acc: 0.8125\n",
      "chunk number: 637 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4447 - acc: 0.8147 - val_loss: 0.3840 - val_acc: 0.8828\n",
      "chunk number: 638 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4246 - acc: 0.8348 - val_loss: 0.5415 - val_acc: 0.8516\n",
      "chunk number: 639 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4472 - acc: 0.8415 - val_loss: 0.4293 - val_acc: 0.8047\n",
      "chunk number: 640 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4822 - acc: 0.8225 - val_loss: 0.4155 - val_acc: 0.8203\n",
      "chunk number: 641 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4152 - acc: 0.8292 - val_loss: 0.5237 - val_acc: 0.7891\n",
      "chunk number: 642 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4345 - acc: 0.8438 - val_loss: 0.5346 - val_acc: 0.8047\n",
      "chunk number: 643 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4075 - acc: 0.8359 - val_loss: 0.4485 - val_acc: 0.8281\n",
      "chunk number: 644 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4120 - acc: 0.8426 - val_loss: 0.6175 - val_acc: 0.7891\n",
      "chunk number: 645 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4436 - acc: 0.8315 - val_loss: 0.4560 - val_acc: 0.7969\n",
      "chunk number: 646 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4544 - acc: 0.8359 - val_loss: 0.4757 - val_acc: 0.8125\n",
      "chunk number: 647 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4121 - acc: 0.8404 - val_loss: 0.4429 - val_acc: 0.8594\n",
      "chunk number: 648 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3967 - acc: 0.8449 - val_loss: 0.5143 - val_acc: 0.8203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 649 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4019 - acc: 0.8237 - val_loss: 0.5235 - val_acc: 0.8047\n",
      "chunk number: 650 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4492 - acc: 0.8181 - val_loss: 0.4627 - val_acc: 0.8516\n",
      "chunk number: 651 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4102 - acc: 0.8359 - val_loss: 0.4678 - val_acc: 0.8359\n",
      "chunk number: 652 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4292 - acc: 0.8426 - val_loss: 0.3446 - val_acc: 0.8906\n",
      "chunk number: 653 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4522 - acc: 0.8270 - val_loss: 0.4832 - val_acc: 0.8438\n",
      "chunk number: 654 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4330 - acc: 0.8304 - val_loss: 0.3588 - val_acc: 0.8750\n",
      "chunk number: 655 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4081 - acc: 0.8415 - val_loss: 0.3896 - val_acc: 0.8359\n",
      "chunk number: 656 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4399 - acc: 0.8170 - val_loss: 0.4578 - val_acc: 0.8125\n",
      "chunk number: 657 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4350 - acc: 0.8270 - val_loss: 0.4823 - val_acc: 0.8359\n",
      "chunk number: 658 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4227 - acc: 0.8560 - val_loss: 0.4080 - val_acc: 0.8281\n",
      "chunk number: 659 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4416 - acc: 0.8404 - val_loss: 0.4598 - val_acc: 0.8281\n",
      "chunk number: 660 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5053 - acc: 0.8114 - val_loss: 0.4472 - val_acc: 0.8359\n",
      "chunk number: 661 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4240 - acc: 0.8404 - val_loss: 0.3501 - val_acc: 0.8750\n",
      "chunk number: 662 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4245 - acc: 0.8359 - val_loss: 0.3604 - val_acc: 0.8750\n",
      "chunk number: 663 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4494 - acc: 0.8359 - val_loss: 0.4582 - val_acc: 0.8203\n",
      "chunk number: 664 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3828 - acc: 0.8605 - val_loss: 0.4176 - val_acc: 0.8359\n",
      "chunk number: 665 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4378 - acc: 0.8359 - val_loss: 0.4014 - val_acc: 0.8516\n",
      "chunk number: 666 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4081 - acc: 0.8315 - val_loss: 0.4903 - val_acc: 0.7969\n",
      "chunk number: 667 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4061 - acc: 0.8426 - val_loss: 0.4805 - val_acc: 0.7891\n",
      "chunk number: 668 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4230 - acc: 0.8438 - val_loss: 0.5853 - val_acc: 0.8203\n",
      "chunk number: 669 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4502 - acc: 0.8214 - val_loss: 0.3900 - val_acc: 0.8281\n",
      "chunk number: 670 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4444 - acc: 0.8359 - val_loss: 0.5308 - val_acc: 0.7969\n",
      "chunk number: 671 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4244 - acc: 0.8393 - val_loss: 0.4747 - val_acc: 0.7969\n",
      "chunk number: 672 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4660 - acc: 0.8237 - val_loss: 0.5600 - val_acc: 0.8125\n",
      "chunk number: 673 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4318 - acc: 0.8371 - val_loss: 0.5252 - val_acc: 0.7891\n",
      "chunk number: 674 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4441 - acc: 0.8225 - val_loss: 0.6132 - val_acc: 0.7422\n",
      "chunk number: 675 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4466 - acc: 0.8415 - val_loss: 0.3996 - val_acc: 0.8438\n",
      "chunk number: 676 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4219 - acc: 0.8471 - val_loss: 0.4468 - val_acc: 0.8359\n",
      "chunk number: 677 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4103 - acc: 0.8382 - val_loss: 0.4412 - val_acc: 0.8047\n",
      "chunk number: 678 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4158 - acc: 0.8225 - val_loss: 0.5886 - val_acc: 0.7812\n",
      "chunk number: 679 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4259 - acc: 0.8348 - val_loss: 0.4101 - val_acc: 0.8359\n",
      "chunk number: 680 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4191 - acc: 0.8493 - val_loss: 0.3692 - val_acc: 0.8594\n",
      "chunk number: 681 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4347 - acc: 0.8326 - val_loss: 0.3651 - val_acc: 0.8516\n",
      "chunk number: 682 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3915 - acc: 0.8638 - val_loss: 0.4024 - val_acc: 0.8281\n",
      "chunk number: 683 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4154 - acc: 0.8404 - val_loss: 0.4860 - val_acc: 0.8047\n",
      "chunk number: 684 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4335 - acc: 0.8281 - val_loss: 0.4025 - val_acc: 0.8203\n",
      "chunk number: 685 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4602 - acc: 0.8348 - val_loss: 0.4516 - val_acc: 0.8125\n",
      "chunk number: 686 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4734 - acc: 0.8292 - val_loss: 0.4205 - val_acc: 0.8281\n",
      "chunk number: 687 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4847 - acc: 0.8315 - val_loss: 0.5110 - val_acc: 0.8125\n",
      "chunk number: 688 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4347 - acc: 0.8393 - val_loss: 0.3557 - val_acc: 0.8594\n",
      "chunk number: 689 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3975 - acc: 0.8359 - val_loss: 0.3941 - val_acc: 0.8438\n",
      "chunk number: 690 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4182 - acc: 0.8348 - val_loss: 0.4252 - val_acc: 0.8594\n",
      "chunk number: 691 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4252 - acc: 0.8259 - val_loss: 0.4789 - val_acc: 0.8438\n",
      "chunk number: 692 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4173 - acc: 0.8337 - val_loss: 0.3689 - val_acc: 0.8281\n",
      "chunk number: 693 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3861 - acc: 0.8527 - val_loss: 0.6067 - val_acc: 0.7812\n",
      "chunk number: 694 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4104 - acc: 0.8259 - val_loss: 0.4943 - val_acc: 0.7969\n",
      "chunk number: 695 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3799 - acc: 0.8460 - val_loss: 0.4270 - val_acc: 0.8281\n",
      "chunk number: 696 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4256 - acc: 0.8404 - val_loss: 0.4221 - val_acc: 0.8438\n",
      "chunk number: 697 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4268 - acc: 0.8471 - val_loss: 0.4119 - val_acc: 0.8203\n",
      "chunk number: 698 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4422 - acc: 0.8371 - val_loss: 0.4426 - val_acc: 0.8281\n",
      "chunk number: 699 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3979 - acc: 0.8527 - val_loss: 0.4171 - val_acc: 0.8281\n",
      "chunk number: 700 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4414 - acc: 0.8359 - val_loss: 0.3654 - val_acc: 0.8438\n",
      "chunk number: 701 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4124 - acc: 0.8493 - val_loss: 0.4019 - val_acc: 0.8672\n",
      "chunk number: 702 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4287 - acc: 0.8359 - val_loss: 0.5409 - val_acc: 0.7891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 703 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4414 - acc: 0.8203 - val_loss: 0.3849 - val_acc: 0.8438\n",
      "chunk number: 704 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4173 - acc: 0.8393 - val_loss: 0.4384 - val_acc: 0.8281\n",
      "chunk number: 705 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4472 - acc: 0.8270 - val_loss: 0.5929 - val_acc: 0.7969\n",
      "chunk number: 706 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3878 - acc: 0.8493 - val_loss: 0.5157 - val_acc: 0.8203\n",
      "chunk number: 707 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4469 - acc: 0.8438 - val_loss: 0.4464 - val_acc: 0.8594\n",
      "chunk number: 708 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3955 - acc: 0.8415 - val_loss: 0.3601 - val_acc: 0.8516\n",
      "chunk number: 709 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3932 - acc: 0.8705 - val_loss: 0.3674 - val_acc: 0.8516\n",
      "chunk number: 710 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4312 - acc: 0.8426 - val_loss: 0.4087 - val_acc: 0.8203\n",
      "chunk number: 711 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4665 - acc: 0.8181 - val_loss: 0.4787 - val_acc: 0.7891\n",
      "chunk number: 712 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4672 - acc: 0.8047 - val_loss: 0.4543 - val_acc: 0.8125\n",
      "chunk number: 713 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4444 - acc: 0.8348 - val_loss: 0.5028 - val_acc: 0.8125\n",
      "chunk number: 714 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4541 - acc: 0.8125 - val_loss: 0.3532 - val_acc: 0.8828\n",
      "chunk number: 715 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4249 - acc: 0.8404 - val_loss: 0.4194 - val_acc: 0.7891\n",
      "chunk number: 716 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3825 - acc: 0.8482 - val_loss: 0.6254 - val_acc: 0.7656\n",
      "chunk number: 717 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4544 - acc: 0.8181 - val_loss: 0.3999 - val_acc: 0.8359\n",
      "chunk number: 718 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4065 - acc: 0.8438 - val_loss: 0.4127 - val_acc: 0.8125\n",
      "chunk number: 719 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4357 - acc: 0.8304 - val_loss: 0.4132 - val_acc: 0.7969\n",
      "chunk number: 720 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4204 - acc: 0.8426 - val_loss: 0.5291 - val_acc: 0.8594\n",
      "chunk number: 721 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3856 - acc: 0.8516 - val_loss: 0.4450 - val_acc: 0.8359\n",
      "chunk number: 722 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4365 - acc: 0.8270 - val_loss: 0.4642 - val_acc: 0.8047\n",
      "chunk number: 723 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4545 - acc: 0.8438 - val_loss: 0.3956 - val_acc: 0.8594\n",
      "chunk number: 724 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4483 - acc: 0.8371 - val_loss: 0.4401 - val_acc: 0.8516\n",
      "chunk number: 725 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4050 - acc: 0.8371 - val_loss: 0.4755 - val_acc: 0.8516\n",
      "chunk number: 726 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4451 - acc: 0.8281 - val_loss: 0.4849 - val_acc: 0.8047\n",
      "chunk number: 727 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4014 - acc: 0.8415 - val_loss: 0.3527 - val_acc: 0.8672\n",
      "chunk number: 728 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4288 - acc: 0.8527 - val_loss: 0.4994 - val_acc: 0.7891\n",
      "chunk number: 729 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4220 - acc: 0.8449 - val_loss: 0.4852 - val_acc: 0.8281\n",
      "chunk number: 730 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4662 - acc: 0.8393 - val_loss: 0.5967 - val_acc: 0.7266\n",
      "chunk number: 731 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4151 - acc: 0.8382 - val_loss: 0.4367 - val_acc: 0.7891\n",
      "chunk number: 732 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4440 - acc: 0.8248 - val_loss: 0.5213 - val_acc: 0.8047\n",
      "chunk number: 733 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4390 - acc: 0.8270 - val_loss: 0.4234 - val_acc: 0.8047\n",
      "chunk number: 734 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4328 - acc: 0.8326 - val_loss: 0.4289 - val_acc: 0.8516\n",
      "chunk number: 735 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4139 - acc: 0.8504 - val_loss: 0.5046 - val_acc: 0.8125\n",
      "chunk number: 736 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4329 - acc: 0.8482 - val_loss: 0.5001 - val_acc: 0.8125\n",
      "chunk number: 737 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4360 - acc: 0.8192 - val_loss: 0.2866 - val_acc: 0.8984\n",
      "chunk number: 738 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3790 - acc: 0.8583 - val_loss: 0.5097 - val_acc: 0.8750\n",
      "chunk number: 739 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4207 - acc: 0.8426 - val_loss: 0.4055 - val_acc: 0.8438\n",
      "chunk number: 740 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4706 - acc: 0.8203 - val_loss: 0.4006 - val_acc: 0.8359\n",
      "chunk number: 741 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3988 - acc: 0.8404 - val_loss: 0.4477 - val_acc: 0.8203\n",
      "chunk number: 742 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4348 - acc: 0.8493 - val_loss: 0.4806 - val_acc: 0.8359\n",
      "chunk number: 743 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4034 - acc: 0.8449 - val_loss: 0.3744 - val_acc: 0.8281\n",
      "chunk number: 744 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3677 - acc: 0.8650 - val_loss: 0.5235 - val_acc: 0.8203\n",
      "chunk number: 745 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3973 - acc: 0.8426 - val_loss: 0.4803 - val_acc: 0.8047\n",
      "chunk number: 746 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4320 - acc: 0.8371 - val_loss: 0.4683 - val_acc: 0.8516\n",
      "chunk number: 747 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3843 - acc: 0.8337 - val_loss: 0.4052 - val_acc: 0.8594\n",
      "chunk number: 748 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3753 - acc: 0.8460 - val_loss: 0.5783 - val_acc: 0.7656\n",
      "chunk number: 749 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3757 - acc: 0.8482 - val_loss: 0.5242 - val_acc: 0.8359\n",
      "chunk number: 750 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4381 - acc: 0.8103 - val_loss: 0.4965 - val_acc: 0.8125\n",
      "chunk number: 751 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4133 - acc: 0.8281 - val_loss: 0.4299 - val_acc: 0.8359\n",
      "chunk number: 752 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4226 - acc: 0.8315 - val_loss: 0.3111 - val_acc: 0.8984\n",
      "chunk number: 753 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4188 - acc: 0.8304 - val_loss: 0.5099 - val_acc: 0.8438\n",
      "chunk number: 754 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4211 - acc: 0.8304 - val_loss: 0.4023 - val_acc: 0.8359\n",
      "chunk number: 755 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3998 - acc: 0.8516 - val_loss: 0.4088 - val_acc: 0.8281\n",
      "chunk number: 756 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4210 - acc: 0.8404 - val_loss: 0.4678 - val_acc: 0.8438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 757 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4258 - acc: 0.8292 - val_loss: 0.4324 - val_acc: 0.8516\n",
      "chunk number: 758 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3944 - acc: 0.8560 - val_loss: 0.4382 - val_acc: 0.8438\n",
      "chunk number: 759 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4258 - acc: 0.8371 - val_loss: 0.3680 - val_acc: 0.8906\n",
      "chunk number: 760 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4462 - acc: 0.8270 - val_loss: 0.4751 - val_acc: 0.8516\n",
      "chunk number: 761 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4279 - acc: 0.8426 - val_loss: 0.3553 - val_acc: 0.8750\n",
      "chunk number: 762 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3955 - acc: 0.8571 - val_loss: 0.3527 - val_acc: 0.8750\n",
      "chunk number: 763 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4311 - acc: 0.8393 - val_loss: 0.4618 - val_acc: 0.8203\n",
      "chunk number: 764 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3671 - acc: 0.8750 - val_loss: 0.4105 - val_acc: 0.8359\n",
      "chunk number: 765 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4193 - acc: 0.8583 - val_loss: 0.3598 - val_acc: 0.8516\n",
      "chunk number: 766 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4288 - acc: 0.8237 - val_loss: 0.4660 - val_acc: 0.8203\n",
      "chunk number: 767 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3794 - acc: 0.8627 - val_loss: 0.4077 - val_acc: 0.8125\n",
      "chunk number: 768 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4238 - acc: 0.8292 - val_loss: 0.5615 - val_acc: 0.7891\n",
      "chunk number: 769 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4161 - acc: 0.8304 - val_loss: 0.4507 - val_acc: 0.8281\n",
      "chunk number: 770 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3879 - acc: 0.8438 - val_loss: 0.4502 - val_acc: 0.8125\n",
      "chunk number: 771 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4059 - acc: 0.8359 - val_loss: 0.3762 - val_acc: 0.8203\n",
      "chunk number: 772 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4184 - acc: 0.8460 - val_loss: 0.5251 - val_acc: 0.8281\n",
      "chunk number: 773 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3892 - acc: 0.8426 - val_loss: 0.5780 - val_acc: 0.7812\n",
      "chunk number: 774 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4401 - acc: 0.8426 - val_loss: 0.5334 - val_acc: 0.7656\n",
      "chunk number: 775 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4097 - acc: 0.8504 - val_loss: 0.4370 - val_acc: 0.7969\n",
      "chunk number: 776 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3519 - acc: 0.8627 - val_loss: 0.4166 - val_acc: 0.8203\n",
      "chunk number: 777 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3836 - acc: 0.8571 - val_loss: 0.4062 - val_acc: 0.8359\n",
      "chunk number: 778 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3990 - acc: 0.8504 - val_loss: 0.6813 - val_acc: 0.7500\n",
      "chunk number: 779 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4382 - acc: 0.8348 - val_loss: 0.4003 - val_acc: 0.8516\n",
      "chunk number: 780 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3838 - acc: 0.8605 - val_loss: 0.4161 - val_acc: 0.8594\n",
      "chunk number: 781 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4097 - acc: 0.8426 - val_loss: 0.3884 - val_acc: 0.8594\n",
      "chunk number: 782 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4123 - acc: 0.8415 - val_loss: 0.3717 - val_acc: 0.8672\n",
      "chunk number: 783 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3957 - acc: 0.8482 - val_loss: 0.4345 - val_acc: 0.7969\n",
      "chunk number: 784 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4413 - acc: 0.8259 - val_loss: 0.4387 - val_acc: 0.8125\n",
      "chunk number: 785 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4577 - acc: 0.8304 - val_loss: 0.4392 - val_acc: 0.8516\n",
      "chunk number: 786 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4186 - acc: 0.8359 - val_loss: 0.3462 - val_acc: 0.8672\n",
      "chunk number: 787 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4461 - acc: 0.8270 - val_loss: 0.4897 - val_acc: 0.7969\n",
      "chunk number: 788 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4103 - acc: 0.8438 - val_loss: 0.3825 - val_acc: 0.8438\n",
      "chunk number: 789 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4146 - acc: 0.8482 - val_loss: 0.4083 - val_acc: 0.8438\n",
      "chunk number: 790 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3716 - acc: 0.8560 - val_loss: 0.3965 - val_acc: 0.8594\n",
      "chunk number: 791 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4075 - acc: 0.8304 - val_loss: 0.4378 - val_acc: 0.8281\n",
      "chunk number: 792 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3926 - acc: 0.8460 - val_loss: 0.3669 - val_acc: 0.8281\n",
      "chunk number: 793 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3830 - acc: 0.8638 - val_loss: 0.5874 - val_acc: 0.7656\n",
      "chunk number: 794 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3787 - acc: 0.8549 - val_loss: 0.5192 - val_acc: 0.8047\n",
      "chunk number: 795 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3704 - acc: 0.8694 - val_loss: 0.3588 - val_acc: 0.8828\n",
      "chunk number: 796 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4213 - acc: 0.8337 - val_loss: 0.4437 - val_acc: 0.8203\n",
      "chunk number: 797 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4026 - acc: 0.8471 - val_loss: 0.4243 - val_acc: 0.7969\n",
      "chunk number: 798 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4419 - acc: 0.8337 - val_loss: 0.4638 - val_acc: 0.7969\n",
      "chunk number: 799 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4171 - acc: 0.8482 - val_loss: 0.3684 - val_acc: 0.8750\n",
      "chunk number: 800 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4576 - acc: 0.8237 - val_loss: 0.3447 - val_acc: 0.8438\n",
      "chunk number: 801 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3697 - acc: 0.8705 - val_loss: 0.3337 - val_acc: 0.8828\n",
      "chunk number: 802 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4349 - acc: 0.8359 - val_loss: 0.5282 - val_acc: 0.8047\n",
      "chunk number: 803 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4066 - acc: 0.8348 - val_loss: 0.3194 - val_acc: 0.8750\n",
      "chunk number: 804 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3789 - acc: 0.8460 - val_loss: 0.3944 - val_acc: 0.8750\n",
      "chunk number: 805 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4339 - acc: 0.8393 - val_loss: 0.4744 - val_acc: 0.8047\n",
      "chunk number: 806 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3800 - acc: 0.8460 - val_loss: 0.6327 - val_acc: 0.8047\n",
      "chunk number: 807 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4318 - acc: 0.8471 - val_loss: 0.4793 - val_acc: 0.8125\n",
      "chunk number: 808 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3806 - acc: 0.8493 - val_loss: 0.3820 - val_acc: 0.8359\n",
      "chunk number: 809 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3321 - acc: 0.8839 - val_loss: 0.3096 - val_acc: 0.8594\n",
      "chunk number: 810 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3964 - acc: 0.8449 - val_loss: 0.4704 - val_acc: 0.8203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 811 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4290 - acc: 0.8281 - val_loss: 0.3420 - val_acc: 0.8594\n",
      "chunk number: 812 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4201 - acc: 0.8270 - val_loss: 0.4192 - val_acc: 0.8516\n",
      "chunk number: 813 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3819 - acc: 0.8594 - val_loss: 0.5673 - val_acc: 0.8125\n",
      "chunk number: 814 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4717 - acc: 0.8237 - val_loss: 0.3351 - val_acc: 0.8750\n",
      "chunk number: 815 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4316 - acc: 0.8371 - val_loss: 0.4383 - val_acc: 0.8281\n",
      "chunk number: 816 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3566 - acc: 0.8560 - val_loss: 0.6359 - val_acc: 0.7500\n",
      "chunk number: 817 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4580 - acc: 0.8147 - val_loss: 0.3960 - val_acc: 0.8359\n",
      "chunk number: 818 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4110 - acc: 0.8449 - val_loss: 0.4903 - val_acc: 0.7969\n",
      "chunk number: 819 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3977 - acc: 0.8438 - val_loss: 0.4665 - val_acc: 0.7969\n",
      "chunk number: 820 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3950 - acc: 0.8493 - val_loss: 0.4808 - val_acc: 0.8438\n",
      "chunk number: 821 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3715 - acc: 0.8516 - val_loss: 0.4461 - val_acc: 0.8281\n",
      "chunk number: 822 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3939 - acc: 0.8382 - val_loss: 0.4845 - val_acc: 0.8047\n",
      "chunk number: 823 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4174 - acc: 0.8516 - val_loss: 0.3695 - val_acc: 0.8594\n",
      "chunk number: 824 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4329 - acc: 0.8359 - val_loss: 0.4489 - val_acc: 0.8281\n",
      "chunk number: 825 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3632 - acc: 0.8516 - val_loss: 0.4308 - val_acc: 0.8047\n",
      "chunk number: 826 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4070 - acc: 0.8359 - val_loss: 0.4496 - val_acc: 0.8125\n",
      "chunk number: 827 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3634 - acc: 0.8583 - val_loss: 0.3526 - val_acc: 0.8750\n",
      "chunk number: 828 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4071 - acc: 0.8415 - val_loss: 0.4454 - val_acc: 0.8594\n",
      "chunk number: 829 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4169 - acc: 0.8460 - val_loss: 0.4071 - val_acc: 0.8750\n",
      "chunk number: 830 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4288 - acc: 0.8359 - val_loss: 0.5004 - val_acc: 0.8203\n",
      "chunk number: 831 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3826 - acc: 0.8616 - val_loss: 0.4256 - val_acc: 0.8203\n",
      "chunk number: 832 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4239 - acc: 0.8438 - val_loss: 0.5015 - val_acc: 0.7891\n",
      "chunk number: 833 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4289 - acc: 0.8382 - val_loss: 0.4034 - val_acc: 0.8672\n",
      "chunk number: 834 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4257 - acc: 0.8292 - val_loss: 0.4890 - val_acc: 0.8203\n",
      "chunk number: 835 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3880 - acc: 0.8549 - val_loss: 0.6238 - val_acc: 0.8047\n",
      "chunk number: 836 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4535 - acc: 0.8415 - val_loss: 0.4549 - val_acc: 0.8125\n",
      "chunk number: 837 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4503 - acc: 0.8080 - val_loss: 0.2937 - val_acc: 0.8906\n",
      "chunk number: 838 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3981 - acc: 0.8393 - val_loss: 0.4776 - val_acc: 0.8672\n",
      "chunk number: 839 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4265 - acc: 0.8337 - val_loss: 0.4130 - val_acc: 0.8359\n",
      "chunk number: 840 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4459 - acc: 0.8192 - val_loss: 0.3676 - val_acc: 0.8594\n",
      "chunk number: 841 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3982 - acc: 0.8527 - val_loss: 0.4085 - val_acc: 0.8594\n",
      "chunk number: 842 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3998 - acc: 0.8482 - val_loss: 0.5165 - val_acc: 0.8281\n",
      "chunk number: 843 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3894 - acc: 0.8326 - val_loss: 0.3837 - val_acc: 0.8438\n",
      "chunk number: 844 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3796 - acc: 0.8672 - val_loss: 0.5446 - val_acc: 0.7969\n",
      "chunk number: 845 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4053 - acc: 0.8393 - val_loss: 0.4750 - val_acc: 0.8125\n",
      "chunk number: 846 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4243 - acc: 0.8270 - val_loss: 0.5982 - val_acc: 0.8047\n",
      "chunk number: 847 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3570 - acc: 0.8571 - val_loss: 0.4617 - val_acc: 0.8672\n",
      "chunk number: 848 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4058 - acc: 0.8281 - val_loss: 0.6318 - val_acc: 0.7812\n",
      "chunk number: 849 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3545 - acc: 0.8605 - val_loss: 0.4578 - val_acc: 0.8125\n",
      "chunk number: 850 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4274 - acc: 0.8214 - val_loss: 0.5235 - val_acc: 0.8281\n",
      "chunk number: 851 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4219 - acc: 0.8304 - val_loss: 0.4422 - val_acc: 0.8125\n",
      "chunk number: 852 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3914 - acc: 0.8348 - val_loss: 0.3422 - val_acc: 0.8594\n",
      "chunk number: 853 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4424 - acc: 0.8203 - val_loss: 0.4710 - val_acc: 0.8281\n",
      "chunk number: 854 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3944 - acc: 0.8438 - val_loss: 0.3142 - val_acc: 0.8906\n",
      "chunk number: 855 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3678 - acc: 0.8638 - val_loss: 0.3682 - val_acc: 0.8516\n",
      "chunk number: 856 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3979 - acc: 0.8527 - val_loss: 0.4251 - val_acc: 0.8750\n",
      "chunk number: 857 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4315 - acc: 0.8326 - val_loss: 0.4771 - val_acc: 0.8594\n",
      "chunk number: 858 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3792 - acc: 0.8594 - val_loss: 0.3590 - val_acc: 0.8672\n",
      "chunk number: 859 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4007 - acc: 0.8538 - val_loss: 0.3625 - val_acc: 0.8828\n",
      "chunk number: 860 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4505 - acc: 0.8158 - val_loss: 0.4049 - val_acc: 0.8594\n",
      "chunk number: 861 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3841 - acc: 0.8650 - val_loss: 0.3196 - val_acc: 0.8750\n",
      "chunk number: 862 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4197 - acc: 0.8482 - val_loss: 0.3090 - val_acc: 0.9062\n",
      "chunk number: 863 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4271 - acc: 0.8438 - val_loss: 0.4281 - val_acc: 0.8516\n",
      "chunk number: 864 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3608 - acc: 0.8661 - val_loss: 0.4026 - val_acc: 0.8438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 865 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4267 - acc: 0.8270 - val_loss: 0.3987 - val_acc: 0.8281\n",
      "chunk number: 866 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4070 - acc: 0.8516 - val_loss: 0.4472 - val_acc: 0.8203\n",
      "chunk number: 867 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3834 - acc: 0.8661 - val_loss: 0.4837 - val_acc: 0.7969\n",
      "chunk number: 868 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4190 - acc: 0.8304 - val_loss: 0.5665 - val_acc: 0.8203\n",
      "chunk number: 869 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4071 - acc: 0.8438 - val_loss: 0.3914 - val_acc: 0.8672\n",
      "chunk number: 870 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3572 - acc: 0.8728 - val_loss: 0.4826 - val_acc: 0.7969\n",
      "chunk number: 871 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3995 - acc: 0.8426 - val_loss: 0.4599 - val_acc: 0.8359\n",
      "chunk number: 872 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3618 - acc: 0.8571 - val_loss: 0.4576 - val_acc: 0.8281\n",
      "chunk number: 873 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4002 - acc: 0.8560 - val_loss: 0.5359 - val_acc: 0.8125\n",
      "chunk number: 874 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4278 - acc: 0.8482 - val_loss: 0.6107 - val_acc: 0.7500\n",
      "chunk number: 875 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3977 - acc: 0.8661 - val_loss: 0.4340 - val_acc: 0.8281\n",
      "chunk number: 876 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3526 - acc: 0.8594 - val_loss: 0.4167 - val_acc: 0.8359\n",
      "chunk number: 877 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3685 - acc: 0.8571 - val_loss: 0.3798 - val_acc: 0.8672\n",
      "chunk number: 878 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3851 - acc: 0.8460 - val_loss: 0.5638 - val_acc: 0.7422\n",
      "chunk number: 879 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4020 - acc: 0.8471 - val_loss: 0.3842 - val_acc: 0.8047\n",
      "chunk number: 880 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3935 - acc: 0.8449 - val_loss: 0.4022 - val_acc: 0.8281\n",
      "chunk number: 881 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4143 - acc: 0.8415 - val_loss: 0.3582 - val_acc: 0.8672\n",
      "chunk number: 882 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3729 - acc: 0.8571 - val_loss: 0.3893 - val_acc: 0.8359\n",
      "chunk number: 883 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3895 - acc: 0.8493 - val_loss: 0.4748 - val_acc: 0.7969\n",
      "chunk number: 884 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4247 - acc: 0.8304 - val_loss: 0.3591 - val_acc: 0.8047\n",
      "chunk number: 885 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4482 - acc: 0.8359 - val_loss: 0.4215 - val_acc: 0.8359\n",
      "chunk number: 886 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3989 - acc: 0.8482 - val_loss: 0.3440 - val_acc: 0.8594\n",
      "chunk number: 887 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4222 - acc: 0.8504 - val_loss: 0.5131 - val_acc: 0.8047\n",
      "chunk number: 888 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4104 - acc: 0.8438 - val_loss: 0.3969 - val_acc: 0.8047\n",
      "chunk number: 889 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3660 - acc: 0.8605 - val_loss: 0.4075 - val_acc: 0.8750\n",
      "chunk number: 890 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3731 - acc: 0.8527 - val_loss: 0.3955 - val_acc: 0.8359\n",
      "chunk number: 891 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3847 - acc: 0.8538 - val_loss: 0.5022 - val_acc: 0.8594\n",
      "chunk number: 892 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3943 - acc: 0.8549 - val_loss: 0.3426 - val_acc: 0.8438\n",
      "chunk number: 893 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4119 - acc: 0.8348 - val_loss: 0.5999 - val_acc: 0.8047\n",
      "chunk number: 894 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3868 - acc: 0.8627 - val_loss: 0.4642 - val_acc: 0.8203\n",
      "chunk number: 895 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3602 - acc: 0.8560 - val_loss: 0.3937 - val_acc: 0.8516\n",
      "chunk number: 896 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4144 - acc: 0.8449 - val_loss: 0.4178 - val_acc: 0.8438\n",
      "chunk number: 897 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3808 - acc: 0.8449 - val_loss: 0.3649 - val_acc: 0.8672\n",
      "chunk number: 898 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4015 - acc: 0.8449 - val_loss: 0.4174 - val_acc: 0.8516\n",
      "chunk number: 899 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4099 - acc: 0.8382 - val_loss: 0.4596 - val_acc: 0.8438\n",
      "chunk number: 900 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4130 - acc: 0.8527 - val_loss: 0.4062 - val_acc: 0.8047\n",
      "chunk number: 901 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3897 - acc: 0.8549 - val_loss: 0.3942 - val_acc: 0.8281\n",
      "chunk number: 902 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4101 - acc: 0.8393 - val_loss: 0.5435 - val_acc: 0.7969\n",
      "chunk number: 903 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3829 - acc: 0.8571 - val_loss: 0.3598 - val_acc: 0.8516\n",
      "chunk number: 904 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3580 - acc: 0.8571 - val_loss: 0.3952 - val_acc: 0.8359\n",
      "chunk number: 905 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4209 - acc: 0.8426 - val_loss: 0.4823 - val_acc: 0.8359\n",
      "chunk number: 906 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3431 - acc: 0.8571 - val_loss: 0.4300 - val_acc: 0.8125\n",
      "chunk number: 907 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3787 - acc: 0.8594 - val_loss: 0.4018 - val_acc: 0.8672\n",
      "chunk number: 908 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3724 - acc: 0.8627 - val_loss: 0.3426 - val_acc: 0.8750\n",
      "chunk number: 909 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3853 - acc: 0.8493 - val_loss: 0.3562 - val_acc: 0.8359\n",
      "chunk number: 910 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4106 - acc: 0.8482 - val_loss: 0.4075 - val_acc: 0.8516\n",
      "chunk number: 911 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4622 - acc: 0.8214 - val_loss: 0.3707 - val_acc: 0.8594\n",
      "chunk number: 912 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4393 - acc: 0.8281 - val_loss: 0.4614 - val_acc: 0.8281\n",
      "chunk number: 913 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3893 - acc: 0.8661 - val_loss: 0.5542 - val_acc: 0.7969\n",
      "chunk number: 914 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4543 - acc: 0.8281 - val_loss: 0.3528 - val_acc: 0.8984\n",
      "chunk number: 915 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4203 - acc: 0.8438 - val_loss: 0.4282 - val_acc: 0.8359\n",
      "chunk number: 916 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3851 - acc: 0.8404 - val_loss: 0.5721 - val_acc: 0.7812\n",
      "chunk number: 917 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4045 - acc: 0.8471 - val_loss: 0.4351 - val_acc: 0.8281\n",
      "chunk number: 918 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3745 - acc: 0.8493 - val_loss: 0.4846 - val_acc: 0.8047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 919 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3834 - acc: 0.8627 - val_loss: 0.4620 - val_acc: 0.7891\n",
      "chunk number: 920 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4100 - acc: 0.8359 - val_loss: 0.4500 - val_acc: 0.8516\n",
      "chunk number: 921 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3683 - acc: 0.8516 - val_loss: 0.4654 - val_acc: 0.8281\n",
      "chunk number: 922 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3800 - acc: 0.8471 - val_loss: 0.4604 - val_acc: 0.8125\n",
      "chunk number: 923 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3983 - acc: 0.8527 - val_loss: 0.4160 - val_acc: 0.8672\n",
      "chunk number: 924 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4076 - acc: 0.8460 - val_loss: 0.4701 - val_acc: 0.8359\n",
      "chunk number: 925 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3748 - acc: 0.8638 - val_loss: 0.3582 - val_acc: 0.8750\n",
      "chunk number: 926 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4116 - acc: 0.8259 - val_loss: 0.4214 - val_acc: 0.7656\n",
      "chunk number: 927 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3619 - acc: 0.8493 - val_loss: 0.3902 - val_acc: 0.8438\n",
      "chunk number: 928 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3472 - acc: 0.8739 - val_loss: 0.4403 - val_acc: 0.8359\n",
      "chunk number: 929 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4165 - acc: 0.8538 - val_loss: 0.4010 - val_acc: 0.8438\n",
      "chunk number: 930 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4103 - acc: 0.8549 - val_loss: 0.5489 - val_acc: 0.8125\n",
      "chunk number: 931 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4105 - acc: 0.8315 - val_loss: 0.4277 - val_acc: 0.8047\n",
      "chunk number: 932 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4152 - acc: 0.8449 - val_loss: 0.5136 - val_acc: 0.8125\n",
      "chunk number: 933 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4122 - acc: 0.8438 - val_loss: 0.3796 - val_acc: 0.8516\n",
      "chunk number: 934 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3894 - acc: 0.8326 - val_loss: 0.4920 - val_acc: 0.8281\n",
      "chunk number: 935 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3910 - acc: 0.8482 - val_loss: 0.5144 - val_acc: 0.8203\n",
      "chunk number: 936 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4030 - acc: 0.8516 - val_loss: 0.3977 - val_acc: 0.8125\n",
      "chunk number: 937 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4064 - acc: 0.8415 - val_loss: 0.3557 - val_acc: 0.8438\n",
      "chunk number: 938 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3869 - acc: 0.8616 - val_loss: 0.5336 - val_acc: 0.8516\n",
      "chunk number: 939 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4373 - acc: 0.8382 - val_loss: 0.4366 - val_acc: 0.8594\n",
      "chunk number: 940 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4426 - acc: 0.8326 - val_loss: 0.4173 - val_acc: 0.8125\n",
      "chunk number: 941 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3518 - acc: 0.8650 - val_loss: 0.3949 - val_acc: 0.8516\n",
      "chunk number: 942 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3788 - acc: 0.8583 - val_loss: 0.4371 - val_acc: 0.8516\n",
      "chunk number: 943 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3742 - acc: 0.8583 - val_loss: 0.2990 - val_acc: 0.8984\n",
      "chunk number: 944 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3541 - acc: 0.8705 - val_loss: 0.5261 - val_acc: 0.8203\n",
      "chunk number: 945 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3829 - acc: 0.8560 - val_loss: 0.3547 - val_acc: 0.8594\n",
      "chunk number: 946 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4130 - acc: 0.8371 - val_loss: 0.5330 - val_acc: 0.8047\n",
      "chunk number: 947 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3646 - acc: 0.8482 - val_loss: 0.3944 - val_acc: 0.9062\n",
      "chunk number: 948 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3851 - acc: 0.8460 - val_loss: 0.5764 - val_acc: 0.7891\n",
      "chunk number: 949 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3923 - acc: 0.8471 - val_loss: 0.4524 - val_acc: 0.8203\n",
      "chunk number: 950 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4047 - acc: 0.8326 - val_loss: 0.4466 - val_acc: 0.8594\n",
      "chunk number: 951 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4010 - acc: 0.8404 - val_loss: 0.5241 - val_acc: 0.8047\n",
      "chunk number: 952 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4110 - acc: 0.8393 - val_loss: 0.3289 - val_acc: 0.8750\n",
      "chunk number: 953 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4320 - acc: 0.8248 - val_loss: 0.5236 - val_acc: 0.7969\n",
      "chunk number: 954 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3986 - acc: 0.8337 - val_loss: 0.3841 - val_acc: 0.8359\n",
      "chunk number: 955 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3456 - acc: 0.8705 - val_loss: 0.4066 - val_acc: 0.8047\n",
      "chunk number: 956 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4091 - acc: 0.8371 - val_loss: 0.4612 - val_acc: 0.8047\n",
      "chunk number: 957 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3744 - acc: 0.8661 - val_loss: 0.4008 - val_acc: 0.8594\n",
      "chunk number: 958 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3869 - acc: 0.8627 - val_loss: 0.3136 - val_acc: 0.8828\n",
      "chunk number: 959 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3645 - acc: 0.8683 - val_loss: 0.4168 - val_acc: 0.8281\n",
      "chunk number: 960 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4293 - acc: 0.8449 - val_loss: 0.5294 - val_acc: 0.7578\n",
      "chunk number: 961 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3912 - acc: 0.8605 - val_loss: 0.3269 - val_acc: 0.8828\n",
      "chunk number: 962 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3843 - acc: 0.8493 - val_loss: 0.3498 - val_acc: 0.8828\n",
      "chunk number: 963 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4514 - acc: 0.8248 - val_loss: 0.4196 - val_acc: 0.8594\n",
      "chunk number: 964 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3565 - acc: 0.8616 - val_loss: 0.5054 - val_acc: 0.7969\n",
      "chunk number: 965 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4223 - acc: 0.8393 - val_loss: 0.3570 - val_acc: 0.8359\n",
      "chunk number: 966 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4106 - acc: 0.8426 - val_loss: 0.4562 - val_acc: 0.8281\n",
      "chunk number: 967 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3694 - acc: 0.8627 - val_loss: 0.4341 - val_acc: 0.8281\n",
      "chunk number: 968 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4095 - acc: 0.8460 - val_loss: 0.5764 - val_acc: 0.7500\n",
      "chunk number: 969 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4225 - acc: 0.8292 - val_loss: 0.4122 - val_acc: 0.8516\n",
      "chunk number: 970 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3836 - acc: 0.8616 - val_loss: 0.5085 - val_acc: 0.8203\n",
      "chunk number: 971 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3556 - acc: 0.8583 - val_loss: 0.4001 - val_acc: 0.8203\n",
      "chunk number: 972 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3938 - acc: 0.8560 - val_loss: 0.4138 - val_acc: 0.8203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 973 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3824 - acc: 0.8694 - val_loss: 0.5499 - val_acc: 0.8281\n",
      "chunk number: 974 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4101 - acc: 0.8449 - val_loss: 0.5472 - val_acc: 0.7812\n",
      "chunk number: 975 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3815 - acc: 0.8594 - val_loss: 0.4129 - val_acc: 0.8047\n",
      "chunk number: 976 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3522 - acc: 0.8583 - val_loss: 0.4480 - val_acc: 0.8281\n",
      "chunk number: 977 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3304 - acc: 0.8683 - val_loss: 0.4181 - val_acc: 0.7891\n",
      "chunk number: 978 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3699 - acc: 0.8560 - val_loss: 0.5257 - val_acc: 0.7891\n",
      "chunk number: 979 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3297 - acc: 0.8661 - val_loss: 0.3710 - val_acc: 0.8516\n",
      "chunk number: 980 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3991 - acc: 0.8359 - val_loss: 0.3429 - val_acc: 0.8906\n",
      "chunk number: 981 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3896 - acc: 0.8538 - val_loss: 0.3244 - val_acc: 0.8594\n",
      "chunk number: 982 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3954 - acc: 0.8516 - val_loss: 0.4237 - val_acc: 0.8125\n",
      "chunk number: 983 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3799 - acc: 0.8471 - val_loss: 0.4799 - val_acc: 0.8047\n",
      "chunk number: 984 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3865 - acc: 0.8560 - val_loss: 0.3598 - val_acc: 0.8125\n",
      "chunk number: 985 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4383 - acc: 0.8560 - val_loss: 0.4874 - val_acc: 0.7891\n",
      "chunk number: 986 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3778 - acc: 0.8616 - val_loss: 0.3633 - val_acc: 0.8516\n",
      "chunk number: 987 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4067 - acc: 0.8426 - val_loss: 0.4597 - val_acc: 0.8359\n",
      "chunk number: 988 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4132 - acc: 0.8337 - val_loss: 0.3072 - val_acc: 0.8828\n",
      "chunk number: 989 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3484 - acc: 0.8705 - val_loss: 0.3559 - val_acc: 0.8594\n",
      "chunk number: 990 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3451 - acc: 0.8538 - val_loss: 0.3436 - val_acc: 0.8672\n",
      "chunk number: 991 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3783 - acc: 0.8549 - val_loss: 0.5566 - val_acc: 0.8203\n",
      "chunk number: 992 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3858 - acc: 0.8583 - val_loss: 0.4177 - val_acc: 0.8125\n",
      "chunk number: 993 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3745 - acc: 0.8438 - val_loss: 0.6046 - val_acc: 0.8359\n",
      "chunk number: 994 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3840 - acc: 0.8705 - val_loss: 0.3949 - val_acc: 0.8203\n",
      "chunk number: 995 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3545 - acc: 0.8538 - val_loss: 0.3775 - val_acc: 0.8359\n",
      "chunk number: 996 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3740 - acc: 0.8527 - val_loss: 0.4029 - val_acc: 0.8438\n",
      "chunk number: 997 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3648 - acc: 0.8605 - val_loss: 0.4412 - val_acc: 0.7969\n",
      "chunk number: 998 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3916 - acc: 0.8549 - val_loss: 0.3910 - val_acc: 0.8594\n",
      "chunk number: 999 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3414 - acc: 0.8694 - val_loss: 0.3604 - val_acc: 0.8672\n",
      "chunk number: 1000 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4013 - acc: 0.8449 - val_loss: 0.3229 - val_acc: 0.8516\n",
      "chunk number: 1001 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3333 - acc: 0.8739 - val_loss: 0.3661 - val_acc: 0.8750\n",
      "chunk number: 1002 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4097 - acc: 0.8482 - val_loss: 0.6026 - val_acc: 0.7891\n",
      "chunk number: 1003 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4104 - acc: 0.8449 - val_loss: 0.3402 - val_acc: 0.8750\n",
      "chunk number: 1004 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3464 - acc: 0.8650 - val_loss: 0.3990 - val_acc: 0.8203\n",
      "chunk number: 1005 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4075 - acc: 0.8460 - val_loss: 0.4557 - val_acc: 0.8047\n",
      "chunk number: 1006 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3344 - acc: 0.8705 - val_loss: 0.4918 - val_acc: 0.8359\n",
      "chunk number: 1007 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3866 - acc: 0.8616 - val_loss: 0.4068 - val_acc: 0.8359\n",
      "chunk number: 1008 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3761 - acc: 0.8616 - val_loss: 0.4052 - val_acc: 0.8281\n",
      "chunk number: 1009 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3265 - acc: 0.8906 - val_loss: 0.3757 - val_acc: 0.8672\n",
      "chunk number: 1010 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3856 - acc: 0.8493 - val_loss: 0.4502 - val_acc: 0.8125\n",
      "chunk number: 1011 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4078 - acc: 0.8371 - val_loss: 0.3996 - val_acc: 0.8438\n",
      "chunk number: 1012 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3853 - acc: 0.8504 - val_loss: 0.4350 - val_acc: 0.8516\n",
      "chunk number: 1013 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3719 - acc: 0.8594 - val_loss: 0.6079 - val_acc: 0.8047\n",
      "chunk number: 1014 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3999 - acc: 0.8438 - val_loss: 0.3554 - val_acc: 0.8906\n",
      "chunk number: 1015 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4248 - acc: 0.8337 - val_loss: 0.3438 - val_acc: 0.8516\n",
      "chunk number: 1016 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3666 - acc: 0.8583 - val_loss: 0.6040 - val_acc: 0.7891\n",
      "chunk number: 1017 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4425 - acc: 0.8304 - val_loss: 0.3986 - val_acc: 0.8359\n",
      "chunk number: 1018 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4056 - acc: 0.8337 - val_loss: 0.4664 - val_acc: 0.8594\n",
      "chunk number: 1019 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3948 - acc: 0.8438 - val_loss: 0.4791 - val_acc: 0.8047\n",
      "chunk number: 1020 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3772 - acc: 0.8560 - val_loss: 0.4967 - val_acc: 0.8516\n",
      "chunk number: 1021 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3337 - acc: 0.8705 - val_loss: 0.3669 - val_acc: 0.8594\n",
      "chunk number: 1022 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3552 - acc: 0.8705 - val_loss: 0.4154 - val_acc: 0.8125\n",
      "chunk number: 1023 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4107 - acc: 0.8594 - val_loss: 0.3400 - val_acc: 0.8906\n",
      "chunk number: 1024 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3995 - acc: 0.8471 - val_loss: 0.4417 - val_acc: 0.8594\n",
      "chunk number: 1025 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3824 - acc: 0.8449 - val_loss: 0.3462 - val_acc: 0.8750\n",
      "chunk number: 1026 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4062 - acc: 0.8326 - val_loss: 0.4585 - val_acc: 0.8359\n",
      "chunk number: 1027 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3874 - acc: 0.8337 - val_loss: 0.3307 - val_acc: 0.8516\n",
      "chunk number: 1028 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3810 - acc: 0.8482 - val_loss: 0.5131 - val_acc: 0.8281\n",
      "chunk number: 1029 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4037 - acc: 0.8504 - val_loss: 0.4450 - val_acc: 0.8516\n",
      "chunk number: 1030 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3770 - acc: 0.8627 - val_loss: 0.5703 - val_acc: 0.7734\n",
      "chunk number: 1031 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3814 - acc: 0.8594 - val_loss: 0.4362 - val_acc: 0.8516\n",
      "chunk number: 1032 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3966 - acc: 0.8594 - val_loss: 0.4830 - val_acc: 0.8203\n",
      "chunk number: 1033 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3825 - acc: 0.8504 - val_loss: 0.3463 - val_acc: 0.8594\n",
      "chunk number: 1034 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3816 - acc: 0.8482 - val_loss: 0.5260 - val_acc: 0.8359\n",
      "chunk number: 1035 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3632 - acc: 0.8650 - val_loss: 0.4777 - val_acc: 0.8203\n",
      "chunk number: 1036 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3799 - acc: 0.8516 - val_loss: 0.3702 - val_acc: 0.8438\n",
      "chunk number: 1037 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4299 - acc: 0.8393 - val_loss: 0.3449 - val_acc: 0.8672\n",
      "chunk number: 1038 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3431 - acc: 0.8694 - val_loss: 0.4937 - val_acc: 0.8438\n",
      "chunk number: 1039 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4087 - acc: 0.8493 - val_loss: 0.3966 - val_acc: 0.8594\n",
      "chunk number: 1040 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4358 - acc: 0.8493 - val_loss: 0.4080 - val_acc: 0.8359\n",
      "chunk number: 1041 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3237 - acc: 0.8761 - val_loss: 0.3289 - val_acc: 0.8828\n",
      "chunk number: 1042 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4053 - acc: 0.8594 - val_loss: 0.5054 - val_acc: 0.7969\n",
      "chunk number: 1043 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3635 - acc: 0.8661 - val_loss: 0.3277 - val_acc: 0.8672\n",
      "chunk number: 1044 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3582 - acc: 0.8717 - val_loss: 0.4704 - val_acc: 0.8203\n",
      "chunk number: 1045 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3687 - acc: 0.8482 - val_loss: 0.4766 - val_acc: 0.8203\n",
      "chunk number: 1046 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4215 - acc: 0.8304 - val_loss: 0.4978 - val_acc: 0.8516\n",
      "chunk number: 1047 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3586 - acc: 0.8527 - val_loss: 0.4336 - val_acc: 0.8516\n",
      "chunk number: 1048 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3683 - acc: 0.8471 - val_loss: 0.6020 - val_acc: 0.7734\n",
      "chunk number: 1049 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3394 - acc: 0.8571 - val_loss: 0.4644 - val_acc: 0.8125\n",
      "chunk number: 1050 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4030 - acc: 0.8471 - val_loss: 0.4993 - val_acc: 0.8672\n",
      "chunk number: 1051 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3719 - acc: 0.8504 - val_loss: 0.4376 - val_acc: 0.8359\n",
      "chunk number: 1052 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3467 - acc: 0.8627 - val_loss: 0.2885 - val_acc: 0.8672\n",
      "chunk number: 1053 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3927 - acc: 0.8415 - val_loss: 0.5203 - val_acc: 0.8359\n",
      "chunk number: 1054 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3704 - acc: 0.8594 - val_loss: 0.2963 - val_acc: 0.8750\n",
      "chunk number: 1055 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3456 - acc: 0.8705 - val_loss: 0.3821 - val_acc: 0.8359\n",
      "chunk number: 1056 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3977 - acc: 0.8538 - val_loss: 0.5094 - val_acc: 0.8438\n",
      "chunk number: 1057 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3884 - acc: 0.8538 - val_loss: 0.3984 - val_acc: 0.8438\n",
      "chunk number: 1058 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3690 - acc: 0.8571 - val_loss: 0.3309 - val_acc: 0.8828\n",
      "chunk number: 1059 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3598 - acc: 0.8705 - val_loss: 0.3224 - val_acc: 0.8984\n",
      "chunk number: 1060 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4244 - acc: 0.8393 - val_loss: 0.4881 - val_acc: 0.8047\n",
      "chunk number: 1061 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3762 - acc: 0.8594 - val_loss: 0.2720 - val_acc: 0.9219\n",
      "chunk number: 1062 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3840 - acc: 0.8527 - val_loss: 0.2623 - val_acc: 0.9219\n",
      "chunk number: 1063 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4125 - acc: 0.8504 - val_loss: 0.4539 - val_acc: 0.8516\n",
      "chunk number: 1064 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3454 - acc: 0.8694 - val_loss: 0.4127 - val_acc: 0.8438\n",
      "chunk number: 1065 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3898 - acc: 0.8571 - val_loss: 0.3673 - val_acc: 0.8672\n",
      "chunk number: 1066 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3617 - acc: 0.8683 - val_loss: 0.3907 - val_acc: 0.8359\n",
      "chunk number: 1067 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3575 - acc: 0.8650 - val_loss: 0.4221 - val_acc: 0.8281\n",
      "chunk number: 1068 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3807 - acc: 0.8471 - val_loss: 0.5813 - val_acc: 0.7812\n",
      "chunk number: 1069 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3889 - acc: 0.8371 - val_loss: 0.4254 - val_acc: 0.8516\n",
      "chunk number: 1070 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3795 - acc: 0.8471 - val_loss: 0.5592 - val_acc: 0.7891\n",
      "chunk number: 1071 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3923 - acc: 0.8359 - val_loss: 0.4398 - val_acc: 0.7891\n",
      "chunk number: 1072 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3636 - acc: 0.8661 - val_loss: 0.5884 - val_acc: 0.7812\n",
      "chunk number: 1073 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3620 - acc: 0.8728 - val_loss: 0.5836 - val_acc: 0.7891\n",
      "chunk number: 1074 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4014 - acc: 0.8538 - val_loss: 0.5698 - val_acc: 0.7812\n",
      "chunk number: 1075 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3614 - acc: 0.8705 - val_loss: 0.4291 - val_acc: 0.8359\n",
      "chunk number: 1076 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3287 - acc: 0.8728 - val_loss: 0.4939 - val_acc: 0.7969\n",
      "chunk number: 1077 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3455 - acc: 0.8650 - val_loss: 0.3929 - val_acc: 0.8438\n",
      "chunk number: 1078 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3504 - acc: 0.8482 - val_loss: 0.7293 - val_acc: 0.7656\n",
      "chunk number: 1079 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3559 - acc: 0.8583 - val_loss: 0.3740 - val_acc: 0.8984\n",
      "chunk number: 1080 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3616 - acc: 0.8627 - val_loss: 0.3574 - val_acc: 0.8828\n",
      "chunk number: 1081 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3809 - acc: 0.8571 - val_loss: 0.3541 - val_acc: 0.8750\n",
      "chunk number: 1082 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3763 - acc: 0.8538 - val_loss: 0.3380 - val_acc: 0.8672\n",
      "chunk number: 1083 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3470 - acc: 0.8571 - val_loss: 0.4980 - val_acc: 0.8047\n",
      "chunk number: 1084 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3553 - acc: 0.8672 - val_loss: 0.3870 - val_acc: 0.8203\n",
      "chunk number: 1085 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3775 - acc: 0.8683 - val_loss: 0.4528 - val_acc: 0.8359\n",
      "chunk number: 1086 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3642 - acc: 0.8616 - val_loss: 0.4064 - val_acc: 0.8438\n",
      "chunk number: 1087 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4350 - acc: 0.8371 - val_loss: 0.4910 - val_acc: 0.8125\n",
      "chunk number: 1088 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3891 - acc: 0.8538 - val_loss: 0.3671 - val_acc: 0.8672\n",
      "chunk number: 1089 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3446 - acc: 0.8583 - val_loss: 0.3566 - val_acc: 0.8516\n",
      "chunk number: 1090 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3547 - acc: 0.8672 - val_loss: 0.3653 - val_acc: 0.8594\n",
      "chunk number: 1091 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3861 - acc: 0.8683 - val_loss: 0.5548 - val_acc: 0.8047\n",
      "chunk number: 1092 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3807 - acc: 0.8504 - val_loss: 0.3703 - val_acc: 0.8359\n",
      "chunk number: 1093 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3640 - acc: 0.8694 - val_loss: 0.5696 - val_acc: 0.8047\n",
      "chunk number: 1094 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3563 - acc: 0.8661 - val_loss: 0.3793 - val_acc: 0.8516\n",
      "chunk number: 1095 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3654 - acc: 0.8661 - val_loss: 0.3645 - val_acc: 0.8359\n",
      "chunk number: 1096 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4185 - acc: 0.8449 - val_loss: 0.4376 - val_acc: 0.8203\n",
      "chunk number: 1097 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3865 - acc: 0.8527 - val_loss: 0.3515 - val_acc: 0.8594\n",
      "chunk number: 1098 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4137 - acc: 0.8449 - val_loss: 0.4250 - val_acc: 0.8438\n",
      "chunk number: 1099 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3607 - acc: 0.8516 - val_loss: 0.4375 - val_acc: 0.8047\n",
      "chunk number: 1100 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3937 - acc: 0.8460 - val_loss: 0.2719 - val_acc: 0.8750\n",
      "chunk number: 1101 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3737 - acc: 0.8616 - val_loss: 0.3545 - val_acc: 0.8672\n",
      "chunk number: 1102 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4042 - acc: 0.8359 - val_loss: 0.6140 - val_acc: 0.7891\n",
      "chunk number: 1103 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4192 - acc: 0.8304 - val_loss: 0.3520 - val_acc: 0.8672\n",
      "chunk number: 1104 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3434 - acc: 0.8728 - val_loss: 0.3567 - val_acc: 0.8281\n",
      "chunk number: 1105 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3862 - acc: 0.8672 - val_loss: 0.4337 - val_acc: 0.8125\n",
      "chunk number: 1106 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3557 - acc: 0.8705 - val_loss: 0.3779 - val_acc: 0.8125\n",
      "chunk number: 1107 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3646 - acc: 0.8694 - val_loss: 0.4152 - val_acc: 0.8516\n",
      "chunk number: 1108 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3294 - acc: 0.8783 - val_loss: 0.3310 - val_acc: 0.8594\n",
      "chunk number: 1109 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3331 - acc: 0.8817 - val_loss: 0.3432 - val_acc: 0.8750\n",
      "chunk number: 1110 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3585 - acc: 0.8694 - val_loss: 0.3874 - val_acc: 0.8516\n",
      "chunk number: 1111 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3956 - acc: 0.8482 - val_loss: 0.4057 - val_acc: 0.8203\n",
      "chunk number: 1112 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3810 - acc: 0.8504 - val_loss: 0.4400 - val_acc: 0.8438\n",
      "chunk number: 1113 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3847 - acc: 0.8605 - val_loss: 0.5365 - val_acc: 0.7969\n",
      "chunk number: 1114 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4026 - acc: 0.8404 - val_loss: 0.3803 - val_acc: 0.8672\n",
      "chunk number: 1115 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3870 - acc: 0.8538 - val_loss: 0.3562 - val_acc: 0.8281\n",
      "chunk number: 1116 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3341 - acc: 0.8783 - val_loss: 0.5469 - val_acc: 0.8125\n",
      "chunk number: 1117 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3868 - acc: 0.8493 - val_loss: 0.4641 - val_acc: 0.7734\n",
      "chunk number: 1118 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3719 - acc: 0.8493 - val_loss: 0.5091 - val_acc: 0.8047\n",
      "chunk number: 1119 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3604 - acc: 0.8549 - val_loss: 0.4586 - val_acc: 0.7891\n",
      "chunk number: 1120 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3807 - acc: 0.8493 - val_loss: 0.4462 - val_acc: 0.8750\n",
      "chunk number: 1121 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3376 - acc: 0.8694 - val_loss: 0.3833 - val_acc: 0.8516\n",
      "chunk number: 1122 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3566 - acc: 0.8672 - val_loss: 0.4104 - val_acc: 0.8281\n",
      "chunk number: 1123 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3366 - acc: 0.8772 - val_loss: 0.3926 - val_acc: 0.8594\n",
      "chunk number: 1124 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3839 - acc: 0.8460 - val_loss: 0.4304 - val_acc: 0.8203\n",
      "chunk number: 1125 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3478 - acc: 0.8705 - val_loss: 0.3666 - val_acc: 0.8438\n",
      "chunk number: 1126 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3890 - acc: 0.8516 - val_loss: 0.4734 - val_acc: 0.8438\n",
      "chunk number: 1127 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3656 - acc: 0.8560 - val_loss: 0.3344 - val_acc: 0.8516\n",
      "chunk number: 1128 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4073 - acc: 0.8471 - val_loss: 0.5184 - val_acc: 0.8047\n",
      "chunk number: 1129 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3825 - acc: 0.8516 - val_loss: 0.4207 - val_acc: 0.8281\n",
      "chunk number: 1130 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3517 - acc: 0.8583 - val_loss: 0.5416 - val_acc: 0.7500\n",
      "chunk number: 1131 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3601 - acc: 0.8661 - val_loss: 0.4673 - val_acc: 0.8047\n",
      "chunk number: 1132 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4108 - acc: 0.8404 - val_loss: 0.5023 - val_acc: 0.8281\n",
      "chunk number: 1133 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4069 - acc: 0.8404 - val_loss: 0.3979 - val_acc: 0.8828\n",
      "chunk number: 1134 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3772 - acc: 0.8482 - val_loss: 0.5141 - val_acc: 0.7969\n",
      "chunk number: 1135 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3303 - acc: 0.8739 - val_loss: 0.4951 - val_acc: 0.7969\n",
      "chunk number: 1136 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3496 - acc: 0.8583 - val_loss: 0.3993 - val_acc: 0.8516\n",
      "chunk number: 1137 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3649 - acc: 0.8516 - val_loss: 0.3103 - val_acc: 0.8906\n",
      "chunk number: 1138 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3492 - acc: 0.8661 - val_loss: 0.4670 - val_acc: 0.8594\n",
      "chunk number: 1139 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4065 - acc: 0.8516 - val_loss: 0.4068 - val_acc: 0.8359\n",
      "chunk number: 1140 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4252 - acc: 0.8304 - val_loss: 0.3900 - val_acc: 0.8516\n",
      "chunk number: 1141 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3380 - acc: 0.8638 - val_loss: 0.3959 - val_acc: 0.8359\n",
      "chunk number: 1142 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3503 - acc: 0.8739 - val_loss: 0.4808 - val_acc: 0.8203\n",
      "chunk number: 1143 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3424 - acc: 0.8694 - val_loss: 0.3535 - val_acc: 0.8906\n",
      "chunk number: 1144 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3684 - acc: 0.8705 - val_loss: 0.3942 - val_acc: 0.8359\n",
      "chunk number: 1145 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3722 - acc: 0.8504 - val_loss: 0.4059 - val_acc: 0.8125\n",
      "chunk number: 1146 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3754 - acc: 0.8538 - val_loss: 0.5563 - val_acc: 0.8281\n",
      "chunk number: 1147 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3215 - acc: 0.8728 - val_loss: 0.4432 - val_acc: 0.8281\n",
      "chunk number: 1148 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3466 - acc: 0.8616 - val_loss: 0.6112 - val_acc: 0.8203\n",
      "chunk number: 1149 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3627 - acc: 0.8739 - val_loss: 0.4540 - val_acc: 0.7969\n",
      "chunk number: 1150 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3744 - acc: 0.8650 - val_loss: 0.4886 - val_acc: 0.8672\n",
      "chunk number: 1151 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3930 - acc: 0.8516 - val_loss: 0.4165 - val_acc: 0.8438\n",
      "chunk number: 1152 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3722 - acc: 0.8583 - val_loss: 0.3537 - val_acc: 0.8594\n",
      "chunk number: 1153 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4151 - acc: 0.8315 - val_loss: 0.5062 - val_acc: 0.8516\n",
      "chunk number: 1154 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4199 - acc: 0.8371 - val_loss: 0.3149 - val_acc: 0.8672\n",
      "chunk number: 1155 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3807 - acc: 0.8661 - val_loss: 0.3734 - val_acc: 0.8438\n",
      "chunk number: 1156 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3769 - acc: 0.8661 - val_loss: 0.5033 - val_acc: 0.7734\n",
      "chunk number: 1157 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3553 - acc: 0.8627 - val_loss: 0.4609 - val_acc: 0.8047\n",
      "chunk number: 1158 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3443 - acc: 0.8672 - val_loss: 0.2598 - val_acc: 0.9141\n",
      "chunk number: 1159 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3514 - acc: 0.8538 - val_loss: 0.4293 - val_acc: 0.8281\n",
      "chunk number: 1160 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3963 - acc: 0.8493 - val_loss: 0.4894 - val_acc: 0.8125\n",
      "chunk number: 1161 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3533 - acc: 0.8616 - val_loss: 0.3669 - val_acc: 0.8828\n",
      "chunk number: 1162 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3735 - acc: 0.8672 - val_loss: 0.3086 - val_acc: 0.8906\n",
      "chunk number: 1163 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3785 - acc: 0.8672 - val_loss: 0.4051 - val_acc: 0.8438\n",
      "chunk number: 1164 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3121 - acc: 0.8895 - val_loss: 0.4914 - val_acc: 0.8125\n",
      "chunk number: 1165 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3598 - acc: 0.8549 - val_loss: 0.3264 - val_acc: 0.8594\n",
      "chunk number: 1166 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3666 - acc: 0.8650 - val_loss: 0.4662 - val_acc: 0.8359\n",
      "chunk number: 1167 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3271 - acc: 0.8627 - val_loss: 0.4514 - val_acc: 0.8125\n",
      "chunk number: 1168 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3883 - acc: 0.8638 - val_loss: 0.6386 - val_acc: 0.7891\n",
      "chunk number: 1169 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3712 - acc: 0.8683 - val_loss: 0.3619 - val_acc: 0.8750\n",
      "chunk number: 1170 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3547 - acc: 0.8806 - val_loss: 0.5540 - val_acc: 0.8125\n",
      "chunk number: 1171 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3501 - acc: 0.8583 - val_loss: 0.3949 - val_acc: 0.8438\n",
      "chunk number: 1172 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3458 - acc: 0.8694 - val_loss: 0.4457 - val_acc: 0.8438\n",
      "chunk number: 1173 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3590 - acc: 0.8683 - val_loss: 0.5829 - val_acc: 0.7891\n",
      "chunk number: 1174 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4062 - acc: 0.8337 - val_loss: 0.5537 - val_acc: 0.8047\n",
      "chunk number: 1175 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3641 - acc: 0.8683 - val_loss: 0.4763 - val_acc: 0.8281\n",
      "chunk number: 1176 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3372 - acc: 0.8717 - val_loss: 0.4318 - val_acc: 0.8047\n",
      "chunk number: 1177 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3348 - acc: 0.8650 - val_loss: 0.3474 - val_acc: 0.8516\n",
      "chunk number: 1178 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3323 - acc: 0.8638 - val_loss: 0.5478 - val_acc: 0.8203\n",
      "chunk number: 1179 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3670 - acc: 0.8583 - val_loss: 0.3977 - val_acc: 0.8594\n",
      "chunk number: 1180 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3994 - acc: 0.8493 - val_loss: 0.4061 - val_acc: 0.8672\n",
      "chunk number: 1181 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4143 - acc: 0.8438 - val_loss: 0.3553 - val_acc: 0.8750\n",
      "chunk number: 1182 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3962 - acc: 0.8426 - val_loss: 0.4145 - val_acc: 0.7969\n",
      "chunk number: 1183 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3692 - acc: 0.8449 - val_loss: 0.4292 - val_acc: 0.8203\n",
      "chunk number: 1184 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3499 - acc: 0.8672 - val_loss: 0.3659 - val_acc: 0.8281\n",
      "chunk number: 1185 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3881 - acc: 0.8627 - val_loss: 0.4511 - val_acc: 0.8281\n",
      "chunk number: 1186 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3847 - acc: 0.8504 - val_loss: 0.3985 - val_acc: 0.8516\n",
      "chunk number: 1187 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3729 - acc: 0.8672 - val_loss: 0.4872 - val_acc: 0.8125\n",
      "chunk number: 1188 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3618 - acc: 0.8549 - val_loss: 0.3527 - val_acc: 0.8828\n",
      "chunk number: 1189 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3478 - acc: 0.8672 - val_loss: 0.3920 - val_acc: 0.8359\n",
      "chunk number: 1190 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3235 - acc: 0.8650 - val_loss: 0.3827 - val_acc: 0.8672\n",
      "chunk number: 1191 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3395 - acc: 0.8672 - val_loss: 0.5388 - val_acc: 0.8047\n",
      "chunk number: 1192 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3582 - acc: 0.8605 - val_loss: 0.3743 - val_acc: 0.8203\n",
      "chunk number: 1193 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4079 - acc: 0.8493 - val_loss: 0.6117 - val_acc: 0.7969\n",
      "chunk number: 1194 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3209 - acc: 0.8750 - val_loss: 0.4780 - val_acc: 0.8281\n",
      "chunk number: 1195 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3825 - acc: 0.8605 - val_loss: 0.3892 - val_acc: 0.8203\n",
      "chunk number: 1196 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3907 - acc: 0.8348 - val_loss: 0.4313 - val_acc: 0.7969\n",
      "chunk number: 1197 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3566 - acc: 0.8650 - val_loss: 0.4389 - val_acc: 0.8047\n",
      "chunk number: 1198 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3617 - acc: 0.8694 - val_loss: 0.3893 - val_acc: 0.8516\n",
      "chunk number: 1199 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3396 - acc: 0.8672 - val_loss: 0.4634 - val_acc: 0.8203\n",
      "chunk number: 1200 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4188 - acc: 0.8326 - val_loss: 0.3129 - val_acc: 0.8516\n",
      "chunk number: 1201 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3361 - acc: 0.8650 - val_loss: 0.3912 - val_acc: 0.8438\n",
      "chunk number: 1202 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3766 - acc: 0.8583 - val_loss: 0.5497 - val_acc: 0.8281\n",
      "chunk number: 1203 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3447 - acc: 0.8527 - val_loss: 0.3419 - val_acc: 0.8516\n",
      "chunk number: 1204 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3322 - acc: 0.8661 - val_loss: 0.3375 - val_acc: 0.8828\n",
      "chunk number: 1205 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3428 - acc: 0.8650 - val_loss: 0.4624 - val_acc: 0.7969\n",
      "chunk number: 1206 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3402 - acc: 0.8661 - val_loss: 0.4473 - val_acc: 0.8438\n",
      "chunk number: 1207 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3220 - acc: 0.8839 - val_loss: 0.3218 - val_acc: 0.8828\n",
      "chunk number: 1208 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3611 - acc: 0.8672 - val_loss: 0.4201 - val_acc: 0.8047\n",
      "chunk number: 1209 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2944 - acc: 0.8940 - val_loss: 0.3463 - val_acc: 0.8438\n",
      "chunk number: 1210 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3429 - acc: 0.8705 - val_loss: 0.3468 - val_acc: 0.8516\n",
      "chunk number: 1211 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4113 - acc: 0.8404 - val_loss: 0.3688 - val_acc: 0.8516\n",
      "chunk number: 1212 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3972 - acc: 0.8426 - val_loss: 0.4663 - val_acc: 0.8125\n",
      "chunk number: 1213 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3607 - acc: 0.8683 - val_loss: 0.4902 - val_acc: 0.8047\n",
      "chunk number: 1214 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3715 - acc: 0.8493 - val_loss: 0.2858 - val_acc: 0.8984\n",
      "chunk number: 1215 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3889 - acc: 0.8571 - val_loss: 0.3609 - val_acc: 0.8281\n",
      "chunk number: 1216 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3309 - acc: 0.8683 - val_loss: 0.5097 - val_acc: 0.7812\n",
      "chunk number: 1217 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3631 - acc: 0.8460 - val_loss: 0.4506 - val_acc: 0.8359\n",
      "chunk number: 1218 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3764 - acc: 0.8560 - val_loss: 0.4687 - val_acc: 0.8125\n",
      "chunk number: 1219 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3404 - acc: 0.8795 - val_loss: 0.4857 - val_acc: 0.7812\n",
      "chunk number: 1220 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3572 - acc: 0.8605 - val_loss: 0.4031 - val_acc: 0.8594\n",
      "chunk number: 1221 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3095 - acc: 0.8772 - val_loss: 0.3804 - val_acc: 0.8281\n",
      "chunk number: 1222 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3489 - acc: 0.8594 - val_loss: 0.3654 - val_acc: 0.8438\n",
      "chunk number: 1223 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4017 - acc: 0.8583 - val_loss: 0.4475 - val_acc: 0.8359\n",
      "chunk number: 1224 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3869 - acc: 0.8493 - val_loss: 0.3990 - val_acc: 0.8672\n",
      "chunk number: 1225 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3600 - acc: 0.8549 - val_loss: 0.4503 - val_acc: 0.8516\n",
      "chunk number: 1226 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4032 - acc: 0.8482 - val_loss: 0.4518 - val_acc: 0.8281\n",
      "chunk number: 1227 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3588 - acc: 0.8460 - val_loss: 0.3126 - val_acc: 0.8828\n",
      "chunk number: 1228 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3466 - acc: 0.8750 - val_loss: 0.4972 - val_acc: 0.8203\n",
      "chunk number: 1229 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3604 - acc: 0.8806 - val_loss: 0.4409 - val_acc: 0.8203\n",
      "chunk number: 1230 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3838 - acc: 0.8583 - val_loss: 0.6163 - val_acc: 0.7578\n",
      "chunk number: 1231 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3579 - acc: 0.8538 - val_loss: 0.4431 - val_acc: 0.8125\n",
      "chunk number: 1232 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3861 - acc: 0.8527 - val_loss: 0.4644 - val_acc: 0.8125\n",
      "chunk number: 1233 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3673 - acc: 0.8549 - val_loss: 0.3195 - val_acc: 0.8750\n",
      "chunk number: 1234 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3381 - acc: 0.8471 - val_loss: 0.4541 - val_acc: 0.8516\n",
      "chunk number: 1235 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3516 - acc: 0.8683 - val_loss: 0.6072 - val_acc: 0.7812\n",
      "chunk number: 1236 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3751 - acc: 0.8616 - val_loss: 0.3683 - val_acc: 0.8359\n",
      "chunk number: 1237 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3551 - acc: 0.8616 - val_loss: 0.2833 - val_acc: 0.8984\n",
      "chunk number: 1238 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3416 - acc: 0.8560 - val_loss: 0.5071 - val_acc: 0.8516\n",
      "chunk number: 1239 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3746 - acc: 0.8627 - val_loss: 0.4114 - val_acc: 0.8125\n",
      "chunk number: 1240 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3923 - acc: 0.8482 - val_loss: 0.4164 - val_acc: 0.8047\n",
      "chunk number: 1241 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3351 - acc: 0.8638 - val_loss: 0.3697 - val_acc: 0.8281\n",
      "chunk number: 1242 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3426 - acc: 0.8806 - val_loss: 0.4785 - val_acc: 0.8359\n",
      "chunk number: 1243 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3521 - acc: 0.8560 - val_loss: 0.4346 - val_acc: 0.8672\n",
      "chunk number: 1244 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3150 - acc: 0.8806 - val_loss: 0.5157 - val_acc: 0.8203\n",
      "chunk number: 1245 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3222 - acc: 0.8661 - val_loss: 0.3515 - val_acc: 0.8516\n",
      "chunk number: 1246 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3737 - acc: 0.8560 - val_loss: 0.5144 - val_acc: 0.8203\n",
      "chunk number: 1247 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3467 - acc: 0.8571 - val_loss: 0.4087 - val_acc: 0.8828\n",
      "chunk number: 1248 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3312 - acc: 0.8538 - val_loss: 0.5648 - val_acc: 0.8047\n",
      "chunk number: 1249 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3205 - acc: 0.8783 - val_loss: 0.3899 - val_acc: 0.8594\n",
      "chunk number: 1250 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3901 - acc: 0.8482 - val_loss: 0.4231 - val_acc: 0.8828\n",
      "chunk number: 1251 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3395 - acc: 0.8672 - val_loss: 0.4448 - val_acc: 0.8125\n",
      "chunk number: 1252 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3408 - acc: 0.8594 - val_loss: 0.2839 - val_acc: 0.8906\n",
      "chunk number: 1253 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3954 - acc: 0.8493 - val_loss: 0.5085 - val_acc: 0.7891\n",
      "chunk number: 1254 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3847 - acc: 0.8504 - val_loss: 0.3564 - val_acc: 0.8594\n",
      "chunk number: 1255 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3573 - acc: 0.8728 - val_loss: 0.3451 - val_acc: 0.8672\n",
      "chunk number: 1256 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3816 - acc: 0.8527 - val_loss: 0.4420 - val_acc: 0.8438\n",
      "chunk number: 1257 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3502 - acc: 0.8627 - val_loss: 0.4849 - val_acc: 0.7969\n",
      "chunk number: 1258 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3195 - acc: 0.8806 - val_loss: 0.2985 - val_acc: 0.8828\n",
      "chunk number: 1259 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3234 - acc: 0.8661 - val_loss: 0.3773 - val_acc: 0.8438\n",
      "chunk number: 1260 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4051 - acc: 0.8560 - val_loss: 0.3909 - val_acc: 0.8516\n",
      "chunk number: 1261 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3486 - acc: 0.8806 - val_loss: 0.3266 - val_acc: 0.8750\n",
      "chunk number: 1262 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3538 - acc: 0.8638 - val_loss: 0.3100 - val_acc: 0.8906\n",
      "chunk number: 1263 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3945 - acc: 0.8471 - val_loss: 0.4887 - val_acc: 0.8125\n",
      "chunk number: 1264 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2841 - acc: 0.8917 - val_loss: 0.4880 - val_acc: 0.7891\n",
      "chunk number: 1265 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3591 - acc: 0.8672 - val_loss: 0.3345 - val_acc: 0.8828\n",
      "chunk number: 1266 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3428 - acc: 0.8650 - val_loss: 0.4064 - val_acc: 0.8359\n",
      "chunk number: 1267 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2995 - acc: 0.8862 - val_loss: 0.3913 - val_acc: 0.8281\n",
      "chunk number: 1268 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3870 - acc: 0.8471 - val_loss: 0.5336 - val_acc: 0.8281\n",
      "chunk number: 1269 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3511 - acc: 0.8638 - val_loss: 0.3882 - val_acc: 0.8828\n",
      "chunk number: 1270 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3388 - acc: 0.8705 - val_loss: 0.4707 - val_acc: 0.8438\n",
      "chunk number: 1271 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3502 - acc: 0.8672 - val_loss: 0.5132 - val_acc: 0.7812\n",
      "chunk number: 1272 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3489 - acc: 0.8739 - val_loss: 0.5998 - val_acc: 0.7969\n",
      "chunk number: 1273 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3442 - acc: 0.8795 - val_loss: 0.6464 - val_acc: 0.7812\n",
      "chunk number: 1274 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3893 - acc: 0.8426 - val_loss: 0.5307 - val_acc: 0.8125\n",
      "chunk number: 1275 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3714 - acc: 0.8538 - val_loss: 0.5300 - val_acc: 0.8203\n",
      "chunk number: 1276 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3754 - acc: 0.8527 - val_loss: 0.4888 - val_acc: 0.8438\n",
      "chunk number: 1277 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3508 - acc: 0.8583 - val_loss: 0.4015 - val_acc: 0.8359\n",
      "chunk number: 1278 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3468 - acc: 0.8650 - val_loss: 0.5499 - val_acc: 0.8359\n",
      "chunk number: 1279 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3615 - acc: 0.8493 - val_loss: 0.3050 - val_acc: 0.8672\n",
      "chunk number: 1280 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3767 - acc: 0.8493 - val_loss: 0.3524 - val_acc: 0.8828\n",
      "chunk number: 1281 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3768 - acc: 0.8504 - val_loss: 0.4885 - val_acc: 0.8438\n",
      "chunk number: 1282 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3659 - acc: 0.8516 - val_loss: 0.4095 - val_acc: 0.8125\n",
      "chunk number: 1283 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4279 - acc: 0.8393 - val_loss: 0.4458 - val_acc: 0.7969\n",
      "chunk number: 1284 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3536 - acc: 0.8795 - val_loss: 0.3916 - val_acc: 0.8359\n",
      "chunk number: 1285 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3792 - acc: 0.8571 - val_loss: 0.3850 - val_acc: 0.8672\n",
      "chunk number: 1286 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3766 - acc: 0.8694 - val_loss: 0.3641 - val_acc: 0.8750\n",
      "chunk number: 1287 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3718 - acc: 0.8728 - val_loss: 0.4630 - val_acc: 0.8359\n",
      "chunk number: 1288 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3786 - acc: 0.8493 - val_loss: 0.3439 - val_acc: 0.8594\n",
      "chunk number: 1289 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3162 - acc: 0.8728 - val_loss: 0.3138 - val_acc: 0.8906\n",
      "chunk number: 1290 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3131 - acc: 0.8839 - val_loss: 0.3842 - val_acc: 0.8438\n",
      "chunk number: 1291 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3275 - acc: 0.8783 - val_loss: 0.5902 - val_acc: 0.8281\n",
      "chunk number: 1292 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3611 - acc: 0.8672 - val_loss: 0.3173 - val_acc: 0.8516\n",
      "chunk number: 1293 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3417 - acc: 0.8638 - val_loss: 0.6651 - val_acc: 0.8125\n",
      "chunk number: 1294 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3259 - acc: 0.8705 - val_loss: 0.3760 - val_acc: 0.8281\n",
      "chunk number: 1295 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3019 - acc: 0.8795 - val_loss: 0.3672 - val_acc: 0.8594\n",
      "chunk number: 1296 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3913 - acc: 0.8694 - val_loss: 0.4355 - val_acc: 0.8359\n",
      "chunk number: 1297 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3431 - acc: 0.8728 - val_loss: 0.3943 - val_acc: 0.8359\n",
      "chunk number: 1298 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3742 - acc: 0.8527 - val_loss: 0.5392 - val_acc: 0.8359\n",
      "chunk number: 1299 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3550 - acc: 0.8717 - val_loss: 0.4694 - val_acc: 0.7969\n",
      "chunk number: 1300 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4019 - acc: 0.8426 - val_loss: 0.2548 - val_acc: 0.8594\n",
      "chunk number: 1301 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3227 - acc: 0.8739 - val_loss: 0.3627 - val_acc: 0.8594\n",
      "chunk number: 1302 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3743 - acc: 0.8571 - val_loss: 0.5254 - val_acc: 0.8203\n",
      "chunk number: 1303 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3612 - acc: 0.8538 - val_loss: 0.3774 - val_acc: 0.8516\n",
      "chunk number: 1304 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3436 - acc: 0.8638 - val_loss: 0.3282 - val_acc: 0.8750\n",
      "chunk number: 1305 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3939 - acc: 0.8438 - val_loss: 0.4229 - val_acc: 0.8125\n",
      "chunk number: 1306 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3104 - acc: 0.8795 - val_loss: 0.4672 - val_acc: 0.8359\n",
      "chunk number: 1307 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3494 - acc: 0.8694 - val_loss: 0.3879 - val_acc: 0.8672\n",
      "chunk number: 1308 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3568 - acc: 0.8739 - val_loss: 0.3547 - val_acc: 0.8438\n",
      "chunk number: 1309 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3223 - acc: 0.8795 - val_loss: 0.3025 - val_acc: 0.8906\n",
      "chunk number: 1310 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3444 - acc: 0.8761 - val_loss: 0.4013 - val_acc: 0.8594\n",
      "chunk number: 1311 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3463 - acc: 0.8560 - val_loss: 0.4223 - val_acc: 0.8359\n",
      "chunk number: 1312 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3753 - acc: 0.8404 - val_loss: 0.4124 - val_acc: 0.8516\n",
      "chunk number: 1313 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3236 - acc: 0.8828 - val_loss: 0.4928 - val_acc: 0.8203\n",
      "chunk number: 1314 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3623 - acc: 0.8527 - val_loss: 0.3888 - val_acc: 0.8906\n",
      "chunk number: 1315 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4184 - acc: 0.8471 - val_loss: 0.4252 - val_acc: 0.8438\n",
      "chunk number: 1316 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3105 - acc: 0.8795 - val_loss: 0.5890 - val_acc: 0.8047\n",
      "chunk number: 1317 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3441 - acc: 0.8672 - val_loss: 0.4891 - val_acc: 0.8203\n",
      "chunk number: 1318 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3548 - acc: 0.8583 - val_loss: 0.4692 - val_acc: 0.8281\n",
      "chunk number: 1319 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3296 - acc: 0.8806 - val_loss: 0.4959 - val_acc: 0.7969\n",
      "chunk number: 1320 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3459 - acc: 0.8616 - val_loss: 0.3558 - val_acc: 0.8984\n",
      "chunk number: 1321 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2914 - acc: 0.8839 - val_loss: 0.3414 - val_acc: 0.8672\n",
      "chunk number: 1322 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3293 - acc: 0.8650 - val_loss: 0.4147 - val_acc: 0.7734\n",
      "chunk number: 1323 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3611 - acc: 0.8583 - val_loss: 0.3492 - val_acc: 0.8438\n",
      "chunk number: 1324 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3599 - acc: 0.8549 - val_loss: 0.4454 - val_acc: 0.8203\n",
      "chunk number: 1325 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3438 - acc: 0.8594 - val_loss: 0.4035 - val_acc: 0.8359\n",
      "chunk number: 1326 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3744 - acc: 0.8527 - val_loss: 0.4500 - val_acc: 0.8672\n",
      "chunk number: 1327 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3783 - acc: 0.8460 - val_loss: 0.2980 - val_acc: 0.8594\n",
      "chunk number: 1328 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3944 - acc: 0.8549 - val_loss: 0.5175 - val_acc: 0.8438\n",
      "chunk number: 1329 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4015 - acc: 0.8560 - val_loss: 0.4000 - val_acc: 0.8438\n",
      "chunk number: 1330 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3690 - acc: 0.8605 - val_loss: 0.4891 - val_acc: 0.7812\n",
      "chunk number: 1331 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3447 - acc: 0.8661 - val_loss: 0.4683 - val_acc: 0.8203\n",
      "chunk number: 1332 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3908 - acc: 0.8449 - val_loss: 0.5295 - val_acc: 0.8125\n",
      "chunk number: 1333 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3615 - acc: 0.8605 - val_loss: 0.3271 - val_acc: 0.8516\n",
      "chunk number: 1334 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3479 - acc: 0.8650 - val_loss: 0.5291 - val_acc: 0.8516\n",
      "chunk number: 1335 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3453 - acc: 0.8650 - val_loss: 0.4793 - val_acc: 0.8125\n",
      "chunk number: 1336 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3696 - acc: 0.8549 - val_loss: 0.4215 - val_acc: 0.8516\n",
      "chunk number: 1337 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3812 - acc: 0.8493 - val_loss: 0.2373 - val_acc: 0.8984\n",
      "chunk number: 1338 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3384 - acc: 0.8795 - val_loss: 0.5480 - val_acc: 0.8516\n",
      "chunk number: 1339 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3418 - acc: 0.8783 - val_loss: 0.4117 - val_acc: 0.8438\n",
      "chunk number: 1340 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4136 - acc: 0.8449 - val_loss: 0.3960 - val_acc: 0.8125\n",
      "chunk number: 1341 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2918 - acc: 0.8761 - val_loss: 0.3946 - val_acc: 0.8594\n",
      "chunk number: 1342 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3657 - acc: 0.8783 - val_loss: 0.4885 - val_acc: 0.8125\n",
      "chunk number: 1343 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3254 - acc: 0.8694 - val_loss: 0.3147 - val_acc: 0.8594\n",
      "chunk number: 1344 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3359 - acc: 0.8772 - val_loss: 0.6095 - val_acc: 0.8047\n",
      "chunk number: 1345 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3436 - acc: 0.8694 - val_loss: 0.4013 - val_acc: 0.8516\n",
      "chunk number: 1346 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3717 - acc: 0.8493 - val_loss: 0.4809 - val_acc: 0.8516\n",
      "chunk number: 1347 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3133 - acc: 0.8694 - val_loss: 0.3856 - val_acc: 0.8672\n",
      "chunk number: 1348 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3409 - acc: 0.8605 - val_loss: 0.5392 - val_acc: 0.7812\n",
      "chunk number: 1349 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3356 - acc: 0.8717 - val_loss: 0.4323 - val_acc: 0.8438\n",
      "chunk number: 1350 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3364 - acc: 0.8583 - val_loss: 0.5655 - val_acc: 0.8203\n",
      "chunk number: 1351 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3436 - acc: 0.8672 - val_loss: 0.4060 - val_acc: 0.8281\n",
      "chunk number: 1352 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3443 - acc: 0.8627 - val_loss: 0.2529 - val_acc: 0.8828\n",
      "chunk number: 1353 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3422 - acc: 0.8661 - val_loss: 0.4807 - val_acc: 0.8281\n",
      "chunk number: 1354 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3407 - acc: 0.8650 - val_loss: 0.3324 - val_acc: 0.8672\n",
      "chunk number: 1355 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3374 - acc: 0.8728 - val_loss: 0.3884 - val_acc: 0.8281\n",
      "chunk number: 1356 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3477 - acc: 0.8694 - val_loss: 0.4245 - val_acc: 0.8203\n",
      "chunk number: 1357 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3390 - acc: 0.8594 - val_loss: 0.3420 - val_acc: 0.8750\n",
      "chunk number: 1358 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3021 - acc: 0.8795 - val_loss: 0.2874 - val_acc: 0.8672\n",
      "chunk number: 1359 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3175 - acc: 0.8839 - val_loss: 0.4030 - val_acc: 0.8750\n",
      "chunk number: 1360 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4063 - acc: 0.8382 - val_loss: 0.4526 - val_acc: 0.8438\n",
      "chunk number: 1361 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3720 - acc: 0.8638 - val_loss: 0.2699 - val_acc: 0.9062\n",
      "chunk number: 1362 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3924 - acc: 0.8650 - val_loss: 0.2989 - val_acc: 0.8438\n",
      "chunk number: 1363 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3799 - acc: 0.8382 - val_loss: 0.4006 - val_acc: 0.8594\n",
      "chunk number: 1364 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3022 - acc: 0.8884 - val_loss: 0.5624 - val_acc: 0.7891\n",
      "chunk number: 1365 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3497 - acc: 0.8672 - val_loss: 0.2588 - val_acc: 0.8906\n",
      "chunk number: 1366 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3169 - acc: 0.8661 - val_loss: 0.4386 - val_acc: 0.7891\n",
      "chunk number: 1367 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3276 - acc: 0.8873 - val_loss: 0.4345 - val_acc: 0.8438\n",
      "chunk number: 1368 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4031 - acc: 0.8449 - val_loss: 0.6602 - val_acc: 0.7812\n",
      "chunk number: 1369 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3475 - acc: 0.8672 - val_loss: 0.3777 - val_acc: 0.8359\n",
      "chunk number: 1370 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3368 - acc: 0.8683 - val_loss: 0.5119 - val_acc: 0.8047\n",
      "chunk number: 1371 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3415 - acc: 0.8650 - val_loss: 0.4448 - val_acc: 0.8203\n",
      "chunk number: 1372 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3420 - acc: 0.8672 - val_loss: 0.4876 - val_acc: 0.8203\n",
      "chunk number: 1373 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3188 - acc: 0.8817 - val_loss: 0.5007 - val_acc: 0.7891\n",
      "chunk number: 1374 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3591 - acc: 0.8705 - val_loss: 0.5076 - val_acc: 0.7812\n",
      "chunk number: 1375 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3025 - acc: 0.8862 - val_loss: 0.5397 - val_acc: 0.7734\n",
      "chunk number: 1376 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3306 - acc: 0.8683 - val_loss: 0.4421 - val_acc: 0.8438\n",
      "chunk number: 1377 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3411 - acc: 0.8717 - val_loss: 0.4360 - val_acc: 0.8203\n",
      "chunk number: 1378 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3105 - acc: 0.8717 - val_loss: 0.4982 - val_acc: 0.7891\n",
      "chunk number: 1379 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3051 - acc: 0.8772 - val_loss: 0.3464 - val_acc: 0.8828\n",
      "chunk number: 1380 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3210 - acc: 0.8828 - val_loss: 0.3241 - val_acc: 0.9062\n",
      "chunk number: 1381 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3463 - acc: 0.8717 - val_loss: 0.4004 - val_acc: 0.8438\n",
      "chunk number: 1382 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3729 - acc: 0.8538 - val_loss: 0.3702 - val_acc: 0.8594\n",
      "chunk number: 1383 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3556 - acc: 0.8616 - val_loss: 0.4403 - val_acc: 0.8203\n",
      "chunk number: 1384 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3407 - acc: 0.8750 - val_loss: 0.3443 - val_acc: 0.8359\n",
      "chunk number: 1385 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4054 - acc: 0.8404 - val_loss: 0.4274 - val_acc: 0.8438\n",
      "chunk number: 1386 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3557 - acc: 0.8605 - val_loss: 0.3653 - val_acc: 0.8438\n",
      "chunk number: 1387 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3816 - acc: 0.8571 - val_loss: 0.5156 - val_acc: 0.7891\n",
      "chunk number: 1388 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3437 - acc: 0.8627 - val_loss: 0.4198 - val_acc: 0.8281\n",
      "chunk number: 1389 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3283 - acc: 0.8806 - val_loss: 0.3481 - val_acc: 0.8984\n",
      "chunk number: 1390 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2831 - acc: 0.8917 - val_loss: 0.3505 - val_acc: 0.8672\n",
      "chunk number: 1391 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3461 - acc: 0.8783 - val_loss: 0.5420 - val_acc: 0.8047\n",
      "chunk number: 1392 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3234 - acc: 0.8705 - val_loss: 0.4129 - val_acc: 0.8203\n",
      "chunk number: 1393 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3008 - acc: 0.8795 - val_loss: 0.6152 - val_acc: 0.8047\n",
      "chunk number: 1394 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3175 - acc: 0.8761 - val_loss: 0.3557 - val_acc: 0.8516\n",
      "chunk number: 1395 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3107 - acc: 0.8817 - val_loss: 0.3827 - val_acc: 0.8281\n",
      "chunk number: 1396 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3522 - acc: 0.8661 - val_loss: 0.4005 - val_acc: 0.8125\n",
      "chunk number: 1397 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3204 - acc: 0.8694 - val_loss: 0.3934 - val_acc: 0.8516\n",
      "chunk number: 1398 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3797 - acc: 0.8560 - val_loss: 0.4077 - val_acc: 0.8672\n",
      "chunk number: 1399 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3396 - acc: 0.8694 - val_loss: 0.4633 - val_acc: 0.8047\n",
      "chunk number: 1400 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3810 - acc: 0.8471 - val_loss: 0.2894 - val_acc: 0.8828\n",
      "chunk number: 1401 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3165 - acc: 0.8806 - val_loss: 0.3429 - val_acc: 0.8672\n",
      "chunk number: 1402 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3446 - acc: 0.8594 - val_loss: 0.5618 - val_acc: 0.7656\n",
      "chunk number: 1403 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3535 - acc: 0.8739 - val_loss: 0.3443 - val_acc: 0.8828\n",
      "chunk number: 1404 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3265 - acc: 0.8717 - val_loss: 0.2902 - val_acc: 0.8984\n",
      "chunk number: 1405 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3446 - acc: 0.8783 - val_loss: 0.4023 - val_acc: 0.8438\n",
      "chunk number: 1406 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3320 - acc: 0.8683 - val_loss: 0.4544 - val_acc: 0.8203\n",
      "chunk number: 1407 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3858 - acc: 0.8493 - val_loss: 0.3478 - val_acc: 0.8750\n",
      "chunk number: 1408 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3410 - acc: 0.8728 - val_loss: 0.3073 - val_acc: 0.8906\n",
      "chunk number: 1409 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3170 - acc: 0.8795 - val_loss: 0.3878 - val_acc: 0.8438\n",
      "chunk number: 1410 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3509 - acc: 0.8594 - val_loss: 0.4221 - val_acc: 0.8672\n",
      "chunk number: 1411 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3996 - acc: 0.8449 - val_loss: 0.3575 - val_acc: 0.8594\n",
      "chunk number: 1412 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3673 - acc: 0.8516 - val_loss: 0.4952 - val_acc: 0.8047\n",
      "chunk number: 1413 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3305 - acc: 0.8795 - val_loss: 0.4753 - val_acc: 0.7969\n",
      "chunk number: 1414 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3446 - acc: 0.8594 - val_loss: 0.4324 - val_acc: 0.8828\n",
      "chunk number: 1415 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3650 - acc: 0.8594 - val_loss: 0.3567 - val_acc: 0.8672\n",
      "chunk number: 1416 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2871 - acc: 0.8850 - val_loss: 0.6291 - val_acc: 0.7812\n",
      "chunk number: 1417 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3515 - acc: 0.8705 - val_loss: 0.4660 - val_acc: 0.8125\n",
      "chunk number: 1418 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3156 - acc: 0.8717 - val_loss: 0.5217 - val_acc: 0.8359\n",
      "chunk number: 1419 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3363 - acc: 0.8705 - val_loss: 0.4581 - val_acc: 0.8047\n",
      "chunk number: 1420 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3245 - acc: 0.8683 - val_loss: 0.4385 - val_acc: 0.8750\n",
      "chunk number: 1421 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3023 - acc: 0.8772 - val_loss: 0.4183 - val_acc: 0.8359\n",
      "chunk number: 1422 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3221 - acc: 0.8717 - val_loss: 0.4388 - val_acc: 0.8125\n",
      "chunk number: 1423 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3743 - acc: 0.8717 - val_loss: 0.4698 - val_acc: 0.8359\n",
      "chunk number: 1424 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3798 - acc: 0.8527 - val_loss: 0.4430 - val_acc: 0.8047\n",
      "chunk number: 1425 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3450 - acc: 0.8728 - val_loss: 0.4354 - val_acc: 0.8359\n",
      "chunk number: 1426 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3589 - acc: 0.8627 - val_loss: 0.5163 - val_acc: 0.8047\n",
      "chunk number: 1427 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3114 - acc: 0.8672 - val_loss: 0.3819 - val_acc: 0.8438\n",
      "chunk number: 1428 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3643 - acc: 0.8538 - val_loss: 0.5759 - val_acc: 0.8203\n",
      "chunk number: 1429 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3568 - acc: 0.8594 - val_loss: 0.4670 - val_acc: 0.8516\n",
      "chunk number: 1430 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3473 - acc: 0.8616 - val_loss: 0.5200 - val_acc: 0.7812\n",
      "chunk number: 1431 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3463 - acc: 0.8527 - val_loss: 0.4323 - val_acc: 0.7891\n",
      "chunk number: 1432 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3593 - acc: 0.8672 - val_loss: 0.4837 - val_acc: 0.8125\n",
      "chunk number: 1433 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3590 - acc: 0.8705 - val_loss: 0.4037 - val_acc: 0.8438\n",
      "chunk number: 1434 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3398 - acc: 0.8783 - val_loss: 0.4712 - val_acc: 0.8438\n",
      "chunk number: 1435 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3420 - acc: 0.8661 - val_loss: 0.4743 - val_acc: 0.8047\n",
      "chunk number: 1436 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3450 - acc: 0.8783 - val_loss: 0.4141 - val_acc: 0.8125\n",
      "chunk number: 1437 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3418 - acc: 0.8694 - val_loss: 0.2793 - val_acc: 0.8672\n",
      "chunk number: 1438 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3177 - acc: 0.8839 - val_loss: 0.4475 - val_acc: 0.8750\n",
      "chunk number: 1439 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3437 - acc: 0.8839 - val_loss: 0.3962 - val_acc: 0.8203\n",
      "chunk number: 1440 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3592 - acc: 0.8594 - val_loss: 0.4321 - val_acc: 0.8125\n",
      "chunk number: 1441 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3107 - acc: 0.8772 - val_loss: 0.3341 - val_acc: 0.8750\n",
      "chunk number: 1442 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3251 - acc: 0.8705 - val_loss: 0.4877 - val_acc: 0.8281\n",
      "chunk number: 1443 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3237 - acc: 0.8817 - val_loss: 0.3152 - val_acc: 0.8906\n",
      "chunk number: 1444 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3438 - acc: 0.8728 - val_loss: 0.5528 - val_acc: 0.8125\n",
      "chunk number: 1445 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3280 - acc: 0.8594 - val_loss: 0.4037 - val_acc: 0.8359\n",
      "chunk number: 1446 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3619 - acc: 0.8605 - val_loss: 0.5358 - val_acc: 0.8125\n",
      "chunk number: 1447 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3427 - acc: 0.8683 - val_loss: 0.3436 - val_acc: 0.9062\n",
      "chunk number: 1448 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3112 - acc: 0.8839 - val_loss: 0.6599 - val_acc: 0.8203\n",
      "chunk number: 1449 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3261 - acc: 0.8672 - val_loss: 0.3371 - val_acc: 0.8203\n",
      "chunk number: 1450 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3376 - acc: 0.8750 - val_loss: 0.4625 - val_acc: 0.8516\n",
      "chunk number: 1451 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3390 - acc: 0.8650 - val_loss: 0.4705 - val_acc: 0.8594\n",
      "chunk number: 1452 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3216 - acc: 0.8795 - val_loss: 0.3052 - val_acc: 0.8906\n",
      "chunk number: 1453 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3599 - acc: 0.8583 - val_loss: 0.5060 - val_acc: 0.8203\n",
      "chunk number: 1454 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3370 - acc: 0.8717 - val_loss: 0.3575 - val_acc: 0.8438\n",
      "chunk number: 1455 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3144 - acc: 0.8750 - val_loss: 0.3916 - val_acc: 0.8125\n",
      "chunk number: 1456 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3279 - acc: 0.8650 - val_loss: 0.4740 - val_acc: 0.8047\n",
      "chunk number: 1457 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3261 - acc: 0.8650 - val_loss: 0.3973 - val_acc: 0.8516\n",
      "chunk number: 1458 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2898 - acc: 0.8917 - val_loss: 0.2583 - val_acc: 0.8906\n",
      "chunk number: 1459 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3502 - acc: 0.8694 - val_loss: 0.4273 - val_acc: 0.8438\n",
      "chunk number: 1460 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3530 - acc: 0.8594 - val_loss: 0.5267 - val_acc: 0.8359\n",
      "chunk number: 1461 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3444 - acc: 0.8817 - val_loss: 0.3374 - val_acc: 0.8906\n",
      "chunk number: 1462 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3364 - acc: 0.8728 - val_loss: 0.3194 - val_acc: 0.8828\n",
      "chunk number: 1463 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3690 - acc: 0.8650 - val_loss: 0.4513 - val_acc: 0.7969\n",
      "chunk number: 1464 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3010 - acc: 0.8906 - val_loss: 0.3617 - val_acc: 0.8672\n",
      "chunk number: 1465 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3509 - acc: 0.8750 - val_loss: 0.3582 - val_acc: 0.8828\n",
      "chunk number: 1466 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3446 - acc: 0.8616 - val_loss: 0.4147 - val_acc: 0.8516\n",
      "chunk number: 1467 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3339 - acc: 0.8717 - val_loss: 0.4225 - val_acc: 0.8203\n",
      "chunk number: 1468 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3599 - acc: 0.8627 - val_loss: 0.5172 - val_acc: 0.8047\n",
      "chunk number: 1469 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3565 - acc: 0.8560 - val_loss: 0.3251 - val_acc: 0.8906\n",
      "chunk number: 1470 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3264 - acc: 0.8806 - val_loss: 0.4342 - val_acc: 0.8594\n",
      "chunk number: 1471 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3197 - acc: 0.8705 - val_loss: 0.3935 - val_acc: 0.8359\n",
      "chunk number: 1472 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3370 - acc: 0.8672 - val_loss: 0.4505 - val_acc: 0.8125\n",
      "chunk number: 1473 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3351 - acc: 0.8873 - val_loss: 0.4536 - val_acc: 0.8359\n",
      "chunk number: 1474 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3483 - acc: 0.8728 - val_loss: 0.5763 - val_acc: 0.7969\n",
      "chunk number: 1475 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3155 - acc: 0.8884 - val_loss: 0.3961 - val_acc: 0.8047\n",
      "chunk number: 1476 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2981 - acc: 0.8917 - val_loss: 0.4004 - val_acc: 0.8359\n",
      "chunk number: 1477 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3142 - acc: 0.8839 - val_loss: 0.3366 - val_acc: 0.8750\n",
      "chunk number: 1478 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2868 - acc: 0.8873 - val_loss: 0.5555 - val_acc: 0.7891\n",
      "chunk number: 1479 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3193 - acc: 0.8717 - val_loss: 0.3829 - val_acc: 0.8438\n",
      "chunk number: 1480 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3418 - acc: 0.8728 - val_loss: 0.4013 - val_acc: 0.8672\n",
      "chunk number: 1481 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3833 - acc: 0.8471 - val_loss: 0.4324 - val_acc: 0.8750\n",
      "chunk number: 1482 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3623 - acc: 0.8616 - val_loss: 0.3770 - val_acc: 0.8281\n",
      "chunk number: 1483 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3118 - acc: 0.8783 - val_loss: 0.4149 - val_acc: 0.8516\n",
      "chunk number: 1484 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3578 - acc: 0.8661 - val_loss: 0.3537 - val_acc: 0.8359\n",
      "chunk number: 1485 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3388 - acc: 0.8683 - val_loss: 0.4435 - val_acc: 0.8359\n",
      "chunk number: 1486 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3682 - acc: 0.8761 - val_loss: 0.3518 - val_acc: 0.8438\n",
      "chunk number: 1487 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3548 - acc: 0.8717 - val_loss: 0.5016 - val_acc: 0.8125\n",
      "chunk number: 1488 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3524 - acc: 0.8650 - val_loss: 0.3652 - val_acc: 0.8828\n",
      "chunk number: 1489 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3280 - acc: 0.8772 - val_loss: 0.4092 - val_acc: 0.8672\n",
      "chunk number: 1490 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2933 - acc: 0.8783 - val_loss: 0.3268 - val_acc: 0.8672\n",
      "chunk number: 1491 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3656 - acc: 0.8728 - val_loss: 0.5480 - val_acc: 0.8438\n",
      "chunk number: 1492 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3405 - acc: 0.8694 - val_loss: 0.3627 - val_acc: 0.8281\n",
      "chunk number: 1493 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3270 - acc: 0.8594 - val_loss: 0.6775 - val_acc: 0.7578\n",
      "chunk number: 1494 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3604 - acc: 0.8605 - val_loss: 0.3929 - val_acc: 0.8203\n",
      "chunk number: 1495 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3323 - acc: 0.8761 - val_loss: 0.4461 - val_acc: 0.8516\n",
      "chunk number: 1496 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3675 - acc: 0.8627 - val_loss: 0.4013 - val_acc: 0.8125\n",
      "chunk number: 1497 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3015 - acc: 0.8884 - val_loss: 0.4494 - val_acc: 0.8359\n",
      "chunk number: 1498 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3355 - acc: 0.8717 - val_loss: 0.3890 - val_acc: 0.8828\n",
      "chunk number: 1499 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3012 - acc: 0.8761 - val_loss: 0.4253 - val_acc: 0.8125\n",
      "chunk number: 1500 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3380 - acc: 0.8627 - val_loss: 0.3054 - val_acc: 0.8516\n",
      "chunk number: 1501 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3083 - acc: 0.8895 - val_loss: 0.3548 - val_acc: 0.8672\n",
      "chunk number: 1502 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3473 - acc: 0.8616 - val_loss: 0.5187 - val_acc: 0.8203\n",
      "chunk number: 1503 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3357 - acc: 0.8750 - val_loss: 0.3865 - val_acc: 0.8594\n",
      "chunk number: 1504 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3247 - acc: 0.8739 - val_loss: 0.3411 - val_acc: 0.8984\n",
      "chunk number: 1505 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3393 - acc: 0.8728 - val_loss: 0.4119 - val_acc: 0.8516\n",
      "chunk number: 1506 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3025 - acc: 0.8862 - val_loss: 0.4491 - val_acc: 0.8594\n",
      "chunk number: 1507 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3454 - acc: 0.8728 - val_loss: 0.3208 - val_acc: 0.8828\n",
      "chunk number: 1508 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3378 - acc: 0.8638 - val_loss: 0.3340 - val_acc: 0.8438\n",
      "chunk number: 1509 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3265 - acc: 0.8638 - val_loss: 0.3682 - val_acc: 0.8359\n",
      "chunk number: 1510 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3585 - acc: 0.8627 - val_loss: 0.3979 - val_acc: 0.8203\n",
      "chunk number: 1511 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3688 - acc: 0.8560 - val_loss: 0.3931 - val_acc: 0.8672\n",
      "chunk number: 1512 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3662 - acc: 0.8605 - val_loss: 0.4812 - val_acc: 0.8359\n",
      "chunk number: 1513 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3214 - acc: 0.8705 - val_loss: 0.5040 - val_acc: 0.8281\n",
      "chunk number: 1514 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3575 - acc: 0.8638 - val_loss: 0.3021 - val_acc: 0.8984\n",
      "chunk number: 1515 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3575 - acc: 0.8739 - val_loss: 0.4325 - val_acc: 0.8438\n",
      "chunk number: 1516 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2967 - acc: 0.8839 - val_loss: 0.5983 - val_acc: 0.7969\n",
      "chunk number: 1517 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3609 - acc: 0.8616 - val_loss: 0.4458 - val_acc: 0.8438\n",
      "chunk number: 1518 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3307 - acc: 0.8739 - val_loss: 0.4425 - val_acc: 0.8125\n",
      "chunk number: 1519 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3492 - acc: 0.8806 - val_loss: 0.4931 - val_acc: 0.7734\n",
      "chunk number: 1520 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3294 - acc: 0.8672 - val_loss: 0.4398 - val_acc: 0.8594\n",
      "chunk number: 1521 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2995 - acc: 0.8772 - val_loss: 0.4106 - val_acc: 0.8594\n",
      "chunk number: 1522 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3199 - acc: 0.8783 - val_loss: 0.4281 - val_acc: 0.8125\n",
      "chunk number: 1523 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3243 - acc: 0.8750 - val_loss: 0.4442 - val_acc: 0.8594\n",
      "chunk number: 1524 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3580 - acc: 0.8616 - val_loss: 0.4371 - val_acc: 0.7969\n",
      "chunk number: 1525 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3228 - acc: 0.8694 - val_loss: 0.4050 - val_acc: 0.8750\n",
      "chunk number: 1526 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3506 - acc: 0.8739 - val_loss: 0.4714 - val_acc: 0.8594\n",
      "chunk number: 1527 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3189 - acc: 0.8761 - val_loss: 0.3394 - val_acc: 0.8516\n",
      "chunk number: 1528 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3423 - acc: 0.8728 - val_loss: 0.5345 - val_acc: 0.8203\n",
      "chunk number: 1529 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3355 - acc: 0.8672 - val_loss: 0.4731 - val_acc: 0.8359\n",
      "chunk number: 1530 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3393 - acc: 0.8560 - val_loss: 0.6415 - val_acc: 0.7891\n",
      "chunk number: 1531 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3023 - acc: 0.8795 - val_loss: 0.4860 - val_acc: 0.8203\n",
      "chunk number: 1532 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3344 - acc: 0.8694 - val_loss: 0.4695 - val_acc: 0.8203\n",
      "chunk number: 1533 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3822 - acc: 0.8359 - val_loss: 0.3976 - val_acc: 0.8359\n",
      "chunk number: 1534 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3243 - acc: 0.8728 - val_loss: 0.5339 - val_acc: 0.8203\n",
      "chunk number: 1535 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3270 - acc: 0.8672 - val_loss: 0.4788 - val_acc: 0.8281\n",
      "chunk number: 1536 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3390 - acc: 0.8661 - val_loss: 0.3711 - val_acc: 0.8594\n",
      "chunk number: 1537 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3642 - acc: 0.8504 - val_loss: 0.2911 - val_acc: 0.9219\n",
      "chunk number: 1538 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2964 - acc: 0.8940 - val_loss: 0.5609 - val_acc: 0.8438\n",
      "chunk number: 1539 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3292 - acc: 0.8739 - val_loss: 0.3706 - val_acc: 0.8672\n",
      "chunk number: 1540 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3921 - acc: 0.8460 - val_loss: 0.3872 - val_acc: 0.8125\n",
      "chunk number: 1541 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3267 - acc: 0.8795 - val_loss: 0.3635 - val_acc: 0.8516\n",
      "chunk number: 1542 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2921 - acc: 0.8940 - val_loss: 0.5335 - val_acc: 0.8359\n",
      "chunk number: 1543 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3194 - acc: 0.8661 - val_loss: 0.3772 - val_acc: 0.8750\n",
      "chunk number: 1544 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2761 - acc: 0.8984 - val_loss: 0.5086 - val_acc: 0.8438\n",
      "chunk number: 1545 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3306 - acc: 0.8672 - val_loss: 0.2808 - val_acc: 0.8828\n",
      "chunk number: 1546 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3375 - acc: 0.8761 - val_loss: 0.4968 - val_acc: 0.8672\n",
      "chunk number: 1547 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3046 - acc: 0.8772 - val_loss: 0.3918 - val_acc: 0.8672\n",
      "chunk number: 1548 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3360 - acc: 0.8616 - val_loss: 0.5996 - val_acc: 0.8047\n",
      "chunk number: 1549 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3155 - acc: 0.8739 - val_loss: 0.4665 - val_acc: 0.8125\n",
      "chunk number: 1550 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3237 - acc: 0.8694 - val_loss: 0.5855 - val_acc: 0.8359\n",
      "chunk number: 1551 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3399 - acc: 0.8672 - val_loss: 0.4538 - val_acc: 0.8438\n",
      "chunk number: 1552 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3210 - acc: 0.8806 - val_loss: 0.3132 - val_acc: 0.8750\n",
      "chunk number: 1553 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3335 - acc: 0.8638 - val_loss: 0.5005 - val_acc: 0.8203\n",
      "chunk number: 1554 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3322 - acc: 0.8761 - val_loss: 0.3037 - val_acc: 0.8672\n",
      "chunk number: 1555 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3212 - acc: 0.8739 - val_loss: 0.3936 - val_acc: 0.8281\n",
      "chunk number: 1556 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3443 - acc: 0.8717 - val_loss: 0.5301 - val_acc: 0.8203\n",
      "chunk number: 1557 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3175 - acc: 0.8806 - val_loss: 0.4006 - val_acc: 0.8438\n",
      "chunk number: 1558 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2893 - acc: 0.8895 - val_loss: 0.3042 - val_acc: 0.8750\n",
      "chunk number: 1559 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3102 - acc: 0.8862 - val_loss: 0.3758 - val_acc: 0.8516\n",
      "chunk number: 1560 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3704 - acc: 0.8627 - val_loss: 0.4531 - val_acc: 0.8594\n",
      "chunk number: 1561 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3583 - acc: 0.8705 - val_loss: 0.2824 - val_acc: 0.9141\n",
      "chunk number: 1562 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3584 - acc: 0.8739 - val_loss: 0.2902 - val_acc: 0.8750\n",
      "chunk number: 1563 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3699 - acc: 0.8426 - val_loss: 0.5108 - val_acc: 0.7969\n",
      "chunk number: 1564 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3135 - acc: 0.8873 - val_loss: 0.4622 - val_acc: 0.8281\n",
      "chunk number: 1565 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3401 - acc: 0.8661 - val_loss: 0.2744 - val_acc: 0.9141\n",
      "chunk number: 1566 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3410 - acc: 0.8594 - val_loss: 0.3812 - val_acc: 0.8203\n",
      "chunk number: 1567 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3045 - acc: 0.8917 - val_loss: 0.3670 - val_acc: 0.8203\n",
      "chunk number: 1568 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3063 - acc: 0.8828 - val_loss: 0.6553 - val_acc: 0.7656\n",
      "chunk number: 1569 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3202 - acc: 0.8705 - val_loss: 0.3808 - val_acc: 0.8594\n",
      "chunk number: 1570 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3079 - acc: 0.8906 - val_loss: 0.5320 - val_acc: 0.8125\n",
      "chunk number: 1571 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3024 - acc: 0.8828 - val_loss: 0.4661 - val_acc: 0.8359\n",
      "chunk number: 1572 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3420 - acc: 0.8672 - val_loss: 0.4315 - val_acc: 0.8203\n",
      "chunk number: 1573 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3278 - acc: 0.8806 - val_loss: 0.5869 - val_acc: 0.7891\n",
      "chunk number: 1574 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3279 - acc: 0.8750 - val_loss: 0.6112 - val_acc: 0.7734\n",
      "chunk number: 1575 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3332 - acc: 0.8839 - val_loss: 0.4709 - val_acc: 0.8125\n",
      "chunk number: 1576 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3155 - acc: 0.8795 - val_loss: 0.3870 - val_acc: 0.8281\n",
      "chunk number: 1577 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3124 - acc: 0.8761 - val_loss: 0.4238 - val_acc: 0.8359\n",
      "chunk number: 1578 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3144 - acc: 0.8772 - val_loss: 0.4350 - val_acc: 0.8281\n",
      "chunk number: 1579 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2954 - acc: 0.8739 - val_loss: 0.3969 - val_acc: 0.8594\n",
      "chunk number: 1580 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3123 - acc: 0.8772 - val_loss: 0.4957 - val_acc: 0.8125\n",
      "chunk number: 1581 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3427 - acc: 0.8761 - val_loss: 0.3590 - val_acc: 0.8750\n",
      "chunk number: 1582 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3398 - acc: 0.8728 - val_loss: 0.3195 - val_acc: 0.8672\n",
      "chunk number: 1583 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3404 - acc: 0.8594 - val_loss: 0.5416 - val_acc: 0.8047\n",
      "chunk number: 1584 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3367 - acc: 0.8627 - val_loss: 0.3627 - val_acc: 0.8281\n",
      "chunk number: 1585 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3539 - acc: 0.8661 - val_loss: 0.4025 - val_acc: 0.8672\n",
      "chunk number: 1586 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3463 - acc: 0.8650 - val_loss: 0.3227 - val_acc: 0.8672\n",
      "chunk number: 1587 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3914 - acc: 0.8605 - val_loss: 0.4765 - val_acc: 0.8281\n",
      "chunk number: 1588 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3448 - acc: 0.8717 - val_loss: 0.3370 - val_acc: 0.9141\n",
      "chunk number: 1589 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2926 - acc: 0.8917 - val_loss: 0.3832 - val_acc: 0.8906\n",
      "chunk number: 1590 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2947 - acc: 0.8806 - val_loss: 0.3912 - val_acc: 0.8438\n",
      "chunk number: 1591 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3061 - acc: 0.8962 - val_loss: 0.6133 - val_acc: 0.8359\n",
      "chunk number: 1592 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2989 - acc: 0.8873 - val_loss: 0.2789 - val_acc: 0.8828\n",
      "chunk number: 1593 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2696 - acc: 0.8817 - val_loss: 0.6517 - val_acc: 0.8125\n",
      "chunk number: 1594 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3588 - acc: 0.8650 - val_loss: 0.3780 - val_acc: 0.8281\n",
      "chunk number: 1595 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3254 - acc: 0.8717 - val_loss: 0.4521 - val_acc: 0.8125\n",
      "chunk number: 1596 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3299 - acc: 0.8694 - val_loss: 0.4863 - val_acc: 0.8203\n",
      "chunk number: 1597 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3184 - acc: 0.8817 - val_loss: 0.3868 - val_acc: 0.8516\n",
      "chunk number: 1598 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3309 - acc: 0.8683 - val_loss: 0.3825 - val_acc: 0.8672\n",
      "chunk number: 1599 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3073 - acc: 0.8850 - val_loss: 0.3753 - val_acc: 0.8438\n",
      "chunk number: 1600 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3604 - acc: 0.8460 - val_loss: 0.2966 - val_acc: 0.8828\n",
      "chunk number: 1601 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2986 - acc: 0.8984 - val_loss: 0.3740 - val_acc: 0.8359\n",
      "chunk number: 1602 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3126 - acc: 0.8772 - val_loss: 0.5373 - val_acc: 0.8047\n",
      "chunk number: 1603 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3244 - acc: 0.8672 - val_loss: 0.3627 - val_acc: 0.8750\n",
      "chunk number: 1604 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2903 - acc: 0.8917 - val_loss: 0.2810 - val_acc: 0.9219\n",
      "chunk number: 1605 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3326 - acc: 0.8806 - val_loss: 0.3216 - val_acc: 0.8516\n",
      "chunk number: 1606 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2367 - acc: 0.9062 - val_loss: 0.4283 - val_acc: 0.8125\n",
      "chunk number: 1607 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3259 - acc: 0.8828 - val_loss: 0.4766 - val_acc: 0.8125\n",
      "chunk number: 1608 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3223 - acc: 0.8795 - val_loss: 0.4322 - val_acc: 0.8281\n",
      "chunk number: 1609 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2960 - acc: 0.8828 - val_loss: 0.4568 - val_acc: 0.8281\n",
      "chunk number: 1610 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3484 - acc: 0.8672 - val_loss: 0.4319 - val_acc: 0.8359\n",
      "chunk number: 1611 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3882 - acc: 0.8504 - val_loss: 0.3813 - val_acc: 0.8516\n",
      "chunk number: 1612 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3291 - acc: 0.8761 - val_loss: 0.4684 - val_acc: 0.8438\n",
      "chunk number: 1613 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3330 - acc: 0.8739 - val_loss: 0.5078 - val_acc: 0.8125\n",
      "chunk number: 1614 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3381 - acc: 0.8683 - val_loss: 0.3705 - val_acc: 0.8828\n",
      "chunk number: 1615 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3569 - acc: 0.8638 - val_loss: 0.4675 - val_acc: 0.8281\n",
      "chunk number: 1616 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2905 - acc: 0.8940 - val_loss: 0.5612 - val_acc: 0.7812\n",
      "chunk number: 1617 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3886 - acc: 0.8482 - val_loss: 0.4878 - val_acc: 0.8438\n",
      "chunk number: 1618 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3322 - acc: 0.8672 - val_loss: 0.5078 - val_acc: 0.8047\n",
      "chunk number: 1619 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3724 - acc: 0.8571 - val_loss: 0.5600 - val_acc: 0.8047\n",
      "chunk number: 1620 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3307 - acc: 0.8839 - val_loss: 0.5243 - val_acc: 0.8594\n",
      "chunk number: 1621 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3154 - acc: 0.8728 - val_loss: 0.3824 - val_acc: 0.8594\n",
      "chunk number: 1622 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3340 - acc: 0.8650 - val_loss: 0.3916 - val_acc: 0.8438\n",
      "chunk number: 1623 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3448 - acc: 0.8616 - val_loss: 0.3836 - val_acc: 0.8672\n",
      "chunk number: 1624 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3688 - acc: 0.8516 - val_loss: 0.4157 - val_acc: 0.8281\n",
      "chunk number: 1625 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3138 - acc: 0.8806 - val_loss: 0.5038 - val_acc: 0.8516\n",
      "chunk number: 1626 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3067 - acc: 0.8828 - val_loss: 0.4489 - val_acc: 0.8516\n",
      "chunk number: 1627 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3314 - acc: 0.8717 - val_loss: 0.3526 - val_acc: 0.8750\n",
      "chunk number: 1628 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3094 - acc: 0.8739 - val_loss: 0.5574 - val_acc: 0.7969\n",
      "chunk number: 1629 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3565 - acc: 0.8795 - val_loss: 0.4176 - val_acc: 0.8438\n",
      "chunk number: 1630 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3392 - acc: 0.8739 - val_loss: 0.6243 - val_acc: 0.7500\n",
      "chunk number: 1631 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3321 - acc: 0.8761 - val_loss: 0.4454 - val_acc: 0.8438\n",
      "chunk number: 1632 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3468 - acc: 0.8839 - val_loss: 0.4380 - val_acc: 0.8125\n",
      "chunk number: 1633 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3196 - acc: 0.8806 - val_loss: 0.3463 - val_acc: 0.8594\n",
      "chunk number: 1634 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3134 - acc: 0.8817 - val_loss: 0.6008 - val_acc: 0.7891\n",
      "chunk number: 1635 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3383 - acc: 0.8739 - val_loss: 0.5244 - val_acc: 0.7969\n",
      "chunk number: 1636 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3454 - acc: 0.8750 - val_loss: 0.3887 - val_acc: 0.8125\n",
      "chunk number: 1637 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3475 - acc: 0.8683 - val_loss: 0.3000 - val_acc: 0.8438\n",
      "chunk number: 1638 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3241 - acc: 0.8828 - val_loss: 0.5051 - val_acc: 0.8359\n",
      "chunk number: 1639 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3836 - acc: 0.8605 - val_loss: 0.3526 - val_acc: 0.8672\n",
      "chunk number: 1640 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3501 - acc: 0.8627 - val_loss: 0.4124 - val_acc: 0.8125\n",
      "chunk number: 1641 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2936 - acc: 0.8929 - val_loss: 0.4446 - val_acc: 0.8281\n",
      "chunk number: 1642 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3115 - acc: 0.8806 - val_loss: 0.5695 - val_acc: 0.7656\n",
      "chunk number: 1643 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3497 - acc: 0.8672 - val_loss: 0.4470 - val_acc: 0.8125\n",
      "chunk number: 1644 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3332 - acc: 0.8739 - val_loss: 0.5072 - val_acc: 0.8359\n",
      "chunk number: 1645 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3241 - acc: 0.8650 - val_loss: 0.4034 - val_acc: 0.8125\n",
      "chunk number: 1646 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3347 - acc: 0.8795 - val_loss: 0.4612 - val_acc: 0.8594\n",
      "chunk number: 1647 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3184 - acc: 0.8739 - val_loss: 0.3566 - val_acc: 0.8750\n",
      "chunk number: 1648 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2835 - acc: 0.8783 - val_loss: 0.6171 - val_acc: 0.8203\n",
      "chunk number: 1649 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2995 - acc: 0.8839 - val_loss: 0.3969 - val_acc: 0.8281\n",
      "chunk number: 1650 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3155 - acc: 0.8594 - val_loss: 0.5347 - val_acc: 0.8047\n",
      "chunk number: 1651 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2995 - acc: 0.8850 - val_loss: 0.4246 - val_acc: 0.8594\n",
      "chunk number: 1652 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3663 - acc: 0.8627 - val_loss: 0.2956 - val_acc: 0.8828\n",
      "chunk number: 1653 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3401 - acc: 0.8594 - val_loss: 0.4174 - val_acc: 0.8672\n",
      "chunk number: 1654 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3052 - acc: 0.8929 - val_loss: 0.3923 - val_acc: 0.8125\n",
      "chunk number: 1655 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3039 - acc: 0.8906 - val_loss: 0.3862 - val_acc: 0.8359\n",
      "chunk number: 1656 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3226 - acc: 0.8772 - val_loss: 0.4638 - val_acc: 0.7969\n",
      "chunk number: 1657 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3008 - acc: 0.8806 - val_loss: 0.4223 - val_acc: 0.8516\n",
      "chunk number: 1658 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2988 - acc: 0.8884 - val_loss: 0.3761 - val_acc: 0.8828\n",
      "chunk number: 1659 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3202 - acc: 0.8895 - val_loss: 0.3406 - val_acc: 0.8750\n",
      "chunk number: 1660 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3457 - acc: 0.8672 - val_loss: 0.3774 - val_acc: 0.8516\n",
      "chunk number: 1661 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3056 - acc: 0.8795 - val_loss: 0.3032 - val_acc: 0.8984\n",
      "chunk number: 1662 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3296 - acc: 0.8761 - val_loss: 0.3148 - val_acc: 0.8906\n",
      "chunk number: 1663 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3427 - acc: 0.8694 - val_loss: 0.4105 - val_acc: 0.8281\n",
      "chunk number: 1664 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2857 - acc: 0.8873 - val_loss: 0.6525 - val_acc: 0.7656\n",
      "chunk number: 1665 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3267 - acc: 0.8817 - val_loss: 0.3124 - val_acc: 0.8984\n",
      "chunk number: 1666 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3195 - acc: 0.8739 - val_loss: 0.3825 - val_acc: 0.8438\n",
      "chunk number: 1667 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2911 - acc: 0.9029 - val_loss: 0.4057 - val_acc: 0.8125\n",
      "chunk number: 1668 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3357 - acc: 0.8650 - val_loss: 0.5681 - val_acc: 0.7656\n",
      "chunk number: 1669 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3290 - acc: 0.8605 - val_loss: 0.4004 - val_acc: 0.8906\n",
      "chunk number: 1670 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3143 - acc: 0.8761 - val_loss: 0.4571 - val_acc: 0.8438\n",
      "chunk number: 1671 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3273 - acc: 0.8672 - val_loss: 0.4601 - val_acc: 0.8359\n",
      "chunk number: 1672 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3194 - acc: 0.8772 - val_loss: 0.4867 - val_acc: 0.8359\n",
      "chunk number: 1673 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3150 - acc: 0.8627 - val_loss: 0.5054 - val_acc: 0.7969\n",
      "chunk number: 1674 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3462 - acc: 0.8750 - val_loss: 0.6159 - val_acc: 0.7812\n",
      "chunk number: 1675 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3108 - acc: 0.8806 - val_loss: 0.4343 - val_acc: 0.8438\n",
      "chunk number: 1676 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3356 - acc: 0.8638 - val_loss: 0.4266 - val_acc: 0.8203\n",
      "chunk number: 1677 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2923 - acc: 0.8962 - val_loss: 0.3847 - val_acc: 0.8281\n",
      "chunk number: 1678 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3247 - acc: 0.8717 - val_loss: 0.5940 - val_acc: 0.8281\n",
      "chunk number: 1679 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2976 - acc: 0.8750 - val_loss: 0.3566 - val_acc: 0.8750\n",
      "chunk number: 1680 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2761 - acc: 0.8839 - val_loss: 0.4676 - val_acc: 0.8438\n",
      "chunk number: 1681 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3467 - acc: 0.8761 - val_loss: 0.3315 - val_acc: 0.8828\n",
      "chunk number: 1682 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2923 - acc: 0.8839 - val_loss: 0.3970 - val_acc: 0.8438\n",
      "chunk number: 1683 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3230 - acc: 0.8739 - val_loss: 0.4496 - val_acc: 0.8281\n",
      "chunk number: 1684 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3185 - acc: 0.8672 - val_loss: 0.3597 - val_acc: 0.8438\n",
      "chunk number: 1685 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3573 - acc: 0.8761 - val_loss: 0.4356 - val_acc: 0.8516\n",
      "chunk number: 1686 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3584 - acc: 0.8616 - val_loss: 0.3440 - val_acc: 0.8516\n",
      "chunk number: 1687 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3746 - acc: 0.8739 - val_loss: 0.4987 - val_acc: 0.8203\n",
      "chunk number: 1688 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3402 - acc: 0.8571 - val_loss: 0.3219 - val_acc: 0.8906\n",
      "chunk number: 1689 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3039 - acc: 0.8705 - val_loss: 0.3562 - val_acc: 0.8203\n",
      "chunk number: 1690 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2713 - acc: 0.8996 - val_loss: 0.3549 - val_acc: 0.8594\n",
      "chunk number: 1691 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3145 - acc: 0.8884 - val_loss: 0.6150 - val_acc: 0.8359\n",
      "chunk number: 1692 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3016 - acc: 0.8772 - val_loss: 0.3430 - val_acc: 0.8672\n",
      "chunk number: 1693 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2843 - acc: 0.8839 - val_loss: 0.5374 - val_acc: 0.8281\n",
      "chunk number: 1694 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3020 - acc: 0.8817 - val_loss: 0.5092 - val_acc: 0.8359\n",
      "chunk number: 1695 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2728 - acc: 0.8973 - val_loss: 0.4226 - val_acc: 0.8594\n",
      "chunk number: 1696 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3354 - acc: 0.8583 - val_loss: 0.5046 - val_acc: 0.8281\n",
      "chunk number: 1697 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3021 - acc: 0.8795 - val_loss: 0.3365 - val_acc: 0.8750\n",
      "chunk number: 1698 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3219 - acc: 0.8772 - val_loss: 0.4491 - val_acc: 0.8359\n",
      "chunk number: 1699 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2831 - acc: 0.8862 - val_loss: 0.4388 - val_acc: 0.8047\n",
      "chunk number: 1700 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3669 - acc: 0.8605 - val_loss: 0.2774 - val_acc: 0.9219\n",
      "chunk number: 1701 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3105 - acc: 0.8728 - val_loss: 0.4468 - val_acc: 0.8203\n",
      "chunk number: 1702 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3436 - acc: 0.8583 - val_loss: 0.6118 - val_acc: 0.7578\n",
      "chunk number: 1703 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3155 - acc: 0.8873 - val_loss: 0.3479 - val_acc: 0.8984\n",
      "chunk number: 1704 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2824 - acc: 0.8850 - val_loss: 0.2806 - val_acc: 0.9141\n",
      "chunk number: 1705 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3172 - acc: 0.8761 - val_loss: 0.4579 - val_acc: 0.8359\n",
      "chunk number: 1706 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2823 - acc: 0.8862 - val_loss: 0.5271 - val_acc: 0.8281\n",
      "chunk number: 1707 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3645 - acc: 0.8672 - val_loss: 0.3611 - val_acc: 0.8828\n",
      "chunk number: 1708 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3269 - acc: 0.8728 - val_loss: 0.3560 - val_acc: 0.8359\n",
      "chunk number: 1709 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2875 - acc: 0.8940 - val_loss: 0.3731 - val_acc: 0.8516\n",
      "chunk number: 1710 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3128 - acc: 0.8962 - val_loss: 0.4905 - val_acc: 0.8438\n",
      "chunk number: 1711 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3461 - acc: 0.8538 - val_loss: 0.3211 - val_acc: 0.8828\n",
      "chunk number: 1712 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3417 - acc: 0.8650 - val_loss: 0.4685 - val_acc: 0.8281\n",
      "chunk number: 1713 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3252 - acc: 0.8750 - val_loss: 0.5258 - val_acc: 0.8203\n",
      "chunk number: 1714 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3305 - acc: 0.8672 - val_loss: 0.3431 - val_acc: 0.8672\n",
      "chunk number: 1715 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3462 - acc: 0.8683 - val_loss: 0.3555 - val_acc: 0.8516\n",
      "chunk number: 1716 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3110 - acc: 0.8717 - val_loss: 0.5784 - val_acc: 0.8047\n",
      "chunk number: 1717 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3690 - acc: 0.8516 - val_loss: 0.5192 - val_acc: 0.8203\n",
      "chunk number: 1718 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3487 - acc: 0.8616 - val_loss: 0.5829 - val_acc: 0.7656\n",
      "chunk number: 1719 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3015 - acc: 0.8862 - val_loss: 0.4636 - val_acc: 0.7500\n",
      "chunk number: 1720 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3682 - acc: 0.8571 - val_loss: 0.4658 - val_acc: 0.8516\n",
      "chunk number: 1721 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2889 - acc: 0.8917 - val_loss: 0.4348 - val_acc: 0.8672\n",
      "chunk number: 1722 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2627 - acc: 0.8906 - val_loss: 0.3353 - val_acc: 0.8672\n",
      "chunk number: 1723 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3172 - acc: 0.8795 - val_loss: 0.4583 - val_acc: 0.8281\n",
      "chunk number: 1724 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3520 - acc: 0.8650 - val_loss: 0.4873 - val_acc: 0.8672\n",
      "chunk number: 1725 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2787 - acc: 0.8951 - val_loss: 0.4559 - val_acc: 0.8516\n",
      "chunk number: 1726 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3063 - acc: 0.8806 - val_loss: 0.3876 - val_acc: 0.8672\n",
      "chunk number: 1727 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3257 - acc: 0.8783 - val_loss: 0.3117 - val_acc: 0.8906\n",
      "chunk number: 1728 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2942 - acc: 0.8929 - val_loss: 0.5426 - val_acc: 0.8359\n",
      "chunk number: 1729 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2923 - acc: 0.8873 - val_loss: 0.5047 - val_acc: 0.8125\n",
      "chunk number: 1730 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3312 - acc: 0.8739 - val_loss: 0.5826 - val_acc: 0.8047\n",
      "chunk number: 1731 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2898 - acc: 0.8839 - val_loss: 0.4191 - val_acc: 0.8281\n",
      "chunk number: 1732 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3347 - acc: 0.8783 - val_loss: 0.5617 - val_acc: 0.7969\n",
      "chunk number: 1733 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3096 - acc: 0.8783 - val_loss: 0.3757 - val_acc: 0.8438\n",
      "chunk number: 1734 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3031 - acc: 0.8694 - val_loss: 0.5151 - val_acc: 0.8359\n",
      "chunk number: 1735 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2819 - acc: 0.8940 - val_loss: 0.4995 - val_acc: 0.8203\n",
      "chunk number: 1736 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3357 - acc: 0.8739 - val_loss: 0.4545 - val_acc: 0.8047\n",
      "chunk number: 1737 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3644 - acc: 0.8583 - val_loss: 0.2720 - val_acc: 0.8906\n",
      "chunk number: 1738 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3239 - acc: 0.8739 - val_loss: 0.4470 - val_acc: 0.8750\n",
      "chunk number: 1739 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3220 - acc: 0.8761 - val_loss: 0.4477 - val_acc: 0.8359\n",
      "chunk number: 1740 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3278 - acc: 0.8694 - val_loss: 0.4485 - val_acc: 0.7891\n",
      "chunk number: 1741 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3043 - acc: 0.8929 - val_loss: 0.3815 - val_acc: 0.8594\n",
      "chunk number: 1742 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2895 - acc: 0.8884 - val_loss: 0.4925 - val_acc: 0.8203\n",
      "chunk number: 1743 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3055 - acc: 0.8817 - val_loss: 0.4775 - val_acc: 0.8594\n",
      "chunk number: 1744 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3300 - acc: 0.8627 - val_loss: 0.4761 - val_acc: 0.8359\n",
      "chunk number: 1745 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3236 - acc: 0.8717 - val_loss: 0.3931 - val_acc: 0.7969\n",
      "chunk number: 1746 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3216 - acc: 0.8850 - val_loss: 0.5057 - val_acc: 0.8672\n",
      "chunk number: 1747 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3150 - acc: 0.8929 - val_loss: 0.3449 - val_acc: 0.8750\n",
      "chunk number: 1748 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2679 - acc: 0.8873 - val_loss: 0.5997 - val_acc: 0.8047\n",
      "chunk number: 1749 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2990 - acc: 0.8873 - val_loss: 0.4213 - val_acc: 0.8516\n",
      "chunk number: 1750 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3379 - acc: 0.8638 - val_loss: 0.5615 - val_acc: 0.8438\n",
      "chunk number: 1751 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3072 - acc: 0.8873 - val_loss: 0.4234 - val_acc: 0.8438\n",
      "chunk number: 1752 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3230 - acc: 0.8817 - val_loss: 0.2879 - val_acc: 0.8828\n",
      "chunk number: 1753 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3086 - acc: 0.8806 - val_loss: 0.5061 - val_acc: 0.8359\n",
      "chunk number: 1754 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3150 - acc: 0.8739 - val_loss: 0.2735 - val_acc: 0.8672\n",
      "chunk number: 1755 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2915 - acc: 0.8873 - val_loss: 0.3939 - val_acc: 0.8516\n",
      "chunk number: 1756 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3418 - acc: 0.8594 - val_loss: 0.4605 - val_acc: 0.8281\n",
      "chunk number: 1757 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3354 - acc: 0.8728 - val_loss: 0.3872 - val_acc: 0.8516\n",
      "chunk number: 1758 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2842 - acc: 0.9029 - val_loss: 0.2789 - val_acc: 0.8594\n",
      "chunk number: 1759 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2906 - acc: 0.8906 - val_loss: 0.3309 - val_acc: 0.8984\n",
      "chunk number: 1760 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3133 - acc: 0.8839 - val_loss: 0.5384 - val_acc: 0.8359\n",
      "chunk number: 1761 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3415 - acc: 0.8839 - val_loss: 0.3620 - val_acc: 0.8906\n",
      "chunk number: 1762 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3218 - acc: 0.8772 - val_loss: 0.3142 - val_acc: 0.8984\n",
      "chunk number: 1763 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3292 - acc: 0.8694 - val_loss: 0.5087 - val_acc: 0.8594\n",
      "chunk number: 1764 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2843 - acc: 0.8929 - val_loss: 0.5564 - val_acc: 0.8281\n",
      "chunk number: 1765 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3242 - acc: 0.8873 - val_loss: 0.3325 - val_acc: 0.8672\n",
      "chunk number: 1766 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2970 - acc: 0.8873 - val_loss: 0.4654 - val_acc: 0.8125\n",
      "chunk number: 1767 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3391 - acc: 0.8750 - val_loss: 0.4692 - val_acc: 0.8125\n",
      "chunk number: 1768 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3682 - acc: 0.8605 - val_loss: 0.5866 - val_acc: 0.8203\n",
      "chunk number: 1769 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3515 - acc: 0.8549 - val_loss: 0.4203 - val_acc: 0.8359\n",
      "chunk number: 1770 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2939 - acc: 0.8828 - val_loss: 0.4673 - val_acc: 0.8438\n",
      "chunk number: 1771 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3024 - acc: 0.8873 - val_loss: 0.5690 - val_acc: 0.7891\n",
      "chunk number: 1772 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3285 - acc: 0.8862 - val_loss: 0.4876 - val_acc: 0.7969\n",
      "chunk number: 1773 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3034 - acc: 0.8795 - val_loss: 0.4820 - val_acc: 0.8203\n",
      "chunk number: 1774 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3229 - acc: 0.8862 - val_loss: 0.7038 - val_acc: 0.7734\n",
      "chunk number: 1775 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2953 - acc: 0.8996 - val_loss: 0.4784 - val_acc: 0.8438\n",
      "chunk number: 1776 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3072 - acc: 0.8739 - val_loss: 0.4111 - val_acc: 0.8359\n",
      "chunk number: 1777 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3118 - acc: 0.8828 - val_loss: 0.3989 - val_acc: 0.8516\n",
      "chunk number: 1778 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3179 - acc: 0.8795 - val_loss: 0.5097 - val_acc: 0.8047\n",
      "chunk number: 1779 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2755 - acc: 0.8906 - val_loss: 0.4300 - val_acc: 0.8359\n",
      "chunk number: 1780 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2724 - acc: 0.8884 - val_loss: 0.4526 - val_acc: 0.8516\n",
      "chunk number: 1781 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3337 - acc: 0.8772 - val_loss: 0.3419 - val_acc: 0.8438\n",
      "chunk number: 1782 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3125 - acc: 0.8806 - val_loss: 0.3856 - val_acc: 0.8594\n",
      "chunk number: 1783 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3245 - acc: 0.8717 - val_loss: 0.4619 - val_acc: 0.8047\n",
      "chunk number: 1784 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2877 - acc: 0.8906 - val_loss: 0.3263 - val_acc: 0.8359\n",
      "chunk number: 1785 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3271 - acc: 0.8761 - val_loss: 0.5481 - val_acc: 0.8438\n",
      "chunk number: 1786 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3364 - acc: 0.8862 - val_loss: 0.4175 - val_acc: 0.8281\n",
      "chunk number: 1787 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3523 - acc: 0.8772 - val_loss: 0.5350 - val_acc: 0.8047\n",
      "chunk number: 1788 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3263 - acc: 0.8783 - val_loss: 0.3125 - val_acc: 0.8750\n",
      "chunk number: 1789 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2949 - acc: 0.8694 - val_loss: 0.3982 - val_acc: 0.8438\n",
      "chunk number: 1790 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3166 - acc: 0.8728 - val_loss: 0.3926 - val_acc: 0.8672\n",
      "chunk number: 1791 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3124 - acc: 0.8828 - val_loss: 0.5723 - val_acc: 0.8047\n",
      "chunk number: 1792 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3022 - acc: 0.8739 - val_loss: 0.3377 - val_acc: 0.8516\n",
      "chunk number: 1793 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2845 - acc: 0.8962 - val_loss: 0.7213 - val_acc: 0.7969\n",
      "chunk number: 1794 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2950 - acc: 0.8940 - val_loss: 0.4289 - val_acc: 0.8438\n",
      "chunk number: 1795 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2458 - acc: 0.9219 - val_loss: 0.2771 - val_acc: 0.8828\n",
      "chunk number: 1796 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3329 - acc: 0.8705 - val_loss: 0.5051 - val_acc: 0.8359\n",
      "chunk number: 1797 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2940 - acc: 0.8795 - val_loss: 0.2910 - val_acc: 0.8750\n",
      "chunk number: 1798 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3133 - acc: 0.8783 - val_loss: 0.4415 - val_acc: 0.8516\n",
      "chunk number: 1799 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3225 - acc: 0.8806 - val_loss: 0.4366 - val_acc: 0.8203\n",
      "chunk number: 1800 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3151 - acc: 0.8739 - val_loss: 0.2959 - val_acc: 0.8984\n",
      "chunk number: 1801 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2876 - acc: 0.8895 - val_loss: 0.3577 - val_acc: 0.8750\n",
      "chunk number: 1802 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3134 - acc: 0.8717 - val_loss: 0.5279 - val_acc: 0.7969\n",
      "chunk number: 1803 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3530 - acc: 0.8638 - val_loss: 0.3691 - val_acc: 0.8750\n",
      "chunk number: 1804 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3010 - acc: 0.8828 - val_loss: 0.2813 - val_acc: 0.8984\n",
      "chunk number: 1805 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3162 - acc: 0.8862 - val_loss: 0.4419 - val_acc: 0.8203\n",
      "chunk number: 1806 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2746 - acc: 0.8906 - val_loss: 0.5142 - val_acc: 0.8203\n",
      "chunk number: 1807 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2868 - acc: 0.8962 - val_loss: 0.3400 - val_acc: 0.8906\n",
      "chunk number: 1808 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2875 - acc: 0.9007 - val_loss: 0.3487 - val_acc: 0.8906\n",
      "chunk number: 1809 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2529 - acc: 0.9051 - val_loss: 0.2482 - val_acc: 0.9062\n",
      "chunk number: 1810 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3144 - acc: 0.8850 - val_loss: 0.5040 - val_acc: 0.8281\n",
      "chunk number: 1811 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3845 - acc: 0.8605 - val_loss: 0.3988 - val_acc: 0.8359\n",
      "chunk number: 1812 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3815 - acc: 0.8560 - val_loss: 0.4941 - val_acc: 0.8047\n",
      "chunk number: 1813 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3312 - acc: 0.8694 - val_loss: 0.5616 - val_acc: 0.7891\n",
      "chunk number: 1814 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3422 - acc: 0.8728 - val_loss: 0.2890 - val_acc: 0.8906\n",
      "chunk number: 1815 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3486 - acc: 0.8817 - val_loss: 0.3802 - val_acc: 0.8516\n",
      "chunk number: 1816 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2374 - acc: 0.9096 - val_loss: 0.5617 - val_acc: 0.8125\n",
      "chunk number: 1817 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3216 - acc: 0.8761 - val_loss: 0.4987 - val_acc: 0.8359\n",
      "chunk number: 1818 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3026 - acc: 0.8717 - val_loss: 0.4853 - val_acc: 0.7969\n",
      "chunk number: 1819 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2736 - acc: 0.8806 - val_loss: 0.5190 - val_acc: 0.8125\n",
      "chunk number: 1820 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3109 - acc: 0.8917 - val_loss: 0.5003 - val_acc: 0.8438\n",
      "chunk number: 1821 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2868 - acc: 0.8862 - val_loss: 0.3924 - val_acc: 0.8828\n",
      "chunk number: 1822 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2963 - acc: 0.8828 - val_loss: 0.3898 - val_acc: 0.8594\n",
      "chunk number: 1823 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3411 - acc: 0.8750 - val_loss: 0.3258 - val_acc: 0.8828\n",
      "chunk number: 1824 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3217 - acc: 0.8783 - val_loss: 0.4734 - val_acc: 0.8203\n",
      "chunk number: 1825 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3126 - acc: 0.8817 - val_loss: 0.3346 - val_acc: 0.8594\n",
      "chunk number: 1826 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3254 - acc: 0.8750 - val_loss: 0.5614 - val_acc: 0.7969\n",
      "chunk number: 1827 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3096 - acc: 0.8806 - val_loss: 0.3919 - val_acc: 0.8828\n",
      "chunk number: 1828 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2973 - acc: 0.8817 - val_loss: 0.4938 - val_acc: 0.8125\n",
      "chunk number: 1829 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3268 - acc: 0.8850 - val_loss: 0.4522 - val_acc: 0.8438\n",
      "chunk number: 1830 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3204 - acc: 0.8650 - val_loss: 0.5131 - val_acc: 0.7969\n",
      "chunk number: 1831 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3092 - acc: 0.8717 - val_loss: 0.3795 - val_acc: 0.8359\n",
      "chunk number: 1832 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3495 - acc: 0.8839 - val_loss: 0.4215 - val_acc: 0.8828\n",
      "chunk number: 1833 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3015 - acc: 0.8973 - val_loss: 0.3102 - val_acc: 0.8438\n",
      "chunk number: 1834 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3290 - acc: 0.8694 - val_loss: 0.4350 - val_acc: 0.8828\n",
      "chunk number: 1835 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2713 - acc: 0.8951 - val_loss: 0.5074 - val_acc: 0.7969\n",
      "chunk number: 1836 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3371 - acc: 0.8862 - val_loss: 0.4429 - val_acc: 0.8438\n",
      "chunk number: 1837 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3474 - acc: 0.8504 - val_loss: 0.3055 - val_acc: 0.8672\n",
      "chunk number: 1838 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3198 - acc: 0.8750 - val_loss: 0.6200 - val_acc: 0.8281\n",
      "chunk number: 1839 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3393 - acc: 0.8739 - val_loss: 0.3797 - val_acc: 0.8359\n",
      "chunk number: 1840 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3379 - acc: 0.8661 - val_loss: 0.4291 - val_acc: 0.7969\n",
      "chunk number: 1841 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2732 - acc: 0.8917 - val_loss: 0.4065 - val_acc: 0.8359\n",
      "chunk number: 1842 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2949 - acc: 0.8772 - val_loss: 0.4227 - val_acc: 0.8672\n",
      "chunk number: 1843 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3164 - acc: 0.8862 - val_loss: 0.3586 - val_acc: 0.8750\n",
      "chunk number: 1844 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2926 - acc: 0.8884 - val_loss: 0.5249 - val_acc: 0.7969\n",
      "chunk number: 1845 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3224 - acc: 0.8783 - val_loss: 0.4060 - val_acc: 0.8359\n",
      "chunk number: 1846 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3046 - acc: 0.8850 - val_loss: 0.4894 - val_acc: 0.8203\n",
      "chunk number: 1847 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2953 - acc: 0.8884 - val_loss: 0.4475 - val_acc: 0.8438\n",
      "chunk number: 1848 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3107 - acc: 0.8783 - val_loss: 0.5773 - val_acc: 0.8281\n",
      "chunk number: 1849 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2926 - acc: 0.8862 - val_loss: 0.4170 - val_acc: 0.8516\n",
      "chunk number: 1850 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3346 - acc: 0.8616 - val_loss: 0.5195 - val_acc: 0.8203\n",
      "chunk number: 1851 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2978 - acc: 0.8817 - val_loss: 0.5465 - val_acc: 0.8359\n",
      "chunk number: 1852 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3294 - acc: 0.8728 - val_loss: 0.3369 - val_acc: 0.8672\n",
      "chunk number: 1853 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3411 - acc: 0.8493 - val_loss: 0.5508 - val_acc: 0.8203\n",
      "chunk number: 1854 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2992 - acc: 0.8806 - val_loss: 0.3145 - val_acc: 0.8828\n",
      "chunk number: 1855 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2918 - acc: 0.8929 - val_loss: 0.3741 - val_acc: 0.8047\n",
      "chunk number: 1856 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3069 - acc: 0.8817 - val_loss: 0.4120 - val_acc: 0.8281\n",
      "chunk number: 1857 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3022 - acc: 0.8906 - val_loss: 0.4343 - val_acc: 0.8359\n",
      "chunk number: 1858 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2552 - acc: 0.9107 - val_loss: 0.2821 - val_acc: 0.8906\n",
      "chunk number: 1859 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3156 - acc: 0.8850 - val_loss: 0.4226 - val_acc: 0.8516\n",
      "chunk number: 1860 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3171 - acc: 0.8694 - val_loss: 0.5066 - val_acc: 0.8594\n",
      "chunk number: 1861 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3290 - acc: 0.8728 - val_loss: 0.4124 - val_acc: 0.8672\n",
      "chunk number: 1862 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3359 - acc: 0.8817 - val_loss: 0.2908 - val_acc: 0.8906\n",
      "chunk number: 1863 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3103 - acc: 0.8862 - val_loss: 0.4900 - val_acc: 0.8203\n",
      "chunk number: 1864 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2763 - acc: 0.8973 - val_loss: 0.3795 - val_acc: 0.8672\n",
      "chunk number: 1865 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3050 - acc: 0.8750 - val_loss: 0.3052 - val_acc: 0.8750\n",
      "chunk number: 1866 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3068 - acc: 0.8783 - val_loss: 0.4506 - val_acc: 0.8125\n",
      "chunk number: 1867 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2966 - acc: 0.8917 - val_loss: 0.5333 - val_acc: 0.7891\n",
      "chunk number: 1868 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3268 - acc: 0.8783 - val_loss: 0.5596 - val_acc: 0.8047\n",
      "chunk number: 1869 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3228 - acc: 0.8817 - val_loss: 0.3434 - val_acc: 0.8672\n",
      "chunk number: 1870 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2937 - acc: 0.8873 - val_loss: 0.6058 - val_acc: 0.8203\n",
      "chunk number: 1871 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3212 - acc: 0.8862 - val_loss: 0.4006 - val_acc: 0.8438\n",
      "chunk number: 1872 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3244 - acc: 0.8817 - val_loss: 0.4176 - val_acc: 0.8281\n",
      "chunk number: 1873 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3416 - acc: 0.8672 - val_loss: 0.5897 - val_acc: 0.7734\n",
      "chunk number: 1874 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3544 - acc: 0.8728 - val_loss: 0.5463 - val_acc: 0.7656\n",
      "chunk number: 1875 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3180 - acc: 0.8728 - val_loss: 0.4151 - val_acc: 0.8906\n",
      "chunk number: 1876 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3003 - acc: 0.8884 - val_loss: 0.4126 - val_acc: 0.8594\n",
      "chunk number: 1877 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2816 - acc: 0.8929 - val_loss: 0.4056 - val_acc: 0.8359\n",
      "chunk number: 1878 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3537 - acc: 0.8638 - val_loss: 0.5678 - val_acc: 0.8281\n",
      "chunk number: 1879 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3343 - acc: 0.8772 - val_loss: 0.3120 - val_acc: 0.8984\n",
      "chunk number: 1880 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2999 - acc: 0.8884 - val_loss: 0.4944 - val_acc: 0.8438\n",
      "chunk number: 1881 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3186 - acc: 0.8683 - val_loss: 0.4304 - val_acc: 0.8203\n",
      "chunk number: 1882 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2852 - acc: 0.8929 - val_loss: 0.4119 - val_acc: 0.8281\n",
      "chunk number: 1883 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3130 - acc: 0.8661 - val_loss: 0.3761 - val_acc: 0.8359\n",
      "chunk number: 1884 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3314 - acc: 0.8661 - val_loss: 0.3389 - val_acc: 0.8594\n",
      "chunk number: 1885 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3599 - acc: 0.8638 - val_loss: 0.5423 - val_acc: 0.8047\n",
      "chunk number: 1886 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3533 - acc: 0.8672 - val_loss: 0.4154 - val_acc: 0.8281\n",
      "chunk number: 1887 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3503 - acc: 0.8817 - val_loss: 0.5174 - val_acc: 0.8125\n",
      "chunk number: 1888 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3440 - acc: 0.8605 - val_loss: 0.3618 - val_acc: 0.8594\n",
      "chunk number: 1889 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2938 - acc: 0.8817 - val_loss: 0.3537 - val_acc: 0.8516\n",
      "chunk number: 1890 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2813 - acc: 0.8929 - val_loss: 0.4520 - val_acc: 0.8516\n",
      "chunk number: 1891 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2891 - acc: 0.8906 - val_loss: 0.5818 - val_acc: 0.8281\n",
      "chunk number: 1892 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3541 - acc: 0.8627 - val_loss: 0.3707 - val_acc: 0.8359\n",
      "chunk number: 1893 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2951 - acc: 0.8728 - val_loss: 0.6684 - val_acc: 0.8125\n",
      "chunk number: 1894 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3245 - acc: 0.8772 - val_loss: 0.4757 - val_acc: 0.8359\n",
      "chunk number: 1895 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2946 - acc: 0.8996 - val_loss: 0.4487 - val_acc: 0.8281\n",
      "chunk number: 1896 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3094 - acc: 0.8772 - val_loss: 0.3923 - val_acc: 0.8516\n",
      "chunk number: 1897 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3061 - acc: 0.8828 - val_loss: 0.3931 - val_acc: 0.8281\n",
      "chunk number: 1898 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3092 - acc: 0.8917 - val_loss: 0.4360 - val_acc: 0.8438\n",
      "chunk number: 1899 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3056 - acc: 0.8817 - val_loss: 0.3586 - val_acc: 0.8359\n",
      "chunk number: 1900 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3197 - acc: 0.8783 - val_loss: 0.3218 - val_acc: 0.8672\n",
      "chunk number: 1901 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2475 - acc: 0.9029 - val_loss: 0.3478 - val_acc: 0.8516\n",
      "chunk number: 1902 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3118 - acc: 0.8739 - val_loss: 0.5029 - val_acc: 0.8359\n",
      "chunk number: 1903 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3146 - acc: 0.8817 - val_loss: 0.3660 - val_acc: 0.8828\n",
      "chunk number: 1904 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2581 - acc: 0.9040 - val_loss: 0.3478 - val_acc: 0.9062\n",
      "chunk number: 1905 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3054 - acc: 0.8917 - val_loss: 0.4196 - val_acc: 0.8438\n",
      "chunk number: 1906 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2746 - acc: 0.8862 - val_loss: 0.5058 - val_acc: 0.8594\n",
      "chunk number: 1907 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2847 - acc: 0.8873 - val_loss: 0.4316 - val_acc: 0.8594\n",
      "chunk number: 1908 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2988 - acc: 0.8940 - val_loss: 0.2910 - val_acc: 0.8906\n",
      "chunk number: 1909 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2651 - acc: 0.8884 - val_loss: 0.4907 - val_acc: 0.8203\n",
      "chunk number: 1910 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3206 - acc: 0.8828 - val_loss: 0.4244 - val_acc: 0.8672\n",
      "chunk number: 1911 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3343 - acc: 0.8605 - val_loss: 0.3559 - val_acc: 0.8594\n",
      "chunk number: 1912 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3251 - acc: 0.8739 - val_loss: 0.3781 - val_acc: 0.8672\n",
      "chunk number: 1913 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3316 - acc: 0.8638 - val_loss: 0.5007 - val_acc: 0.7969\n",
      "chunk number: 1914 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3141 - acc: 0.8717 - val_loss: 0.3487 - val_acc: 0.8984\n",
      "chunk number: 1915 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3491 - acc: 0.8694 - val_loss: 0.3524 - val_acc: 0.8672\n",
      "chunk number: 1916 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2899 - acc: 0.8828 - val_loss: 0.6199 - val_acc: 0.7812\n",
      "chunk number: 1917 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3204 - acc: 0.8728 - val_loss: 0.4557 - val_acc: 0.8516\n",
      "chunk number: 1918 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3043 - acc: 0.9007 - val_loss: 0.5340 - val_acc: 0.7891\n",
      "chunk number: 1919 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3308 - acc: 0.8839 - val_loss: 0.5182 - val_acc: 0.7812\n",
      "chunk number: 1920 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3115 - acc: 0.8739 - val_loss: 0.4518 - val_acc: 0.8359\n",
      "chunk number: 1921 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2974 - acc: 0.8839 - val_loss: 0.3695 - val_acc: 0.8359\n",
      "chunk number: 1922 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2947 - acc: 0.8761 - val_loss: 0.4090 - val_acc: 0.8281\n",
      "chunk number: 1923 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3298 - acc: 0.8750 - val_loss: 0.4178 - val_acc: 0.8828\n",
      "chunk number: 1924 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3473 - acc: 0.8605 - val_loss: 0.4543 - val_acc: 0.8203\n",
      "chunk number: 1925 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3270 - acc: 0.8783 - val_loss: 0.3861 - val_acc: 0.8594\n",
      "chunk number: 1926 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3204 - acc: 0.8806 - val_loss: 0.4648 - val_acc: 0.8516\n",
      "chunk number: 1927 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3063 - acc: 0.8828 - val_loss: 0.3742 - val_acc: 0.8672\n",
      "chunk number: 1928 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2900 - acc: 0.8783 - val_loss: 0.4068 - val_acc: 0.8672\n",
      "chunk number: 1929 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3032 - acc: 0.8806 - val_loss: 0.4919 - val_acc: 0.8750\n",
      "chunk number: 1930 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3367 - acc: 0.8761 - val_loss: 0.4634 - val_acc: 0.8281\n",
      "chunk number: 1931 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2813 - acc: 0.9029 - val_loss: 0.3790 - val_acc: 0.8516\n",
      "chunk number: 1932 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3206 - acc: 0.8862 - val_loss: 0.4038 - val_acc: 0.8672\n",
      "chunk number: 1933 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2827 - acc: 0.8795 - val_loss: 0.4213 - val_acc: 0.8516\n",
      "chunk number: 1934 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3034 - acc: 0.8862 - val_loss: 0.4979 - val_acc: 0.8359\n",
      "chunk number: 1935 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3083 - acc: 0.8795 - val_loss: 0.5736 - val_acc: 0.8516\n",
      "chunk number: 1936 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3191 - acc: 0.8750 - val_loss: 0.3518 - val_acc: 0.8438\n",
      "chunk number: 1937 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3007 - acc: 0.8862 - val_loss: 0.2993 - val_acc: 0.8828\n",
      "chunk number: 1938 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2931 - acc: 0.8906 - val_loss: 0.5628 - val_acc: 0.8438\n",
      "chunk number: 1939 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3209 - acc: 0.8806 - val_loss: 0.3601 - val_acc: 0.8672\n",
      "chunk number: 1940 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3446 - acc: 0.8705 - val_loss: 0.3944 - val_acc: 0.8516\n",
      "chunk number: 1941 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2525 - acc: 0.9096 - val_loss: 0.3320 - val_acc: 0.8594\n",
      "chunk number: 1942 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2808 - acc: 0.8906 - val_loss: 0.5303 - val_acc: 0.8203\n",
      "chunk number: 1943 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2859 - acc: 0.8884 - val_loss: 0.3446 - val_acc: 0.8906\n",
      "chunk number: 1944 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2726 - acc: 0.9007 - val_loss: 0.5190 - val_acc: 0.8281\n",
      "chunk number: 1945 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2757 - acc: 0.8795 - val_loss: 0.3675 - val_acc: 0.8516\n",
      "chunk number: 1946 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3256 - acc: 0.8839 - val_loss: 0.5514 - val_acc: 0.7891\n",
      "chunk number: 1947 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3072 - acc: 0.8750 - val_loss: 0.4992 - val_acc: 0.8125\n",
      "chunk number: 1948 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2941 - acc: 0.8884 - val_loss: 0.6269 - val_acc: 0.8281\n",
      "chunk number: 1949 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3029 - acc: 0.8694 - val_loss: 0.3959 - val_acc: 0.8750\n",
      "chunk number: 1950 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3081 - acc: 0.8783 - val_loss: 0.4945 - val_acc: 0.8672\n",
      "chunk number: 1951 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3096 - acc: 0.8839 - val_loss: 0.5190 - val_acc: 0.8281\n",
      "chunk number: 1952 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2540 - acc: 0.8962 - val_loss: 0.3399 - val_acc: 0.8516\n",
      "chunk number: 1953 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3271 - acc: 0.8683 - val_loss: 0.4626 - val_acc: 0.8672\n",
      "chunk number: 1954 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3102 - acc: 0.8850 - val_loss: 0.3606 - val_acc: 0.8672\n",
      "chunk number: 1955 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2892 - acc: 0.8839 - val_loss: 0.3702 - val_acc: 0.8594\n",
      "chunk number: 1956 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2949 - acc: 0.8850 - val_loss: 0.5179 - val_acc: 0.8359\n",
      "chunk number: 1957 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2852 - acc: 0.8884 - val_loss: 0.4978 - val_acc: 0.8203\n",
      "chunk number: 1958 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2703 - acc: 0.8850 - val_loss: 0.2303 - val_acc: 0.8906\n",
      "chunk number: 1959 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3269 - acc: 0.8873 - val_loss: 0.3751 - val_acc: 0.8672\n",
      "chunk number: 1960 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3273 - acc: 0.8672 - val_loss: 0.4739 - val_acc: 0.8516\n",
      "chunk number: 1961 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3084 - acc: 0.8705 - val_loss: 0.4943 - val_acc: 0.8672\n",
      "chunk number: 1962 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3585 - acc: 0.8750 - val_loss: 0.3563 - val_acc: 0.8828\n",
      "chunk number: 1963 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3599 - acc: 0.8750 - val_loss: 0.4768 - val_acc: 0.8672\n",
      "chunk number: 1964 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2681 - acc: 0.9040 - val_loss: 0.5126 - val_acc: 0.7891\n",
      "chunk number: 1965 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3261 - acc: 0.8783 - val_loss: 0.3655 - val_acc: 0.8516\n",
      "chunk number: 1966 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2769 - acc: 0.8973 - val_loss: 0.5916 - val_acc: 0.8359\n",
      "chunk number: 1967 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2647 - acc: 0.8973 - val_loss: 0.4269 - val_acc: 0.8359\n",
      "chunk number: 1968 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3103 - acc: 0.8694 - val_loss: 0.6652 - val_acc: 0.7969\n",
      "chunk number: 1969 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2822 - acc: 0.8929 - val_loss: 0.3958 - val_acc: 0.8828\n",
      "chunk number: 1970 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2705 - acc: 0.8962 - val_loss: 0.5025 - val_acc: 0.8594\n",
      "chunk number: 1971 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2733 - acc: 0.8962 - val_loss: 0.3953 - val_acc: 0.8672\n",
      "chunk number: 1972 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2840 - acc: 0.8873 - val_loss: 0.3888 - val_acc: 0.8516\n",
      "chunk number: 1973 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2877 - acc: 0.8862 - val_loss: 0.6750 - val_acc: 0.8438\n",
      "chunk number: 1974 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3342 - acc: 0.8750 - val_loss: 0.5240 - val_acc: 0.7812\n",
      "chunk number: 1975 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2725 - acc: 0.8984 - val_loss: 0.3911 - val_acc: 0.8828\n",
      "chunk number: 1976 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2649 - acc: 0.8895 - val_loss: 0.4190 - val_acc: 0.8594\n",
      "chunk number: 1977 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2952 - acc: 0.8884 - val_loss: 0.4035 - val_acc: 0.8516\n",
      "chunk number: 1978 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2691 - acc: 0.8917 - val_loss: 0.4829 - val_acc: 0.8047\n",
      "chunk number: 1979 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2528 - acc: 0.8951 - val_loss: 0.3662 - val_acc: 0.8672\n",
      "chunk number: 1980 of 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2907 - acc: 0.8984 - val_loss: 0.4061 - val_acc: 0.8906\n",
      "chunk number: 1981 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3146 - acc: 0.8817 - val_loss: 0.3933 - val_acc: 0.8516\n",
      "chunk number: 1982 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3175 - acc: 0.8750 - val_loss: 0.3150 - val_acc: 0.8750\n",
      "chunk number: 1983 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2911 - acc: 0.8850 - val_loss: 0.4107 - val_acc: 0.8359\n",
      "chunk number: 1984 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2782 - acc: 0.8917 - val_loss: 0.3658 - val_acc: 0.8438\n",
      "chunk number: 1985 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3028 - acc: 0.8962 - val_loss: 0.4337 - val_acc: 0.8594\n",
      "chunk number: 1986 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3021 - acc: 0.8940 - val_loss: 0.4338 - val_acc: 0.8594\n",
      "chunk number: 1987 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3310 - acc: 0.8761 - val_loss: 0.5095 - val_acc: 0.7969\n",
      "chunk number: 1988 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3599 - acc: 0.8661 - val_loss: 0.3681 - val_acc: 0.8750\n",
      "chunk number: 1989 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2998 - acc: 0.8951 - val_loss: 0.4385 - val_acc: 0.8516\n",
      "chunk number: 1990 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2661 - acc: 0.8973 - val_loss: 0.4006 - val_acc: 0.8750\n",
      "chunk number: 1991 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2898 - acc: 0.8862 - val_loss: 0.5464 - val_acc: 0.8359\n",
      "chunk number: 1992 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2981 - acc: 0.8895 - val_loss: 0.3982 - val_acc: 0.7891\n",
      "chunk number: 1993 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2779 - acc: 0.8806 - val_loss: 0.6270 - val_acc: 0.8359\n",
      "chunk number: 1994 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2859 - acc: 0.8962 - val_loss: 0.3737 - val_acc: 0.8594\n",
      "chunk number: 1995 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2647 - acc: 0.8951 - val_loss: 0.3875 - val_acc: 0.8516\n",
      "chunk number: 1996 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3180 - acc: 0.8817 - val_loss: 0.4368 - val_acc: 0.8516\n",
      "chunk number: 1997 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2640 - acc: 0.9141 - val_loss: 0.3966 - val_acc: 0.8672\n",
      "chunk number: 1998 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3190 - acc: 0.8783 - val_loss: 0.4840 - val_acc: 0.8594\n",
      "chunk number: 1999 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2981 - acc: 0.8873 - val_loss: 0.3859 - val_acc: 0.8359\n",
      "chunk number: 2000 of 2000\n",
      "Train on 896 samples, validate on 128 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3407 - acc: 0.8717 - val_loss: 0.2288 - val_acc: 0.8828\n"
     ]
    }
   ],
   "source": [
    "X_files = sorted(os.listdir(pickle_path + \"Spectra\"))\n",
    "y_files = sorted(os.listdir(pickle_path + \"Targets\"))\n",
    "\n",
    "num_chunks = len(y_files)\n",
    "iteration = 0\n",
    "\n",
    "acc=[]\n",
    "loss=[]\n",
    "\n",
    "val_loss=[]\n",
    "val_acc=[]\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "for _ in range(num_epochs):\n",
    "    \n",
    "    for X_file, y_file in zip(X_files,y_files):\n",
    "\n",
    "        iteration +=1\n",
    "        print('chunk number: ' + str(iteration) + \" of \" + str(num_chunks*num_epochs))\n",
    "        \n",
    "        X,y = Data_Gen(X_file, y_file, mean_log_amplitude, threshold = 1.0, h_shift_range=(-30,30))\n",
    "\n",
    "        history=model.fit(X, y, batch_size=128, epochs=1, validation_split=1/8, verbose=2)\n",
    "\n",
    "        val_acc.append(history.history['val_acc'])\n",
    "        acc.append(history.history['acc'])\n",
    "        \n",
    "        loss.append(history.history['loss'])\n",
    "        val_loss.append(history.history['val_loss'])\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc032961a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.plot(acc)\n",
    "plt.plot(val_acc, alpha=0.5)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss, alpha=0.5)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.subplots_adjust(right=1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"Model/Scratch_Aug_1_hrange_pm20_v2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  The above figures show improvement in the training-test data generalization gap. The model has only been given 87.5% of the total dataset. Below training is applied the same reinitialized model with no validation split. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 -- Full train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reinitialize + re-train model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(4, 4), strides=(1, 1), activation='relu', input_shape=(129,129,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (4, 4), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (4, 4), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 1 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 3.7283 - acc: 0.2979\n",
      "chunk number: 2 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.5431 - acc: 0.3623\n",
      "chunk number: 3 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.2734 - acc: 0.4727\n",
      "chunk number: 4 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1335 - acc: 0.5557\n",
      "chunk number: 5 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.2032 - acc: 0.5322\n",
      "chunk number: 6 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0640 - acc: 0.5674\n",
      "chunk number: 7 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0313 - acc: 0.5986\n",
      "chunk number: 8 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0325 - acc: 0.6084\n",
      "chunk number: 9 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9763 - acc: 0.6328\n",
      "chunk number: 10 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0078 - acc: 0.5996\n",
      "chunk number: 11 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0013 - acc: 0.6025\n",
      "chunk number: 12 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9589 - acc: 0.6240\n",
      "chunk number: 13 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9484 - acc: 0.6211\n",
      "chunk number: 14 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9706 - acc: 0.6289\n",
      "chunk number: 15 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9536 - acc: 0.6221\n",
      "chunk number: 16 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9012 - acc: 0.6494\n",
      "chunk number: 17 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8998 - acc: 0.6602\n",
      "chunk number: 18 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9455 - acc: 0.6426\n",
      "chunk number: 19 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9008 - acc: 0.6436\n",
      "chunk number: 20 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9454 - acc: 0.6543\n",
      "chunk number: 21 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8508 - acc: 0.6592\n",
      "chunk number: 22 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8900 - acc: 0.6670\n",
      "chunk number: 23 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8573 - acc: 0.6699\n",
      "chunk number: 24 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9048 - acc: 0.6348\n",
      "chunk number: 25 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8408 - acc: 0.6777\n",
      "chunk number: 26 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8647 - acc: 0.6729\n",
      "chunk number: 27 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8329 - acc: 0.6729\n",
      "chunk number: 28 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8840 - acc: 0.6631\n",
      "chunk number: 29 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8609 - acc: 0.6611\n",
      "chunk number: 30 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9004 - acc: 0.6572\n",
      "chunk number: 31 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8617 - acc: 0.6543\n",
      "chunk number: 32 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8639 - acc: 0.6660\n",
      "chunk number: 33 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8479 - acc: 0.6768\n",
      "chunk number: 34 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8483 - acc: 0.6641\n",
      "chunk number: 35 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8050 - acc: 0.6963\n",
      "chunk number: 36 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8153 - acc: 0.6914\n",
      "chunk number: 37 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8110 - acc: 0.6953\n",
      "chunk number: 38 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8022 - acc: 0.6895\n",
      "chunk number: 39 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8160 - acc: 0.6826\n",
      "chunk number: 40 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8075 - acc: 0.6865\n",
      "chunk number: 41 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7927 - acc: 0.6914\n",
      "chunk number: 42 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8285 - acc: 0.6982\n",
      "chunk number: 43 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7694 - acc: 0.7012\n",
      "chunk number: 44 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7382 - acc: 0.7324\n",
      "chunk number: 45 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8189 - acc: 0.6562\n",
      "chunk number: 46 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8183 - acc: 0.6719\n",
      "chunk number: 47 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7892 - acc: 0.7051\n",
      "chunk number: 48 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8089 - acc: 0.6963\n",
      "chunk number: 49 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7040 - acc: 0.7256\n",
      "chunk number: 50 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8146 - acc: 0.6973\n",
      "chunk number: 51 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8233 - acc: 0.6895\n",
      "chunk number: 52 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7507 - acc: 0.7031\n",
      "chunk number: 53 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7635 - acc: 0.7031\n",
      "chunk number: 54 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7750 - acc: 0.7070\n",
      "chunk number: 55 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7929 - acc: 0.6895\n",
      "chunk number: 56 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8255 - acc: 0.6875\n",
      "chunk number: 57 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8029 - acc: 0.6895\n",
      "chunk number: 58 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7522 - acc: 0.7109\n",
      "chunk number: 59 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7091 - acc: 0.7266\n",
      "chunk number: 60 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8140 - acc: 0.6836\n",
      "chunk number: 61 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7551 - acc: 0.7139\n",
      "chunk number: 62 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7337 - acc: 0.7432\n",
      "chunk number: 63 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8050 - acc: 0.6699\n",
      "chunk number: 64 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7188 - acc: 0.7217\n",
      "chunk number: 65 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7595 - acc: 0.7070\n",
      "chunk number: 66 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8019 - acc: 0.6953\n",
      "chunk number: 67 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7513 - acc: 0.7188\n",
      "chunk number: 68 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7778 - acc: 0.6973\n",
      "chunk number: 69 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7288 - acc: 0.7148\n",
      "chunk number: 70 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7797 - acc: 0.7061\n",
      "chunk number: 71 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7504 - acc: 0.7119\n",
      "chunk number: 72 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7266 - acc: 0.7148\n",
      "chunk number: 73 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7063 - acc: 0.7178\n",
      "chunk number: 74 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7456 - acc: 0.7168\n",
      "chunk number: 75 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7463 - acc: 0.6934\n",
      "chunk number: 76 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7184 - acc: 0.7256\n",
      "chunk number: 77 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6979 - acc: 0.7373\n",
      "chunk number: 78 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7121 - acc: 0.7334\n",
      "chunk number: 79 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6696 - acc: 0.7334\n",
      "chunk number: 80 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7355 - acc: 0.7285\n",
      "chunk number: 81 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6949 - acc: 0.7227\n",
      "chunk number: 82 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6923 - acc: 0.7324\n",
      "chunk number: 83 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7756 - acc: 0.7021\n",
      "chunk number: 84 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7165 - acc: 0.7061\n",
      "chunk number: 85 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7160 - acc: 0.7412\n",
      "chunk number: 86 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7023 - acc: 0.7236\n",
      "chunk number: 87 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7366 - acc: 0.7285\n",
      "chunk number: 88 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7068 - acc: 0.7295\n",
      "chunk number: 89 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6721 - acc: 0.7480\n",
      "chunk number: 90 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6914 - acc: 0.7354\n",
      "chunk number: 91 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7785 - acc: 0.7031\n",
      "chunk number: 92 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6674 - acc: 0.7295\n",
      "chunk number: 93 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6862 - acc: 0.7275\n",
      "chunk number: 94 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7139 - acc: 0.7314\n",
      "chunk number: 95 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6767 - acc: 0.7402\n",
      "chunk number: 96 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6771 - acc: 0.7314\n",
      "chunk number: 97 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7230 - acc: 0.7139\n",
      "chunk number: 98 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7101 - acc: 0.7266\n",
      "chunk number: 99 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6752 - acc: 0.7402\n",
      "chunk number: 100 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6904 - acc: 0.7451\n",
      "chunk number: 101 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6608 - acc: 0.7656\n",
      "chunk number: 102 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7266 - acc: 0.7197\n",
      "chunk number: 103 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6760 - acc: 0.7324\n",
      "chunk number: 104 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6514 - acc: 0.7637\n",
      "chunk number: 105 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6995 - acc: 0.7295\n",
      "chunk number: 106 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6673 - acc: 0.7422\n",
      "chunk number: 107 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7191 - acc: 0.7100\n",
      "chunk number: 108 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6447 - acc: 0.7500\n",
      "chunk number: 109 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6654 - acc: 0.7520\n",
      "chunk number: 110 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6976 - acc: 0.7275\n",
      "chunk number: 111 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7261 - acc: 0.7246\n",
      "chunk number: 112 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6874 - acc: 0.7529\n",
      "chunk number: 113 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6746 - acc: 0.7393\n",
      "chunk number: 114 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7066 - acc: 0.7305\n",
      "chunk number: 115 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6970 - acc: 0.7451\n",
      "chunk number: 116 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6416 - acc: 0.7480\n",
      "chunk number: 117 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6605 - acc: 0.7402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 118 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6831 - acc: 0.7305\n",
      "chunk number: 119 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6715 - acc: 0.7412\n",
      "chunk number: 120 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7163 - acc: 0.7217\n",
      "chunk number: 121 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6125 - acc: 0.7529\n",
      "chunk number: 122 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7042 - acc: 0.7363\n",
      "chunk number: 123 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6259 - acc: 0.7637\n",
      "chunk number: 124 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6636 - acc: 0.7432\n",
      "chunk number: 125 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6344 - acc: 0.7539\n",
      "chunk number: 126 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6591 - acc: 0.7383\n",
      "chunk number: 127 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6510 - acc: 0.7432\n",
      "chunk number: 128 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6723 - acc: 0.7412\n",
      "chunk number: 129 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6783 - acc: 0.7490\n",
      "chunk number: 130 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7429 - acc: 0.7236\n",
      "chunk number: 131 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6810 - acc: 0.7354\n",
      "chunk number: 132 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6989 - acc: 0.7275\n",
      "chunk number: 133 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6331 - acc: 0.7520\n",
      "chunk number: 134 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6834 - acc: 0.7217\n",
      "chunk number: 135 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6537 - acc: 0.7539\n",
      "chunk number: 136 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6372 - acc: 0.7451\n",
      "chunk number: 137 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6441 - acc: 0.7676\n",
      "chunk number: 138 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6271 - acc: 0.7520\n",
      "chunk number: 139 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6383 - acc: 0.7598\n",
      "chunk number: 140 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6572 - acc: 0.7441\n",
      "chunk number: 141 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6163 - acc: 0.7539\n",
      "chunk number: 142 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6630 - acc: 0.7510\n",
      "chunk number: 143 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6449 - acc: 0.7520\n",
      "chunk number: 144 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6117 - acc: 0.7588\n",
      "chunk number: 145 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6294 - acc: 0.7461\n",
      "chunk number: 146 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6444 - acc: 0.7500\n",
      "chunk number: 147 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6272 - acc: 0.7686\n",
      "chunk number: 148 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6273 - acc: 0.7607\n",
      "chunk number: 149 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6104 - acc: 0.7627\n",
      "chunk number: 150 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6588 - acc: 0.7314\n",
      "chunk number: 151 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6875 - acc: 0.7275\n",
      "chunk number: 152 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6212 - acc: 0.7578\n",
      "chunk number: 153 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6832 - acc: 0.7500\n",
      "chunk number: 154 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6729 - acc: 0.7334\n",
      "chunk number: 155 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6302 - acc: 0.7783\n",
      "chunk number: 156 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6627 - acc: 0.7500\n",
      "chunk number: 157 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6496 - acc: 0.7422\n",
      "chunk number: 158 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6093 - acc: 0.7764\n",
      "chunk number: 159 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6568 - acc: 0.7568\n",
      "chunk number: 160 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6941 - acc: 0.7236\n",
      "chunk number: 161 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6338 - acc: 0.7598\n",
      "chunk number: 162 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6086 - acc: 0.7744\n",
      "chunk number: 163 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6527 - acc: 0.7412\n",
      "chunk number: 164 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5970 - acc: 0.7744\n",
      "chunk number: 165 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6524 - acc: 0.7549\n",
      "chunk number: 166 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6376 - acc: 0.7588\n",
      "chunk number: 167 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6754 - acc: 0.7461\n",
      "chunk number: 168 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6731 - acc: 0.7383\n",
      "chunk number: 169 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6652 - acc: 0.7275\n",
      "chunk number: 170 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6396 - acc: 0.7686\n",
      "chunk number: 171 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6112 - acc: 0.7715\n",
      "chunk number: 172 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6054 - acc: 0.7598\n",
      "chunk number: 173 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5912 - acc: 0.7617\n",
      "chunk number: 174 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6479 - acc: 0.7480\n",
      "chunk number: 175 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5839 - acc: 0.7764\n",
      "chunk number: 176 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6086 - acc: 0.7686\n",
      "chunk number: 177 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5977 - acc: 0.7559\n",
      "chunk number: 178 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5947 - acc: 0.7646\n",
      "chunk number: 179 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5999 - acc: 0.7695\n",
      "chunk number: 180 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6248 - acc: 0.7568\n",
      "chunk number: 181 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6143 - acc: 0.7559\n",
      "chunk number: 182 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6077 - acc: 0.7656\n",
      "chunk number: 183 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6323 - acc: 0.7500\n",
      "chunk number: 184 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6103 - acc: 0.7656\n",
      "chunk number: 185 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5981 - acc: 0.7734\n",
      "chunk number: 186 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6402 - acc: 0.7529\n",
      "chunk number: 187 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6361 - acc: 0.7539\n",
      "chunk number: 188 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5922 - acc: 0.7607\n",
      "chunk number: 189 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5715 - acc: 0.7930\n",
      "chunk number: 190 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5943 - acc: 0.7686\n",
      "chunk number: 191 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6267 - acc: 0.7393\n",
      "chunk number: 192 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5909 - acc: 0.7686\n",
      "chunk number: 193 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5882 - acc: 0.7627\n",
      "chunk number: 194 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6189 - acc: 0.7559\n",
      "chunk number: 195 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5698 - acc: 0.7754\n",
      "chunk number: 196 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5608 - acc: 0.7754\n",
      "chunk number: 197 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5801 - acc: 0.7812\n",
      "chunk number: 198 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6241 - acc: 0.7559\n",
      "chunk number: 199 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5790 - acc: 0.7754\n",
      "chunk number: 200 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6090 - acc: 0.7715\n",
      "chunk number: 201 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5448 - acc: 0.8018\n",
      "chunk number: 202 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6349 - acc: 0.7520\n",
      "chunk number: 203 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6072 - acc: 0.7559\n",
      "chunk number: 204 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5913 - acc: 0.7812\n",
      "chunk number: 205 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6335 - acc: 0.7480\n",
      "chunk number: 206 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5804 - acc: 0.7744\n",
      "chunk number: 207 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6200 - acc: 0.7480\n",
      "chunk number: 208 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5344 - acc: 0.7891\n",
      "chunk number: 209 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5509 - acc: 0.8008\n",
      "chunk number: 210 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5679 - acc: 0.7959\n",
      "chunk number: 211 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6074 - acc: 0.7627\n",
      "chunk number: 212 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6364 - acc: 0.7549\n",
      "chunk number: 213 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5722 - acc: 0.7900\n",
      "chunk number: 214 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6433 - acc: 0.7588\n",
      "chunk number: 215 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6041 - acc: 0.7676\n",
      "chunk number: 216 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5514 - acc: 0.7842\n",
      "chunk number: 217 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5543 - acc: 0.7783\n",
      "chunk number: 218 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5749 - acc: 0.7754\n",
      "chunk number: 219 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5805 - acc: 0.7773\n",
      "chunk number: 220 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5983 - acc: 0.7744\n",
      "chunk number: 221 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5369 - acc: 0.7871\n",
      "chunk number: 222 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6071 - acc: 0.7617\n",
      "chunk number: 223 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5939 - acc: 0.7852\n",
      "chunk number: 224 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6009 - acc: 0.7656\n",
      "chunk number: 225 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5398 - acc: 0.7783\n",
      "chunk number: 226 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5754 - acc: 0.7617\n",
      "chunk number: 227 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5635 - acc: 0.7793\n",
      "chunk number: 228 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5983 - acc: 0.7822\n",
      "chunk number: 229 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6048 - acc: 0.7793\n",
      "chunk number: 230 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6000 - acc: 0.7705\n",
      "chunk number: 231 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5559 - acc: 0.7734\n",
      "chunk number: 232 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6063 - acc: 0.7695\n",
      "chunk number: 233 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5608 - acc: 0.7793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 234 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6059 - acc: 0.7637\n",
      "chunk number: 235 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5686 - acc: 0.7930\n",
      "chunk number: 236 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5700 - acc: 0.7812\n",
      "chunk number: 237 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5392 - acc: 0.8008\n",
      "chunk number: 238 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5316 - acc: 0.8037\n",
      "chunk number: 239 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5621 - acc: 0.7910\n",
      "chunk number: 240 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6128 - acc: 0.7725\n",
      "chunk number: 241 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5234 - acc: 0.7998\n",
      "chunk number: 242 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5896 - acc: 0.7812\n",
      "chunk number: 243 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5397 - acc: 0.7881\n",
      "chunk number: 244 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5238 - acc: 0.8154\n",
      "chunk number: 245 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5607 - acc: 0.7920\n",
      "chunk number: 246 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5936 - acc: 0.7812\n",
      "chunk number: 247 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5473 - acc: 0.7910\n",
      "chunk number: 248 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5575 - acc: 0.7832\n",
      "chunk number: 249 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5416 - acc: 0.7861\n",
      "chunk number: 250 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5647 - acc: 0.7695\n",
      "chunk number: 251 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5607 - acc: 0.7891\n",
      "chunk number: 252 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5805 - acc: 0.7705\n",
      "chunk number: 253 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6190 - acc: 0.7588\n",
      "chunk number: 254 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5545 - acc: 0.7871\n",
      "chunk number: 255 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5602 - acc: 0.7832\n",
      "chunk number: 256 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6197 - acc: 0.7676\n",
      "chunk number: 257 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5770 - acc: 0.7793\n",
      "chunk number: 258 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5371 - acc: 0.8008\n",
      "chunk number: 259 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6104 - acc: 0.7803\n",
      "chunk number: 260 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6351 - acc: 0.7539\n",
      "chunk number: 261 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6152 - acc: 0.7656\n",
      "chunk number: 262 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5740 - acc: 0.7842\n",
      "chunk number: 263 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6359 - acc: 0.7637\n",
      "chunk number: 264 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5481 - acc: 0.7998\n",
      "chunk number: 265 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5873 - acc: 0.7793\n",
      "chunk number: 266 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5549 - acc: 0.7891\n",
      "chunk number: 267 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5712 - acc: 0.7979\n",
      "chunk number: 268 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5600 - acc: 0.7646\n",
      "chunk number: 269 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5605 - acc: 0.7686\n",
      "chunk number: 270 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5953 - acc: 0.7871\n",
      "chunk number: 271 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5927 - acc: 0.7734\n",
      "chunk number: 272 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5700 - acc: 0.7744\n",
      "chunk number: 273 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5178 - acc: 0.7881\n",
      "chunk number: 274 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5455 - acc: 0.7939\n",
      "chunk number: 275 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5447 - acc: 0.7842\n",
      "chunk number: 276 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5475 - acc: 0.7793\n",
      "chunk number: 277 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4767 - acc: 0.8203\n",
      "chunk number: 278 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5457 - acc: 0.7783\n",
      "chunk number: 279 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5312 - acc: 0.8057\n",
      "chunk number: 280 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5529 - acc: 0.7949\n",
      "chunk number: 281 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5574 - acc: 0.7832\n",
      "chunk number: 282 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5014 - acc: 0.8242\n",
      "chunk number: 283 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5891 - acc: 0.7686\n",
      "chunk number: 284 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5432 - acc: 0.7939\n",
      "chunk number: 285 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5516 - acc: 0.7998\n",
      "chunk number: 286 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5488 - acc: 0.7842\n",
      "chunk number: 287 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5637 - acc: 0.7881\n",
      "chunk number: 288 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5654 - acc: 0.7812\n",
      "chunk number: 289 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5272 - acc: 0.8008\n",
      "chunk number: 290 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5102 - acc: 0.7998\n",
      "chunk number: 291 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5786 - acc: 0.7822\n",
      "chunk number: 292 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5362 - acc: 0.7910\n",
      "chunk number: 293 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4940 - acc: 0.7979\n",
      "chunk number: 294 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5309 - acc: 0.8057\n",
      "chunk number: 295 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4954 - acc: 0.7979\n",
      "chunk number: 296 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5515 - acc: 0.7881\n",
      "chunk number: 297 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5123 - acc: 0.8047\n",
      "chunk number: 298 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5386 - acc: 0.7822\n",
      "chunk number: 299 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5068 - acc: 0.7998\n",
      "chunk number: 300 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5371 - acc: 0.7734\n",
      "chunk number: 301 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5054 - acc: 0.8027\n",
      "chunk number: 302 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6128 - acc: 0.7559\n",
      "chunk number: 303 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5398 - acc: 0.7900\n",
      "chunk number: 304 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5371 - acc: 0.7910\n",
      "chunk number: 305 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5421 - acc: 0.7686\n",
      "chunk number: 306 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5104 - acc: 0.8096\n",
      "chunk number: 307 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5624 - acc: 0.7803\n",
      "chunk number: 308 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5101 - acc: 0.7920\n",
      "chunk number: 309 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5253 - acc: 0.8115\n",
      "chunk number: 310 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5401 - acc: 0.7920\n",
      "chunk number: 311 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5666 - acc: 0.7764\n",
      "chunk number: 312 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5632 - acc: 0.7812\n",
      "chunk number: 313 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5448 - acc: 0.8018\n",
      "chunk number: 314 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6148 - acc: 0.7656\n",
      "chunk number: 315 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5533 - acc: 0.8018\n",
      "chunk number: 316 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5523 - acc: 0.7803\n",
      "chunk number: 317 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5498 - acc: 0.7900\n",
      "chunk number: 318 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5474 - acc: 0.7852\n",
      "chunk number: 319 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5429 - acc: 0.7910\n",
      "chunk number: 320 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5605 - acc: 0.7725\n",
      "chunk number: 321 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4820 - acc: 0.8184\n",
      "chunk number: 322 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5662 - acc: 0.7783\n",
      "chunk number: 323 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5183 - acc: 0.8057\n",
      "chunk number: 324 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5364 - acc: 0.8047\n",
      "chunk number: 325 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4849 - acc: 0.8086\n",
      "chunk number: 326 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5508 - acc: 0.7812\n",
      "chunk number: 327 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5179 - acc: 0.8018\n",
      "chunk number: 328 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5568 - acc: 0.7959\n",
      "chunk number: 329 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5437 - acc: 0.8037\n",
      "chunk number: 330 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5706 - acc: 0.7910\n",
      "chunk number: 331 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5170 - acc: 0.8066\n",
      "chunk number: 332 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5454 - acc: 0.7822\n",
      "chunk number: 333 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5137 - acc: 0.7930\n",
      "chunk number: 334 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5382 - acc: 0.7822\n",
      "chunk number: 335 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5259 - acc: 0.8115\n",
      "chunk number: 336 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5268 - acc: 0.7852\n",
      "chunk number: 337 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5417 - acc: 0.7939\n",
      "chunk number: 338 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5386 - acc: 0.7900\n",
      "chunk number: 339 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5382 - acc: 0.7910\n",
      "chunk number: 340 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5483 - acc: 0.7910\n",
      "chunk number: 341 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4769 - acc: 0.8066\n",
      "chunk number: 342 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5493 - acc: 0.7988\n",
      "chunk number: 343 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4909 - acc: 0.8008\n",
      "chunk number: 344 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4970 - acc: 0.8115\n",
      "chunk number: 345 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5087 - acc: 0.7969\n",
      "chunk number: 346 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5236 - acc: 0.8027\n",
      "chunk number: 347 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4736 - acc: 0.8145\n",
      "chunk number: 348 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5213 - acc: 0.7998\n",
      "chunk number: 349 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5014 - acc: 0.8047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 350 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5274 - acc: 0.7871\n",
      "chunk number: 351 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5265 - acc: 0.7852\n",
      "chunk number: 352 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5212 - acc: 0.7988\n",
      "chunk number: 353 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5672 - acc: 0.7812\n",
      "chunk number: 354 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5176 - acc: 0.8076\n",
      "chunk number: 355 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5186 - acc: 0.8066\n",
      "chunk number: 356 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5693 - acc: 0.7891\n",
      "chunk number: 357 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5496 - acc: 0.7891\n",
      "chunk number: 358 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4778 - acc: 0.8193\n",
      "chunk number: 359 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5475 - acc: 0.7939\n",
      "chunk number: 360 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5944 - acc: 0.7764\n",
      "chunk number: 361 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5538 - acc: 0.8027\n",
      "chunk number: 362 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5353 - acc: 0.8018\n",
      "chunk number: 363 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5790 - acc: 0.7617\n",
      "chunk number: 364 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4807 - acc: 0.8115\n",
      "chunk number: 365 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5051 - acc: 0.8145\n",
      "chunk number: 366 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5152 - acc: 0.7930\n",
      "chunk number: 367 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5100 - acc: 0.8125\n",
      "chunk number: 368 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5292 - acc: 0.7900\n",
      "chunk number: 369 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5209 - acc: 0.7871\n",
      "chunk number: 370 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5116 - acc: 0.8164\n",
      "chunk number: 371 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5284 - acc: 0.7891\n",
      "chunk number: 372 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5240 - acc: 0.7881\n",
      "chunk number: 373 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4947 - acc: 0.8027\n",
      "chunk number: 374 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5105 - acc: 0.8047\n",
      "chunk number: 375 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5238 - acc: 0.7998\n",
      "chunk number: 376 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5047 - acc: 0.7949\n",
      "chunk number: 377 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4879 - acc: 0.8076\n",
      "chunk number: 378 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5159 - acc: 0.7939\n",
      "chunk number: 379 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5171 - acc: 0.7969\n",
      "chunk number: 380 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5053 - acc: 0.8057\n",
      "chunk number: 381 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5157 - acc: 0.8057\n",
      "chunk number: 382 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4995 - acc: 0.8135\n",
      "chunk number: 383 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5636 - acc: 0.7725\n",
      "chunk number: 384 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5105 - acc: 0.8008\n",
      "chunk number: 385 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5390 - acc: 0.7891\n",
      "chunk number: 386 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5369 - acc: 0.8018\n",
      "chunk number: 387 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5466 - acc: 0.7959\n",
      "chunk number: 388 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5247 - acc: 0.7920\n",
      "chunk number: 389 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4679 - acc: 0.8184\n",
      "chunk number: 390 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4508 - acc: 0.8242\n",
      "chunk number: 391 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5276 - acc: 0.8008\n",
      "chunk number: 392 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4881 - acc: 0.8105\n",
      "chunk number: 393 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4978 - acc: 0.8086\n",
      "chunk number: 394 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5209 - acc: 0.8105\n",
      "chunk number: 395 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4706 - acc: 0.8066\n",
      "chunk number: 396 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4890 - acc: 0.8184\n",
      "chunk number: 397 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4746 - acc: 0.8057\n",
      "chunk number: 398 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5370 - acc: 0.7949\n",
      "chunk number: 399 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5014 - acc: 0.8066\n",
      "chunk number: 400 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5050 - acc: 0.7930\n",
      "chunk number: 401 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4710 - acc: 0.8213\n",
      "chunk number: 402 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5287 - acc: 0.7822\n",
      "chunk number: 403 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4949 - acc: 0.7969\n",
      "chunk number: 404 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5080 - acc: 0.8115\n",
      "chunk number: 405 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5044 - acc: 0.8018\n",
      "chunk number: 406 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5220 - acc: 0.8008\n",
      "chunk number: 407 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5515 - acc: 0.7920\n",
      "chunk number: 408 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4645 - acc: 0.8154\n",
      "chunk number: 409 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4721 - acc: 0.8281\n",
      "chunk number: 410 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5037 - acc: 0.8145\n",
      "chunk number: 411 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5407 - acc: 0.7881\n",
      "chunk number: 412 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5416 - acc: 0.7930\n",
      "chunk number: 413 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5092 - acc: 0.8066\n",
      "chunk number: 414 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5593 - acc: 0.7871\n",
      "chunk number: 415 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5251 - acc: 0.7959\n",
      "chunk number: 416 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5052 - acc: 0.8086\n",
      "chunk number: 417 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5048 - acc: 0.8027\n",
      "chunk number: 418 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5249 - acc: 0.8096\n",
      "chunk number: 419 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5033 - acc: 0.8125\n",
      "chunk number: 420 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5073 - acc: 0.7930\n",
      "chunk number: 421 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4648 - acc: 0.8271\n",
      "chunk number: 422 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5090 - acc: 0.7988\n",
      "chunk number: 423 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5265 - acc: 0.8115\n",
      "chunk number: 424 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5222 - acc: 0.7871\n",
      "chunk number: 425 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4359 - acc: 0.8301\n",
      "chunk number: 426 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5404 - acc: 0.7744\n",
      "chunk number: 427 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5020 - acc: 0.8037\n",
      "chunk number: 428 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5249 - acc: 0.7998\n",
      "chunk number: 429 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5144 - acc: 0.8203\n",
      "chunk number: 430 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5396 - acc: 0.7793\n",
      "chunk number: 431 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5016 - acc: 0.7969\n",
      "chunk number: 432 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5251 - acc: 0.7969\n",
      "chunk number: 433 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4695 - acc: 0.8008\n",
      "chunk number: 434 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4942 - acc: 0.7998\n",
      "chunk number: 435 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4969 - acc: 0.8066\n",
      "chunk number: 436 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4866 - acc: 0.8096\n",
      "chunk number: 437 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5231 - acc: 0.7920\n",
      "chunk number: 438 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4859 - acc: 0.8213\n",
      "chunk number: 439 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5235 - acc: 0.7988\n",
      "chunk number: 440 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5296 - acc: 0.8008\n",
      "chunk number: 441 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4918 - acc: 0.8057\n",
      "chunk number: 442 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5253 - acc: 0.8047\n",
      "chunk number: 443 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4865 - acc: 0.8223\n",
      "chunk number: 444 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4935 - acc: 0.8311\n",
      "chunk number: 445 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4995 - acc: 0.8174\n",
      "chunk number: 446 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5166 - acc: 0.7959\n",
      "chunk number: 447 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4815 - acc: 0.8164\n",
      "chunk number: 448 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4928 - acc: 0.8037\n",
      "chunk number: 449 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4827 - acc: 0.8203\n",
      "chunk number: 450 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5056 - acc: 0.8076\n",
      "chunk number: 451 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5056 - acc: 0.8027\n",
      "chunk number: 452 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4966 - acc: 0.7939\n",
      "chunk number: 453 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5351 - acc: 0.7949\n",
      "chunk number: 454 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4971 - acc: 0.8066\n",
      "chunk number: 455 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4751 - acc: 0.8145\n",
      "chunk number: 456 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4936 - acc: 0.8037\n",
      "chunk number: 457 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5081 - acc: 0.8096\n",
      "chunk number: 458 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4498 - acc: 0.8252\n",
      "chunk number: 459 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4910 - acc: 0.8135\n",
      "chunk number: 460 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5346 - acc: 0.7910\n",
      "chunk number: 461 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4790 - acc: 0.8252\n",
      "chunk number: 462 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4871 - acc: 0.8154\n",
      "chunk number: 463 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5645 - acc: 0.7822\n",
      "chunk number: 464 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4662 - acc: 0.8154\n",
      "chunk number: 465 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5073 - acc: 0.8145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 466 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5185 - acc: 0.7959\n",
      "chunk number: 467 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4796 - acc: 0.8203\n",
      "chunk number: 468 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4912 - acc: 0.8066\n",
      "chunk number: 469 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4904 - acc: 0.7959\n",
      "chunk number: 470 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4895 - acc: 0.8145\n",
      "chunk number: 471 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5135 - acc: 0.7959\n",
      "chunk number: 472 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4620 - acc: 0.8320\n",
      "chunk number: 473 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4633 - acc: 0.8096\n",
      "chunk number: 474 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4991 - acc: 0.7920\n",
      "chunk number: 475 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4763 - acc: 0.8135\n",
      "chunk number: 476 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4715 - acc: 0.8184\n",
      "chunk number: 477 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4242 - acc: 0.8271\n",
      "chunk number: 478 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4612 - acc: 0.8057\n",
      "chunk number: 479 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5064 - acc: 0.8047\n",
      "chunk number: 480 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4953 - acc: 0.8262\n",
      "chunk number: 481 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4894 - acc: 0.8154\n",
      "chunk number: 482 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4692 - acc: 0.8223\n",
      "chunk number: 483 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5146 - acc: 0.8008\n",
      "chunk number: 484 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5000 - acc: 0.8105\n",
      "chunk number: 485 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5247 - acc: 0.7988\n",
      "chunk number: 486 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4957 - acc: 0.8008\n",
      "chunk number: 487 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5356 - acc: 0.7979\n",
      "chunk number: 488 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4906 - acc: 0.8066\n",
      "chunk number: 489 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4594 - acc: 0.8174\n",
      "chunk number: 490 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4948 - acc: 0.8057\n",
      "chunk number: 491 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4965 - acc: 0.8213\n",
      "chunk number: 492 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4743 - acc: 0.8105\n",
      "chunk number: 493 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4688 - acc: 0.8174\n",
      "chunk number: 494 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4610 - acc: 0.8262\n",
      "chunk number: 495 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4295 - acc: 0.8320\n",
      "chunk number: 496 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4722 - acc: 0.8193\n",
      "chunk number: 497 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4554 - acc: 0.8242\n",
      "chunk number: 498 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5061 - acc: 0.8037\n",
      "chunk number: 499 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4554 - acc: 0.8271\n",
      "chunk number: 500 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4797 - acc: 0.8086\n",
      "chunk number: 501 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4387 - acc: 0.8262\n",
      "chunk number: 502 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5537 - acc: 0.7852\n",
      "chunk number: 503 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4706 - acc: 0.7988\n",
      "chunk number: 504 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4835 - acc: 0.8105\n",
      "chunk number: 505 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4740 - acc: 0.8213\n",
      "chunk number: 506 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4721 - acc: 0.8174\n",
      "chunk number: 507 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5167 - acc: 0.8057\n",
      "chunk number: 508 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4479 - acc: 0.8096\n",
      "chunk number: 509 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4430 - acc: 0.8477\n",
      "chunk number: 510 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4774 - acc: 0.8262\n",
      "chunk number: 511 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5284 - acc: 0.7871\n",
      "chunk number: 512 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5489 - acc: 0.7910\n",
      "chunk number: 513 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4813 - acc: 0.8145\n",
      "chunk number: 514 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5234 - acc: 0.8027\n",
      "chunk number: 515 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4915 - acc: 0.8242\n",
      "chunk number: 516 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4672 - acc: 0.8271\n",
      "chunk number: 517 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4742 - acc: 0.8135\n",
      "chunk number: 518 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5067 - acc: 0.8125\n",
      "chunk number: 519 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4707 - acc: 0.8262\n",
      "chunk number: 520 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4950 - acc: 0.8154\n",
      "chunk number: 521 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4341 - acc: 0.8330\n",
      "chunk number: 522 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5020 - acc: 0.7949\n",
      "chunk number: 523 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4915 - acc: 0.8350\n",
      "chunk number: 524 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5157 - acc: 0.7930\n",
      "chunk number: 525 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4430 - acc: 0.8350\n",
      "chunk number: 526 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4966 - acc: 0.7988\n",
      "chunk number: 527 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4740 - acc: 0.7998\n",
      "chunk number: 528 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5009 - acc: 0.8037\n",
      "chunk number: 529 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4902 - acc: 0.8125\n",
      "chunk number: 530 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5024 - acc: 0.8086\n",
      "chunk number: 531 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4737 - acc: 0.8213\n",
      "chunk number: 532 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4850 - acc: 0.8105\n",
      "chunk number: 533 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4581 - acc: 0.8223\n",
      "chunk number: 534 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4828 - acc: 0.8018\n",
      "chunk number: 535 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4546 - acc: 0.8359\n",
      "chunk number: 536 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4896 - acc: 0.8242\n",
      "chunk number: 537 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5009 - acc: 0.8057\n",
      "chunk number: 538 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4590 - acc: 0.8359\n",
      "chunk number: 539 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4838 - acc: 0.8154\n",
      "chunk number: 540 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5562 - acc: 0.8037\n",
      "chunk number: 541 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4665 - acc: 0.8057\n",
      "chunk number: 542 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4958 - acc: 0.8096\n",
      "chunk number: 543 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4595 - acc: 0.8184\n",
      "chunk number: 544 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4932 - acc: 0.8008\n",
      "chunk number: 545 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4741 - acc: 0.8145\n",
      "chunk number: 546 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4741 - acc: 0.8223\n",
      "chunk number: 547 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4511 - acc: 0.8232\n",
      "chunk number: 548 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4761 - acc: 0.8135\n",
      "chunk number: 549 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4517 - acc: 0.8242\n",
      "chunk number: 550 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4645 - acc: 0.8232\n",
      "chunk number: 551 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5017 - acc: 0.8145\n",
      "chunk number: 552 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4505 - acc: 0.8223\n",
      "chunk number: 553 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5251 - acc: 0.7773\n",
      "chunk number: 554 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4743 - acc: 0.8164\n",
      "chunk number: 555 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4781 - acc: 0.8242\n",
      "chunk number: 556 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4899 - acc: 0.8115\n",
      "chunk number: 557 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4922 - acc: 0.8066\n",
      "chunk number: 558 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4432 - acc: 0.8428\n",
      "chunk number: 559 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4949 - acc: 0.8086\n",
      "chunk number: 560 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5149 - acc: 0.8037\n",
      "chunk number: 561 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4615 - acc: 0.8350\n",
      "chunk number: 562 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4576 - acc: 0.8291\n",
      "chunk number: 563 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5257 - acc: 0.7959\n",
      "chunk number: 564 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4268 - acc: 0.8340\n",
      "chunk number: 565 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4863 - acc: 0.8232\n",
      "chunk number: 566 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4893 - acc: 0.8057\n",
      "chunk number: 567 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4664 - acc: 0.8311\n",
      "chunk number: 568 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5111 - acc: 0.7969\n",
      "chunk number: 569 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5013 - acc: 0.8145\n",
      "chunk number: 570 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4708 - acc: 0.8184\n",
      "chunk number: 571 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5019 - acc: 0.7988\n",
      "chunk number: 572 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5011 - acc: 0.8086\n",
      "chunk number: 573 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4537 - acc: 0.8262\n",
      "chunk number: 574 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5111 - acc: 0.7871\n",
      "chunk number: 575 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4794 - acc: 0.8145\n",
      "chunk number: 576 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4788 - acc: 0.8232\n",
      "chunk number: 577 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4726 - acc: 0.8232\n",
      "chunk number: 578 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4452 - acc: 0.8193\n",
      "chunk number: 579 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4587 - acc: 0.8145\n",
      "chunk number: 580 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5040 - acc: 0.8096\n",
      "chunk number: 581 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5263 - acc: 0.7979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 582 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4794 - acc: 0.8145\n",
      "chunk number: 583 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5082 - acc: 0.8047\n",
      "chunk number: 584 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4584 - acc: 0.8252\n",
      "chunk number: 585 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4824 - acc: 0.7959\n",
      "chunk number: 586 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4800 - acc: 0.8262\n",
      "chunk number: 587 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4849 - acc: 0.8174\n",
      "chunk number: 588 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4910 - acc: 0.8115\n",
      "chunk number: 589 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4430 - acc: 0.8359\n",
      "chunk number: 590 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4586 - acc: 0.8281\n",
      "chunk number: 591 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5121 - acc: 0.7979\n",
      "chunk number: 592 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4461 - acc: 0.8232\n",
      "chunk number: 593 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4470 - acc: 0.8301\n",
      "chunk number: 594 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4452 - acc: 0.8379\n",
      "chunk number: 595 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4507 - acc: 0.8291\n",
      "chunk number: 596 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4497 - acc: 0.8379\n",
      "chunk number: 597 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4370 - acc: 0.8301\n",
      "chunk number: 598 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4823 - acc: 0.8076\n",
      "chunk number: 599 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4871 - acc: 0.8135\n",
      "chunk number: 600 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5032 - acc: 0.8105\n",
      "chunk number: 601 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4275 - acc: 0.8262\n",
      "chunk number: 602 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5172 - acc: 0.7881\n",
      "chunk number: 603 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4462 - acc: 0.8262\n",
      "chunk number: 604 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4672 - acc: 0.8203\n",
      "chunk number: 605 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4685 - acc: 0.8086\n",
      "chunk number: 606 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4714 - acc: 0.8086\n",
      "chunk number: 607 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5119 - acc: 0.8047\n",
      "chunk number: 608 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4380 - acc: 0.8135\n",
      "chunk number: 609 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4282 - acc: 0.8496\n",
      "chunk number: 610 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4591 - acc: 0.8291\n",
      "chunk number: 611 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5169 - acc: 0.7979\n",
      "chunk number: 612 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5255 - acc: 0.7900\n",
      "chunk number: 613 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4901 - acc: 0.8145\n",
      "chunk number: 614 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5073 - acc: 0.8047\n",
      "chunk number: 615 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4976 - acc: 0.8096\n",
      "chunk number: 616 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4648 - acc: 0.8252\n",
      "chunk number: 617 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4437 - acc: 0.8301\n",
      "chunk number: 618 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5009 - acc: 0.8076\n",
      "chunk number: 619 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4782 - acc: 0.8252\n",
      "chunk number: 620 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5159 - acc: 0.8105\n",
      "chunk number: 621 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4240 - acc: 0.8340\n",
      "chunk number: 622 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4696 - acc: 0.8154\n",
      "chunk number: 623 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4635 - acc: 0.8242\n",
      "chunk number: 624 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4910 - acc: 0.7998\n",
      "chunk number: 625 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3980 - acc: 0.8369\n",
      "chunk number: 626 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4618 - acc: 0.8203\n",
      "chunk number: 627 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4570 - acc: 0.8242\n",
      "chunk number: 628 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4855 - acc: 0.8203\n",
      "chunk number: 629 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5089 - acc: 0.8027\n",
      "chunk number: 630 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5202 - acc: 0.8037\n",
      "chunk number: 631 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4655 - acc: 0.8135\n",
      "chunk number: 632 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4850 - acc: 0.8252\n",
      "chunk number: 633 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4597 - acc: 0.8232\n",
      "chunk number: 634 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4940 - acc: 0.8008\n",
      "chunk number: 635 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4554 - acc: 0.8330\n",
      "chunk number: 636 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4650 - acc: 0.8145\n",
      "chunk number: 637 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4484 - acc: 0.8193\n",
      "chunk number: 638 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4678 - acc: 0.8340\n",
      "chunk number: 639 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4843 - acc: 0.8193\n",
      "chunk number: 640 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5117 - acc: 0.8096\n",
      "chunk number: 641 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4239 - acc: 0.8359\n",
      "chunk number: 642 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4871 - acc: 0.8223\n",
      "chunk number: 643 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4850 - acc: 0.8047\n",
      "chunk number: 644 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4316 - acc: 0.8291\n",
      "chunk number: 645 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4918 - acc: 0.7930\n",
      "chunk number: 646 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4766 - acc: 0.8223\n",
      "chunk number: 647 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4392 - acc: 0.8223\n",
      "chunk number: 648 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4674 - acc: 0.8018\n",
      "chunk number: 649 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4542 - acc: 0.8193\n",
      "chunk number: 650 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4748 - acc: 0.8271\n",
      "chunk number: 651 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4832 - acc: 0.8145\n",
      "chunk number: 652 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4428 - acc: 0.8223\n",
      "chunk number: 653 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4843 - acc: 0.8008\n",
      "chunk number: 654 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4465 - acc: 0.8320\n",
      "chunk number: 655 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4666 - acc: 0.8154\n",
      "chunk number: 656 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5116 - acc: 0.7969\n",
      "chunk number: 657 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4780 - acc: 0.8076\n",
      "chunk number: 658 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4299 - acc: 0.8379\n",
      "chunk number: 659 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4741 - acc: 0.8213\n",
      "chunk number: 660 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4904 - acc: 0.8135\n",
      "chunk number: 661 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4465 - acc: 0.8330\n",
      "chunk number: 662 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4531 - acc: 0.8320\n",
      "chunk number: 663 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5222 - acc: 0.7891\n",
      "chunk number: 664 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4068 - acc: 0.8467\n",
      "chunk number: 665 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4939 - acc: 0.8105\n",
      "chunk number: 666 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4846 - acc: 0.8096\n",
      "chunk number: 667 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4797 - acc: 0.8096\n",
      "chunk number: 668 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4716 - acc: 0.8271\n",
      "chunk number: 669 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4690 - acc: 0.8174\n",
      "chunk number: 670 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4725 - acc: 0.8213\n",
      "chunk number: 671 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4539 - acc: 0.8193\n",
      "chunk number: 672 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4897 - acc: 0.8066\n",
      "chunk number: 673 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4723 - acc: 0.8242\n",
      "chunk number: 674 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4921 - acc: 0.8213\n",
      "chunk number: 675 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4615 - acc: 0.8311\n",
      "chunk number: 676 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4496 - acc: 0.8271\n",
      "chunk number: 677 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4067 - acc: 0.8320\n",
      "chunk number: 678 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4427 - acc: 0.8398\n",
      "chunk number: 679 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4633 - acc: 0.8213\n",
      "chunk number: 680 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4594 - acc: 0.8301\n",
      "chunk number: 681 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4513 - acc: 0.8193\n",
      "chunk number: 682 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4292 - acc: 0.8311\n",
      "chunk number: 683 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4809 - acc: 0.8096\n",
      "chunk number: 684 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4703 - acc: 0.8203\n",
      "chunk number: 685 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4782 - acc: 0.8125\n",
      "chunk number: 686 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4541 - acc: 0.8271\n",
      "chunk number: 687 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4866 - acc: 0.8105\n",
      "chunk number: 688 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4337 - acc: 0.8242\n",
      "chunk number: 689 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4470 - acc: 0.8184\n",
      "chunk number: 690 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4388 - acc: 0.8428\n",
      "chunk number: 691 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4885 - acc: 0.8105\n",
      "chunk number: 692 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4398 - acc: 0.8369\n",
      "chunk number: 693 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4391 - acc: 0.8213\n",
      "chunk number: 694 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4632 - acc: 0.8281\n",
      "chunk number: 695 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4257 - acc: 0.8320\n",
      "chunk number: 696 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4590 - acc: 0.8174\n",
      "chunk number: 697 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4293 - acc: 0.8262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 698 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4584 - acc: 0.8232\n",
      "chunk number: 699 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4433 - acc: 0.8184\n",
      "chunk number: 700 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4701 - acc: 0.8154\n",
      "chunk number: 701 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4269 - acc: 0.8467\n",
      "chunk number: 702 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5072 - acc: 0.7969\n",
      "chunk number: 703 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5093 - acc: 0.7949\n",
      "chunk number: 704 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4633 - acc: 0.8311\n",
      "chunk number: 705 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4711 - acc: 0.8154\n",
      "chunk number: 706 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4247 - acc: 0.8281\n",
      "chunk number: 707 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4851 - acc: 0.8193\n",
      "chunk number: 708 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4292 - acc: 0.8223\n",
      "chunk number: 709 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3967 - acc: 0.8467\n",
      "chunk number: 710 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4606 - acc: 0.8223\n",
      "chunk number: 711 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4893 - acc: 0.8242\n",
      "chunk number: 712 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5214 - acc: 0.8047\n",
      "chunk number: 713 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4809 - acc: 0.8184\n",
      "chunk number: 714 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4984 - acc: 0.8154\n",
      "chunk number: 715 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4646 - acc: 0.8223\n",
      "chunk number: 716 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4651 - acc: 0.8252\n",
      "chunk number: 717 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4652 - acc: 0.8203\n",
      "chunk number: 718 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4487 - acc: 0.8311\n",
      "chunk number: 719 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4473 - acc: 0.8262\n",
      "chunk number: 720 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4493 - acc: 0.8184\n",
      "chunk number: 721 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4306 - acc: 0.8330\n",
      "chunk number: 722 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4525 - acc: 0.8115\n",
      "chunk number: 723 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4751 - acc: 0.8174\n",
      "chunk number: 724 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4673 - acc: 0.8164\n",
      "chunk number: 725 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4123 - acc: 0.8535\n",
      "chunk number: 726 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4816 - acc: 0.8096\n",
      "chunk number: 727 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4945 - acc: 0.8027\n",
      "chunk number: 728 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4685 - acc: 0.8105\n",
      "chunk number: 729 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4897 - acc: 0.8096\n",
      "chunk number: 730 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4780 - acc: 0.8037\n",
      "chunk number: 731 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4527 - acc: 0.8223\n",
      "chunk number: 732 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4525 - acc: 0.8369\n",
      "chunk number: 733 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4323 - acc: 0.8369\n",
      "chunk number: 734 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4320 - acc: 0.8223\n",
      "chunk number: 735 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4362 - acc: 0.8408\n",
      "chunk number: 736 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4382 - acc: 0.8350\n",
      "chunk number: 737 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4559 - acc: 0.8242\n",
      "chunk number: 738 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4605 - acc: 0.8408\n",
      "chunk number: 739 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4735 - acc: 0.8145\n",
      "chunk number: 740 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5112 - acc: 0.8105\n",
      "chunk number: 741 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4385 - acc: 0.8232\n",
      "chunk number: 742 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4371 - acc: 0.8301\n",
      "chunk number: 743 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4443 - acc: 0.8350\n",
      "chunk number: 744 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4369 - acc: 0.8408\n",
      "chunk number: 745 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4469 - acc: 0.8301\n",
      "chunk number: 746 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4679 - acc: 0.8223\n",
      "chunk number: 747 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4342 - acc: 0.8320\n",
      "chunk number: 748 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4536 - acc: 0.8232\n",
      "chunk number: 749 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4507 - acc: 0.8311\n",
      "chunk number: 750 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4639 - acc: 0.8037\n",
      "chunk number: 751 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4633 - acc: 0.8242\n",
      "chunk number: 752 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4433 - acc: 0.8330\n",
      "chunk number: 753 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4941 - acc: 0.8096\n",
      "chunk number: 754 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4611 - acc: 0.8174\n",
      "chunk number: 755 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4358 - acc: 0.8291\n",
      "chunk number: 756 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4358 - acc: 0.8340\n",
      "chunk number: 757 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4295 - acc: 0.8340\n",
      "chunk number: 758 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4117 - acc: 0.8477\n",
      "chunk number: 759 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4359 - acc: 0.8506\n",
      "chunk number: 760 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4807 - acc: 0.8086\n",
      "chunk number: 761 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4468 - acc: 0.8359\n",
      "chunk number: 762 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4286 - acc: 0.8379\n",
      "chunk number: 763 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4948 - acc: 0.8076\n",
      "chunk number: 764 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3905 - acc: 0.8438\n",
      "chunk number: 765 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4673 - acc: 0.8320\n",
      "chunk number: 766 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4545 - acc: 0.8145\n",
      "chunk number: 767 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4583 - acc: 0.8252\n",
      "chunk number: 768 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4435 - acc: 0.8350\n",
      "chunk number: 769 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4400 - acc: 0.8359\n",
      "chunk number: 770 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4526 - acc: 0.8291\n",
      "chunk number: 771 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4626 - acc: 0.8145\n",
      "chunk number: 772 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4678 - acc: 0.8135\n",
      "chunk number: 773 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4271 - acc: 0.8438\n",
      "chunk number: 774 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4660 - acc: 0.8291\n",
      "chunk number: 775 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4068 - acc: 0.8438\n",
      "chunk number: 776 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4303 - acc: 0.8271\n",
      "chunk number: 777 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3932 - acc: 0.8467\n",
      "chunk number: 778 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4198 - acc: 0.8223\n",
      "chunk number: 779 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4387 - acc: 0.8291\n",
      "chunk number: 780 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4311 - acc: 0.8369\n",
      "chunk number: 781 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4588 - acc: 0.8252\n",
      "chunk number: 782 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4461 - acc: 0.8281\n",
      "chunk number: 783 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4987 - acc: 0.7998\n",
      "chunk number: 784 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4458 - acc: 0.8262\n",
      "chunk number: 785 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4756 - acc: 0.8164\n",
      "chunk number: 786 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4573 - acc: 0.8213\n",
      "chunk number: 787 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4425 - acc: 0.8271\n",
      "chunk number: 788 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4448 - acc: 0.8301\n",
      "chunk number: 789 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4104 - acc: 0.8486\n",
      "chunk number: 790 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3894 - acc: 0.8447\n",
      "chunk number: 791 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4682 - acc: 0.8066\n",
      "chunk number: 792 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4285 - acc: 0.8320\n",
      "chunk number: 793 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4580 - acc: 0.8105\n",
      "chunk number: 794 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4305 - acc: 0.8486\n",
      "chunk number: 795 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3781 - acc: 0.8555\n",
      "chunk number: 796 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4205 - acc: 0.8438\n",
      "chunk number: 797 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3985 - acc: 0.8496\n",
      "chunk number: 798 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4706 - acc: 0.8174\n",
      "chunk number: 799 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3966 - acc: 0.8398\n",
      "chunk number: 800 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4542 - acc: 0.8213\n",
      "chunk number: 801 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4151 - acc: 0.8389\n",
      "chunk number: 802 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5003 - acc: 0.7979\n",
      "chunk number: 803 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4312 - acc: 0.8193\n",
      "chunk number: 804 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4237 - acc: 0.8398\n",
      "chunk number: 805 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4039 - acc: 0.8379\n",
      "chunk number: 806 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4314 - acc: 0.8340\n",
      "chunk number: 807 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4599 - acc: 0.8291\n",
      "chunk number: 808 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4018 - acc: 0.8477\n",
      "chunk number: 809 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3996 - acc: 0.8564\n",
      "chunk number: 810 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4485 - acc: 0.8359\n",
      "chunk number: 811 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4819 - acc: 0.8066\n",
      "chunk number: 812 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4682 - acc: 0.8203\n",
      "chunk number: 813 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4429 - acc: 0.8350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 814 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4871 - acc: 0.8232\n",
      "chunk number: 815 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4379 - acc: 0.8330\n",
      "chunk number: 816 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4413 - acc: 0.8174\n",
      "chunk number: 817 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4486 - acc: 0.8047\n",
      "chunk number: 818 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4401 - acc: 0.8301\n",
      "chunk number: 819 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4323 - acc: 0.8340\n",
      "chunk number: 820 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4473 - acc: 0.8252\n",
      "chunk number: 821 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4130 - acc: 0.8428\n",
      "chunk number: 822 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4259 - acc: 0.8271\n",
      "chunk number: 823 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4465 - acc: 0.8428\n",
      "chunk number: 824 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4785 - acc: 0.8125\n",
      "chunk number: 825 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3792 - acc: 0.8525\n",
      "chunk number: 826 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4392 - acc: 0.8232\n",
      "chunk number: 827 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4450 - acc: 0.8291\n",
      "chunk number: 828 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4688 - acc: 0.8174\n",
      "chunk number: 829 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4677 - acc: 0.8242\n",
      "chunk number: 830 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4670 - acc: 0.8135\n",
      "chunk number: 831 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4641 - acc: 0.8379\n",
      "chunk number: 832 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4396 - acc: 0.8379\n",
      "chunk number: 833 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4279 - acc: 0.8428\n",
      "chunk number: 834 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4330 - acc: 0.8281\n",
      "chunk number: 835 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4275 - acc: 0.8350\n",
      "chunk number: 836 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4817 - acc: 0.8252\n",
      "chunk number: 837 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4500 - acc: 0.8223\n",
      "chunk number: 838 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4293 - acc: 0.8506\n",
      "chunk number: 839 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4356 - acc: 0.8379\n",
      "chunk number: 840 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4735 - acc: 0.8105\n",
      "chunk number: 841 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3877 - acc: 0.8428\n",
      "chunk number: 842 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4455 - acc: 0.8271\n",
      "chunk number: 843 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4373 - acc: 0.8223\n",
      "chunk number: 844 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4285 - acc: 0.8389\n",
      "chunk number: 845 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4517 - acc: 0.8223\n",
      "chunk number: 846 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4376 - acc: 0.8242\n",
      "chunk number: 847 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4163 - acc: 0.8340\n",
      "chunk number: 848 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4131 - acc: 0.8516\n",
      "chunk number: 849 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4026 - acc: 0.8477\n",
      "chunk number: 850 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4330 - acc: 0.8291\n",
      "chunk number: 851 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4434 - acc: 0.8408\n",
      "chunk number: 852 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4035 - acc: 0.8379\n",
      "chunk number: 853 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4767 - acc: 0.7939\n",
      "chunk number: 854 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4294 - acc: 0.8398\n",
      "chunk number: 855 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4312 - acc: 0.8330\n",
      "chunk number: 856 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4467 - acc: 0.8330\n",
      "chunk number: 857 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4269 - acc: 0.8271\n",
      "chunk number: 858 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3986 - acc: 0.8506\n",
      "chunk number: 859 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4093 - acc: 0.8477\n",
      "chunk number: 860 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4717 - acc: 0.8154\n",
      "chunk number: 861 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4258 - acc: 0.8340\n",
      "chunk number: 862 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4192 - acc: 0.8486\n",
      "chunk number: 863 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5004 - acc: 0.8008\n",
      "chunk number: 864 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3901 - acc: 0.8477\n",
      "chunk number: 865 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4472 - acc: 0.8164\n",
      "chunk number: 866 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4440 - acc: 0.8301\n",
      "chunk number: 867 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4196 - acc: 0.8447\n",
      "chunk number: 868 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4389 - acc: 0.8252\n",
      "chunk number: 869 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4681 - acc: 0.8008\n",
      "chunk number: 870 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4133 - acc: 0.8418\n",
      "chunk number: 871 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4296 - acc: 0.8311\n",
      "chunk number: 872 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4436 - acc: 0.8320\n",
      "chunk number: 873 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4132 - acc: 0.8447\n",
      "chunk number: 874 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4521 - acc: 0.8330\n",
      "chunk number: 875 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4344 - acc: 0.8350\n",
      "chunk number: 876 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4403 - acc: 0.8223\n",
      "chunk number: 877 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4134 - acc: 0.8418\n",
      "chunk number: 878 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4053 - acc: 0.8438\n",
      "chunk number: 879 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4231 - acc: 0.8271\n",
      "chunk number: 880 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3890 - acc: 0.8613\n",
      "chunk number: 881 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4387 - acc: 0.8281\n",
      "chunk number: 882 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4155 - acc: 0.8389\n",
      "chunk number: 883 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5084 - acc: 0.8018\n",
      "chunk number: 884 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4170 - acc: 0.8398\n",
      "chunk number: 885 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4675 - acc: 0.8271\n",
      "chunk number: 886 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4439 - acc: 0.8086\n",
      "chunk number: 887 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4524 - acc: 0.8320\n",
      "chunk number: 888 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4243 - acc: 0.8281\n",
      "chunk number: 889 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4059 - acc: 0.8418\n",
      "chunk number: 890 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3919 - acc: 0.8516\n",
      "chunk number: 891 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4334 - acc: 0.8281\n",
      "chunk number: 892 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4389 - acc: 0.8330\n",
      "chunk number: 893 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4057 - acc: 0.8389\n",
      "chunk number: 894 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4360 - acc: 0.8164\n",
      "chunk number: 895 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4123 - acc: 0.8330\n",
      "chunk number: 896 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4143 - acc: 0.8496\n",
      "chunk number: 897 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3773 - acc: 0.8623\n",
      "chunk number: 898 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4330 - acc: 0.8359\n",
      "chunk number: 899 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3902 - acc: 0.8447\n",
      "chunk number: 900 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4021 - acc: 0.8369\n",
      "chunk number: 901 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3898 - acc: 0.8457\n",
      "chunk number: 902 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4584 - acc: 0.8203\n",
      "chunk number: 903 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3931 - acc: 0.8428\n",
      "chunk number: 904 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4298 - acc: 0.8398\n",
      "chunk number: 905 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4237 - acc: 0.8330\n",
      "chunk number: 906 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3864 - acc: 0.8516\n",
      "chunk number: 907 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4442 - acc: 0.8232\n",
      "chunk number: 908 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3934 - acc: 0.8418\n",
      "chunk number: 909 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4093 - acc: 0.8418\n",
      "chunk number: 910 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4270 - acc: 0.8398\n",
      "chunk number: 911 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4683 - acc: 0.8174\n",
      "chunk number: 912 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4640 - acc: 0.8086\n",
      "chunk number: 913 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4306 - acc: 0.8311\n",
      "chunk number: 914 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4745 - acc: 0.8252\n",
      "chunk number: 915 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4536 - acc: 0.8291\n",
      "chunk number: 916 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4233 - acc: 0.8379\n",
      "chunk number: 917 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4276 - acc: 0.8262\n",
      "chunk number: 918 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4489 - acc: 0.8271\n",
      "chunk number: 919 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4050 - acc: 0.8438\n",
      "chunk number: 920 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4436 - acc: 0.8340\n",
      "chunk number: 921 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3769 - acc: 0.8545\n",
      "chunk number: 922 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4233 - acc: 0.8369\n",
      "chunk number: 923 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4151 - acc: 0.8535\n",
      "chunk number: 924 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4385 - acc: 0.8242\n",
      "chunk number: 925 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3894 - acc: 0.8525\n",
      "chunk number: 926 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4397 - acc: 0.8301\n",
      "chunk number: 927 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4379 - acc: 0.8262\n",
      "chunk number: 928 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4246 - acc: 0.8438\n",
      "chunk number: 929 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4490 - acc: 0.8330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 930 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4707 - acc: 0.8213\n",
      "chunk number: 931 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4435 - acc: 0.8389\n",
      "chunk number: 932 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4353 - acc: 0.8281\n",
      "chunk number: 933 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4189 - acc: 0.8418\n",
      "chunk number: 934 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4375 - acc: 0.8242\n",
      "chunk number: 935 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4221 - acc: 0.8320\n",
      "chunk number: 936 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4118 - acc: 0.8477\n",
      "chunk number: 937 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4251 - acc: 0.8291\n",
      "chunk number: 938 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3989 - acc: 0.8613\n",
      "chunk number: 939 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4442 - acc: 0.8232\n",
      "chunk number: 940 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4761 - acc: 0.8076\n",
      "chunk number: 941 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4342 - acc: 0.8359\n",
      "chunk number: 942 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4242 - acc: 0.8379\n",
      "chunk number: 943 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4420 - acc: 0.8311\n",
      "chunk number: 944 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4323 - acc: 0.8408\n",
      "chunk number: 945 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4340 - acc: 0.8320\n",
      "chunk number: 946 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4527 - acc: 0.8447\n",
      "chunk number: 947 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4033 - acc: 0.8389\n",
      "chunk number: 948 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4164 - acc: 0.8369\n",
      "chunk number: 949 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4050 - acc: 0.8408\n",
      "chunk number: 950 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4195 - acc: 0.8291\n",
      "chunk number: 951 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4246 - acc: 0.8301\n",
      "chunk number: 952 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4169 - acc: 0.8379\n",
      "chunk number: 953 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4628 - acc: 0.8154\n",
      "chunk number: 954 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4182 - acc: 0.8516\n",
      "chunk number: 955 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3909 - acc: 0.8496\n",
      "chunk number: 956 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4339 - acc: 0.8457\n",
      "chunk number: 957 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4353 - acc: 0.8271\n",
      "chunk number: 958 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3845 - acc: 0.8643\n",
      "chunk number: 959 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4249 - acc: 0.8398\n",
      "chunk number: 960 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4579 - acc: 0.8281\n",
      "chunk number: 961 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4175 - acc: 0.8613\n",
      "chunk number: 962 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4353 - acc: 0.8389\n",
      "chunk number: 963 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4543 - acc: 0.8320\n",
      "chunk number: 964 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4044 - acc: 0.8457\n",
      "chunk number: 965 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4316 - acc: 0.8330\n",
      "chunk number: 966 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4309 - acc: 0.8340\n",
      "chunk number: 967 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3968 - acc: 0.8535\n",
      "chunk number: 968 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4534 - acc: 0.8174\n",
      "chunk number: 969 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4422 - acc: 0.8271\n",
      "chunk number: 970 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4335 - acc: 0.8467\n",
      "chunk number: 971 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4243 - acc: 0.8271\n",
      "chunk number: 972 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4686 - acc: 0.8057\n",
      "chunk number: 973 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3920 - acc: 0.8457\n",
      "chunk number: 974 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4714 - acc: 0.8145\n",
      "chunk number: 975 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4090 - acc: 0.8545\n",
      "chunk number: 976 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4090 - acc: 0.8340\n",
      "chunk number: 977 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4006 - acc: 0.8389\n",
      "chunk number: 978 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3928 - acc: 0.8379\n",
      "chunk number: 979 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4218 - acc: 0.8330\n",
      "chunk number: 980 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4307 - acc: 0.8633\n",
      "chunk number: 981 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4410 - acc: 0.8242\n",
      "chunk number: 982 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4189 - acc: 0.8291\n",
      "chunk number: 983 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4454 - acc: 0.8271\n",
      "chunk number: 984 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4254 - acc: 0.8252\n",
      "chunk number: 985 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4324 - acc: 0.8389\n",
      "chunk number: 986 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4170 - acc: 0.8408\n",
      "chunk number: 987 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4590 - acc: 0.8154\n",
      "chunk number: 988 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3960 - acc: 0.8506\n",
      "chunk number: 989 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3835 - acc: 0.8555\n",
      "chunk number: 990 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3859 - acc: 0.8496\n",
      "chunk number: 991 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4511 - acc: 0.8252\n",
      "chunk number: 992 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4196 - acc: 0.8252\n",
      "chunk number: 993 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3887 - acc: 0.8418\n",
      "chunk number: 994 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4037 - acc: 0.8496\n",
      "chunk number: 995 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3788 - acc: 0.8506\n",
      "chunk number: 996 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4027 - acc: 0.8477\n",
      "chunk number: 997 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3926 - acc: 0.8447\n",
      "chunk number: 998 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4039 - acc: 0.8291\n",
      "chunk number: 999 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3764 - acc: 0.8477\n",
      "chunk number: 1000 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4210 - acc: 0.8447\n",
      "chunk number: 1001 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3744 - acc: 0.8506\n",
      "chunk number: 1002 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4492 - acc: 0.8193\n",
      "chunk number: 1003 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4150 - acc: 0.8320\n",
      "chunk number: 1004 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4330 - acc: 0.8369\n",
      "chunk number: 1005 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3966 - acc: 0.8379\n",
      "chunk number: 1006 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3830 - acc: 0.8594\n",
      "chunk number: 1007 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4908 - acc: 0.8193\n",
      "chunk number: 1008 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3975 - acc: 0.8496\n",
      "chunk number: 1009 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3840 - acc: 0.8525\n",
      "chunk number: 1010 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4028 - acc: 0.8535\n",
      "chunk number: 1011 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4761 - acc: 0.8135\n",
      "chunk number: 1012 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.5008 - acc: 0.8125\n",
      "chunk number: 1013 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4165 - acc: 0.8418\n",
      "chunk number: 1014 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4456 - acc: 0.8301\n",
      "chunk number: 1015 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4250 - acc: 0.8447\n",
      "chunk number: 1016 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4064 - acc: 0.8457\n",
      "chunk number: 1017 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4336 - acc: 0.8223\n",
      "chunk number: 1018 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4346 - acc: 0.8281\n",
      "chunk number: 1019 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4111 - acc: 0.8350\n",
      "chunk number: 1020 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4324 - acc: 0.8477\n",
      "chunk number: 1021 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3751 - acc: 0.8564\n",
      "chunk number: 1022 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3850 - acc: 0.8516\n",
      "chunk number: 1023 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4252 - acc: 0.8584\n",
      "chunk number: 1024 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4538 - acc: 0.8096\n",
      "chunk number: 1025 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3668 - acc: 0.8516\n",
      "chunk number: 1026 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4392 - acc: 0.8252\n",
      "chunk number: 1027 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4244 - acc: 0.8330\n",
      "chunk number: 1028 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4287 - acc: 0.8477\n",
      "chunk number: 1029 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4282 - acc: 0.8379\n",
      "chunk number: 1030 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4132 - acc: 0.8311\n",
      "chunk number: 1031 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4369 - acc: 0.8174\n",
      "chunk number: 1032 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4486 - acc: 0.8379\n",
      "chunk number: 1033 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3767 - acc: 0.8398\n",
      "chunk number: 1034 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4142 - acc: 0.8428\n",
      "chunk number: 1035 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4110 - acc: 0.8369\n",
      "chunk number: 1036 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4436 - acc: 0.8193\n",
      "chunk number: 1037 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4164 - acc: 0.8320\n",
      "chunk number: 1038 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4222 - acc: 0.8555\n",
      "chunk number: 1039 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4044 - acc: 0.8486\n",
      "chunk number: 1040 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4752 - acc: 0.8271\n",
      "chunk number: 1041 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3842 - acc: 0.8486\n",
      "chunk number: 1042 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4337 - acc: 0.8369\n",
      "chunk number: 1043 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4326 - acc: 0.8271\n",
      "chunk number: 1044 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4188 - acc: 0.8467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 1045 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4274 - acc: 0.8418\n",
      "chunk number: 1046 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4297 - acc: 0.8320\n",
      "chunk number: 1047 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3887 - acc: 0.8477\n",
      "chunk number: 1048 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4186 - acc: 0.8203\n",
      "chunk number: 1049 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3695 - acc: 0.8438\n",
      "chunk number: 1050 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3924 - acc: 0.8330\n",
      "chunk number: 1051 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4297 - acc: 0.8242\n",
      "chunk number: 1052 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3963 - acc: 0.8516\n",
      "chunk number: 1053 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4431 - acc: 0.8252\n",
      "chunk number: 1054 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4258 - acc: 0.8496\n",
      "chunk number: 1055 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4049 - acc: 0.8457\n",
      "chunk number: 1056 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4151 - acc: 0.8350\n",
      "chunk number: 1057 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4128 - acc: 0.8564\n",
      "chunk number: 1058 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3956 - acc: 0.8525\n",
      "chunk number: 1059 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3906 - acc: 0.8467\n",
      "chunk number: 1060 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4658 - acc: 0.8174\n",
      "chunk number: 1061 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4013 - acc: 0.8438\n",
      "chunk number: 1062 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4020 - acc: 0.8525\n",
      "chunk number: 1063 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4594 - acc: 0.8184\n",
      "chunk number: 1064 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3611 - acc: 0.8662\n",
      "chunk number: 1065 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4073 - acc: 0.8359\n",
      "chunk number: 1066 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4203 - acc: 0.8389\n",
      "chunk number: 1067 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4016 - acc: 0.8447\n",
      "chunk number: 1068 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4211 - acc: 0.8252\n",
      "chunk number: 1069 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4095 - acc: 0.8320\n",
      "chunk number: 1070 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4548 - acc: 0.8271\n",
      "chunk number: 1071 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4276 - acc: 0.8467\n",
      "chunk number: 1072 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4584 - acc: 0.8281\n",
      "chunk number: 1073 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4213 - acc: 0.8340\n",
      "chunk number: 1074 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4298 - acc: 0.8301\n",
      "chunk number: 1075 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4082 - acc: 0.8467\n",
      "chunk number: 1076 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4208 - acc: 0.8379\n",
      "chunk number: 1077 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3843 - acc: 0.8555\n",
      "chunk number: 1078 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4077 - acc: 0.8467\n",
      "chunk number: 1079 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3932 - acc: 0.8496\n",
      "chunk number: 1080 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3976 - acc: 0.8594\n",
      "chunk number: 1081 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4116 - acc: 0.8438\n",
      "chunk number: 1082 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3891 - acc: 0.8350\n",
      "chunk number: 1083 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3936 - acc: 0.8477\n",
      "chunk number: 1084 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4120 - acc: 0.8340\n",
      "chunk number: 1085 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3927 - acc: 0.8545\n",
      "chunk number: 1086 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4099 - acc: 0.8525\n",
      "chunk number: 1087 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4466 - acc: 0.8223\n",
      "chunk number: 1088 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3797 - acc: 0.8682\n",
      "chunk number: 1089 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3585 - acc: 0.8545\n",
      "chunk number: 1090 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3766 - acc: 0.8594\n",
      "chunk number: 1091 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4380 - acc: 0.8291\n",
      "chunk number: 1092 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4184 - acc: 0.8389\n",
      "chunk number: 1093 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3695 - acc: 0.8525\n",
      "chunk number: 1094 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4101 - acc: 0.8447\n",
      "chunk number: 1095 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3587 - acc: 0.8506\n",
      "chunk number: 1096 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4117 - acc: 0.8369\n",
      "chunk number: 1097 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3835 - acc: 0.8447\n",
      "chunk number: 1098 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4057 - acc: 0.8447\n",
      "chunk number: 1099 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4202 - acc: 0.8340\n",
      "chunk number: 1100 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4183 - acc: 0.8232\n",
      "chunk number: 1101 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3861 - acc: 0.8594\n",
      "chunk number: 1102 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4160 - acc: 0.8496\n",
      "chunk number: 1103 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3894 - acc: 0.8350\n",
      "chunk number: 1104 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3960 - acc: 0.8496\n",
      "chunk number: 1105 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3980 - acc: 0.8428\n",
      "chunk number: 1106 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3820 - acc: 0.8486\n",
      "chunk number: 1107 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4230 - acc: 0.8486\n",
      "chunk number: 1108 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3885 - acc: 0.8428\n",
      "chunk number: 1109 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3774 - acc: 0.8740\n",
      "chunk number: 1110 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3939 - acc: 0.8447\n",
      "chunk number: 1111 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4456 - acc: 0.8096\n",
      "chunk number: 1112 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4566 - acc: 0.8281\n",
      "chunk number: 1113 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3988 - acc: 0.8467\n",
      "chunk number: 1114 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4034 - acc: 0.8379\n",
      "chunk number: 1115 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4551 - acc: 0.8359\n",
      "chunk number: 1116 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3769 - acc: 0.8467\n",
      "chunk number: 1117 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4054 - acc: 0.8340\n",
      "chunk number: 1118 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4249 - acc: 0.8447\n",
      "chunk number: 1119 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4205 - acc: 0.8467\n",
      "chunk number: 1120 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4423 - acc: 0.8447\n",
      "chunk number: 1121 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3795 - acc: 0.8613\n",
      "chunk number: 1122 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3960 - acc: 0.8477\n",
      "chunk number: 1123 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3830 - acc: 0.8506\n",
      "chunk number: 1124 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4371 - acc: 0.8330\n",
      "chunk number: 1125 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3696 - acc: 0.8525\n",
      "chunk number: 1126 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4016 - acc: 0.8379\n",
      "chunk number: 1127 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3938 - acc: 0.8496\n",
      "chunk number: 1128 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4244 - acc: 0.8457\n",
      "chunk number: 1129 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4063 - acc: 0.8477\n",
      "chunk number: 1130 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4567 - acc: 0.8232\n",
      "chunk number: 1131 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3949 - acc: 0.8447\n",
      "chunk number: 1132 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4187 - acc: 0.8389\n",
      "chunk number: 1133 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4000 - acc: 0.8584\n",
      "chunk number: 1134 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4106 - acc: 0.8408\n",
      "chunk number: 1135 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3629 - acc: 0.8682\n",
      "chunk number: 1136 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4356 - acc: 0.8408\n",
      "chunk number: 1137 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4150 - acc: 0.8340\n",
      "chunk number: 1138 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4132 - acc: 0.8623\n",
      "chunk number: 1139 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3774 - acc: 0.8506\n",
      "chunk number: 1140 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4527 - acc: 0.8330\n",
      "chunk number: 1141 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4009 - acc: 0.8408\n",
      "chunk number: 1142 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3879 - acc: 0.8604\n",
      "chunk number: 1143 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4074 - acc: 0.8438\n",
      "chunk number: 1144 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3748 - acc: 0.8604\n",
      "chunk number: 1145 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4053 - acc: 0.8379\n",
      "chunk number: 1146 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4135 - acc: 0.8418\n",
      "chunk number: 1147 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3878 - acc: 0.8506\n",
      "chunk number: 1148 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4218 - acc: 0.8301\n",
      "chunk number: 1149 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3738 - acc: 0.8516\n",
      "chunk number: 1150 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4149 - acc: 0.8320\n",
      "chunk number: 1151 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3974 - acc: 0.8438\n",
      "chunk number: 1152 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4034 - acc: 0.8398\n",
      "chunk number: 1153 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4750 - acc: 0.8086\n",
      "chunk number: 1154 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4247 - acc: 0.8467\n",
      "chunk number: 1155 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4143 - acc: 0.8467\n",
      "chunk number: 1156 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4208 - acc: 0.8398\n",
      "chunk number: 1157 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3669 - acc: 0.8564\n",
      "chunk number: 1158 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3698 - acc: 0.8740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 1159 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3993 - acc: 0.8574\n",
      "chunk number: 1160 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4238 - acc: 0.8301\n",
      "chunk number: 1161 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3922 - acc: 0.8574\n",
      "chunk number: 1162 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4034 - acc: 0.8438\n",
      "chunk number: 1163 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4395 - acc: 0.8330\n",
      "chunk number: 1164 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3507 - acc: 0.8691\n",
      "chunk number: 1165 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4273 - acc: 0.8369\n",
      "chunk number: 1166 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4186 - acc: 0.8457\n",
      "chunk number: 1167 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3928 - acc: 0.8564\n",
      "chunk number: 1168 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4006 - acc: 0.8545\n",
      "chunk number: 1169 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3907 - acc: 0.8516\n",
      "chunk number: 1170 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4030 - acc: 0.8486\n",
      "chunk number: 1171 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4035 - acc: 0.8467\n",
      "chunk number: 1172 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4025 - acc: 0.8369\n",
      "chunk number: 1173 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3623 - acc: 0.8633\n",
      "chunk number: 1174 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4084 - acc: 0.8525\n",
      "chunk number: 1175 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4061 - acc: 0.8389\n",
      "chunk number: 1176 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3955 - acc: 0.8447\n",
      "chunk number: 1177 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3982 - acc: 0.8457\n",
      "chunk number: 1178 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3756 - acc: 0.8467\n",
      "chunk number: 1179 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4042 - acc: 0.8428\n",
      "chunk number: 1180 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3790 - acc: 0.8691\n",
      "chunk number: 1181 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4163 - acc: 0.8350\n",
      "chunk number: 1182 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3824 - acc: 0.8604\n",
      "chunk number: 1183 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3929 - acc: 0.8447\n",
      "chunk number: 1184 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3833 - acc: 0.8486\n",
      "chunk number: 1185 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4156 - acc: 0.8350\n",
      "chunk number: 1186 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3933 - acc: 0.8350\n",
      "chunk number: 1187 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4232 - acc: 0.8350\n",
      "chunk number: 1188 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3900 - acc: 0.8389\n",
      "chunk number: 1189 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3817 - acc: 0.8574\n",
      "chunk number: 1190 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3909 - acc: 0.8418\n",
      "chunk number: 1191 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4612 - acc: 0.8281\n",
      "chunk number: 1192 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3741 - acc: 0.8516\n",
      "chunk number: 1193 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3762 - acc: 0.8438\n",
      "chunk number: 1194 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3740 - acc: 0.8535\n",
      "chunk number: 1195 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3486 - acc: 0.8496\n",
      "chunk number: 1196 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3669 - acc: 0.8652\n",
      "chunk number: 1197 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3401 - acc: 0.8672\n",
      "chunk number: 1198 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3693 - acc: 0.8555\n",
      "chunk number: 1199 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3767 - acc: 0.8457\n",
      "chunk number: 1200 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4057 - acc: 0.8496\n",
      "chunk number: 1201 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3786 - acc: 0.8564\n",
      "chunk number: 1202 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4187 - acc: 0.8359\n",
      "chunk number: 1203 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3974 - acc: 0.8418\n",
      "chunk number: 1204 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3917 - acc: 0.8574\n",
      "chunk number: 1205 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3817 - acc: 0.8594\n",
      "chunk number: 1206 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3506 - acc: 0.8623\n",
      "chunk number: 1207 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4125 - acc: 0.8506\n",
      "chunk number: 1208 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4153 - acc: 0.8369\n",
      "chunk number: 1209 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3504 - acc: 0.8828\n",
      "chunk number: 1210 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3973 - acc: 0.8506\n",
      "chunk number: 1211 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4169 - acc: 0.8467\n",
      "chunk number: 1212 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4040 - acc: 0.8340\n",
      "chunk number: 1213 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4057 - acc: 0.8545\n",
      "chunk number: 1214 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4265 - acc: 0.8418\n",
      "chunk number: 1215 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4201 - acc: 0.8359\n",
      "chunk number: 1216 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3800 - acc: 0.8516\n",
      "chunk number: 1217 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4259 - acc: 0.8398\n",
      "chunk number: 1218 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4339 - acc: 0.8271\n",
      "chunk number: 1219 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4063 - acc: 0.8320\n",
      "chunk number: 1220 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4240 - acc: 0.8447\n",
      "chunk number: 1221 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3585 - acc: 0.8545\n",
      "chunk number: 1222 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3783 - acc: 0.8428\n",
      "chunk number: 1223 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3987 - acc: 0.8535\n",
      "chunk number: 1224 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4290 - acc: 0.8291\n",
      "chunk number: 1225 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3393 - acc: 0.8613\n",
      "chunk number: 1226 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3933 - acc: 0.8486\n",
      "chunk number: 1227 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3742 - acc: 0.8379\n",
      "chunk number: 1228 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3924 - acc: 0.8486\n",
      "chunk number: 1229 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3975 - acc: 0.8418\n",
      "chunk number: 1230 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3908 - acc: 0.8389\n",
      "chunk number: 1231 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3642 - acc: 0.8594\n",
      "chunk number: 1232 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4059 - acc: 0.8242\n",
      "chunk number: 1233 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3772 - acc: 0.8555\n",
      "chunk number: 1234 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4244 - acc: 0.8271\n",
      "chunk number: 1235 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3920 - acc: 0.8467\n",
      "chunk number: 1236 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4355 - acc: 0.8262\n",
      "chunk number: 1237 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4174 - acc: 0.8438\n",
      "chunk number: 1238 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4015 - acc: 0.8506\n",
      "chunk number: 1239 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3834 - acc: 0.8467\n",
      "chunk number: 1240 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4402 - acc: 0.8291\n",
      "chunk number: 1241 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3655 - acc: 0.8545\n",
      "chunk number: 1242 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3798 - acc: 0.8535\n",
      "chunk number: 1243 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3677 - acc: 0.8525\n",
      "chunk number: 1244 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3535 - acc: 0.8750\n",
      "chunk number: 1245 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3847 - acc: 0.8418\n",
      "chunk number: 1246 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4074 - acc: 0.8525\n",
      "chunk number: 1247 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3643 - acc: 0.8486\n",
      "chunk number: 1248 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3887 - acc: 0.8369\n",
      "chunk number: 1249 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3596 - acc: 0.8652\n",
      "chunk number: 1250 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4288 - acc: 0.8301\n",
      "chunk number: 1251 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4221 - acc: 0.8350\n",
      "chunk number: 1252 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3842 - acc: 0.8555\n",
      "chunk number: 1253 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4425 - acc: 0.8193\n",
      "chunk number: 1254 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4126 - acc: 0.8340\n",
      "chunk number: 1255 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3927 - acc: 0.8350\n",
      "chunk number: 1256 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3933 - acc: 0.8516\n",
      "chunk number: 1257 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3586 - acc: 0.8643\n",
      "chunk number: 1258 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3779 - acc: 0.8535\n",
      "chunk number: 1259 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4024 - acc: 0.8438\n",
      "chunk number: 1260 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3995 - acc: 0.8418\n",
      "chunk number: 1261 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3587 - acc: 0.8711\n",
      "chunk number: 1262 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3913 - acc: 0.8477\n",
      "chunk number: 1263 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4489 - acc: 0.8379\n",
      "chunk number: 1264 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3477 - acc: 0.8613\n",
      "chunk number: 1265 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4061 - acc: 0.8447\n",
      "chunk number: 1266 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4147 - acc: 0.8350\n",
      "chunk number: 1267 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3693 - acc: 0.8516\n",
      "chunk number: 1268 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3812 - acc: 0.8438\n",
      "chunk number: 1269 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4048 - acc: 0.8301\n",
      "chunk number: 1270 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3909 - acc: 0.8594\n",
      "chunk number: 1271 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3988 - acc: 0.8457\n",
      "chunk number: 1272 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4083 - acc: 0.8457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 1273 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3754 - acc: 0.8662\n",
      "chunk number: 1274 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4129 - acc: 0.8467\n",
      "chunk number: 1275 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3712 - acc: 0.8613\n",
      "chunk number: 1276 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3841 - acc: 0.8457\n",
      "chunk number: 1277 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3683 - acc: 0.8555\n",
      "chunk number: 1278 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3922 - acc: 0.8379\n",
      "chunk number: 1279 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3765 - acc: 0.8535\n",
      "chunk number: 1280 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4092 - acc: 0.8457\n",
      "chunk number: 1281 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3957 - acc: 0.8320\n",
      "chunk number: 1282 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3783 - acc: 0.8486\n",
      "chunk number: 1283 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4001 - acc: 0.8447\n",
      "chunk number: 1284 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4136 - acc: 0.8389\n",
      "chunk number: 1285 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3927 - acc: 0.8506\n",
      "chunk number: 1286 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3704 - acc: 0.8584\n",
      "chunk number: 1287 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4021 - acc: 0.8457\n",
      "chunk number: 1288 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3770 - acc: 0.8594\n",
      "chunk number: 1289 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3393 - acc: 0.8730\n",
      "chunk number: 1290 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3560 - acc: 0.8545\n",
      "chunk number: 1291 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4151 - acc: 0.8428\n",
      "chunk number: 1292 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3841 - acc: 0.8535\n",
      "chunk number: 1293 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3777 - acc: 0.8516\n",
      "chunk number: 1294 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3460 - acc: 0.8770\n",
      "chunk number: 1295 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3503 - acc: 0.8662\n",
      "chunk number: 1296 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3975 - acc: 0.8369\n",
      "chunk number: 1297 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3568 - acc: 0.8633\n",
      "chunk number: 1298 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3891 - acc: 0.8594\n",
      "chunk number: 1299 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3439 - acc: 0.8662\n",
      "chunk number: 1300 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3718 - acc: 0.8574\n",
      "chunk number: 1301 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3384 - acc: 0.8623\n",
      "chunk number: 1302 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4148 - acc: 0.8418\n",
      "chunk number: 1303 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3586 - acc: 0.8535\n",
      "chunk number: 1304 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3641 - acc: 0.8604\n",
      "chunk number: 1305 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4255 - acc: 0.8232\n",
      "chunk number: 1306 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3922 - acc: 0.8545\n",
      "chunk number: 1307 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3928 - acc: 0.8555\n",
      "chunk number: 1308 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3687 - acc: 0.8613\n",
      "chunk number: 1309 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3488 - acc: 0.8701\n",
      "chunk number: 1310 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3908 - acc: 0.8574\n",
      "chunk number: 1311 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4468 - acc: 0.8301\n",
      "chunk number: 1312 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4403 - acc: 0.8340\n",
      "chunk number: 1313 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3749 - acc: 0.8496\n",
      "chunk number: 1314 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4203 - acc: 0.8496\n",
      "chunk number: 1315 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4364 - acc: 0.8311\n",
      "chunk number: 1316 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3718 - acc: 0.8682\n",
      "chunk number: 1317 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3775 - acc: 0.8477\n",
      "chunk number: 1318 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3928 - acc: 0.8467\n",
      "chunk number: 1319 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3873 - acc: 0.8535\n",
      "chunk number: 1320 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4425 - acc: 0.8311\n",
      "chunk number: 1321 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3695 - acc: 0.8545\n",
      "chunk number: 1322 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3942 - acc: 0.8555\n",
      "chunk number: 1323 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3850 - acc: 0.8594\n",
      "chunk number: 1324 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3993 - acc: 0.8418\n",
      "chunk number: 1325 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3300 - acc: 0.8633\n",
      "chunk number: 1326 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3849 - acc: 0.8467\n",
      "chunk number: 1327 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3868 - acc: 0.8594\n",
      "chunk number: 1328 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4123 - acc: 0.8525\n",
      "chunk number: 1329 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4163 - acc: 0.8496\n",
      "chunk number: 1330 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4091 - acc: 0.8389\n",
      "chunk number: 1331 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3811 - acc: 0.8564\n",
      "chunk number: 1332 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3854 - acc: 0.8545\n",
      "chunk number: 1333 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3826 - acc: 0.8447\n",
      "chunk number: 1334 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3771 - acc: 0.8604\n",
      "chunk number: 1335 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3676 - acc: 0.8555\n",
      "chunk number: 1336 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4355 - acc: 0.8398\n",
      "chunk number: 1337 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4075 - acc: 0.8467\n",
      "chunk number: 1338 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3912 - acc: 0.8535\n",
      "chunk number: 1339 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3558 - acc: 0.8789\n",
      "chunk number: 1340 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4175 - acc: 0.8369\n",
      "chunk number: 1341 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3352 - acc: 0.8682\n",
      "chunk number: 1342 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3873 - acc: 0.8506\n",
      "chunk number: 1343 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4185 - acc: 0.8301\n",
      "chunk number: 1344 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3745 - acc: 0.8682\n",
      "chunk number: 1345 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3834 - acc: 0.8467\n",
      "chunk number: 1346 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4209 - acc: 0.8350\n",
      "chunk number: 1347 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3688 - acc: 0.8545\n",
      "chunk number: 1348 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3795 - acc: 0.8496\n",
      "chunk number: 1349 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3417 - acc: 0.8652\n",
      "chunk number: 1350 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3833 - acc: 0.8584\n",
      "chunk number: 1351 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3807 - acc: 0.8496\n",
      "chunk number: 1352 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3665 - acc: 0.8584\n",
      "chunk number: 1353 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4303 - acc: 0.8311\n",
      "chunk number: 1354 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3846 - acc: 0.8467\n",
      "chunk number: 1355 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3713 - acc: 0.8477\n",
      "chunk number: 1356 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3609 - acc: 0.8516\n",
      "chunk number: 1357 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3595 - acc: 0.8643\n",
      "chunk number: 1358 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3380 - acc: 0.8770\n",
      "chunk number: 1359 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3550 - acc: 0.8672\n",
      "chunk number: 1360 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4124 - acc: 0.8369\n",
      "chunk number: 1361 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3499 - acc: 0.8721\n",
      "chunk number: 1362 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4090 - acc: 0.8467\n",
      "chunk number: 1363 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4396 - acc: 0.8320\n",
      "chunk number: 1364 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3425 - acc: 0.8633\n",
      "chunk number: 1365 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4160 - acc: 0.8457\n",
      "chunk number: 1366 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4143 - acc: 0.8467\n",
      "chunk number: 1367 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3708 - acc: 0.8574\n",
      "chunk number: 1368 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4025 - acc: 0.8525\n",
      "chunk number: 1369 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3671 - acc: 0.8584\n",
      "chunk number: 1370 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3899 - acc: 0.8525\n",
      "chunk number: 1371 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4095 - acc: 0.8545\n",
      "chunk number: 1372 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4186 - acc: 0.8398\n",
      "chunk number: 1373 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4025 - acc: 0.8369\n",
      "chunk number: 1374 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4280 - acc: 0.8496\n",
      "chunk number: 1375 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3645 - acc: 0.8672\n",
      "chunk number: 1376 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3755 - acc: 0.8623\n",
      "chunk number: 1377 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3738 - acc: 0.8525\n",
      "chunk number: 1378 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3631 - acc: 0.8594\n",
      "chunk number: 1379 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4026 - acc: 0.8477\n",
      "chunk number: 1380 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3781 - acc: 0.8672\n",
      "chunk number: 1381 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4035 - acc: 0.8389\n",
      "chunk number: 1382 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3719 - acc: 0.8623\n",
      "chunk number: 1383 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3809 - acc: 0.8516\n",
      "chunk number: 1384 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3850 - acc: 0.8496\n",
      "chunk number: 1385 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4056 - acc: 0.8506\n",
      "chunk number: 1386 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3637 - acc: 0.8643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 1387 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3846 - acc: 0.8477\n",
      "chunk number: 1388 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3446 - acc: 0.8633\n",
      "chunk number: 1389 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3525 - acc: 0.8691\n",
      "chunk number: 1390 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3474 - acc: 0.8643\n",
      "chunk number: 1391 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4009 - acc: 0.8496\n",
      "chunk number: 1392 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3678 - acc: 0.8584\n",
      "chunk number: 1393 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3502 - acc: 0.8574\n",
      "chunk number: 1394 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3211 - acc: 0.8682\n",
      "chunk number: 1395 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3246 - acc: 0.8789\n",
      "chunk number: 1396 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3876 - acc: 0.8428\n",
      "chunk number: 1397 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3555 - acc: 0.8633\n",
      "chunk number: 1398 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3953 - acc: 0.8516\n",
      "chunk number: 1399 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3484 - acc: 0.8613\n",
      "chunk number: 1400 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3843 - acc: 0.8457\n",
      "chunk number: 1401 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3853 - acc: 0.8633\n",
      "chunk number: 1402 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4206 - acc: 0.8359\n",
      "chunk number: 1403 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3541 - acc: 0.8662\n",
      "chunk number: 1404 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3871 - acc: 0.8545\n",
      "chunk number: 1405 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3794 - acc: 0.8457\n",
      "chunk number: 1406 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3542 - acc: 0.8643\n",
      "chunk number: 1407 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3459 - acc: 0.8662\n",
      "chunk number: 1408 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3588 - acc: 0.8564\n",
      "chunk number: 1409 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3485 - acc: 0.8770\n",
      "chunk number: 1410 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3630 - acc: 0.8613\n",
      "chunk number: 1411 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3988 - acc: 0.8486\n",
      "chunk number: 1412 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4267 - acc: 0.8330\n",
      "chunk number: 1413 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3933 - acc: 0.8545\n",
      "chunk number: 1414 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3827 - acc: 0.8701\n",
      "chunk number: 1415 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3633 - acc: 0.8574\n",
      "chunk number: 1416 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3601 - acc: 0.8643\n",
      "chunk number: 1417 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3951 - acc: 0.8330\n",
      "chunk number: 1418 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3766 - acc: 0.8623\n",
      "chunk number: 1419 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3723 - acc: 0.8535\n",
      "chunk number: 1420 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4022 - acc: 0.8506\n",
      "chunk number: 1421 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3516 - acc: 0.8633\n",
      "chunk number: 1422 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3718 - acc: 0.8496\n",
      "chunk number: 1423 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4001 - acc: 0.8564\n",
      "chunk number: 1424 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4124 - acc: 0.8330\n",
      "chunk number: 1425 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3414 - acc: 0.8633\n",
      "chunk number: 1426 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4167 - acc: 0.8359\n",
      "chunk number: 1427 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3692 - acc: 0.8643\n",
      "chunk number: 1428 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3910 - acc: 0.8535\n",
      "chunk number: 1429 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3985 - acc: 0.8369\n",
      "chunk number: 1430 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3998 - acc: 0.8428\n",
      "chunk number: 1431 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3539 - acc: 0.8574\n",
      "chunk number: 1432 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4051 - acc: 0.8486\n",
      "chunk number: 1433 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3671 - acc: 0.8633\n",
      "chunk number: 1434 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3903 - acc: 0.8467\n",
      "chunk number: 1435 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3558 - acc: 0.8711\n",
      "chunk number: 1436 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4074 - acc: 0.8506\n",
      "chunk number: 1437 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3902 - acc: 0.8408\n",
      "chunk number: 1438 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3780 - acc: 0.8584\n",
      "chunk number: 1439 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3854 - acc: 0.8506\n",
      "chunk number: 1440 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3757 - acc: 0.8447\n",
      "chunk number: 1441 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3602 - acc: 0.8574\n",
      "chunk number: 1442 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3599 - acc: 0.8672\n",
      "chunk number: 1443 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3440 - acc: 0.8652\n",
      "chunk number: 1444 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3604 - acc: 0.8711\n",
      "chunk number: 1445 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3675 - acc: 0.8604\n",
      "chunk number: 1446 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4103 - acc: 0.8447\n",
      "chunk number: 1447 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3537 - acc: 0.8613\n",
      "chunk number: 1448 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3798 - acc: 0.8457\n",
      "chunk number: 1449 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3280 - acc: 0.8740\n",
      "chunk number: 1450 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3813 - acc: 0.8438\n",
      "chunk number: 1451 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3885 - acc: 0.8525\n",
      "chunk number: 1452 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3765 - acc: 0.8613\n",
      "chunk number: 1453 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4207 - acc: 0.8350\n",
      "chunk number: 1454 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3718 - acc: 0.8545\n",
      "chunk number: 1455 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4047 - acc: 0.8359\n",
      "chunk number: 1456 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3696 - acc: 0.8506\n",
      "chunk number: 1457 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3474 - acc: 0.8662\n",
      "chunk number: 1458 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3572 - acc: 0.8701\n",
      "chunk number: 1459 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3620 - acc: 0.8662\n",
      "chunk number: 1460 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3977 - acc: 0.8506\n",
      "chunk number: 1461 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3376 - acc: 0.8770\n",
      "chunk number: 1462 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3763 - acc: 0.8525\n",
      "chunk number: 1463 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4358 - acc: 0.8262\n",
      "chunk number: 1464 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3584 - acc: 0.8564\n",
      "chunk number: 1465 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4096 - acc: 0.8467\n",
      "chunk number: 1466 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3678 - acc: 0.8477\n",
      "chunk number: 1467 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3650 - acc: 0.8633\n",
      "chunk number: 1468 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3910 - acc: 0.8555\n",
      "chunk number: 1469 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3557 - acc: 0.8535\n",
      "chunk number: 1470 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3731 - acc: 0.8574\n",
      "chunk number: 1471 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3747 - acc: 0.8564\n",
      "chunk number: 1472 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3984 - acc: 0.8438\n",
      "chunk number: 1473 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3594 - acc: 0.8691\n",
      "chunk number: 1474 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3667 - acc: 0.8564\n",
      "chunk number: 1475 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3646 - acc: 0.8574\n",
      "chunk number: 1476 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3364 - acc: 0.8574\n",
      "chunk number: 1477 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3265 - acc: 0.8691\n",
      "chunk number: 1478 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3501 - acc: 0.8604\n",
      "chunk number: 1479 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4092 - acc: 0.8545\n",
      "chunk number: 1480 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3510 - acc: 0.8818\n",
      "chunk number: 1481 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3749 - acc: 0.8486\n",
      "chunk number: 1482 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3598 - acc: 0.8594\n",
      "chunk number: 1483 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3556 - acc: 0.8662\n",
      "chunk number: 1484 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3393 - acc: 0.8555\n",
      "chunk number: 1485 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3735 - acc: 0.8574\n",
      "chunk number: 1486 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3448 - acc: 0.8662\n",
      "chunk number: 1487 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4103 - acc: 0.8389\n",
      "chunk number: 1488 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3377 - acc: 0.8652\n",
      "chunk number: 1489 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3212 - acc: 0.8721\n",
      "chunk number: 1490 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3391 - acc: 0.8672\n",
      "chunk number: 1491 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3805 - acc: 0.8516\n",
      "chunk number: 1492 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3362 - acc: 0.8721\n",
      "chunk number: 1493 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3453 - acc: 0.8721\n",
      "chunk number: 1494 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3187 - acc: 0.8779\n",
      "chunk number: 1495 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3202 - acc: 0.8809\n",
      "chunk number: 1496 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3584 - acc: 0.8613\n",
      "chunk number: 1497 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3484 - acc: 0.8770\n",
      "chunk number: 1498 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3680 - acc: 0.8525\n",
      "chunk number: 1499 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3526 - acc: 0.8516\n",
      "chunk number: 1500 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3770 - acc: 0.8574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 1501 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3537 - acc: 0.8711\n",
      "chunk number: 1502 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3801 - acc: 0.8506\n",
      "chunk number: 1503 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3354 - acc: 0.8750\n",
      "chunk number: 1504 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3593 - acc: 0.8604\n",
      "chunk number: 1505 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3494 - acc: 0.8701\n",
      "chunk number: 1506 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3443 - acc: 0.8770\n",
      "chunk number: 1507 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3715 - acc: 0.8604\n",
      "chunk number: 1508 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3490 - acc: 0.8721\n",
      "chunk number: 1509 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3351 - acc: 0.8809\n",
      "chunk number: 1510 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3783 - acc: 0.8545\n",
      "chunk number: 1511 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3989 - acc: 0.8486\n",
      "chunk number: 1512 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3829 - acc: 0.8467\n",
      "chunk number: 1513 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3598 - acc: 0.8662\n",
      "chunk number: 1514 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3917 - acc: 0.8525\n",
      "chunk number: 1515 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3867 - acc: 0.8535\n",
      "chunk number: 1516 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3438 - acc: 0.8652\n",
      "chunk number: 1517 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3544 - acc: 0.8613\n",
      "chunk number: 1518 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4001 - acc: 0.8516\n",
      "chunk number: 1519 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3649 - acc: 0.8516\n",
      "chunk number: 1520 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3884 - acc: 0.8477\n",
      "chunk number: 1521 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3496 - acc: 0.8555\n",
      "chunk number: 1522 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3488 - acc: 0.8564\n",
      "chunk number: 1523 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3688 - acc: 0.8672\n",
      "chunk number: 1524 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3888 - acc: 0.8525\n",
      "chunk number: 1525 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3440 - acc: 0.8691\n",
      "chunk number: 1526 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3866 - acc: 0.8506\n",
      "chunk number: 1527 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4117 - acc: 0.8467\n",
      "chunk number: 1528 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3658 - acc: 0.8584\n",
      "chunk number: 1529 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4161 - acc: 0.8438\n",
      "chunk number: 1530 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3792 - acc: 0.8594\n",
      "chunk number: 1531 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3501 - acc: 0.8574\n",
      "chunk number: 1532 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3781 - acc: 0.8574\n",
      "chunk number: 1533 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3436 - acc: 0.8623\n",
      "chunk number: 1534 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3787 - acc: 0.8604\n",
      "chunk number: 1535 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3587 - acc: 0.8623\n",
      "chunk number: 1536 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3742 - acc: 0.8584\n",
      "chunk number: 1537 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3673 - acc: 0.8604\n",
      "chunk number: 1538 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3656 - acc: 0.8633\n",
      "chunk number: 1539 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3589 - acc: 0.8652\n",
      "chunk number: 1540 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3800 - acc: 0.8428\n",
      "chunk number: 1541 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3126 - acc: 0.8721\n",
      "chunk number: 1542 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3420 - acc: 0.8623\n",
      "chunk number: 1543 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3744 - acc: 0.8594\n",
      "chunk number: 1544 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3577 - acc: 0.8604\n",
      "chunk number: 1545 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3883 - acc: 0.8408\n",
      "chunk number: 1546 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3783 - acc: 0.8418\n",
      "chunk number: 1547 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3461 - acc: 0.8604\n",
      "chunk number: 1548 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3360 - acc: 0.8672\n",
      "chunk number: 1549 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3455 - acc: 0.8652\n",
      "chunk number: 1550 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3686 - acc: 0.8389\n",
      "chunk number: 1551 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3900 - acc: 0.8584\n",
      "chunk number: 1552 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3885 - acc: 0.8496\n",
      "chunk number: 1553 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4390 - acc: 0.8223\n",
      "chunk number: 1554 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3891 - acc: 0.8467\n",
      "chunk number: 1555 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3658 - acc: 0.8555\n",
      "chunk number: 1556 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3905 - acc: 0.8486\n",
      "chunk number: 1557 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3267 - acc: 0.8789\n",
      "chunk number: 1558 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3268 - acc: 0.8730\n",
      "chunk number: 1559 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3601 - acc: 0.8662\n",
      "chunk number: 1560 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3673 - acc: 0.8633\n",
      "chunk number: 1561 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3533 - acc: 0.8691\n",
      "chunk number: 1562 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3799 - acc: 0.8662\n",
      "chunk number: 1563 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4299 - acc: 0.8398\n",
      "chunk number: 1564 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3403 - acc: 0.8770\n",
      "chunk number: 1565 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3804 - acc: 0.8506\n",
      "chunk number: 1566 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3707 - acc: 0.8574\n",
      "chunk number: 1567 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3739 - acc: 0.8574\n",
      "chunk number: 1568 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3821 - acc: 0.8594\n",
      "chunk number: 1569 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3690 - acc: 0.8477\n",
      "chunk number: 1570 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3854 - acc: 0.8555\n",
      "chunk number: 1571 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3718 - acc: 0.8525\n",
      "chunk number: 1572 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3979 - acc: 0.8467\n",
      "chunk number: 1573 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3729 - acc: 0.8613\n",
      "chunk number: 1574 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4035 - acc: 0.8428\n",
      "chunk number: 1575 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4021 - acc: 0.8535\n",
      "chunk number: 1576 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3305 - acc: 0.8838\n",
      "chunk number: 1577 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3109 - acc: 0.8838\n",
      "chunk number: 1578 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3704 - acc: 0.8447\n",
      "chunk number: 1579 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3680 - acc: 0.8613\n",
      "chunk number: 1580 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3499 - acc: 0.8701\n",
      "chunk number: 1581 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3498 - acc: 0.8711\n",
      "chunk number: 1582 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3357 - acc: 0.8662\n",
      "chunk number: 1583 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3640 - acc: 0.8613\n",
      "chunk number: 1584 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3504 - acc: 0.8613\n",
      "chunk number: 1585 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3762 - acc: 0.8584\n",
      "chunk number: 1586 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3344 - acc: 0.8701\n",
      "chunk number: 1587 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3913 - acc: 0.8506\n",
      "chunk number: 1588 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3419 - acc: 0.8711\n",
      "chunk number: 1589 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3243 - acc: 0.8867\n",
      "chunk number: 1590 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3226 - acc: 0.8818\n",
      "chunk number: 1591 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3866 - acc: 0.8564\n",
      "chunk number: 1592 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3734 - acc: 0.8594\n",
      "chunk number: 1593 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3203 - acc: 0.8691\n",
      "chunk number: 1594 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2841 - acc: 0.8916\n",
      "chunk number: 1595 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2955 - acc: 0.8926\n",
      "chunk number: 1596 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3329 - acc: 0.8750\n",
      "chunk number: 1597 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2992 - acc: 0.8848\n",
      "chunk number: 1598 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3915 - acc: 0.8594\n",
      "chunk number: 1599 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3140 - acc: 0.8672\n",
      "chunk number: 1600 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3438 - acc: 0.8604\n",
      "chunk number: 1601 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3324 - acc: 0.8721\n",
      "chunk number: 1602 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4123 - acc: 0.8545\n",
      "chunk number: 1603 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3544 - acc: 0.8574\n",
      "chunk number: 1604 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3413 - acc: 0.8828\n",
      "chunk number: 1605 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3665 - acc: 0.8555\n",
      "chunk number: 1606 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3347 - acc: 0.8643\n",
      "chunk number: 1607 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3765 - acc: 0.8574\n",
      "chunk number: 1608 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3419 - acc: 0.8652\n",
      "chunk number: 1609 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3123 - acc: 0.8955\n",
      "chunk number: 1610 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3537 - acc: 0.8643\n",
      "chunk number: 1611 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4078 - acc: 0.8379\n",
      "chunk number: 1612 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3953 - acc: 0.8535\n",
      "chunk number: 1613 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3771 - acc: 0.8555\n",
      "chunk number: 1614 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3699 - acc: 0.8545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 1615 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3800 - acc: 0.8496\n",
      "chunk number: 1616 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3318 - acc: 0.8623\n",
      "chunk number: 1617 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3554 - acc: 0.8584\n",
      "chunk number: 1618 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3840 - acc: 0.8525\n",
      "chunk number: 1619 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3523 - acc: 0.8691\n",
      "chunk number: 1620 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3477 - acc: 0.8584\n",
      "chunk number: 1621 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3605 - acc: 0.8555\n",
      "chunk number: 1622 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3616 - acc: 0.8604\n",
      "chunk number: 1623 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3773 - acc: 0.8701\n",
      "chunk number: 1624 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3980 - acc: 0.8545\n",
      "chunk number: 1625 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3144 - acc: 0.8740\n",
      "chunk number: 1626 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3714 - acc: 0.8457\n",
      "chunk number: 1627 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3760 - acc: 0.8584\n",
      "chunk number: 1628 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3599 - acc: 0.8711\n",
      "chunk number: 1629 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3655 - acc: 0.8584\n",
      "chunk number: 1630 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3602 - acc: 0.8594\n",
      "chunk number: 1631 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3546 - acc: 0.8457\n",
      "chunk number: 1632 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3674 - acc: 0.8633\n",
      "chunk number: 1633 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3529 - acc: 0.8574\n",
      "chunk number: 1634 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3702 - acc: 0.8555\n",
      "chunk number: 1635 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3200 - acc: 0.8711\n",
      "chunk number: 1636 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3838 - acc: 0.8574\n",
      "chunk number: 1637 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3616 - acc: 0.8584\n",
      "chunk number: 1638 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3404 - acc: 0.8779\n",
      "chunk number: 1639 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3799 - acc: 0.8486\n",
      "chunk number: 1640 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3774 - acc: 0.8467\n",
      "chunk number: 1641 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3208 - acc: 0.8770\n",
      "chunk number: 1642 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3286 - acc: 0.8809\n",
      "chunk number: 1643 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3596 - acc: 0.8652\n",
      "chunk number: 1644 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3418 - acc: 0.8809\n",
      "chunk number: 1645 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3469 - acc: 0.8633\n",
      "chunk number: 1646 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4096 - acc: 0.8584\n",
      "chunk number: 1647 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3217 - acc: 0.8760\n",
      "chunk number: 1648 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3723 - acc: 0.8545\n",
      "chunk number: 1649 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3338 - acc: 0.8672\n",
      "chunk number: 1650 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3827 - acc: 0.8486\n",
      "chunk number: 1651 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3518 - acc: 0.8584\n",
      "chunk number: 1652 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3456 - acc: 0.8604\n",
      "chunk number: 1653 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3871 - acc: 0.8545\n",
      "chunk number: 1654 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3608 - acc: 0.8594\n",
      "chunk number: 1655 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3565 - acc: 0.8594\n",
      "chunk number: 1656 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3471 - acc: 0.8740\n",
      "chunk number: 1657 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3054 - acc: 0.8779\n",
      "chunk number: 1658 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3509 - acc: 0.8750\n",
      "chunk number: 1659 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3344 - acc: 0.8760\n",
      "chunk number: 1660 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3790 - acc: 0.8516\n",
      "chunk number: 1661 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3362 - acc: 0.8809\n",
      "chunk number: 1662 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3511 - acc: 0.8682\n",
      "chunk number: 1663 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4332 - acc: 0.8340\n",
      "chunk number: 1664 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3342 - acc: 0.8564\n",
      "chunk number: 1665 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4016 - acc: 0.8389\n",
      "chunk number: 1666 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3767 - acc: 0.8496\n",
      "chunk number: 1667 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3583 - acc: 0.8652\n",
      "chunk number: 1668 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3616 - acc: 0.8555\n",
      "chunk number: 1669 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4000 - acc: 0.8389\n",
      "chunk number: 1670 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3589 - acc: 0.8682\n",
      "chunk number: 1671 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3487 - acc: 0.8672\n",
      "chunk number: 1672 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3691 - acc: 0.8574\n",
      "chunk number: 1673 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3550 - acc: 0.8652\n",
      "chunk number: 1674 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3949 - acc: 0.8545\n",
      "chunk number: 1675 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3707 - acc: 0.8643\n",
      "chunk number: 1676 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3331 - acc: 0.8711\n",
      "chunk number: 1677 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3489 - acc: 0.8643\n",
      "chunk number: 1678 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3403 - acc: 0.8652\n",
      "chunk number: 1679 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3537 - acc: 0.8594\n",
      "chunk number: 1680 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3675 - acc: 0.8623\n",
      "chunk number: 1681 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3557 - acc: 0.8643\n",
      "chunk number: 1682 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3587 - acc: 0.8359\n",
      "chunk number: 1683 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3668 - acc: 0.8672\n",
      "chunk number: 1684 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3640 - acc: 0.8545\n",
      "chunk number: 1685 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3618 - acc: 0.8555\n",
      "chunk number: 1686 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3459 - acc: 0.8652\n",
      "chunk number: 1687 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3638 - acc: 0.8750\n",
      "chunk number: 1688 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3312 - acc: 0.8760\n",
      "chunk number: 1689 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3023 - acc: 0.8750\n",
      "chunk number: 1690 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3111 - acc: 0.8779\n",
      "chunk number: 1691 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3686 - acc: 0.8643\n",
      "chunk number: 1692 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3414 - acc: 0.8613\n",
      "chunk number: 1693 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3557 - acc: 0.8584\n",
      "chunk number: 1694 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3341 - acc: 0.8867\n",
      "chunk number: 1695 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2917 - acc: 0.8828\n",
      "chunk number: 1696 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3614 - acc: 0.8555\n",
      "chunk number: 1697 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2986 - acc: 0.8779\n",
      "chunk number: 1698 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3411 - acc: 0.8682\n",
      "chunk number: 1699 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3230 - acc: 0.8750\n",
      "chunk number: 1700 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3601 - acc: 0.8594\n",
      "chunk number: 1701 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3317 - acc: 0.8721\n",
      "chunk number: 1702 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3955 - acc: 0.8584\n",
      "chunk number: 1703 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3500 - acc: 0.8574\n",
      "chunk number: 1704 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3241 - acc: 0.8740\n",
      "chunk number: 1705 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3398 - acc: 0.8623\n",
      "chunk number: 1706 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2972 - acc: 0.8809\n",
      "chunk number: 1707 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3424 - acc: 0.8701\n",
      "chunk number: 1708 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3381 - acc: 0.8701\n",
      "chunk number: 1709 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3648 - acc: 0.8682\n",
      "chunk number: 1710 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3229 - acc: 0.8799\n",
      "chunk number: 1711 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3643 - acc: 0.8516\n",
      "chunk number: 1712 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3809 - acc: 0.8506\n",
      "chunk number: 1713 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3501 - acc: 0.8623\n",
      "chunk number: 1714 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3856 - acc: 0.8584\n",
      "chunk number: 1715 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4208 - acc: 0.8457\n",
      "chunk number: 1716 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3345 - acc: 0.8721\n",
      "chunk number: 1717 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3736 - acc: 0.8496\n",
      "chunk number: 1718 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3836 - acc: 0.8408\n",
      "chunk number: 1719 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3573 - acc: 0.8652\n",
      "chunk number: 1720 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3565 - acc: 0.8740\n",
      "chunk number: 1721 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3006 - acc: 0.8838\n",
      "chunk number: 1722 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3405 - acc: 0.8760\n",
      "chunk number: 1723 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3597 - acc: 0.8721\n",
      "chunk number: 1724 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3862 - acc: 0.8320\n",
      "chunk number: 1725 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3048 - acc: 0.8818\n",
      "chunk number: 1726 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3649 - acc: 0.8506\n",
      "chunk number: 1727 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3378 - acc: 0.8545\n",
      "chunk number: 1728 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3642 - acc: 0.8604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 1729 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3667 - acc: 0.8457\n",
      "chunk number: 1730 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3590 - acc: 0.8594\n",
      "chunk number: 1731 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3488 - acc: 0.8662\n",
      "chunk number: 1732 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3478 - acc: 0.8701\n",
      "chunk number: 1733 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3548 - acc: 0.8662\n",
      "chunk number: 1734 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3281 - acc: 0.8750\n",
      "chunk number: 1735 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3317 - acc: 0.8770\n",
      "chunk number: 1736 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4206 - acc: 0.8369\n",
      "chunk number: 1737 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3897 - acc: 0.8486\n",
      "chunk number: 1738 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3748 - acc: 0.8604\n",
      "chunk number: 1739 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3475 - acc: 0.8682\n",
      "chunk number: 1740 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3749 - acc: 0.8604\n",
      "chunk number: 1741 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3512 - acc: 0.8623\n",
      "chunk number: 1742 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3312 - acc: 0.8633\n",
      "chunk number: 1743 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3448 - acc: 0.8672\n",
      "chunk number: 1744 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3420 - acc: 0.8682\n",
      "chunk number: 1745 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3260 - acc: 0.8672\n",
      "chunk number: 1746 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3525 - acc: 0.8672\n",
      "chunk number: 1747 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3161 - acc: 0.8799\n",
      "chunk number: 1748 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3620 - acc: 0.8535\n",
      "chunk number: 1749 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3266 - acc: 0.8623\n",
      "chunk number: 1750 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3599 - acc: 0.8623\n",
      "chunk number: 1751 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3623 - acc: 0.8516\n",
      "chunk number: 1752 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3502 - acc: 0.8584\n",
      "chunk number: 1753 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3703 - acc: 0.8564\n",
      "chunk number: 1754 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3758 - acc: 0.8545\n",
      "chunk number: 1755 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3532 - acc: 0.8770\n",
      "chunk number: 1756 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3308 - acc: 0.8750\n",
      "chunk number: 1757 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3043 - acc: 0.8896\n",
      "chunk number: 1758 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3367 - acc: 0.8701\n",
      "chunk number: 1759 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3293 - acc: 0.8809\n",
      "chunk number: 1760 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3869 - acc: 0.8613\n",
      "chunk number: 1761 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3219 - acc: 0.8828\n",
      "chunk number: 1762 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3407 - acc: 0.8652\n",
      "chunk number: 1763 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4118 - acc: 0.8428\n",
      "chunk number: 1764 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3162 - acc: 0.8828\n",
      "chunk number: 1765 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3669 - acc: 0.8623\n",
      "chunk number: 1766 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3713 - acc: 0.8535\n",
      "chunk number: 1767 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3489 - acc: 0.8682\n",
      "chunk number: 1768 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3544 - acc: 0.8643\n",
      "chunk number: 1769 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3450 - acc: 0.8691\n",
      "chunk number: 1770 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3319 - acc: 0.8721\n",
      "chunk number: 1771 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3818 - acc: 0.8535\n",
      "chunk number: 1772 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3642 - acc: 0.8604\n",
      "chunk number: 1773 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3596 - acc: 0.8633\n",
      "chunk number: 1774 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3921 - acc: 0.8594\n",
      "chunk number: 1775 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3419 - acc: 0.8701\n",
      "chunk number: 1776 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3329 - acc: 0.8682\n",
      "chunk number: 1777 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3383 - acc: 0.8584\n",
      "chunk number: 1778 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3282 - acc: 0.8613\n",
      "chunk number: 1779 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3322 - acc: 0.8623\n",
      "chunk number: 1780 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3455 - acc: 0.8760\n",
      "chunk number: 1781 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3645 - acc: 0.8486\n",
      "chunk number: 1782 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3277 - acc: 0.8652\n",
      "chunk number: 1783 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3400 - acc: 0.8691\n",
      "chunk number: 1784 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3283 - acc: 0.8701\n",
      "chunk number: 1785 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3604 - acc: 0.8682\n",
      "chunk number: 1786 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3264 - acc: 0.8672\n",
      "chunk number: 1787 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3755 - acc: 0.8662\n",
      "chunk number: 1788 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3133 - acc: 0.8760\n",
      "chunk number: 1789 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3245 - acc: 0.8691\n",
      "chunk number: 1790 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3143 - acc: 0.8809\n",
      "chunk number: 1791 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3776 - acc: 0.8545\n",
      "chunk number: 1792 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3388 - acc: 0.8643\n",
      "chunk number: 1793 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3103 - acc: 0.8750\n",
      "chunk number: 1794 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2781 - acc: 0.8936\n",
      "chunk number: 1795 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2575 - acc: 0.9004\n",
      "chunk number: 1796 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3224 - acc: 0.8887\n",
      "chunk number: 1797 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3417 - acc: 0.8691\n",
      "chunk number: 1798 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3719 - acc: 0.8545\n",
      "chunk number: 1799 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3128 - acc: 0.8682\n",
      "chunk number: 1800 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3584 - acc: 0.8623\n",
      "chunk number: 1801 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2957 - acc: 0.8857\n",
      "chunk number: 1802 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3423 - acc: 0.8721\n",
      "chunk number: 1803 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3031 - acc: 0.8838\n",
      "chunk number: 1804 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3315 - acc: 0.8828\n",
      "chunk number: 1805 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3372 - acc: 0.8633\n",
      "chunk number: 1806 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3044 - acc: 0.8789\n",
      "chunk number: 1807 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3529 - acc: 0.8613\n",
      "chunk number: 1808 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3140 - acc: 0.8799\n",
      "chunk number: 1809 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3249 - acc: 0.8799\n",
      "chunk number: 1810 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3392 - acc: 0.8691\n",
      "chunk number: 1811 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3916 - acc: 0.8447\n",
      "chunk number: 1812 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3755 - acc: 0.8584\n",
      "chunk number: 1813 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3438 - acc: 0.8682\n",
      "chunk number: 1814 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3665 - acc: 0.8691\n",
      "chunk number: 1815 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3391 - acc: 0.8682\n",
      "chunk number: 1816 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3476 - acc: 0.8740\n",
      "chunk number: 1817 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3279 - acc: 0.8662\n",
      "chunk number: 1818 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3700 - acc: 0.8574\n",
      "chunk number: 1819 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3570 - acc: 0.8613\n",
      "chunk number: 1820 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3550 - acc: 0.8662\n",
      "chunk number: 1821 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3168 - acc: 0.8779\n",
      "chunk number: 1822 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3066 - acc: 0.8750\n",
      "chunk number: 1823 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3384 - acc: 0.8799\n",
      "chunk number: 1824 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3754 - acc: 0.8594\n",
      "chunk number: 1825 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3322 - acc: 0.8682\n",
      "chunk number: 1826 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3438 - acc: 0.8633\n",
      "chunk number: 1827 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3263 - acc: 0.8584\n",
      "chunk number: 1828 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3403 - acc: 0.8643\n",
      "chunk number: 1829 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3588 - acc: 0.8623\n",
      "chunk number: 1830 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3387 - acc: 0.8613\n",
      "chunk number: 1831 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3350 - acc: 0.8770\n",
      "chunk number: 1832 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3354 - acc: 0.8789\n",
      "chunk number: 1833 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3313 - acc: 0.8740\n",
      "chunk number: 1834 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3379 - acc: 0.8730\n",
      "chunk number: 1835 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3368 - acc: 0.8857\n",
      "chunk number: 1836 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3732 - acc: 0.8623\n",
      "chunk number: 1837 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3820 - acc: 0.8418\n",
      "chunk number: 1838 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3388 - acc: 0.8711\n",
      "chunk number: 1839 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3808 - acc: 0.8477\n",
      "chunk number: 1840 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3562 - acc: 0.8604\n",
      "chunk number: 1841 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3399 - acc: 0.8604\n",
      "chunk number: 1842 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3604 - acc: 0.8711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 1843 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3238 - acc: 0.8809\n",
      "chunk number: 1844 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3124 - acc: 0.8789\n",
      "chunk number: 1845 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3366 - acc: 0.8662\n",
      "chunk number: 1846 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3638 - acc: 0.8711\n",
      "chunk number: 1847 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3195 - acc: 0.8730\n",
      "chunk number: 1848 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3396 - acc: 0.8633\n",
      "chunk number: 1849 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2974 - acc: 0.8838\n",
      "chunk number: 1850 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3259 - acc: 0.8623\n",
      "chunk number: 1851 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3308 - acc: 0.8789\n",
      "chunk number: 1852 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3124 - acc: 0.8887\n",
      "chunk number: 1853 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3799 - acc: 0.8584\n",
      "chunk number: 1854 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3317 - acc: 0.8770\n",
      "chunk number: 1855 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3228 - acc: 0.8730\n",
      "chunk number: 1856 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3714 - acc: 0.8594\n",
      "chunk number: 1857 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3142 - acc: 0.8848\n",
      "chunk number: 1858 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2805 - acc: 0.8965\n",
      "chunk number: 1859 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3164 - acc: 0.8799\n",
      "chunk number: 1860 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3468 - acc: 0.8701\n",
      "chunk number: 1861 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3185 - acc: 0.8896\n",
      "chunk number: 1862 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3445 - acc: 0.8789\n",
      "chunk number: 1863 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.4146 - acc: 0.8398\n",
      "chunk number: 1864 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3023 - acc: 0.8906\n",
      "chunk number: 1865 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3682 - acc: 0.8682\n",
      "chunk number: 1866 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3495 - acc: 0.8701\n",
      "chunk number: 1867 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3406 - acc: 0.8818\n",
      "chunk number: 1868 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3617 - acc: 0.8555\n",
      "chunk number: 1869 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3188 - acc: 0.8633\n",
      "chunk number: 1870 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3197 - acc: 0.8779\n",
      "chunk number: 1871 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3211 - acc: 0.8760\n",
      "chunk number: 1872 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3716 - acc: 0.8555\n",
      "chunk number: 1873 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3594 - acc: 0.8506\n",
      "chunk number: 1874 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3660 - acc: 0.8633\n",
      "chunk number: 1875 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3661 - acc: 0.8643\n",
      "chunk number: 1876 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3681 - acc: 0.8672\n",
      "chunk number: 1877 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3230 - acc: 0.8750\n",
      "chunk number: 1878 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3304 - acc: 0.8652\n",
      "chunk number: 1879 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3645 - acc: 0.8525\n",
      "chunk number: 1880 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3187 - acc: 0.8848\n",
      "chunk number: 1881 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3515 - acc: 0.8721\n",
      "chunk number: 1882 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3367 - acc: 0.8652\n",
      "chunk number: 1883 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3326 - acc: 0.8701\n",
      "chunk number: 1884 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3315 - acc: 0.8701\n",
      "chunk number: 1885 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3423 - acc: 0.8672\n",
      "chunk number: 1886 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3232 - acc: 0.8662\n",
      "chunk number: 1887 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3414 - acc: 0.8711\n",
      "chunk number: 1888 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3161 - acc: 0.8682\n",
      "chunk number: 1889 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3176 - acc: 0.8760\n",
      "chunk number: 1890 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3194 - acc: 0.8896\n",
      "chunk number: 1891 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3602 - acc: 0.8652\n",
      "chunk number: 1892 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3105 - acc: 0.8818\n",
      "chunk number: 1893 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2885 - acc: 0.8799\n",
      "chunk number: 1894 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2856 - acc: 0.8994\n",
      "chunk number: 1895 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2748 - acc: 0.8965\n",
      "chunk number: 1896 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3028 - acc: 0.8965\n",
      "chunk number: 1897 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3301 - acc: 0.8770\n",
      "chunk number: 1898 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3326 - acc: 0.8760\n",
      "chunk number: 1899 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3098 - acc: 0.8730\n",
      "chunk number: 1900 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3157 - acc: 0.8770\n",
      "chunk number: 1901 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3252 - acc: 0.8721\n",
      "chunk number: 1902 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3502 - acc: 0.8730\n",
      "chunk number: 1903 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3474 - acc: 0.8633\n",
      "chunk number: 1904 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3229 - acc: 0.8730\n",
      "chunk number: 1905 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3309 - acc: 0.8701\n",
      "chunk number: 1906 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3032 - acc: 0.8809\n",
      "chunk number: 1907 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3345 - acc: 0.8711\n",
      "chunk number: 1908 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3600 - acc: 0.8682\n",
      "chunk number: 1909 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3168 - acc: 0.8838\n",
      "chunk number: 1910 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3228 - acc: 0.8711\n",
      "chunk number: 1911 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3977 - acc: 0.8447\n",
      "chunk number: 1912 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3490 - acc: 0.8740\n",
      "chunk number: 1913 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3146 - acc: 0.8730\n",
      "chunk number: 1914 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3176 - acc: 0.8809\n",
      "chunk number: 1915 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3625 - acc: 0.8574\n",
      "chunk number: 1916 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3104 - acc: 0.8848\n",
      "chunk number: 1917 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3344 - acc: 0.8711\n",
      "chunk number: 1918 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3332 - acc: 0.8652\n",
      "chunk number: 1919 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3234 - acc: 0.8760\n",
      "chunk number: 1920 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3551 - acc: 0.8682\n",
      "chunk number: 1921 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3225 - acc: 0.8682\n",
      "chunk number: 1922 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3479 - acc: 0.8672\n",
      "chunk number: 1923 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3334 - acc: 0.8789\n",
      "chunk number: 1924 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3757 - acc: 0.8535\n",
      "chunk number: 1925 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2805 - acc: 0.8857\n",
      "chunk number: 1926 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3500 - acc: 0.8672\n",
      "chunk number: 1927 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3539 - acc: 0.8545\n",
      "chunk number: 1928 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3961 - acc: 0.8594\n",
      "chunk number: 1929 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3510 - acc: 0.8613\n",
      "chunk number: 1930 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3568 - acc: 0.8555\n",
      "chunk number: 1931 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3301 - acc: 0.8662\n",
      "chunk number: 1932 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3498 - acc: 0.8740\n",
      "chunk number: 1933 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3222 - acc: 0.8750\n",
      "chunk number: 1934 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3201 - acc: 0.8760\n",
      "chunk number: 1935 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3087 - acc: 0.8877\n",
      "chunk number: 1936 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3348 - acc: 0.8701\n",
      "chunk number: 1937 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3855 - acc: 0.8447\n",
      "chunk number: 1938 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3309 - acc: 0.8779\n",
      "chunk number: 1939 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3280 - acc: 0.8779\n",
      "chunk number: 1940 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3321 - acc: 0.8809\n",
      "chunk number: 1941 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3409 - acc: 0.8662\n",
      "chunk number: 1942 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3362 - acc: 0.8730\n",
      "chunk number: 1943 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3207 - acc: 0.8867\n",
      "chunk number: 1944 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3273 - acc: 0.8672\n",
      "chunk number: 1945 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3292 - acc: 0.8672\n",
      "chunk number: 1946 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3803 - acc: 0.8594\n",
      "chunk number: 1947 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2967 - acc: 0.8730\n",
      "chunk number: 1948 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3321 - acc: 0.8711\n",
      "chunk number: 1949 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3213 - acc: 0.8623\n",
      "chunk number: 1950 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3433 - acc: 0.8643\n",
      "chunk number: 1951 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3010 - acc: 0.8887\n",
      "chunk number: 1952 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3114 - acc: 0.8799\n",
      "chunk number: 1953 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3675 - acc: 0.8486\n",
      "chunk number: 1954 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3409 - acc: 0.8652\n",
      "chunk number: 1955 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3310 - acc: 0.8828\n",
      "chunk number: 1956 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3296 - acc: 0.8711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 1957 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3074 - acc: 0.8750\n",
      "chunk number: 1958 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3068 - acc: 0.8906\n",
      "chunk number: 1959 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3388 - acc: 0.8789\n",
      "chunk number: 1960 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3601 - acc: 0.8594\n",
      "chunk number: 1961 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3393 - acc: 0.8730\n",
      "chunk number: 1962 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3278 - acc: 0.8770\n",
      "chunk number: 1963 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3753 - acc: 0.8604\n",
      "chunk number: 1964 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2890 - acc: 0.8926\n",
      "chunk number: 1965 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3171 - acc: 0.8721\n",
      "chunk number: 1966 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3287 - acc: 0.8672\n",
      "chunk number: 1967 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3369 - acc: 0.8711\n",
      "chunk number: 1968 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3578 - acc: 0.8535\n",
      "chunk number: 1969 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3300 - acc: 0.8730\n",
      "chunk number: 1970 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3582 - acc: 0.8701\n",
      "chunk number: 1971 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3223 - acc: 0.8760\n",
      "chunk number: 1972 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3450 - acc: 0.8730\n",
      "chunk number: 1973 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3457 - acc: 0.8643\n",
      "chunk number: 1974 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3805 - acc: 0.8594\n",
      "chunk number: 1975 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3643 - acc: 0.8564\n",
      "chunk number: 1976 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3448 - acc: 0.8555\n",
      "chunk number: 1977 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3131 - acc: 0.8779\n",
      "chunk number: 1978 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3270 - acc: 0.8682\n",
      "chunk number: 1979 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3336 - acc: 0.8750\n",
      "chunk number: 1980 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3117 - acc: 0.8896\n",
      "chunk number: 1981 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3180 - acc: 0.8730\n",
      "chunk number: 1982 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3153 - acc: 0.8770\n",
      "chunk number: 1983 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3299 - acc: 0.8721\n",
      "chunk number: 1984 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3292 - acc: 0.8809\n",
      "chunk number: 1985 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3655 - acc: 0.8555\n",
      "chunk number: 1986 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3148 - acc: 0.8799\n",
      "chunk number: 1987 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3450 - acc: 0.8682\n",
      "chunk number: 1988 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3080 - acc: 0.8809\n",
      "chunk number: 1989 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3060 - acc: 0.8730\n",
      "chunk number: 1990 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3134 - acc: 0.8711\n",
      "chunk number: 1991 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3472 - acc: 0.8633\n",
      "chunk number: 1992 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3184 - acc: 0.8740\n",
      "chunk number: 1993 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3002 - acc: 0.8828\n",
      "chunk number: 1994 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3231 - acc: 0.8730\n",
      "chunk number: 1995 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2796 - acc: 0.8965\n",
      "chunk number: 1996 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3172 - acc: 0.8730\n",
      "chunk number: 1997 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3320 - acc: 0.8721\n",
      "chunk number: 1998 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3348 - acc: 0.8721\n",
      "chunk number: 1999 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3124 - acc: 0.8721\n",
      "chunk number: 2000 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3366 - acc: 0.8623\n",
      "chunk number: 2001 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3214 - acc: 0.8730\n",
      "chunk number: 2002 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3573 - acc: 0.8633\n",
      "chunk number: 2003 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3092 - acc: 0.8760\n",
      "chunk number: 2004 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3149 - acc: 0.8779\n",
      "chunk number: 2005 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3001 - acc: 0.8760\n",
      "chunk number: 2006 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3022 - acc: 0.8818\n",
      "chunk number: 2007 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2974 - acc: 0.8906\n",
      "chunk number: 2008 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3286 - acc: 0.8672\n",
      "chunk number: 2009 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3131 - acc: 0.8857\n",
      "chunk number: 2010 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3258 - acc: 0.8799\n",
      "chunk number: 2011 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3482 - acc: 0.8594\n",
      "chunk number: 2012 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3456 - acc: 0.8711\n",
      "chunk number: 2013 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3189 - acc: 0.8711\n",
      "chunk number: 2014 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3381 - acc: 0.8730\n",
      "chunk number: 2015 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3376 - acc: 0.8662\n",
      "chunk number: 2016 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2963 - acc: 0.8789\n",
      "chunk number: 2017 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3128 - acc: 0.8789\n",
      "chunk number: 2018 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3415 - acc: 0.8652\n",
      "chunk number: 2019 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3539 - acc: 0.8701\n",
      "chunk number: 2020 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3087 - acc: 0.8789\n",
      "chunk number: 2021 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3125 - acc: 0.8721\n",
      "chunk number: 2022 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3119 - acc: 0.8779\n",
      "chunk number: 2023 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3609 - acc: 0.8691\n",
      "chunk number: 2024 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3286 - acc: 0.8682\n",
      "chunk number: 2025 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2979 - acc: 0.8857\n",
      "chunk number: 2026 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3467 - acc: 0.8750\n",
      "chunk number: 2027 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3279 - acc: 0.8730\n",
      "chunk number: 2028 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3433 - acc: 0.8691\n",
      "chunk number: 2029 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3476 - acc: 0.8604\n",
      "chunk number: 2030 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3306 - acc: 0.8760\n",
      "chunk number: 2031 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3221 - acc: 0.8789\n",
      "chunk number: 2032 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3309 - acc: 0.8809\n",
      "chunk number: 2033 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3138 - acc: 0.8770\n",
      "chunk number: 2034 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3229 - acc: 0.8867\n",
      "chunk number: 2035 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3179 - acc: 0.8789\n",
      "chunk number: 2036 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3568 - acc: 0.8623\n",
      "chunk number: 2037 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3620 - acc: 0.8555\n",
      "chunk number: 2038 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3232 - acc: 0.8721\n",
      "chunk number: 2039 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3150 - acc: 0.8730\n",
      "chunk number: 2040 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3288 - acc: 0.8594\n",
      "chunk number: 2041 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2844 - acc: 0.8926\n",
      "chunk number: 2042 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3029 - acc: 0.8867\n",
      "chunk number: 2043 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3077 - acc: 0.8730\n",
      "chunk number: 2044 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2983 - acc: 0.8877\n",
      "chunk number: 2045 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3133 - acc: 0.8711\n",
      "chunk number: 2046 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3284 - acc: 0.8740\n",
      "chunk number: 2047 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3049 - acc: 0.8789\n",
      "chunk number: 2048 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3288 - acc: 0.8691\n",
      "chunk number: 2049 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3275 - acc: 0.8779\n",
      "chunk number: 2050 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3426 - acc: 0.8604\n",
      "chunk number: 2051 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3322 - acc: 0.8779\n",
      "chunk number: 2052 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3287 - acc: 0.8818\n",
      "chunk number: 2053 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3552 - acc: 0.8584\n",
      "chunk number: 2054 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3087 - acc: 0.8740\n",
      "chunk number: 2055 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3375 - acc: 0.8740\n",
      "chunk number: 2056 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3190 - acc: 0.8770\n",
      "chunk number: 2057 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3099 - acc: 0.8867\n",
      "chunk number: 2058 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3000 - acc: 0.8906\n",
      "chunk number: 2059 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2550 - acc: 0.8955\n",
      "chunk number: 2060 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3551 - acc: 0.8760\n",
      "chunk number: 2061 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2970 - acc: 0.8906\n",
      "chunk number: 2062 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3521 - acc: 0.8623\n",
      "chunk number: 2063 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3530 - acc: 0.8730\n",
      "chunk number: 2064 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3088 - acc: 0.8965\n",
      "chunk number: 2065 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3538 - acc: 0.8789\n",
      "chunk number: 2066 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3237 - acc: 0.8672\n",
      "chunk number: 2067 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3094 - acc: 0.8867\n",
      "chunk number: 2068 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3421 - acc: 0.8779\n",
      "chunk number: 2069 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3192 - acc: 0.8682\n",
      "chunk number: 2070 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3334 - acc: 0.8730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 2071 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3615 - acc: 0.8594\n",
      "chunk number: 2072 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3451 - acc: 0.8633\n",
      "chunk number: 2073 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3367 - acc: 0.8691\n",
      "chunk number: 2074 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3315 - acc: 0.8730\n",
      "chunk number: 2075 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3360 - acc: 0.8652\n",
      "chunk number: 2076 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3110 - acc: 0.8818\n",
      "chunk number: 2077 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2877 - acc: 0.8857\n",
      "chunk number: 2078 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3066 - acc: 0.8721\n",
      "chunk number: 2079 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3058 - acc: 0.8701\n",
      "chunk number: 2080 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3180 - acc: 0.8838\n",
      "chunk number: 2081 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3225 - acc: 0.8789\n",
      "chunk number: 2082 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3129 - acc: 0.8809\n",
      "chunk number: 2083 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3347 - acc: 0.8701\n",
      "chunk number: 2084 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2954 - acc: 0.8838\n",
      "chunk number: 2085 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3556 - acc: 0.8691\n",
      "chunk number: 2086 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2919 - acc: 0.8867\n",
      "chunk number: 2087 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3195 - acc: 0.8623\n",
      "chunk number: 2088 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2868 - acc: 0.8926\n",
      "chunk number: 2089 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2935 - acc: 0.8828\n",
      "chunk number: 2090 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3105 - acc: 0.8789\n",
      "chunk number: 2091 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3428 - acc: 0.8760\n",
      "chunk number: 2092 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3228 - acc: 0.8682\n",
      "chunk number: 2093 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2906 - acc: 0.8867\n",
      "chunk number: 2094 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2854 - acc: 0.8809\n",
      "chunk number: 2095 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2818 - acc: 0.8818\n",
      "chunk number: 2096 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2872 - acc: 0.9023\n",
      "chunk number: 2097 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2798 - acc: 0.8896\n",
      "chunk number: 2098 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3257 - acc: 0.8809\n",
      "chunk number: 2099 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2933 - acc: 0.8730\n",
      "chunk number: 2100 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3121 - acc: 0.8633\n",
      "chunk number: 2101 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3038 - acc: 0.8877\n",
      "chunk number: 2102 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3328 - acc: 0.8779\n",
      "chunk number: 2103 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2996 - acc: 0.8877\n",
      "chunk number: 2104 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3027 - acc: 0.8760\n",
      "chunk number: 2105 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3078 - acc: 0.8867\n",
      "chunk number: 2106 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2999 - acc: 0.8730\n",
      "chunk number: 2107 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3126 - acc: 0.8789\n",
      "chunk number: 2108 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3284 - acc: 0.8701\n",
      "chunk number: 2109 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3005 - acc: 0.8896\n",
      "chunk number: 2110 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3357 - acc: 0.8662\n",
      "chunk number: 2111 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3413 - acc: 0.8623\n",
      "chunk number: 2112 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3506 - acc: 0.8604\n",
      "chunk number: 2113 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3055 - acc: 0.8818\n",
      "chunk number: 2114 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3373 - acc: 0.8721\n",
      "chunk number: 2115 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3243 - acc: 0.8672\n",
      "chunk number: 2116 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3210 - acc: 0.8779\n",
      "chunk number: 2117 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3236 - acc: 0.8721\n",
      "chunk number: 2118 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3204 - acc: 0.8760\n",
      "chunk number: 2119 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3169 - acc: 0.8721\n",
      "chunk number: 2120 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3152 - acc: 0.8838\n",
      "chunk number: 2121 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3061 - acc: 0.8691\n",
      "chunk number: 2122 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2994 - acc: 0.8721\n",
      "chunk number: 2123 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3354 - acc: 0.8916\n",
      "chunk number: 2124 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3520 - acc: 0.8682\n",
      "chunk number: 2125 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2766 - acc: 0.8848\n",
      "chunk number: 2126 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3288 - acc: 0.8779\n",
      "chunk number: 2127 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3258 - acc: 0.8779\n",
      "chunk number: 2128 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3290 - acc: 0.8760\n",
      "chunk number: 2129 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3318 - acc: 0.8770\n",
      "chunk number: 2130 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3465 - acc: 0.8643\n",
      "chunk number: 2131 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3242 - acc: 0.8721\n",
      "chunk number: 2132 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3220 - acc: 0.8721\n",
      "chunk number: 2133 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3284 - acc: 0.8789\n",
      "chunk number: 2134 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3259 - acc: 0.8701\n",
      "chunk number: 2135 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2921 - acc: 0.8906\n",
      "chunk number: 2136 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3334 - acc: 0.8779\n",
      "chunk number: 2137 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3442 - acc: 0.8574\n",
      "chunk number: 2138 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3300 - acc: 0.8750\n",
      "chunk number: 2139 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3475 - acc: 0.8643\n",
      "chunk number: 2140 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3578 - acc: 0.8691\n",
      "chunk number: 2141 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2817 - acc: 0.8965\n",
      "chunk number: 2142 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3334 - acc: 0.8789\n",
      "chunk number: 2143 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2671 - acc: 0.8994\n",
      "chunk number: 2144 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2739 - acc: 0.8975\n",
      "chunk number: 2145 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3266 - acc: 0.8721\n",
      "chunk number: 2146 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3661 - acc: 0.8750\n",
      "chunk number: 2147 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3137 - acc: 0.8682\n",
      "chunk number: 2148 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3244 - acc: 0.8809\n",
      "chunk number: 2149 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3107 - acc: 0.8809\n",
      "chunk number: 2150 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3358 - acc: 0.8711\n",
      "chunk number: 2151 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3254 - acc: 0.8916\n",
      "chunk number: 2152 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3074 - acc: 0.8691\n",
      "chunk number: 2153 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3753 - acc: 0.8506\n",
      "chunk number: 2154 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3416 - acc: 0.8682\n",
      "chunk number: 2155 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3153 - acc: 0.8838\n",
      "chunk number: 2156 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3154 - acc: 0.8838\n",
      "chunk number: 2157 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2760 - acc: 0.8848\n",
      "chunk number: 2158 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2658 - acc: 0.9033\n",
      "chunk number: 2159 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2988 - acc: 0.8867\n",
      "chunk number: 2160 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3497 - acc: 0.8652\n",
      "chunk number: 2161 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3173 - acc: 0.8896\n",
      "chunk number: 2162 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3102 - acc: 0.8906\n",
      "chunk number: 2163 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3596 - acc: 0.8457\n",
      "chunk number: 2164 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2872 - acc: 0.8838\n",
      "chunk number: 2165 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3586 - acc: 0.8574\n",
      "chunk number: 2166 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3144 - acc: 0.8789\n",
      "chunk number: 2167 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3069 - acc: 0.8857\n",
      "chunk number: 2168 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3476 - acc: 0.8613\n",
      "chunk number: 2169 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2755 - acc: 0.8984\n",
      "chunk number: 2170 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3074 - acc: 0.8799\n",
      "chunk number: 2171 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3055 - acc: 0.8877\n",
      "chunk number: 2172 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3354 - acc: 0.8633\n",
      "chunk number: 2173 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3167 - acc: 0.8779\n",
      "chunk number: 2174 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3207 - acc: 0.8740\n",
      "chunk number: 2175 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3210 - acc: 0.8779\n",
      "chunk number: 2176 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3290 - acc: 0.8555\n",
      "chunk number: 2177 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2791 - acc: 0.8945\n",
      "chunk number: 2178 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3145 - acc: 0.8789\n",
      "chunk number: 2179 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3326 - acc: 0.8691\n",
      "chunk number: 2180 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3167 - acc: 0.8818\n",
      "chunk number: 2181 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3273 - acc: 0.8760\n",
      "chunk number: 2182 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2982 - acc: 0.8838\n",
      "chunk number: 2183 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3303 - acc: 0.8760\n",
      "chunk number: 2184 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3044 - acc: 0.8779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 2185 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3178 - acc: 0.8770\n",
      "chunk number: 2186 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3024 - acc: 0.8760\n",
      "chunk number: 2187 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3286 - acc: 0.8730\n",
      "chunk number: 2188 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2921 - acc: 0.8887\n",
      "chunk number: 2189 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2652 - acc: 0.8916\n",
      "chunk number: 2190 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3126 - acc: 0.8721\n",
      "chunk number: 2191 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3144 - acc: 0.8789\n",
      "chunk number: 2192 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3035 - acc: 0.8857\n",
      "chunk number: 2193 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3014 - acc: 0.8828\n",
      "chunk number: 2194 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2634 - acc: 0.8955\n",
      "chunk number: 2195 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2488 - acc: 0.9043\n",
      "chunk number: 2196 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2775 - acc: 0.8994\n",
      "chunk number: 2197 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2881 - acc: 0.8740\n",
      "chunk number: 2198 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3102 - acc: 0.8818\n",
      "chunk number: 2199 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2898 - acc: 0.8945\n",
      "chunk number: 2200 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3192 - acc: 0.8750\n",
      "chunk number: 2201 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2901 - acc: 0.8857\n",
      "chunk number: 2202 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3387 - acc: 0.8770\n",
      "chunk number: 2203 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3022 - acc: 0.8867\n",
      "chunk number: 2204 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3067 - acc: 0.8857\n",
      "chunk number: 2205 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3269 - acc: 0.8721\n",
      "chunk number: 2206 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3121 - acc: 0.8721\n",
      "chunk number: 2207 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3111 - acc: 0.8818\n",
      "chunk number: 2208 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3364 - acc: 0.8643\n",
      "chunk number: 2209 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3128 - acc: 0.8955\n",
      "chunk number: 2210 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3476 - acc: 0.8652\n",
      "chunk number: 2211 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3303 - acc: 0.8643\n",
      "chunk number: 2212 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3362 - acc: 0.8623\n",
      "chunk number: 2213 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3144 - acc: 0.8838\n",
      "chunk number: 2214 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3361 - acc: 0.8770\n",
      "chunk number: 2215 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3295 - acc: 0.8760\n",
      "chunk number: 2216 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2699 - acc: 0.9014\n",
      "chunk number: 2217 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3222 - acc: 0.8721\n",
      "chunk number: 2218 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3216 - acc: 0.8779\n",
      "chunk number: 2219 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3368 - acc: 0.8721\n",
      "chunk number: 2220 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3265 - acc: 0.8760\n",
      "chunk number: 2221 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3229 - acc: 0.8779\n",
      "chunk number: 2222 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3292 - acc: 0.8701\n",
      "chunk number: 2223 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3419 - acc: 0.8740\n",
      "chunk number: 2224 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3514 - acc: 0.8604\n",
      "chunk number: 2225 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2996 - acc: 0.8828\n",
      "chunk number: 2226 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3170 - acc: 0.8740\n",
      "chunk number: 2227 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2882 - acc: 0.8809\n",
      "chunk number: 2228 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3499 - acc: 0.8750\n",
      "chunk number: 2229 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3134 - acc: 0.8750\n",
      "chunk number: 2230 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3208 - acc: 0.8760\n",
      "chunk number: 2231 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3131 - acc: 0.8799\n",
      "chunk number: 2232 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3184 - acc: 0.8730\n",
      "chunk number: 2233 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2962 - acc: 0.8857\n",
      "chunk number: 2234 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3237 - acc: 0.8643\n",
      "chunk number: 2235 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2842 - acc: 0.8838\n",
      "chunk number: 2236 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3366 - acc: 0.8760\n",
      "chunk number: 2237 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3309 - acc: 0.8730\n",
      "chunk number: 2238 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3480 - acc: 0.8701\n",
      "chunk number: 2239 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3371 - acc: 0.8770\n",
      "chunk number: 2240 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3155 - acc: 0.8770\n",
      "chunk number: 2241 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2918 - acc: 0.8838\n",
      "chunk number: 2242 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3093 - acc: 0.8848\n",
      "chunk number: 2243 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2930 - acc: 0.8916\n",
      "chunk number: 2244 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2847 - acc: 0.8906\n",
      "chunk number: 2245 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3192 - acc: 0.8750\n",
      "chunk number: 2246 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3531 - acc: 0.8633\n",
      "chunk number: 2247 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2926 - acc: 0.8857\n",
      "chunk number: 2248 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3031 - acc: 0.8809\n",
      "chunk number: 2249 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3188 - acc: 0.8730\n",
      "chunk number: 2250 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3337 - acc: 0.8750\n",
      "chunk number: 2251 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3310 - acc: 0.8818\n",
      "chunk number: 2252 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3055 - acc: 0.8818\n",
      "chunk number: 2253 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3614 - acc: 0.8545\n",
      "chunk number: 2254 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3241 - acc: 0.8740\n",
      "chunk number: 2255 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3130 - acc: 0.8828\n",
      "chunk number: 2256 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3333 - acc: 0.8662\n",
      "chunk number: 2257 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2520 - acc: 0.8984\n",
      "chunk number: 2258 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3025 - acc: 0.8887\n",
      "chunk number: 2259 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2902 - acc: 0.8887\n",
      "chunk number: 2260 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3680 - acc: 0.8662\n",
      "chunk number: 2261 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3279 - acc: 0.8828\n",
      "chunk number: 2262 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3100 - acc: 0.8936\n",
      "chunk number: 2263 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3843 - acc: 0.8564\n",
      "chunk number: 2264 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3053 - acc: 0.8857\n",
      "chunk number: 2265 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2989 - acc: 0.8877\n",
      "chunk number: 2266 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3292 - acc: 0.8662\n",
      "chunk number: 2267 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3040 - acc: 0.8848\n",
      "chunk number: 2268 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3281 - acc: 0.8691\n",
      "chunk number: 2269 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3014 - acc: 0.8779\n",
      "chunk number: 2270 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3024 - acc: 0.8887\n",
      "chunk number: 2271 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3170 - acc: 0.8828\n",
      "chunk number: 2272 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3284 - acc: 0.8711\n",
      "chunk number: 2273 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3115 - acc: 0.8789\n",
      "chunk number: 2274 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3300 - acc: 0.8799\n",
      "chunk number: 2275 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3199 - acc: 0.8867\n",
      "chunk number: 2276 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3075 - acc: 0.8877\n",
      "chunk number: 2277 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3114 - acc: 0.8701\n",
      "chunk number: 2278 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2984 - acc: 0.8838\n",
      "chunk number: 2279 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2821 - acc: 0.8809\n",
      "chunk number: 2280 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3058 - acc: 0.8936\n",
      "chunk number: 2281 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3141 - acc: 0.8740\n",
      "chunk number: 2282 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3296 - acc: 0.8730\n",
      "chunk number: 2283 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3542 - acc: 0.8682\n",
      "chunk number: 2284 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3129 - acc: 0.8789\n",
      "chunk number: 2285 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3643 - acc: 0.8613\n",
      "chunk number: 2286 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2872 - acc: 0.8926\n",
      "chunk number: 2287 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3308 - acc: 0.8779\n",
      "chunk number: 2288 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2850 - acc: 0.8926\n",
      "chunk number: 2289 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3194 - acc: 0.8848\n",
      "chunk number: 2290 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2778 - acc: 0.8984\n",
      "chunk number: 2291 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3119 - acc: 0.8779\n",
      "chunk number: 2292 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2962 - acc: 0.8926\n",
      "chunk number: 2293 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3052 - acc: 0.8818\n",
      "chunk number: 2294 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2600 - acc: 0.8955\n",
      "chunk number: 2295 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2268 - acc: 0.9170\n",
      "chunk number: 2296 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3008 - acc: 0.8975\n",
      "chunk number: 2297 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2824 - acc: 0.8926\n",
      "chunk number: 2298 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3085 - acc: 0.8887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 2299 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2753 - acc: 0.8896\n",
      "chunk number: 2300 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3164 - acc: 0.8691\n",
      "chunk number: 2301 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2857 - acc: 0.8838\n",
      "chunk number: 2302 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3581 - acc: 0.8701\n",
      "chunk number: 2303 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3084 - acc: 0.8848\n",
      "chunk number: 2304 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2836 - acc: 0.8955\n",
      "chunk number: 2305 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3261 - acc: 0.8848\n",
      "chunk number: 2306 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2811 - acc: 0.8896\n",
      "chunk number: 2307 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3414 - acc: 0.8721\n",
      "chunk number: 2308 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3012 - acc: 0.8877\n",
      "chunk number: 2309 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2844 - acc: 0.8984\n",
      "chunk number: 2310 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3199 - acc: 0.8652\n",
      "chunk number: 2311 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3553 - acc: 0.8682\n",
      "chunk number: 2312 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3073 - acc: 0.8867\n",
      "chunk number: 2313 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3103 - acc: 0.8857\n",
      "chunk number: 2314 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3188 - acc: 0.8770\n",
      "chunk number: 2315 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3312 - acc: 0.8672\n",
      "chunk number: 2316 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2800 - acc: 0.9043\n",
      "chunk number: 2317 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3822 - acc: 0.8652\n",
      "chunk number: 2318 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3272 - acc: 0.8750\n",
      "chunk number: 2319 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3448 - acc: 0.8652\n",
      "chunk number: 2320 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3180 - acc: 0.8818\n",
      "chunk number: 2321 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2866 - acc: 0.8916\n",
      "chunk number: 2322 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2957 - acc: 0.8838\n",
      "chunk number: 2323 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3100 - acc: 0.8818\n",
      "chunk number: 2324 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3503 - acc: 0.8623\n",
      "chunk number: 2325 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2857 - acc: 0.8926\n",
      "chunk number: 2326 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3079 - acc: 0.8799\n",
      "chunk number: 2327 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2912 - acc: 0.8926\n",
      "chunk number: 2328 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3154 - acc: 0.8779\n",
      "chunk number: 2329 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3160 - acc: 0.8838\n",
      "chunk number: 2330 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3176 - acc: 0.8584\n",
      "chunk number: 2331 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2991 - acc: 0.8906\n",
      "chunk number: 2332 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3217 - acc: 0.8711\n",
      "chunk number: 2333 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3210 - acc: 0.8750\n",
      "chunk number: 2334 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3020 - acc: 0.8770\n",
      "chunk number: 2335 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2935 - acc: 0.8838\n",
      "chunk number: 2336 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3185 - acc: 0.8633\n",
      "chunk number: 2337 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3296 - acc: 0.8672\n",
      "chunk number: 2338 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3164 - acc: 0.8721\n",
      "chunk number: 2339 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3143 - acc: 0.8877\n",
      "chunk number: 2340 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3203 - acc: 0.8818\n",
      "chunk number: 2341 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2627 - acc: 0.9004\n",
      "chunk number: 2342 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2722 - acc: 0.8945\n",
      "chunk number: 2343 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2674 - acc: 0.8936\n",
      "chunk number: 2344 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3191 - acc: 0.8828\n",
      "chunk number: 2345 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2925 - acc: 0.8896\n",
      "chunk number: 2346 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3413 - acc: 0.8750\n",
      "chunk number: 2347 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3099 - acc: 0.8750\n",
      "chunk number: 2348 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3071 - acc: 0.8672\n",
      "chunk number: 2349 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2947 - acc: 0.8906\n",
      "chunk number: 2350 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3462 - acc: 0.8564\n",
      "chunk number: 2351 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2905 - acc: 0.8887\n",
      "chunk number: 2352 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3180 - acc: 0.8770\n",
      "chunk number: 2353 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3612 - acc: 0.8604\n",
      "chunk number: 2354 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3287 - acc: 0.8779\n",
      "chunk number: 2355 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3088 - acc: 0.8809\n",
      "chunk number: 2356 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3192 - acc: 0.8818\n",
      "chunk number: 2357 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2645 - acc: 0.8916\n",
      "chunk number: 2358 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2412 - acc: 0.9209\n",
      "chunk number: 2359 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3032 - acc: 0.8848\n",
      "chunk number: 2360 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3433 - acc: 0.8779\n",
      "chunk number: 2361 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3069 - acc: 0.8994\n",
      "chunk number: 2362 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3305 - acc: 0.8779\n",
      "chunk number: 2363 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3729 - acc: 0.8730\n",
      "chunk number: 2364 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2724 - acc: 0.8906\n",
      "chunk number: 2365 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3513 - acc: 0.8662\n",
      "chunk number: 2366 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3125 - acc: 0.8887\n",
      "chunk number: 2367 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3006 - acc: 0.8896\n",
      "chunk number: 2368 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3346 - acc: 0.8789\n",
      "chunk number: 2369 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3355 - acc: 0.8594\n",
      "chunk number: 2370 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3169 - acc: 0.8818\n",
      "chunk number: 2371 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3121 - acc: 0.8789\n",
      "chunk number: 2372 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3691 - acc: 0.8662\n",
      "chunk number: 2373 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3003 - acc: 0.8926\n",
      "chunk number: 2374 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3263 - acc: 0.8750\n",
      "chunk number: 2375 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3094 - acc: 0.8848\n",
      "chunk number: 2376 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3118 - acc: 0.8867\n",
      "chunk number: 2377 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2950 - acc: 0.8936\n",
      "chunk number: 2378 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2886 - acc: 0.8760\n",
      "chunk number: 2379 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2819 - acc: 0.8945\n",
      "chunk number: 2380 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2954 - acc: 0.8789\n",
      "chunk number: 2381 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2837 - acc: 0.8877\n",
      "chunk number: 2382 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2917 - acc: 0.8760\n",
      "chunk number: 2383 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3349 - acc: 0.8623\n",
      "chunk number: 2384 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2970 - acc: 0.8896\n",
      "chunk number: 2385 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3049 - acc: 0.8984\n",
      "chunk number: 2386 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3042 - acc: 0.8975\n",
      "chunk number: 2387 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3224 - acc: 0.8740\n",
      "chunk number: 2388 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2993 - acc: 0.8760\n",
      "chunk number: 2389 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2579 - acc: 0.9053\n",
      "chunk number: 2390 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2843 - acc: 0.8838\n",
      "chunk number: 2391 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3243 - acc: 0.8838\n",
      "chunk number: 2392 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2743 - acc: 0.8926\n",
      "chunk number: 2393 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2967 - acc: 0.8926\n",
      "chunk number: 2394 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2796 - acc: 0.8926\n",
      "chunk number: 2395 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2671 - acc: 0.8877\n",
      "chunk number: 2396 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3230 - acc: 0.8828\n",
      "chunk number: 2397 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2836 - acc: 0.8848\n",
      "chunk number: 2398 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3036 - acc: 0.8828\n",
      "chunk number: 2399 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2671 - acc: 0.8975\n",
      "chunk number: 2400 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3207 - acc: 0.8818\n",
      "chunk number: 2401 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3012 - acc: 0.8877\n",
      "chunk number: 2402 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3333 - acc: 0.8789\n",
      "chunk number: 2403 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3026 - acc: 0.8828\n",
      "chunk number: 2404 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2584 - acc: 0.9072\n",
      "chunk number: 2405 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3218 - acc: 0.8809\n",
      "chunk number: 2406 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2667 - acc: 0.8848\n",
      "chunk number: 2407 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3093 - acc: 0.8838\n",
      "chunk number: 2408 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3047 - acc: 0.8740\n",
      "chunk number: 2409 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2975 - acc: 0.8799\n",
      "chunk number: 2410 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3014 - acc: 0.8809\n",
      "chunk number: 2411 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2869 - acc: 0.8838\n",
      "chunk number: 2412 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3642 - acc: 0.8574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 2413 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2977 - acc: 0.8789\n",
      "chunk number: 2414 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3069 - acc: 0.8906\n",
      "chunk number: 2415 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3181 - acc: 0.8857\n",
      "chunk number: 2416 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2804 - acc: 0.8955\n",
      "chunk number: 2417 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3073 - acc: 0.8740\n",
      "chunk number: 2418 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3191 - acc: 0.8789\n",
      "chunk number: 2419 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2871 - acc: 0.8809\n",
      "chunk number: 2420 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2977 - acc: 0.8896\n",
      "chunk number: 2421 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2784 - acc: 0.8770\n",
      "chunk number: 2422 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3076 - acc: 0.8760\n",
      "chunk number: 2423 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3032 - acc: 0.8994\n",
      "chunk number: 2424 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3277 - acc: 0.8633\n",
      "chunk number: 2425 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2706 - acc: 0.8994\n",
      "chunk number: 2426 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2871 - acc: 0.9033\n",
      "chunk number: 2427 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2906 - acc: 0.8818\n",
      "chunk number: 2428 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3131 - acc: 0.8857\n",
      "chunk number: 2429 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2935 - acc: 0.8857\n",
      "chunk number: 2430 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2967 - acc: 0.8945\n",
      "chunk number: 2431 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3011 - acc: 0.8828\n",
      "chunk number: 2432 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3192 - acc: 0.8730\n",
      "chunk number: 2433 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2965 - acc: 0.8877\n",
      "chunk number: 2434 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2986 - acc: 0.8809\n",
      "chunk number: 2435 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2887 - acc: 0.8896\n",
      "chunk number: 2436 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3110 - acc: 0.8809\n",
      "chunk number: 2437 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2714 - acc: 0.8975\n",
      "chunk number: 2438 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3196 - acc: 0.8730\n",
      "chunk number: 2439 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3089 - acc: 0.8975\n",
      "chunk number: 2440 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2959 - acc: 0.8877\n",
      "chunk number: 2441 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2614 - acc: 0.8975\n",
      "chunk number: 2442 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3183 - acc: 0.8906\n",
      "chunk number: 2443 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3045 - acc: 0.8818\n",
      "chunk number: 2444 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2882 - acc: 0.9023\n",
      "chunk number: 2445 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2862 - acc: 0.8906\n",
      "chunk number: 2446 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3161 - acc: 0.8789\n",
      "chunk number: 2447 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2673 - acc: 0.8926\n",
      "chunk number: 2448 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2887 - acc: 0.8945\n",
      "chunk number: 2449 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2744 - acc: 0.8965\n",
      "chunk number: 2450 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3147 - acc: 0.8770\n",
      "chunk number: 2451 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2957 - acc: 0.8809\n",
      "chunk number: 2452 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3136 - acc: 0.8691\n",
      "chunk number: 2453 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3729 - acc: 0.8584\n",
      "chunk number: 2454 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3147 - acc: 0.8711\n",
      "chunk number: 2455 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3051 - acc: 0.8838\n",
      "chunk number: 2456 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2991 - acc: 0.8877\n",
      "chunk number: 2457 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2523 - acc: 0.9033\n",
      "chunk number: 2458 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2319 - acc: 0.9131\n",
      "chunk number: 2459 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2762 - acc: 0.9102\n",
      "chunk number: 2460 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2986 - acc: 0.8867\n",
      "chunk number: 2461 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2936 - acc: 0.8965\n",
      "chunk number: 2462 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3016 - acc: 0.8877\n",
      "chunk number: 2463 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3573 - acc: 0.8652\n",
      "chunk number: 2464 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3078 - acc: 0.8887\n",
      "chunk number: 2465 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3426 - acc: 0.8623\n",
      "chunk number: 2466 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3114 - acc: 0.8848\n",
      "chunk number: 2467 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3131 - acc: 0.8799\n",
      "chunk number: 2468 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3004 - acc: 0.8750\n",
      "chunk number: 2469 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3017 - acc: 0.8848\n",
      "chunk number: 2470 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3236 - acc: 0.8945\n",
      "chunk number: 2471 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2926 - acc: 0.8867\n",
      "chunk number: 2472 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3458 - acc: 0.8691\n",
      "chunk number: 2473 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3089 - acc: 0.8916\n",
      "chunk number: 2474 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3200 - acc: 0.8887\n",
      "chunk number: 2475 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3148 - acc: 0.8877\n",
      "chunk number: 2476 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2954 - acc: 0.8867\n",
      "chunk number: 2477 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2853 - acc: 0.8857\n",
      "chunk number: 2478 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2847 - acc: 0.8818\n",
      "chunk number: 2479 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2858 - acc: 0.8877\n",
      "chunk number: 2480 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2865 - acc: 0.8877\n",
      "chunk number: 2481 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2753 - acc: 0.8838\n",
      "chunk number: 2482 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3146 - acc: 0.8711\n",
      "chunk number: 2483 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2982 - acc: 0.8740\n",
      "chunk number: 2484 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3169 - acc: 0.8682\n",
      "chunk number: 2485 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3051 - acc: 0.8828\n",
      "chunk number: 2486 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2685 - acc: 0.8975\n",
      "chunk number: 2487 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3483 - acc: 0.8779\n",
      "chunk number: 2488 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2413 - acc: 0.9092\n",
      "chunk number: 2489 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2634 - acc: 0.8984\n",
      "chunk number: 2490 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3208 - acc: 0.8701\n",
      "chunk number: 2491 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3229 - acc: 0.8789\n",
      "chunk number: 2492 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2967 - acc: 0.8799\n",
      "chunk number: 2493 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2771 - acc: 0.8936\n",
      "chunk number: 2494 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2648 - acc: 0.9082\n",
      "chunk number: 2495 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2589 - acc: 0.8936\n",
      "chunk number: 2496 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2577 - acc: 0.9072\n",
      "chunk number: 2497 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2793 - acc: 0.8936\n",
      "chunk number: 2498 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3150 - acc: 0.8818\n",
      "chunk number: 2499 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2947 - acc: 0.8789\n",
      "chunk number: 2500 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3384 - acc: 0.8701\n",
      "chunk number: 2501 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2757 - acc: 0.8936\n",
      "chunk number: 2502 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2850 - acc: 0.9043\n",
      "chunk number: 2503 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2849 - acc: 0.8828\n",
      "chunk number: 2504 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2542 - acc: 0.9082\n",
      "chunk number: 2505 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2752 - acc: 0.8945\n",
      "chunk number: 2506 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2660 - acc: 0.8984\n",
      "chunk number: 2507 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3293 - acc: 0.8682\n",
      "chunk number: 2508 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3059 - acc: 0.8828\n",
      "chunk number: 2509 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2618 - acc: 0.8984\n",
      "chunk number: 2510 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2939 - acc: 0.8809\n",
      "chunk number: 2511 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3252 - acc: 0.8604\n",
      "chunk number: 2512 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3275 - acc: 0.8652\n",
      "chunk number: 2513 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3111 - acc: 0.8779\n",
      "chunk number: 2514 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2961 - acc: 0.8857\n",
      "chunk number: 2515 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3212 - acc: 0.8809\n",
      "chunk number: 2516 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2579 - acc: 0.9072\n",
      "chunk number: 2517 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2881 - acc: 0.8857\n",
      "chunk number: 2518 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3037 - acc: 0.8809\n",
      "chunk number: 2519 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3037 - acc: 0.8750\n",
      "chunk number: 2520 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3115 - acc: 0.8916\n",
      "chunk number: 2521 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2864 - acc: 0.8848\n",
      "chunk number: 2522 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2891 - acc: 0.8887\n",
      "chunk number: 2523 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3119 - acc: 0.8887\n",
      "chunk number: 2524 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3208 - acc: 0.8662\n",
      "chunk number: 2525 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2541 - acc: 0.9033\n",
      "chunk number: 2526 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2978 - acc: 0.8857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 2527 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3053 - acc: 0.8711\n",
      "chunk number: 2528 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3076 - acc: 0.8877\n",
      "chunk number: 2529 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3059 - acc: 0.8887\n",
      "chunk number: 2530 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3173 - acc: 0.8789\n",
      "chunk number: 2531 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2408 - acc: 0.9082\n",
      "chunk number: 2532 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3023 - acc: 0.8838\n",
      "chunk number: 2533 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2972 - acc: 0.8887\n",
      "chunk number: 2534 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2795 - acc: 0.8965\n",
      "chunk number: 2535 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3297 - acc: 0.8926\n",
      "chunk number: 2536 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3021 - acc: 0.8799\n",
      "chunk number: 2537 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2864 - acc: 0.8877\n",
      "chunk number: 2538 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2878 - acc: 0.8887\n",
      "chunk number: 2539 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3104 - acc: 0.8828\n",
      "chunk number: 2540 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3266 - acc: 0.8779\n",
      "chunk number: 2541 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2752 - acc: 0.8955\n",
      "chunk number: 2542 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2919 - acc: 0.8916\n",
      "chunk number: 2543 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3038 - acc: 0.8857\n",
      "chunk number: 2544 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3416 - acc: 0.8721\n",
      "chunk number: 2545 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3049 - acc: 0.8838\n",
      "chunk number: 2546 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3657 - acc: 0.8750\n",
      "chunk number: 2547 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2750 - acc: 0.8896\n",
      "chunk number: 2548 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3001 - acc: 0.8848\n",
      "chunk number: 2549 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3034 - acc: 0.8799\n",
      "chunk number: 2550 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2952 - acc: 0.8770\n",
      "chunk number: 2551 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2793 - acc: 0.9023\n",
      "chunk number: 2552 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2903 - acc: 0.8916\n",
      "chunk number: 2553 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3299 - acc: 0.8740\n",
      "chunk number: 2554 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3148 - acc: 0.8848\n",
      "chunk number: 2555 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2989 - acc: 0.8848\n",
      "chunk number: 2556 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2998 - acc: 0.8975\n",
      "chunk number: 2557 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2583 - acc: 0.8975\n",
      "chunk number: 2558 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2677 - acc: 0.9023\n",
      "chunk number: 2559 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2675 - acc: 0.9014\n",
      "chunk number: 2560 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3193 - acc: 0.8779\n",
      "chunk number: 2561 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2992 - acc: 0.8955\n",
      "chunk number: 2562 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3081 - acc: 0.8730\n",
      "chunk number: 2563 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3170 - acc: 0.8828\n",
      "chunk number: 2564 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2597 - acc: 0.9082\n",
      "chunk number: 2565 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3176 - acc: 0.8857\n",
      "chunk number: 2566 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2511 - acc: 0.9033\n",
      "chunk number: 2567 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3031 - acc: 0.8799\n",
      "chunk number: 2568 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3251 - acc: 0.8652\n",
      "chunk number: 2569 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3042 - acc: 0.8789\n",
      "chunk number: 2570 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2926 - acc: 0.8896\n",
      "chunk number: 2571 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3119 - acc: 0.8691\n",
      "chunk number: 2572 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3158 - acc: 0.8789\n",
      "chunk number: 2573 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2881 - acc: 0.8848\n",
      "chunk number: 2574 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3347 - acc: 0.8711\n",
      "chunk number: 2575 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3242 - acc: 0.8760\n",
      "chunk number: 2576 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2906 - acc: 0.8877\n",
      "chunk number: 2577 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2771 - acc: 0.8896\n",
      "chunk number: 2578 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3059 - acc: 0.8818\n",
      "chunk number: 2579 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2637 - acc: 0.8945\n",
      "chunk number: 2580 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2753 - acc: 0.8965\n",
      "chunk number: 2581 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2885 - acc: 0.8877\n",
      "chunk number: 2582 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2744 - acc: 0.8906\n",
      "chunk number: 2583 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3040 - acc: 0.8828\n",
      "chunk number: 2584 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2939 - acc: 0.8867\n",
      "chunk number: 2585 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3041 - acc: 0.8887\n",
      "chunk number: 2586 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2673 - acc: 0.8926\n",
      "chunk number: 2587 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3093 - acc: 0.8877\n",
      "chunk number: 2588 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2759 - acc: 0.8867\n",
      "chunk number: 2589 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2420 - acc: 0.9082\n",
      "chunk number: 2590 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2926 - acc: 0.8887\n",
      "chunk number: 2591 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2806 - acc: 0.8936\n",
      "chunk number: 2592 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3141 - acc: 0.8779\n",
      "chunk number: 2593 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2822 - acc: 0.8965\n",
      "chunk number: 2594 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2597 - acc: 0.9043\n",
      "chunk number: 2595 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2853 - acc: 0.8877\n",
      "chunk number: 2596 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2460 - acc: 0.8926\n",
      "chunk number: 2597 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2902 - acc: 0.8916\n",
      "chunk number: 2598 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2790 - acc: 0.8867\n",
      "chunk number: 2599 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2829 - acc: 0.8828\n",
      "chunk number: 2600 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2923 - acc: 0.8877\n",
      "chunk number: 2601 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2912 - acc: 0.8887\n",
      "chunk number: 2602 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3090 - acc: 0.8955\n",
      "chunk number: 2603 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3117 - acc: 0.8789\n",
      "chunk number: 2604 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2634 - acc: 0.8994\n",
      "chunk number: 2605 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2946 - acc: 0.8965\n",
      "chunk number: 2606 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2369 - acc: 0.9092\n",
      "chunk number: 2607 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2640 - acc: 0.9053\n",
      "chunk number: 2608 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2734 - acc: 0.8896\n",
      "chunk number: 2609 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2839 - acc: 0.9043\n",
      "chunk number: 2610 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2784 - acc: 0.8926\n",
      "chunk number: 2611 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3250 - acc: 0.8750\n",
      "chunk number: 2612 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3338 - acc: 0.8711\n",
      "chunk number: 2613 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3215 - acc: 0.8848\n",
      "chunk number: 2614 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3304 - acc: 0.8838\n",
      "chunk number: 2615 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3141 - acc: 0.8721\n",
      "chunk number: 2616 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2682 - acc: 0.8965\n",
      "chunk number: 2617 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3046 - acc: 0.8857\n",
      "chunk number: 2618 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3123 - acc: 0.8857\n",
      "chunk number: 2619 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2781 - acc: 0.8848\n",
      "chunk number: 2620 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2655 - acc: 0.9043\n",
      "chunk number: 2621 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2887 - acc: 0.8965\n",
      "chunk number: 2622 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2811 - acc: 0.8887\n",
      "chunk number: 2623 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2992 - acc: 0.8994\n",
      "chunk number: 2624 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3183 - acc: 0.8779\n",
      "chunk number: 2625 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2792 - acc: 0.8936\n",
      "chunk number: 2626 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2923 - acc: 0.8896\n",
      "chunk number: 2627 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2810 - acc: 0.8730\n",
      "chunk number: 2628 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3026 - acc: 0.8848\n",
      "chunk number: 2629 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2962 - acc: 0.8896\n",
      "chunk number: 2630 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3290 - acc: 0.8721\n",
      "chunk number: 2631 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2873 - acc: 0.8916\n",
      "chunk number: 2632 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2839 - acc: 0.8945\n",
      "chunk number: 2633 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2899 - acc: 0.8848\n",
      "chunk number: 2634 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2615 - acc: 0.9023\n",
      "chunk number: 2635 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2795 - acc: 0.8984\n",
      "chunk number: 2636 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3186 - acc: 0.8672\n",
      "chunk number: 2637 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3320 - acc: 0.8711\n",
      "chunk number: 2638 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2932 - acc: 0.8896\n",
      "chunk number: 2639 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3495 - acc: 0.8701\n",
      "chunk number: 2640 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3190 - acc: 0.8691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 2641 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2537 - acc: 0.9043\n",
      "chunk number: 2642 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3228 - acc: 0.8896\n",
      "chunk number: 2643 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2749 - acc: 0.8887\n",
      "chunk number: 2644 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2977 - acc: 0.8916\n",
      "chunk number: 2645 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2747 - acc: 0.8926\n",
      "chunk number: 2646 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3384 - acc: 0.8818\n",
      "chunk number: 2647 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2745 - acc: 0.8877\n",
      "chunk number: 2648 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2918 - acc: 0.8838\n",
      "chunk number: 2649 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2740 - acc: 0.9023\n",
      "chunk number: 2650 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3018 - acc: 0.8760\n",
      "chunk number: 2651 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2764 - acc: 0.8896\n",
      "chunk number: 2652 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2505 - acc: 0.8984\n",
      "chunk number: 2653 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3238 - acc: 0.8818\n",
      "chunk number: 2654 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2788 - acc: 0.8867\n",
      "chunk number: 2655 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2626 - acc: 0.8916\n",
      "chunk number: 2656 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2985 - acc: 0.8867\n",
      "chunk number: 2657 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2553 - acc: 0.9053\n",
      "chunk number: 2658 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2461 - acc: 0.9082\n",
      "chunk number: 2659 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2628 - acc: 0.9062\n",
      "chunk number: 2660 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2811 - acc: 0.8906\n",
      "chunk number: 2661 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3244 - acc: 0.8809\n",
      "chunk number: 2662 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3214 - acc: 0.8750\n",
      "chunk number: 2663 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3247 - acc: 0.8740\n",
      "chunk number: 2664 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2543 - acc: 0.9004\n",
      "chunk number: 2665 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2825 - acc: 0.8994\n",
      "chunk number: 2666 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2970 - acc: 0.8916\n",
      "chunk number: 2667 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3104 - acc: 0.9023\n",
      "chunk number: 2668 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3316 - acc: 0.8818\n",
      "chunk number: 2669 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3057 - acc: 0.8809\n",
      "chunk number: 2670 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3008 - acc: 0.8906\n",
      "chunk number: 2671 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2609 - acc: 0.9053\n",
      "chunk number: 2672 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3036 - acc: 0.8848\n",
      "chunk number: 2673 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2840 - acc: 0.8994\n",
      "chunk number: 2674 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2956 - acc: 0.8877\n",
      "chunk number: 2675 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2806 - acc: 0.8936\n",
      "chunk number: 2676 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2621 - acc: 0.8926\n",
      "chunk number: 2677 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3055 - acc: 0.8867\n",
      "chunk number: 2678 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2845 - acc: 0.8818\n",
      "chunk number: 2679 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2693 - acc: 0.8994\n",
      "chunk number: 2680 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3034 - acc: 0.8867\n",
      "chunk number: 2681 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3135 - acc: 0.8779\n",
      "chunk number: 2682 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2774 - acc: 0.8926\n",
      "chunk number: 2683 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2803 - acc: 0.8906\n",
      "chunk number: 2684 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2884 - acc: 0.8877\n",
      "chunk number: 2685 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2929 - acc: 0.8887\n",
      "chunk number: 2686 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2533 - acc: 0.9072\n",
      "chunk number: 2687 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3223 - acc: 0.8711\n",
      "chunk number: 2688 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2564 - acc: 0.8975\n",
      "chunk number: 2689 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2326 - acc: 0.9023\n",
      "chunk number: 2690 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2971 - acc: 0.8848\n",
      "chunk number: 2691 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3023 - acc: 0.8848\n",
      "chunk number: 2692 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2613 - acc: 0.8926\n",
      "chunk number: 2693 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2867 - acc: 0.8809\n",
      "chunk number: 2694 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2698 - acc: 0.8975\n",
      "chunk number: 2695 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2444 - acc: 0.9102\n",
      "chunk number: 2696 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2594 - acc: 0.9053\n",
      "chunk number: 2697 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2525 - acc: 0.8965\n",
      "chunk number: 2698 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2812 - acc: 0.8916\n",
      "chunk number: 2699 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3089 - acc: 0.8701\n",
      "chunk number: 2700 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3190 - acc: 0.8799\n",
      "chunk number: 2701 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2844 - acc: 0.8896\n",
      "chunk number: 2702 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3394 - acc: 0.8750\n",
      "chunk number: 2703 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2983 - acc: 0.8779\n",
      "chunk number: 2704 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2955 - acc: 0.8799\n",
      "chunk number: 2705 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3237 - acc: 0.8838\n",
      "chunk number: 2706 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2411 - acc: 0.9082\n",
      "chunk number: 2707 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2719 - acc: 0.8916\n",
      "chunk number: 2708 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2798 - acc: 0.8984\n",
      "chunk number: 2709 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2657 - acc: 0.9082\n",
      "chunk number: 2710 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2711 - acc: 0.8945\n",
      "chunk number: 2711 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2796 - acc: 0.8984\n",
      "chunk number: 2712 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2839 - acc: 0.8789\n",
      "chunk number: 2713 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3123 - acc: 0.8789\n",
      "chunk number: 2714 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2990 - acc: 0.8906\n",
      "chunk number: 2715 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3006 - acc: 0.8740\n",
      "chunk number: 2716 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2505 - acc: 0.9033\n",
      "chunk number: 2717 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3280 - acc: 0.8779\n",
      "chunk number: 2718 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2921 - acc: 0.8896\n",
      "chunk number: 2719 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2778 - acc: 0.9043\n",
      "chunk number: 2720 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2759 - acc: 0.8984\n",
      "chunk number: 2721 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2657 - acc: 0.8926\n",
      "chunk number: 2722 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3155 - acc: 0.8828\n",
      "chunk number: 2723 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2798 - acc: 0.9033\n",
      "chunk number: 2724 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3200 - acc: 0.8779\n",
      "chunk number: 2725 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2641 - acc: 0.8955\n",
      "chunk number: 2726 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2868 - acc: 0.8955\n",
      "chunk number: 2727 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2958 - acc: 0.8799\n",
      "chunk number: 2728 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2848 - acc: 0.8936\n",
      "chunk number: 2729 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3042 - acc: 0.8867\n",
      "chunk number: 2730 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2724 - acc: 0.8896\n",
      "chunk number: 2731 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2641 - acc: 0.8926\n",
      "chunk number: 2732 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3100 - acc: 0.8896\n",
      "chunk number: 2733 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2713 - acc: 0.8906\n",
      "chunk number: 2734 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2824 - acc: 0.8965\n",
      "chunk number: 2735 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2836 - acc: 0.8877\n",
      "chunk number: 2736 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3273 - acc: 0.8730\n",
      "chunk number: 2737 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2902 - acc: 0.8789\n",
      "chunk number: 2738 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2910 - acc: 0.8818\n",
      "chunk number: 2739 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3018 - acc: 0.8838\n",
      "chunk number: 2740 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2949 - acc: 0.8887\n",
      "chunk number: 2741 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2474 - acc: 0.9033\n",
      "chunk number: 2742 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2769 - acc: 0.9053\n",
      "chunk number: 2743 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2773 - acc: 0.8857\n",
      "chunk number: 2744 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2518 - acc: 0.9111\n",
      "chunk number: 2745 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2807 - acc: 0.8887\n",
      "chunk number: 2746 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3112 - acc: 0.8896\n",
      "chunk number: 2747 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2547 - acc: 0.8848\n",
      "chunk number: 2748 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2896 - acc: 0.8779\n",
      "chunk number: 2749 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2976 - acc: 0.8848\n",
      "chunk number: 2750 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2957 - acc: 0.8818\n",
      "chunk number: 2751 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2526 - acc: 0.8994\n",
      "chunk number: 2752 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2834 - acc: 0.8916\n",
      "chunk number: 2753 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2861 - acc: 0.8916\n",
      "chunk number: 2754 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2920 - acc: 0.8848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 2755 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3217 - acc: 0.8887\n",
      "chunk number: 2756 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2947 - acc: 0.8867\n",
      "chunk number: 2757 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2448 - acc: 0.9082\n",
      "chunk number: 2758 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2268 - acc: 0.9131\n",
      "chunk number: 2759 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2469 - acc: 0.9082\n",
      "chunk number: 2760 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3187 - acc: 0.8916\n",
      "chunk number: 2761 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2922 - acc: 0.8916\n",
      "chunk number: 2762 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2911 - acc: 0.8887\n",
      "chunk number: 2763 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3319 - acc: 0.8750\n",
      "chunk number: 2764 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2572 - acc: 0.9043\n",
      "chunk number: 2765 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3132 - acc: 0.8838\n",
      "chunk number: 2766 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2825 - acc: 0.8936\n",
      "chunk number: 2767 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2536 - acc: 0.9141\n",
      "chunk number: 2768 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3087 - acc: 0.8945\n",
      "chunk number: 2769 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2713 - acc: 0.8916\n",
      "chunk number: 2770 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2873 - acc: 0.9023\n",
      "chunk number: 2771 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3084 - acc: 0.8730\n",
      "chunk number: 2772 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3100 - acc: 0.8906\n",
      "chunk number: 2773 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2935 - acc: 0.8838\n",
      "chunk number: 2774 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3016 - acc: 0.8848\n",
      "chunk number: 2775 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2852 - acc: 0.8877\n",
      "chunk number: 2776 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2895 - acc: 0.8926\n",
      "chunk number: 2777 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2747 - acc: 0.8828\n",
      "chunk number: 2778 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3038 - acc: 0.8779\n",
      "chunk number: 2779 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2574 - acc: 0.9014\n",
      "chunk number: 2780 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2953 - acc: 0.8896\n",
      "chunk number: 2781 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2744 - acc: 0.8818\n",
      "chunk number: 2782 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3077 - acc: 0.8828\n",
      "chunk number: 2783 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2940 - acc: 0.8926\n",
      "chunk number: 2784 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3050 - acc: 0.8779\n",
      "chunk number: 2785 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3074 - acc: 0.8809\n",
      "chunk number: 2786 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2404 - acc: 0.9092\n",
      "chunk number: 2787 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2838 - acc: 0.8877\n",
      "chunk number: 2788 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2652 - acc: 0.9014\n",
      "chunk number: 2789 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2439 - acc: 0.9043\n",
      "chunk number: 2790 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2758 - acc: 0.8945\n",
      "chunk number: 2791 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2927 - acc: 0.8965\n",
      "chunk number: 2792 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2828 - acc: 0.8926\n",
      "chunk number: 2793 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2606 - acc: 0.9004\n",
      "chunk number: 2794 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2153 - acc: 0.9062\n",
      "chunk number: 2795 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2234 - acc: 0.9258\n",
      "chunk number: 2796 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2393 - acc: 0.9053\n",
      "chunk number: 2797 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2428 - acc: 0.8984\n",
      "chunk number: 2798 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2985 - acc: 0.8916\n",
      "chunk number: 2799 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2685 - acc: 0.8877\n",
      "chunk number: 2800 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2970 - acc: 0.8818\n",
      "chunk number: 2801 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2692 - acc: 0.9004\n",
      "chunk number: 2802 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2973 - acc: 0.8975\n",
      "chunk number: 2803 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2758 - acc: 0.8906\n",
      "chunk number: 2804 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2531 - acc: 0.9072\n",
      "chunk number: 2805 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2866 - acc: 0.8896\n",
      "chunk number: 2806 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2563 - acc: 0.9062\n",
      "chunk number: 2807 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2885 - acc: 0.8936\n",
      "chunk number: 2808 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2783 - acc: 0.8936\n",
      "chunk number: 2809 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2503 - acc: 0.9023\n",
      "chunk number: 2810 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2653 - acc: 0.8965\n",
      "chunk number: 2811 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2923 - acc: 0.8984\n",
      "chunk number: 2812 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2737 - acc: 0.8965\n",
      "chunk number: 2813 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2436 - acc: 0.9141\n",
      "chunk number: 2814 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3066 - acc: 0.8945\n",
      "chunk number: 2815 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3366 - acc: 0.8682\n",
      "chunk number: 2816 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2524 - acc: 0.9102\n",
      "chunk number: 2817 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2864 - acc: 0.8926\n",
      "chunk number: 2818 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2878 - acc: 0.8926\n",
      "chunk number: 2819 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2884 - acc: 0.8906\n",
      "chunk number: 2820 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2692 - acc: 0.8926\n",
      "chunk number: 2821 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2734 - acc: 0.9014\n",
      "chunk number: 2822 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2663 - acc: 0.9023\n",
      "chunk number: 2823 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2926 - acc: 0.8955\n",
      "chunk number: 2824 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3019 - acc: 0.8916\n",
      "chunk number: 2825 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2880 - acc: 0.8857\n",
      "chunk number: 2826 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2890 - acc: 0.8945\n",
      "chunk number: 2827 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2880 - acc: 0.8857\n",
      "chunk number: 2828 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2765 - acc: 0.8838\n",
      "chunk number: 2829 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2679 - acc: 0.9043\n",
      "chunk number: 2830 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2937 - acc: 0.8838\n",
      "chunk number: 2831 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2685 - acc: 0.9014\n",
      "chunk number: 2832 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2696 - acc: 0.8945\n",
      "chunk number: 2833 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2757 - acc: 0.8828\n",
      "chunk number: 2834 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2713 - acc: 0.8926\n",
      "chunk number: 2835 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2864 - acc: 0.8887\n",
      "chunk number: 2836 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3332 - acc: 0.8770\n",
      "chunk number: 2837 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2837 - acc: 0.8916\n",
      "chunk number: 2838 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2745 - acc: 0.8955\n",
      "chunk number: 2839 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2953 - acc: 0.8906\n",
      "chunk number: 2840 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3130 - acc: 0.8701\n",
      "chunk number: 2841 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2774 - acc: 0.8896\n",
      "chunk number: 2842 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2985 - acc: 0.8945\n",
      "chunk number: 2843 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2492 - acc: 0.8994\n",
      "chunk number: 2844 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3033 - acc: 0.8994\n",
      "chunk number: 2845 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2962 - acc: 0.8936\n",
      "chunk number: 2846 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2925 - acc: 0.8936\n",
      "chunk number: 2847 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2941 - acc: 0.8926\n",
      "chunk number: 2848 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2770 - acc: 0.8887\n",
      "chunk number: 2849 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2869 - acc: 0.8955\n",
      "chunk number: 2850 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2475 - acc: 0.9033\n",
      "chunk number: 2851 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2851 - acc: 0.8877\n",
      "chunk number: 2852 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2652 - acc: 0.9023\n",
      "chunk number: 2853 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3072 - acc: 0.8770\n",
      "chunk number: 2854 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3085 - acc: 0.8877\n",
      "chunk number: 2855 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2569 - acc: 0.9062\n",
      "chunk number: 2856 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2665 - acc: 0.8877\n",
      "chunk number: 2857 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2438 - acc: 0.8955\n",
      "chunk number: 2858 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2245 - acc: 0.9082\n",
      "chunk number: 2859 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2389 - acc: 0.9043\n",
      "chunk number: 2860 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2673 - acc: 0.8975\n",
      "chunk number: 2861 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2607 - acc: 0.9062\n",
      "chunk number: 2862 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2825 - acc: 0.8896\n",
      "chunk number: 2863 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3259 - acc: 0.8750\n",
      "chunk number: 2864 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2612 - acc: 0.9072\n",
      "chunk number: 2865 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3198 - acc: 0.8760\n",
      "chunk number: 2866 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3024 - acc: 0.8711\n",
      "chunk number: 2867 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2922 - acc: 0.8857\n",
      "chunk number: 2868 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3073 - acc: 0.8770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 2869 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3095 - acc: 0.8828\n",
      "chunk number: 2870 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2830 - acc: 0.8828\n",
      "chunk number: 2871 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2740 - acc: 0.9102\n",
      "chunk number: 2872 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3174 - acc: 0.8789\n",
      "chunk number: 2873 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2413 - acc: 0.9043\n",
      "chunk number: 2874 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2834 - acc: 0.8916\n",
      "chunk number: 2875 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2822 - acc: 0.8906\n",
      "chunk number: 2876 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2932 - acc: 0.8887\n",
      "chunk number: 2877 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2793 - acc: 0.8945\n",
      "chunk number: 2878 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2771 - acc: 0.8926\n",
      "chunk number: 2879 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2589 - acc: 0.8984\n",
      "chunk number: 2880 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2761 - acc: 0.9062\n",
      "chunk number: 2881 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2994 - acc: 0.8711\n",
      "chunk number: 2882 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2614 - acc: 0.8867\n",
      "chunk number: 2883 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2789 - acc: 0.8916\n",
      "chunk number: 2884 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2362 - acc: 0.9023\n",
      "chunk number: 2885 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2929 - acc: 0.9033\n",
      "chunk number: 2886 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2284 - acc: 0.9150\n",
      "chunk number: 2887 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3065 - acc: 0.8838\n",
      "chunk number: 2888 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2450 - acc: 0.9062\n",
      "chunk number: 2889 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2390 - acc: 0.9160\n",
      "chunk number: 2890 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2567 - acc: 0.8965\n",
      "chunk number: 2891 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3026 - acc: 0.8857\n",
      "chunk number: 2892 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2614 - acc: 0.8965\n",
      "chunk number: 2893 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3009 - acc: 0.8936\n",
      "chunk number: 2894 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2467 - acc: 0.9111\n",
      "chunk number: 2895 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2186 - acc: 0.9102\n",
      "chunk number: 2896 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2610 - acc: 0.8984\n",
      "chunk number: 2897 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2604 - acc: 0.9043\n",
      "chunk number: 2898 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2845 - acc: 0.8848\n",
      "chunk number: 2899 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2831 - acc: 0.8857\n",
      "chunk number: 2900 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3040 - acc: 0.8779\n",
      "chunk number: 2901 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2642 - acc: 0.8965\n",
      "chunk number: 2902 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3076 - acc: 0.8818\n",
      "chunk number: 2903 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2791 - acc: 0.8926\n",
      "chunk number: 2904 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2505 - acc: 0.9053\n",
      "chunk number: 2905 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2725 - acc: 0.8896\n",
      "chunk number: 2906 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2745 - acc: 0.8926\n",
      "chunk number: 2907 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2571 - acc: 0.9082\n",
      "chunk number: 2908 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2688 - acc: 0.8926\n",
      "chunk number: 2909 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2635 - acc: 0.9141\n",
      "chunk number: 2910 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2875 - acc: 0.8848\n",
      "chunk number: 2911 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2874 - acc: 0.8936\n",
      "chunk number: 2912 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2853 - acc: 0.8926\n",
      "chunk number: 2913 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2834 - acc: 0.8838\n",
      "chunk number: 2914 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2837 - acc: 0.8848\n",
      "chunk number: 2915 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2832 - acc: 0.8857\n",
      "chunk number: 2916 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2633 - acc: 0.8916\n",
      "chunk number: 2917 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2661 - acc: 0.8926\n",
      "chunk number: 2918 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3096 - acc: 0.8721\n",
      "chunk number: 2919 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2721 - acc: 0.8965\n",
      "chunk number: 2920 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2653 - acc: 0.8887\n",
      "chunk number: 2921 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2465 - acc: 0.9072\n",
      "chunk number: 2922 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2741 - acc: 0.8877\n",
      "chunk number: 2923 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2497 - acc: 0.9082\n",
      "chunk number: 2924 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3113 - acc: 0.8857\n",
      "chunk number: 2925 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2742 - acc: 0.9004\n",
      "chunk number: 2926 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3000 - acc: 0.8877\n",
      "chunk number: 2927 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2806 - acc: 0.8965\n",
      "chunk number: 2928 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2697 - acc: 0.8916\n",
      "chunk number: 2929 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2946 - acc: 0.8857\n",
      "chunk number: 2930 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3075 - acc: 0.8848\n",
      "chunk number: 2931 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2585 - acc: 0.8984\n",
      "chunk number: 2932 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2668 - acc: 0.8965\n",
      "chunk number: 2933 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2496 - acc: 0.8955\n",
      "chunk number: 2934 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2554 - acc: 0.9062\n",
      "chunk number: 2935 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2483 - acc: 0.9053\n",
      "chunk number: 2936 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2913 - acc: 0.8877\n",
      "chunk number: 2937 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2847 - acc: 0.8848\n",
      "chunk number: 2938 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2725 - acc: 0.8896\n",
      "chunk number: 2939 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2856 - acc: 0.8848\n",
      "chunk number: 2940 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3119 - acc: 0.8779\n",
      "chunk number: 2941 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2516 - acc: 0.8965\n",
      "chunk number: 2942 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2527 - acc: 0.9014\n",
      "chunk number: 2943 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3087 - acc: 0.8896\n",
      "chunk number: 2944 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2740 - acc: 0.9004\n",
      "chunk number: 2945 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2864 - acc: 0.8848\n",
      "chunk number: 2946 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3296 - acc: 0.8887\n",
      "chunk number: 2947 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2742 - acc: 0.8809\n",
      "chunk number: 2948 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2936 - acc: 0.8857\n",
      "chunk number: 2949 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2765 - acc: 0.8926\n",
      "chunk number: 2950 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2886 - acc: 0.8818\n",
      "chunk number: 2951 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2873 - acc: 0.8926\n",
      "chunk number: 2952 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2641 - acc: 0.8887\n",
      "chunk number: 2953 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3041 - acc: 0.8896\n",
      "chunk number: 2954 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2967 - acc: 0.8955\n",
      "chunk number: 2955 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2634 - acc: 0.9014\n",
      "chunk number: 2956 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2563 - acc: 0.9023\n",
      "chunk number: 2957 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2498 - acc: 0.9102\n",
      "chunk number: 2958 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2261 - acc: 0.9170\n",
      "chunk number: 2959 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2568 - acc: 0.9043\n",
      "chunk number: 2960 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2713 - acc: 0.9004\n",
      "chunk number: 2961 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2369 - acc: 0.9072\n",
      "chunk number: 2962 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2794 - acc: 0.8906\n",
      "chunk number: 2963 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3716 - acc: 0.8633\n",
      "chunk number: 2964 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2640 - acc: 0.9033\n",
      "chunk number: 2965 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2799 - acc: 0.8887\n",
      "chunk number: 2966 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2563 - acc: 0.8936\n",
      "chunk number: 2967 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2752 - acc: 0.8965\n",
      "chunk number: 2968 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2917 - acc: 0.8994\n",
      "chunk number: 2969 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2631 - acc: 0.9004\n",
      "chunk number: 2970 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2304 - acc: 0.9033\n",
      "chunk number: 2971 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2675 - acc: 0.8926\n",
      "chunk number: 2972 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3094 - acc: 0.8818\n",
      "chunk number: 2973 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3086 - acc: 0.8828\n",
      "chunk number: 2974 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3191 - acc: 0.8799\n",
      "chunk number: 2975 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2774 - acc: 0.8994\n",
      "chunk number: 2976 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2818 - acc: 0.8896\n",
      "chunk number: 2977 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2798 - acc: 0.8896\n",
      "chunk number: 2978 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2758 - acc: 0.9004\n",
      "chunk number: 2979 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2652 - acc: 0.8975\n",
      "chunk number: 2980 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2536 - acc: 0.9121\n",
      "chunk number: 2981 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2668 - acc: 0.8896\n",
      "chunk number: 2982 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2516 - acc: 0.9004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number: 2983 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2791 - acc: 0.8828\n",
      "chunk number: 2984 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2759 - acc: 0.9023\n",
      "chunk number: 2985 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2821 - acc: 0.8945\n",
      "chunk number: 2986 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2617 - acc: 0.9131\n",
      "chunk number: 2987 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3000 - acc: 0.8730\n",
      "chunk number: 2988 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2628 - acc: 0.9023\n",
      "chunk number: 2989 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2445 - acc: 0.9131\n",
      "chunk number: 2990 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2349 - acc: 0.9082\n",
      "chunk number: 2991 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.3058 - acc: 0.8906\n",
      "chunk number: 2992 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2821 - acc: 0.8896\n",
      "chunk number: 2993 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2391 - acc: 0.9053\n",
      "chunk number: 2994 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2505 - acc: 0.8955\n",
      "chunk number: 2995 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2279 - acc: 0.9160\n",
      "chunk number: 2996 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2835 - acc: 0.9014\n",
      "chunk number: 2997 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2492 - acc: 0.9053\n",
      "chunk number: 2998 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2750 - acc: 0.8916\n",
      "chunk number: 2999 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2376 - acc: 0.8975\n",
      "chunk number: 3000 of 3000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.2700 - acc: 0.8955\n"
     ]
    }
   ],
   "source": [
    "X_files = sorted(os.listdir(pickle_path + \"Spectra\"))\n",
    "y_files = sorted(os.listdir(pickle_path + \"Targets\"))\n",
    "\n",
    "num_chunks = len(y_files)\n",
    "iteration = 0\n",
    "\n",
    "acc=[]\n",
    "loss=[]\n",
    "\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "for _ in range(num_epochs):\n",
    "    \n",
    "    for X_file, y_file in zip(X_files,y_files):\n",
    "\n",
    "        iteration +=1\n",
    "        print('chunk number: ' + str(iteration) + \" of \" + str(num_chunks*num_epochs))\n",
    "        \n",
    "        X,y = Data_Gen(X_file, y_file, mean_log_amplitude, threshold = 1.0, h_shift_range=(-30,30))\n",
    "\n",
    "        history=model.fit(X, y, batch_size=128, epochs=1, validation_split=0, verbose=2)\n",
    "\n",
    "        acc.append(history.history['acc'])\n",
    "        loss.append(history.history['loss'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa2ffbf4048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.plot(acc)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(loss)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplots_adjust(right=1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Without validation data it is difficult to tell whether the model is overfitting. However, the previous experiments suggest that further training might cause overfitting. The above model is saved and its performance analyzed in the next notebook: Evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"Model/Scratch_Aug_1_hrange_pm20_v3.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
